{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captcha dataset used for testing is taken from Kaggle: https://www.kaggle.com/fournierp/captcha-version-2-images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CHAR_COUNT = 26 + 10\n",
    "TOTAL_CAPTCHA_LEN = 5\n",
    "CHAR_SET = []\n",
    "for num in range(10):\n",
    "    CHAR_SET.append(str(num))\n",
    "for chari in range(97, 97+26):\n",
    "    CHAR_SET.append(chr(chari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHotEncoding(s):\n",
    "    ohev = torch.zeros(TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, dtype = torch.float32)\n",
    "    for ind in range(TOTAL_CAPTCHA_LEN):\n",
    "        c = s[ind]\n",
    "        ohev[TOTAL_CHAR_COUNT*ind + CHAR_SET.index(c)] = 1\n",
    "    return ohev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_list = os.listdir(self.img_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        img = Image.open(self.img_path +'/'+ img_name)\n",
    "        img = img.convert('L')\n",
    "        label = (img_name)[:-4]\n",
    "        #print(label)\n",
    "        ohev = getOneHotEncoding(label)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, ohev, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H, IMG_W = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([IMG_H, IMG_W]),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CaptchaDataset('./Captcha_Dataset', transform=transform)\n",
    "test_ds = CaptchaDataset('./Captcha_Dataset', transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=4)\n",
    "test_dl = DataLoader(train_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model = models.DenseNet(growth_rate=32, block_config=(2, 4, 12, 8), num_classes = TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT)\n",
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "        self.fcl = nn.Linear(in_features = 512,out_features=TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, bias=True)\n",
    "        self.model = models.resnet18(pretrained = False)\n",
    "        self.model = nn.Sequential(*list(model.children())[1:-1])\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.model(out)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fcl(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "# fcl = nn.Linear(in_features = 32768,out_features=TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, bias=True)\n",
    "# new_model = nn.Sequential(conv0, *list(model.children())[1:-1], fcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optm = torch.optim.Adam(new_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (fcl): Linear(in_features=512, out_features=180, bias=True)\n",
       "  (model): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 1 step: 1 loss: 0.06129993870854378\n",
      "eopch: 1 step: 2 loss: 0.058805570006370544\n",
      "eopch: 1 step: 3 loss: 0.059360913932323456\n",
      "eopch: 1 step: 4 loss: 0.060044631361961365\n",
      "eopch: 1 step: 5 loss: 0.058337483555078506\n",
      "eopch: 1 step: 6 loss: 0.059389628469944\n",
      "eopch: 1 step: 7 loss: 0.05897968262434006\n",
      "eopch: 1 step: 8 loss: 0.06003958359360695\n",
      "eopch: 1 step: 9 loss: 0.058112483471632004\n",
      "eopch: 1 step: 10 loss: 0.058236800134181976\n",
      "eopch: 1 step: 11 loss: 0.058174893260002136\n",
      "eopch: 1 step: 12 loss: 0.056974686682224274\n",
      "eopch: 1 step: 13 loss: 0.056501761078834534\n",
      "eopch: 1 step: 14 loss: 0.0566464439034462\n",
      "eopch: 1 step: 15 loss: 0.05844882130622864\n",
      "eopch: 1 step: 16 loss: 0.057101741433143616\n",
      "eopch: 1 step: 17 loss: 0.051686763763427734\n",
      "eopch: 2 step: 1 loss: 0.05727478861808777\n",
      "eopch: 2 step: 2 loss: 0.05470728129148483\n",
      "eopch: 2 step: 3 loss: 0.05536648631095886\n",
      "eopch: 2 step: 4 loss: 0.05612003430724144\n",
      "eopch: 2 step: 5 loss: 0.054416071623563766\n",
      "eopch: 2 step: 6 loss: 0.05571752041578293\n",
      "eopch: 2 step: 7 loss: 0.05536085367202759\n",
      "eopch: 2 step: 8 loss: 0.05638695880770683\n",
      "eopch: 2 step: 9 loss: 0.05441778898239136\n",
      "eopch: 2 step: 10 loss: 0.054575055837631226\n",
      "eopch: 2 step: 11 loss: 0.05427215248346329\n",
      "eopch: 2 step: 12 loss: 0.05327162146568298\n",
      "eopch: 2 step: 13 loss: 0.052879080176353455\n",
      "eopch: 2 step: 14 loss: 0.05286340415477753\n",
      "eopch: 2 step: 15 loss: 0.054909247905015945\n",
      "eopch: 2 step: 16 loss: 0.05389074608683586\n",
      "eopch: 2 step: 17 loss: 0.04845593497157097\n",
      "eopch: 3 step: 1 loss: 0.05391145497560501\n",
      "eopch: 3 step: 2 loss: 0.051428258419036865\n",
      "eopch: 3 step: 3 loss: 0.051951222121715546\n",
      "eopch: 3 step: 4 loss: 0.05251975357532501\n",
      "eopch: 3 step: 5 loss: 0.05091661214828491\n",
      "eopch: 3 step: 6 loss: 0.052229996770620346\n",
      "eopch: 3 step: 7 loss: 0.052064914256334305\n",
      "eopch: 3 step: 8 loss: 0.05337085574865341\n",
      "eopch: 3 step: 9 loss: 0.051589153707027435\n",
      "eopch: 3 step: 10 loss: 0.05147114396095276\n",
      "eopch: 3 step: 11 loss: 0.05115681141614914\n",
      "eopch: 3 step: 12 loss: 0.050173044204711914\n",
      "eopch: 3 step: 13 loss: 0.04963001608848572\n",
      "eopch: 3 step: 14 loss: 0.049430809915065765\n",
      "eopch: 3 step: 15 loss: 0.05133901908993721\n",
      "eopch: 3 step: 16 loss: 0.050373539328575134\n",
      "eopch: 3 step: 17 loss: 0.04525218904018402\n",
      "eopch: 4 step: 1 loss: 0.05097176134586334\n",
      "eopch: 4 step: 2 loss: 0.04853973537683487\n",
      "eopch: 4 step: 3 loss: 0.04883259907364845\n",
      "eopch: 4 step: 4 loss: 0.049505360424518585\n",
      "eopch: 4 step: 5 loss: 0.04774317145347595\n",
      "eopch: 4 step: 6 loss: 0.04904294013977051\n",
      "eopch: 4 step: 7 loss: 0.04879216104745865\n",
      "eopch: 4 step: 8 loss: 0.04988797754049301\n",
      "eopch: 4 step: 9 loss: 0.048098258674144745\n",
      "eopch: 4 step: 10 loss: 0.048218488693237305\n",
      "eopch: 4 step: 11 loss: 0.04803867265582085\n",
      "eopch: 4 step: 12 loss: 0.04705386981368065\n",
      "eopch: 4 step: 13 loss: 0.046454839408397675\n",
      "eopch: 4 step: 14 loss: 0.046530116349458694\n",
      "eopch: 4 step: 15 loss: 0.0479329451918602\n",
      "eopch: 4 step: 16 loss: 0.04712314158678055\n",
      "eopch: 4 step: 17 loss: 0.041931889951229095\n",
      "eopch: 5 step: 1 loss: 0.047212518751621246\n",
      "eopch: 5 step: 2 loss: 0.04515649378299713\n",
      "eopch: 5 step: 3 loss: 0.04558129981160164\n",
      "eopch: 5 step: 4 loss: 0.046015962958335876\n",
      "eopch: 5 step: 5 loss: 0.044499970972537994\n",
      "eopch: 5 step: 6 loss: 0.04597686603665352\n",
      "eopch: 5 step: 7 loss: 0.04556488245725632\n",
      "eopch: 5 step: 8 loss: 0.04642459377646446\n",
      "eopch: 5 step: 9 loss: 0.044862836599349976\n",
      "eopch: 5 step: 10 loss: 0.04482319951057434\n",
      "eopch: 5 step: 11 loss: 0.04474953934550285\n",
      "eopch: 5 step: 12 loss: 0.0438811331987381\n",
      "eopch: 5 step: 13 loss: 0.0431622639298439\n",
      "eopch: 5 step: 14 loss: 0.04337018355727196\n",
      "eopch: 5 step: 15 loss: 0.04481329023838043\n",
      "eopch: 5 step: 16 loss: 0.04398955777287483\n",
      "eopch: 5 step: 17 loss: 0.039058905094861984\n",
      "eopch: 6 step: 1 loss: 0.04392241686582565\n",
      "eopch: 6 step: 2 loss: 0.041939470916986465\n",
      "eopch: 6 step: 3 loss: 0.042474836111068726\n",
      "eopch: 6 step: 4 loss: 0.04283270239830017\n",
      "eopch: 6 step: 5 loss: 0.04138677194714546\n",
      "eopch: 6 step: 6 loss: 0.042792897671461105\n",
      "eopch: 6 step: 7 loss: 0.04254467040300369\n",
      "eopch: 6 step: 8 loss: 0.04329554736614227\n",
      "eopch: 6 step: 9 loss: 0.04177006334066391\n",
      "eopch: 6 step: 10 loss: 0.04164732247591019\n",
      "eopch: 6 step: 11 loss: 0.041602347046136856\n",
      "eopch: 6 step: 12 loss: 0.04085700213909149\n",
      "eopch: 6 step: 13 loss: 0.04010998457670212\n",
      "eopch: 6 step: 14 loss: 0.0402805469930172\n",
      "eopch: 6 step: 15 loss: 0.041755158454179764\n",
      "eopch: 6 step: 16 loss: 0.04106494411826134\n",
      "eopch: 6 step: 17 loss: 0.03639817610383034\n",
      "eopch: 7 step: 1 loss: 0.04099804908037186\n",
      "eopch: 7 step: 2 loss: 0.03903574496507645\n",
      "eopch: 7 step: 3 loss: 0.03961469233036041\n",
      "eopch: 7 step: 4 loss: 0.03990247845649719\n",
      "eopch: 7 step: 5 loss: 0.03865193575620651\n",
      "eopch: 7 step: 6 loss: 0.03990630805492401\n",
      "eopch: 7 step: 7 loss: 0.039676204323768616\n",
      "eopch: 7 step: 8 loss: 0.04037605971097946\n",
      "eopch: 7 step: 9 loss: 0.03907933458685875\n",
      "eopch: 7 step: 10 loss: 0.03883446753025055\n",
      "eopch: 7 step: 11 loss: 0.03881616145372391\n",
      "eopch: 7 step: 12 loss: 0.038199521601200104\n",
      "eopch: 7 step: 13 loss: 0.03758709877729416\n",
      "eopch: 7 step: 14 loss: 0.03774387761950493\n",
      "eopch: 7 step: 15 loss: 0.038895316421985626\n",
      "eopch: 7 step: 16 loss: 0.03843304142355919\n",
      "eopch: 7 step: 17 loss: 0.03395276889204979\n",
      "eopch: 8 step: 1 loss: 0.03836308419704437\n",
      "eopch: 8 step: 2 loss: 0.03652339428663254\n",
      "eopch: 8 step: 3 loss: 0.03710230439901352\n",
      "eopch: 8 step: 4 loss: 0.037463199347257614\n",
      "eopch: 8 step: 5 loss: 0.036347679793834686\n",
      "eopch: 8 step: 6 loss: 0.03747882694005966\n",
      "eopch: 8 step: 7 loss: 0.037110067903995514\n",
      "eopch: 8 step: 8 loss: 0.03786124289035797\n",
      "eopch: 8 step: 9 loss: 0.03667154163122177\n",
      "eopch: 8 step: 10 loss: 0.0364786833524704\n",
      "eopch: 8 step: 11 loss: 0.03637949377298355\n",
      "eopch: 8 step: 12 loss: 0.035892076790332794\n",
      "eopch: 8 step: 13 loss: 0.03518214821815491\n",
      "eopch: 8 step: 14 loss: 0.035613760352134705\n",
      "eopch: 8 step: 15 loss: 0.036621950566768646\n",
      "eopch: 8 step: 16 loss: 0.03620550408959389\n",
      "eopch: 8 step: 17 loss: 0.03195076063275337\n",
      "eopch: 9 step: 1 loss: 0.03610491752624512\n",
      "eopch: 9 step: 2 loss: 0.03450784832239151\n",
      "eopch: 9 step: 3 loss: 0.03496721386909485\n",
      "eopch: 9 step: 4 loss: 0.035204410552978516\n",
      "eopch: 9 step: 5 loss: 0.034224167466163635\n",
      "eopch: 9 step: 6 loss: 0.03533972054719925\n",
      "eopch: 9 step: 7 loss: 0.03499225154519081\n",
      "eopch: 9 step: 8 loss: 0.03562485799193382\n",
      "eopch: 9 step: 9 loss: 0.034671470522880554\n",
      "eopch: 9 step: 10 loss: 0.034510768949985504\n",
      "eopch: 9 step: 11 loss: 0.034410521388053894\n",
      "eopch: 9 step: 12 loss: 0.03391024097800255\n",
      "eopch: 9 step: 13 loss: 0.03316275775432587\n",
      "eopch: 9 step: 14 loss: 0.03364461660385132\n",
      "eopch: 9 step: 15 loss: 0.03453908488154411\n",
      "eopch: 9 step: 16 loss: 0.03411145880818367\n",
      "eopch: 9 step: 17 loss: 0.030192632228136063\n",
      "eopch: 10 step: 1 loss: 0.03415057063102722\n",
      "eopch: 10 step: 2 loss: 0.03265763074159622\n",
      "eopch: 10 step: 3 loss: 0.03314679116010666\n",
      "eopch: 10 step: 4 loss: 0.03333906829357147\n",
      "eopch: 10 step: 5 loss: 0.03231985121965408\n",
      "eopch: 10 step: 6 loss: 0.0333143025636673\n",
      "eopch: 10 step: 7 loss: 0.03292021155357361\n",
      "eopch: 10 step: 8 loss: 0.03358493745326996\n",
      "eopch: 10 step: 9 loss: 0.03267402946949005\n",
      "eopch: 10 step: 10 loss: 0.03265351057052612\n",
      "eopch: 10 step: 11 loss: 0.03267144411802292\n",
      "eopch: 10 step: 12 loss: 0.032058678567409515\n",
      "eopch: 10 step: 13 loss: 0.03134570270776749\n",
      "eopch: 10 step: 14 loss: 0.03177984058856964\n",
      "eopch: 10 step: 15 loss: 0.03271648287773132\n",
      "eopch: 10 step: 16 loss: 0.03214894235134125\n",
      "eopch: 10 step: 17 loss: 0.02840346470475197\n",
      "eopch: 11 step: 1 loss: 0.032116055488586426\n",
      "eopch: 11 step: 2 loss: 0.030669357627630234\n",
      "eopch: 11 step: 3 loss: 0.03125251457095146\n",
      "eopch: 11 step: 4 loss: 0.03149261698126793\n",
      "eopch: 11 step: 5 loss: 0.030653230845928192\n",
      "eopch: 11 step: 6 loss: 0.031542886048555374\n",
      "eopch: 11 step: 7 loss: 0.031145542860031128\n",
      "eopch: 11 step: 8 loss: 0.03177370876073837\n",
      "eopch: 11 step: 9 loss: 0.030728202313184738\n",
      "eopch: 11 step: 10 loss: 0.030682161450386047\n",
      "eopch: 11 step: 11 loss: 0.030778754502534866\n",
      "eopch: 11 step: 12 loss: 0.030196771025657654\n",
      "eopch: 11 step: 13 loss: 0.02949082851409912\n",
      "eopch: 11 step: 14 loss: 0.029840003699064255\n",
      "eopch: 11 step: 15 loss: 0.03084782138466835\n",
      "eopch: 11 step: 16 loss: 0.030305912718176842\n",
      "eopch: 11 step: 17 loss: 0.026791665703058243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 12 step: 1 loss: 0.03029671311378479\n",
      "eopch: 12 step: 2 loss: 0.028888089582324028\n",
      "eopch: 12 step: 3 loss: 0.029419856145977974\n",
      "eopch: 12 step: 4 loss: 0.02961622178554535\n",
      "eopch: 12 step: 5 loss: 0.0288187637925148\n",
      "eopch: 12 step: 6 loss: 0.02958245947957039\n",
      "eopch: 12 step: 7 loss: 0.029216736555099487\n",
      "eopch: 12 step: 8 loss: 0.029756512492895126\n",
      "eopch: 12 step: 9 loss: 0.028863176703453064\n",
      "eopch: 12 step: 10 loss: 0.02882460504770279\n",
      "eopch: 12 step: 11 loss: 0.02905050292611122\n",
      "eopch: 12 step: 12 loss: 0.028542863205075264\n",
      "eopch: 12 step: 13 loss: 0.027846915647387505\n",
      "eopch: 12 step: 14 loss: 0.028147924691438675\n",
      "eopch: 12 step: 15 loss: 0.028914161026477814\n",
      "eopch: 12 step: 16 loss: 0.028389740735292435\n",
      "eopch: 12 step: 17 loss: 0.025019405409693718\n",
      "eopch: 13 step: 1 loss: 0.02824549376964569\n",
      "eopch: 13 step: 2 loss: 0.027083449065685272\n",
      "eopch: 13 step: 3 loss: 0.0276944637298584\n",
      "eopch: 13 step: 4 loss: 0.027939872816205025\n",
      "eopch: 13 step: 5 loss: 0.027219638228416443\n",
      "eopch: 13 step: 6 loss: 0.02787443995475769\n",
      "eopch: 13 step: 7 loss: 0.027643997222185135\n",
      "eopch: 13 step: 8 loss: 0.028007593005895615\n",
      "eopch: 13 step: 9 loss: 0.027136629447340965\n",
      "eopch: 13 step: 10 loss: 0.02690463699400425\n",
      "eopch: 13 step: 11 loss: 0.027030538767576218\n",
      "eopch: 13 step: 12 loss: 0.026759084314107895\n",
      "eopch: 13 step: 13 loss: 0.026177236810326576\n",
      "eopch: 13 step: 14 loss: 0.026562992483377457\n",
      "eopch: 13 step: 15 loss: 0.027292732149362564\n",
      "eopch: 13 step: 16 loss: 0.026888186112046242\n",
      "eopch: 13 step: 17 loss: 0.02368375100195408\n",
      "eopch: 14 step: 1 loss: 0.026565441861748695\n",
      "eopch: 14 step: 2 loss: 0.02533082105219364\n",
      "eopch: 14 step: 3 loss: 0.025816084817051888\n",
      "eopch: 14 step: 4 loss: 0.026103291660547256\n",
      "eopch: 14 step: 5 loss: 0.025522669777274132\n",
      "eopch: 14 step: 6 loss: 0.026256322860717773\n",
      "eopch: 14 step: 7 loss: 0.026094526052474976\n",
      "eopch: 14 step: 8 loss: 0.026505444198846817\n",
      "eopch: 14 step: 9 loss: 0.025720439851284027\n",
      "eopch: 14 step: 10 loss: 0.025544442236423492\n",
      "eopch: 14 step: 11 loss: 0.025476573035120964\n",
      "eopch: 14 step: 12 loss: 0.025007475167512894\n",
      "eopch: 14 step: 13 loss: 0.024414092302322388\n",
      "eopch: 14 step: 14 loss: 0.02492147497832775\n",
      "eopch: 14 step: 15 loss: 0.025649044662714005\n",
      "eopch: 14 step: 16 loss: 0.025310762226581573\n",
      "eopch: 14 step: 17 loss: 0.02230503037571907\n",
      "eopch: 15 step: 1 loss: 0.025110216811299324\n",
      "eopch: 15 step: 2 loss: 0.02400551363825798\n",
      "eopch: 15 step: 3 loss: 0.024428270757198334\n",
      "eopch: 15 step: 4 loss: 0.024551143869757652\n",
      "eopch: 15 step: 5 loss: 0.02397219091653824\n",
      "eopch: 15 step: 6 loss: 0.024660691618919373\n",
      "eopch: 15 step: 7 loss: 0.024491721764206886\n",
      "eopch: 15 step: 8 loss: 0.024911172688007355\n",
      "eopch: 15 step: 9 loss: 0.02422379143536091\n",
      "eopch: 15 step: 10 loss: 0.024162814021110535\n",
      "eopch: 15 step: 11 loss: 0.024152245372533798\n",
      "eopch: 15 step: 12 loss: 0.023649178445339203\n",
      "eopch: 15 step: 13 loss: 0.023035269230604172\n",
      "eopch: 15 step: 14 loss: 0.023477140814065933\n",
      "eopch: 15 step: 15 loss: 0.024200109764933586\n",
      "eopch: 15 step: 16 loss: 0.023875370621681213\n",
      "eopch: 15 step: 17 loss: 0.02099495194852352\n",
      "eopch: 16 step: 1 loss: 0.02359500527381897\n",
      "eopch: 16 step: 2 loss: 0.022617552429437637\n",
      "eopch: 16 step: 3 loss: 0.0230528824031353\n",
      "eopch: 16 step: 4 loss: 0.02314377948641777\n",
      "eopch: 16 step: 5 loss: 0.022602010518312454\n",
      "eopch: 16 step: 6 loss: 0.023197494447231293\n",
      "eopch: 16 step: 7 loss: 0.023127418011426926\n",
      "eopch: 16 step: 8 loss: 0.023539414629340172\n",
      "eopch: 16 step: 9 loss: 0.022854838520288467\n",
      "eopch: 16 step: 10 loss: 0.022790759801864624\n",
      "eopch: 16 step: 11 loss: 0.022832728922367096\n",
      "eopch: 16 step: 12 loss: 0.02236914448440075\n",
      "eopch: 16 step: 13 loss: 0.021720554679632187\n",
      "eopch: 16 step: 14 loss: 0.02210744097828865\n",
      "eopch: 16 step: 15 loss: 0.02279007062315941\n",
      "eopch: 16 step: 16 loss: 0.022595223039388657\n",
      "eopch: 16 step: 17 loss: 0.019845597445964813\n",
      "eopch: 17 step: 1 loss: 0.022253045812249184\n",
      "eopch: 17 step: 2 loss: 0.021370641887187958\n",
      "eopch: 17 step: 3 loss: 0.02179788239300251\n",
      "eopch: 17 step: 4 loss: 0.021931862458586693\n",
      "eopch: 17 step: 5 loss: 0.021338464692234993\n",
      "eopch: 17 step: 6 loss: 0.021845588460564613\n",
      "eopch: 17 step: 7 loss: 0.021834392100572586\n",
      "eopch: 17 step: 8 loss: 0.02227344736456871\n",
      "eopch: 17 step: 9 loss: 0.021621007472276688\n",
      "eopch: 17 step: 10 loss: 0.021484393626451492\n",
      "eopch: 17 step: 11 loss: 0.02152377739548683\n",
      "eopch: 17 step: 12 loss: 0.02121061086654663\n",
      "eopch: 17 step: 13 loss: 0.020675748586654663\n",
      "eopch: 17 step: 14 loss: 0.02097664773464203\n",
      "eopch: 17 step: 15 loss: 0.021422434598207474\n",
      "eopch: 17 step: 16 loss: 0.021254099905490875\n",
      "eopch: 17 step: 17 loss: 0.01880091242492199\n",
      "eopch: 18 step: 1 loss: 0.021146943792700768\n",
      "eopch: 18 step: 2 loss: 0.020204072818160057\n",
      "eopch: 18 step: 3 loss: 0.020526621490716934\n",
      "eopch: 18 step: 4 loss: 0.020764682441949844\n",
      "eopch: 18 step: 5 loss: 0.020293837413191795\n",
      "eopch: 18 step: 6 loss: 0.02081366255879402\n",
      "eopch: 18 step: 7 loss: 0.02063349261879921\n",
      "eopch: 18 step: 8 loss: 0.02099316567182541\n",
      "eopch: 18 step: 9 loss: 0.020481552928686142\n",
      "eopch: 18 step: 10 loss: 0.020409569144248962\n",
      "eopch: 18 step: 11 loss: 0.020325668156147003\n",
      "eopch: 18 step: 12 loss: 0.019965311512351036\n",
      "eopch: 18 step: 13 loss: 0.019497858360409737\n",
      "eopch: 18 step: 14 loss: 0.019925657659769058\n",
      "eopch: 18 step: 15 loss: 0.02040938101708889\n",
      "eopch: 18 step: 16 loss: 0.020072653889656067\n",
      "eopch: 18 step: 17 loss: 0.01770600862801075\n",
      "eopch: 19 step: 1 loss: 0.01996370032429695\n",
      "eopch: 19 step: 2 loss: 0.019165221601724625\n",
      "eopch: 19 step: 3 loss: 0.019503042101860046\n",
      "eopch: 19 step: 4 loss: 0.0196146909147501\n",
      "eopch: 19 step: 5 loss: 0.019146258011460304\n",
      "eopch: 19 step: 6 loss: 0.019699444994330406\n",
      "eopch: 19 step: 7 loss: 0.01963396742939949\n",
      "eopch: 19 step: 8 loss: 0.019934887066483498\n",
      "eopch: 19 step: 9 loss: 0.019383952021598816\n",
      "eopch: 19 step: 10 loss: 0.019339483231306076\n",
      "eopch: 19 step: 11 loss: 0.01926751807332039\n",
      "eopch: 19 step: 12 loss: 0.018961135298013687\n",
      "eopch: 19 step: 13 loss: 0.018435530364513397\n",
      "eopch: 19 step: 14 loss: 0.018798908218741417\n",
      "eopch: 19 step: 15 loss: 0.019310809671878815\n",
      "eopch: 19 step: 16 loss: 0.019086845219135284\n",
      "eopch: 19 step: 17 loss: 0.01680026389658451\n",
      "eopch: 20 step: 1 loss: 0.01893211528658867\n",
      "eopch: 20 step: 2 loss: 0.0181440282613039\n",
      "eopch: 20 step: 3 loss: 0.018515363335609436\n",
      "eopch: 20 step: 4 loss: 0.018646538257598877\n",
      "eopch: 20 step: 5 loss: 0.018206704407930374\n",
      "eopch: 20 step: 6 loss: 0.018663199618458748\n",
      "eopch: 20 step: 7 loss: 0.01862846501171589\n",
      "eopch: 20 step: 8 loss: 0.01891450770199299\n",
      "eopch: 20 step: 9 loss: 0.018444862216711044\n",
      "eopch: 20 step: 10 loss: 0.018415510654449463\n",
      "eopch: 20 step: 11 loss: 0.018330417573451996\n",
      "eopch: 20 step: 12 loss: 0.018040131777524948\n",
      "eopch: 20 step: 13 loss: 0.01758711040019989\n",
      "eopch: 20 step: 14 loss: 0.017904289066791534\n",
      "eopch: 20 step: 15 loss: 0.018325623124837875\n",
      "eopch: 20 step: 16 loss: 0.018169619143009186\n",
      "eopch: 20 step: 17 loss: 0.015986109152436256\n",
      "eopch: 21 step: 1 loss: 0.01803208887577057\n",
      "eopch: 21 step: 2 loss: 0.01727285236120224\n",
      "eopch: 21 step: 3 loss: 0.017653852701187134\n",
      "eopch: 21 step: 4 loss: 0.017769705504179\n",
      "eopch: 21 step: 5 loss: 0.017358869314193726\n",
      "eopch: 21 step: 6 loss: 0.017775744199752808\n",
      "eopch: 21 step: 7 loss: 0.01771784946322441\n",
      "eopch: 21 step: 8 loss: 0.01804240047931671\n",
      "eopch: 21 step: 9 loss: 0.01759054698050022\n",
      "eopch: 21 step: 10 loss: 0.017551911994814873\n",
      "eopch: 21 step: 11 loss: 0.01746169850230217\n",
      "eopch: 21 step: 12 loss: 0.017181556671857834\n",
      "eopch: 21 step: 13 loss: 0.016809212043881416\n",
      "eopch: 21 step: 14 loss: 0.017080750316381454\n",
      "eopch: 21 step: 15 loss: 0.017450276762247086\n",
      "eopch: 21 step: 16 loss: 0.01730971597135067\n",
      "eopch: 21 step: 17 loss: 0.015258395113050938\n",
      "eopch: 22 step: 1 loss: 0.017208803445100784\n",
      "eopch: 22 step: 2 loss: 0.016468476504087448\n",
      "eopch: 22 step: 3 loss: 0.016822099685668945\n",
      "eopch: 22 step: 4 loss: 0.01691332273185253\n",
      "eopch: 22 step: 5 loss: 0.016545165330171585\n",
      "eopch: 22 step: 6 loss: 0.016949540004134178\n",
      "eopch: 22 step: 7 loss: 0.016880370676517487\n",
      "eopch: 22 step: 8 loss: 0.017218217253684998\n",
      "eopch: 22 step: 9 loss: 0.016784969717264175\n",
      "eopch: 22 step: 10 loss: 0.016770165413618088\n",
      "eopch: 22 step: 11 loss: 0.016678262501955032\n",
      "eopch: 22 step: 12 loss: 0.016377491876482964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 22 step: 13 loss: 0.01600104570388794\n",
      "eopch: 22 step: 14 loss: 0.01627293974161148\n",
      "eopch: 22 step: 15 loss: 0.016650507226586342\n",
      "eopch: 22 step: 16 loss: 0.016516100615262985\n",
      "eopch: 22 step: 17 loss: 0.014548659324645996\n",
      "eopch: 23 step: 1 loss: 0.016415216028690338\n",
      "eopch: 23 step: 2 loss: 0.015735764056444168\n",
      "eopch: 23 step: 3 loss: 0.016095707193017006\n",
      "eopch: 23 step: 4 loss: 0.016118768602609634\n",
      "eopch: 23 step: 5 loss: 0.01577705517411232\n",
      "eopch: 23 step: 6 loss: 0.01619456708431244\n",
      "eopch: 23 step: 7 loss: 0.016138318926095963\n",
      "eopch: 23 step: 8 loss: 0.01644483581185341\n",
      "eopch: 23 step: 9 loss: 0.016000233590602875\n",
      "eopch: 23 step: 10 loss: 0.016005244106054306\n",
      "eopch: 23 step: 11 loss: 0.015946175903081894\n",
      "eopch: 23 step: 12 loss: 0.01566373184323311\n",
      "eopch: 23 step: 13 loss: 0.015247335657477379\n",
      "eopch: 23 step: 14 loss: 0.015554388053715229\n",
      "eopch: 23 step: 15 loss: 0.01593976840376854\n",
      "eopch: 23 step: 16 loss: 0.015814755111932755\n",
      "eopch: 23 step: 17 loss: 0.01389466691762209\n",
      "eopch: 24 step: 1 loss: 0.01561101246625185\n",
      "eopch: 24 step: 2 loss: 0.015012449584901333\n",
      "eopch: 24 step: 3 loss: 0.015394840389490128\n",
      "eopch: 24 step: 4 loss: 0.015391985885798931\n",
      "eopch: 24 step: 5 loss: 0.015067379921674728\n",
      "eopch: 24 step: 6 loss: 0.015482977032661438\n",
      "eopch: 24 step: 7 loss: 0.01547783613204956\n",
      "eopch: 24 step: 8 loss: 0.015781491994857788\n",
      "eopch: 24 step: 9 loss: 0.015297362580895424\n",
      "eopch: 24 step: 10 loss: 0.015281904488801956\n",
      "eopch: 24 step: 11 loss: 0.015219696797430515\n",
      "eopch: 24 step: 12 loss: 0.014990666881203651\n",
      "eopch: 24 step: 13 loss: 0.014581529423594475\n",
      "eopch: 24 step: 14 loss: 0.014882486313581467\n",
      "eopch: 24 step: 15 loss: 0.015257660299539566\n",
      "eopch: 24 step: 16 loss: 0.015182401984930038\n",
      "eopch: 24 step: 17 loss: 0.013352353125810623\n",
      "eopch: 25 step: 1 loss: 0.014954010024666786\n",
      "eopch: 25 step: 2 loss: 0.014358121901750565\n",
      "eopch: 25 step: 3 loss: 0.014710061252117157\n",
      "eopch: 25 step: 4 loss: 0.01475454494357109\n",
      "eopch: 25 step: 5 loss: 0.014434341341257095\n",
      "eopch: 25 step: 6 loss: 0.014788947068154812\n",
      "eopch: 25 step: 7 loss: 0.014797374606132507\n",
      "eopch: 25 step: 8 loss: 0.015146084129810333\n",
      "eopch: 25 step: 9 loss: 0.01470294687896967\n",
      "eopch: 25 step: 10 loss: 0.014666829258203506\n",
      "eopch: 25 step: 11 loss: 0.014566844329237938\n",
      "eopch: 25 step: 12 loss: 0.014348683878779411\n",
      "eopch: 25 step: 13 loss: 0.013998163864016533\n",
      "eopch: 25 step: 14 loss: 0.014280999079346657\n",
      "eopch: 25 step: 15 loss: 0.01456508319824934\n",
      "eopch: 25 step: 16 loss: 0.014508355408906937\n",
      "eopch: 25 step: 17 loss: 0.012810153886675835\n",
      "eopch: 26 step: 1 loss: 0.014364084228873253\n",
      "eopch: 26 step: 2 loss: 0.013791162520647049\n",
      "eopch: 26 step: 3 loss: 0.01408788189291954\n",
      "eopch: 26 step: 4 loss: 0.014148923568427563\n",
      "eopch: 26 step: 5 loss: 0.013863458298146725\n",
      "eopch: 26 step: 6 loss: 0.014158904552459717\n",
      "eopch: 26 step: 7 loss: 0.014147887006402016\n",
      "eopch: 26 step: 8 loss: 0.014452056027948856\n",
      "eopch: 26 step: 9 loss: 0.014069754630327225\n",
      "eopch: 26 step: 10 loss: 0.01408045832067728\n",
      "eopch: 26 step: 11 loss: 0.013969413936138153\n",
      "eopch: 26 step: 12 loss: 0.013717208057641983\n",
      "eopch: 26 step: 13 loss: 0.013426263816654682\n",
      "eopch: 26 step: 14 loss: 0.013730532489717007\n",
      "eopch: 26 step: 15 loss: 0.013972547836601734\n",
      "eopch: 26 step: 16 loss: 0.013855569064617157\n",
      "eopch: 26 step: 17 loss: 0.012226571328938007\n",
      "eopch: 27 step: 1 loss: 0.013716146349906921\n",
      "eopch: 27 step: 2 loss: 0.013205671682953835\n",
      "eopch: 27 step: 3 loss: 0.013507887721061707\n",
      "eopch: 27 step: 4 loss: 0.013545552268624306\n",
      "eopch: 27 step: 5 loss: 0.013298457488417625\n",
      "eopch: 27 step: 6 loss: 0.013580555096268654\n",
      "eopch: 27 step: 7 loss: 0.01359625905752182\n",
      "eopch: 27 step: 8 loss: 0.013834013603627682\n",
      "eopch: 27 step: 9 loss: 0.013411326333880424\n",
      "eopch: 27 step: 10 loss: 0.01345173642039299\n",
      "eopch: 27 step: 11 loss: 0.013372199609875679\n",
      "eopch: 27 step: 12 loss: 0.013121197931468487\n",
      "eopch: 27 step: 13 loss: 0.012852552346885204\n",
      "eopch: 27 step: 14 loss: 0.013153020292520523\n",
      "eopch: 27 step: 15 loss: 0.013393349945545197\n",
      "eopch: 27 step: 16 loss: 0.013309137895703316\n",
      "eopch: 27 step: 17 loss: 0.011714166030287743\n",
      "eopch: 28 step: 1 loss: 0.013078189454972744\n",
      "eopch: 28 step: 2 loss: 0.012581310234963894\n",
      "eopch: 28 step: 3 loss: 0.012896077707409859\n",
      "eopch: 28 step: 4 loss: 0.012935934588313103\n",
      "eopch: 28 step: 5 loss: 0.012715605087578297\n",
      "eopch: 28 step: 6 loss: 0.013007722795009613\n",
      "eopch: 28 step: 7 loss: 0.013064181432127953\n",
      "eopch: 28 step: 8 loss: 0.013312985189259052\n",
      "eopch: 28 step: 9 loss: 0.012860869988799095\n",
      "eopch: 28 step: 10 loss: 0.012879474088549614\n",
      "eopch: 28 step: 11 loss: 0.012766867876052856\n",
      "eopch: 28 step: 12 loss: 0.012523657642304897\n",
      "eopch: 28 step: 13 loss: 0.012275924906134605\n",
      "eopch: 28 step: 14 loss: 0.012562115676701069\n",
      "eopch: 28 step: 15 loss: 0.01278785802423954\n",
      "eopch: 28 step: 16 loss: 0.012755121104419231\n",
      "eopch: 28 step: 17 loss: 0.011257856152951717\n",
      "eopch: 29 step: 1 loss: 0.012582007795572281\n",
      "eopch: 29 step: 2 loss: 0.012049676850438118\n",
      "eopch: 29 step: 3 loss: 0.012334040366113186\n",
      "eopch: 29 step: 4 loss: 0.012365888804197311\n",
      "eopch: 29 step: 5 loss: 0.01212473213672638\n",
      "eopch: 29 step: 6 loss: 0.012421924620866776\n",
      "eopch: 29 step: 7 loss: 0.01247706264257431\n",
      "eopch: 29 step: 8 loss: 0.012773029506206512\n",
      "eopch: 29 step: 9 loss: 0.012381434440612793\n",
      "eopch: 29 step: 10 loss: 0.012423254549503326\n",
      "eopch: 29 step: 11 loss: 0.01227668859064579\n",
      "eopch: 29 step: 12 loss: 0.012019490823149681\n",
      "eopch: 29 step: 13 loss: 0.011738996021449566\n",
      "eopch: 29 step: 14 loss: 0.011996319517493248\n",
      "eopch: 29 step: 15 loss: 0.012204231694340706\n",
      "eopch: 29 step: 16 loss: 0.012168066576123238\n",
      "eopch: 29 step: 17 loss: 0.010767641477286816\n",
      "eopch: 30 step: 1 loss: 0.012099675834178925\n",
      "eopch: 30 step: 2 loss: 0.011597256176173687\n",
      "eopch: 30 step: 3 loss: 0.011881778948009014\n",
      "eopch: 30 step: 4 loss: 0.011887645348906517\n",
      "eopch: 30 step: 5 loss: 0.011622329242527485\n",
      "eopch: 30 step: 6 loss: 0.011895176023244858\n",
      "eopch: 30 step: 7 loss: 0.011916184797883034\n",
      "eopch: 30 step: 8 loss: 0.012196820229291916\n",
      "eopch: 30 step: 9 loss: 0.011840758845210075\n",
      "eopch: 30 step: 10 loss: 0.011925805360078812\n",
      "eopch: 30 step: 11 loss: 0.011814257130026817\n",
      "eopch: 30 step: 12 loss: 0.011583670973777771\n",
      "eopch: 30 step: 13 loss: 0.011299189180135727\n",
      "eopch: 30 step: 14 loss: 0.01152682676911354\n",
      "eopch: 30 step: 15 loss: 0.011712226085364819\n",
      "eopch: 30 step: 16 loss: 0.011649657972157001\n",
      "eopch: 30 step: 17 loss: 0.010283970274031162\n",
      "eopch: 31 step: 1 loss: 0.011562741361558437\n",
      "eopch: 31 step: 2 loss: 0.011119470931589603\n",
      "eopch: 31 step: 3 loss: 0.011421669274568558\n",
      "eopch: 31 step: 4 loss: 0.011439649388194084\n",
      "eopch: 31 step: 5 loss: 0.01120634563267231\n",
      "eopch: 31 step: 6 loss: 0.011462157592177391\n",
      "eopch: 31 step: 7 loss: 0.011466891504824162\n",
      "eopch: 31 step: 8 loss: 0.011699463240802288\n",
      "eopch: 31 step: 9 loss: 0.0113294068723917\n",
      "eopch: 31 step: 10 loss: 0.011404898017644882\n",
      "eopch: 31 step: 11 loss: 0.011313495226204395\n",
      "eopch: 31 step: 12 loss: 0.011123443022370338\n",
      "eopch: 31 step: 13 loss: 0.010880430229008198\n",
      "eopch: 31 step: 14 loss: 0.01111556775867939\n",
      "eopch: 31 step: 15 loss: 0.011318682692945004\n",
      "eopch: 31 step: 16 loss: 0.011229152791202068\n",
      "eopch: 31 step: 17 loss: 0.009883918799459934\n",
      "eopch: 32 step: 1 loss: 0.01107017695903778\n",
      "eopch: 32 step: 2 loss: 0.01064562052488327\n",
      "eopch: 32 step: 3 loss: 0.010931769385933876\n",
      "eopch: 32 step: 4 loss: 0.010959894396364689\n",
      "eopch: 32 step: 5 loss: 0.010773795656859875\n",
      "eopch: 32 step: 6 loss: 0.011040540412068367\n",
      "eopch: 32 step: 7 loss: 0.011065607890486717\n",
      "eopch: 32 step: 8 loss: 0.011291717179119587\n",
      "eopch: 32 step: 9 loss: 0.010906223207712173\n",
      "eopch: 32 step: 10 loss: 0.010944848880171776\n",
      "eopch: 32 step: 11 loss: 0.010848507285118103\n",
      "eopch: 32 step: 12 loss: 0.010656306520104408\n",
      "eopch: 32 step: 13 loss: 0.010441523045301437\n",
      "eopch: 32 step: 14 loss: 0.01067198533564806\n",
      "eopch: 32 step: 15 loss: 0.010903321206569672\n",
      "eopch: 32 step: 16 loss: 0.010826660320162773\n",
      "eopch: 32 step: 17 loss: 0.009531011804938316\n",
      "eopch: 33 step: 1 loss: 0.010659553110599518\n",
      "eopch: 33 step: 2 loss: 0.010232624597847462\n",
      "eopch: 33 step: 3 loss: 0.010494919493794441\n",
      "eopch: 33 step: 4 loss: 0.010500410571694374\n",
      "eopch: 33 step: 5 loss: 0.010324617847800255\n",
      "eopch: 33 step: 6 loss: 0.010583259165287018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 33 step: 7 loss: 0.01063862070441246\n",
      "eopch: 33 step: 8 loss: 0.010886786505579948\n",
      "eopch: 33 step: 9 loss: 0.010524651035666466\n",
      "eopch: 33 step: 10 loss: 0.01054549403488636\n",
      "eopch: 33 step: 11 loss: 0.010448509827256203\n",
      "eopch: 33 step: 12 loss: 0.010243739001452923\n",
      "eopch: 33 step: 13 loss: 0.010031133890151978\n",
      "eopch: 33 step: 14 loss: 0.010245384648442268\n",
      "eopch: 33 step: 15 loss: 0.010464038699865341\n",
      "eopch: 33 step: 16 loss: 0.010408978909254074\n",
      "eopch: 33 step: 17 loss: 0.009169411845505238\n",
      "eopch: 34 step: 1 loss: 0.010276935063302517\n",
      "eopch: 34 step: 2 loss: 0.009868258610367775\n",
      "eopch: 34 step: 3 loss: 0.010115448385477066\n",
      "eopch: 34 step: 4 loss: 0.01009758748114109\n",
      "eopch: 34 step: 5 loss: 0.00993285421282053\n",
      "eopch: 34 step: 6 loss: 0.010174131020903587\n",
      "eopch: 34 step: 7 loss: 0.010226339101791382\n",
      "eopch: 34 step: 8 loss: 0.010468566790223122\n",
      "eopch: 34 step: 9 loss: 0.010130532085895538\n",
      "eopch: 34 step: 10 loss: 0.010167911648750305\n",
      "eopch: 34 step: 11 loss: 0.010064241476356983\n",
      "eopch: 34 step: 12 loss: 0.009867728687822819\n",
      "eopch: 34 step: 13 loss: 0.009661386720836163\n",
      "eopch: 34 step: 14 loss: 0.009875692427158356\n",
      "eopch: 34 step: 15 loss: 0.01006724126636982\n",
      "eopch: 34 step: 16 loss: 0.010016215965151787\n",
      "eopch: 34 step: 17 loss: 0.008813222870230675\n",
      "eopch: 35 step: 1 loss: 0.009883150458335876\n",
      "eopch: 35 step: 2 loss: 0.009505929425358772\n",
      "eopch: 35 step: 3 loss: 0.009752156212925911\n",
      "eopch: 35 step: 4 loss: 0.009717797860503197\n",
      "eopch: 35 step: 5 loss: 0.009572522714734077\n",
      "eopch: 35 step: 6 loss: 0.009813040494918823\n",
      "eopch: 35 step: 7 loss: 0.009866314008831978\n",
      "eopch: 35 step: 8 loss: 0.010090496391057968\n",
      "eopch: 35 step: 9 loss: 0.009759360924363136\n",
      "eopch: 35 step: 10 loss: 0.009808877483010292\n",
      "eopch: 35 step: 11 loss: 0.00970066525042057\n",
      "eopch: 35 step: 12 loss: 0.009502945467829704\n",
      "eopch: 35 step: 13 loss: 0.009297472424805164\n",
      "eopch: 35 step: 14 loss: 0.009520972147583961\n",
      "eopch: 35 step: 15 loss: 0.009707655757665634\n",
      "eopch: 35 step: 16 loss: 0.009665713645517826\n",
      "eopch: 35 step: 17 loss: 0.00850739050656557\n",
      "eopch: 36 step: 1 loss: 0.009530536830425262\n",
      "eopch: 36 step: 2 loss: 0.00916614755988121\n",
      "eopch: 36 step: 3 loss: 0.00940683577209711\n",
      "eopch: 36 step: 4 loss: 0.009362720884382725\n",
      "eopch: 36 step: 5 loss: 0.009214594028890133\n",
      "eopch: 36 step: 6 loss: 0.009440336376428604\n",
      "eopch: 36 step: 7 loss: 0.009513208642601967\n",
      "eopch: 36 step: 8 loss: 0.009737448766827583\n",
      "eopch: 36 step: 9 loss: 0.009427867829799652\n",
      "eopch: 36 step: 10 loss: 0.009480067528784275\n",
      "eopch: 36 step: 11 loss: 0.009384183213114738\n",
      "eopch: 36 step: 12 loss: 0.009177690371870995\n",
      "eopch: 36 step: 13 loss: 0.00895936880260706\n",
      "eopch: 36 step: 14 loss: 0.009167489595711231\n",
      "eopch: 36 step: 15 loss: 0.009345152415335178\n",
      "eopch: 36 step: 16 loss: 0.009308641776442528\n",
      "eopch: 36 step: 17 loss: 0.00821523554623127\n",
      "eopch: 37 step: 1 loss: 0.009211761876940727\n",
      "eopch: 37 step: 2 loss: 0.008860956877470016\n",
      "eopch: 37 step: 3 loss: 0.009103241376578808\n",
      "eopch: 37 step: 4 loss: 0.0090583935379982\n",
      "eopch: 37 step: 5 loss: 0.008894838392734528\n",
      "eopch: 37 step: 6 loss: 0.009095304645597935\n",
      "eopch: 37 step: 7 loss: 0.009165442548692226\n",
      "eopch: 37 step: 8 loss: 0.009382424876093864\n",
      "eopch: 37 step: 9 loss: 0.009094830602407455\n",
      "eopch: 37 step: 10 loss: 0.009163000620901585\n",
      "eopch: 37 step: 11 loss: 0.00908070057630539\n",
      "eopch: 37 step: 12 loss: 0.008888393640518188\n",
      "eopch: 37 step: 13 loss: 0.008670569397509098\n",
      "eopch: 37 step: 14 loss: 0.008859950117766857\n",
      "eopch: 37 step: 15 loss: 0.009019071236252785\n",
      "eopch: 37 step: 16 loss: 0.008967073634266853\n",
      "eopch: 37 step: 17 loss: 0.007918059825897217\n",
      "eopch: 38 step: 1 loss: 0.008882207795977592\n",
      "eopch: 38 step: 2 loss: 0.008551438339054585\n",
      "eopch: 38 step: 3 loss: 0.008805200457572937\n",
      "eopch: 38 step: 4 loss: 0.008772368542850018\n",
      "eopch: 38 step: 5 loss: 0.008616594597697258\n",
      "eopch: 38 step: 6 loss: 0.00880548357963562\n",
      "eopch: 38 step: 7 loss: 0.008858786895871162\n",
      "eopch: 38 step: 8 loss: 0.009058572351932526\n",
      "eopch: 38 step: 9 loss: 0.008767451159656048\n",
      "eopch: 38 step: 10 loss: 0.008843605406582355\n",
      "eopch: 38 step: 11 loss: 0.008762698620557785\n",
      "eopch: 38 step: 12 loss: 0.00859188474714756\n",
      "eopch: 38 step: 13 loss: 0.008394756354391575\n",
      "eopch: 38 step: 14 loss: 0.008576039224863052\n",
      "eopch: 38 step: 15 loss: 0.008730962872505188\n",
      "eopch: 38 step: 16 loss: 0.008673942647874355\n",
      "eopch: 38 step: 17 loss: 0.007648694794625044\n",
      "eopch: 39 step: 1 loss: 0.008571892976760864\n",
      "eopch: 39 step: 2 loss: 0.00825349148362875\n",
      "eopch: 39 step: 3 loss: 0.008500874042510986\n",
      "eopch: 39 step: 4 loss: 0.008476879447698593\n",
      "eopch: 39 step: 5 loss: 0.008333229459822178\n",
      "eopch: 39 step: 6 loss: 0.00852520577609539\n",
      "eopch: 39 step: 7 loss: 0.008572405204176903\n",
      "eopch: 39 step: 8 loss: 0.008768333122134209\n",
      "eopch: 39 step: 9 loss: 0.008474165573716164\n",
      "eopch: 39 step: 10 loss: 0.008544168435037136\n",
      "eopch: 39 step: 11 loss: 0.008458783850073814\n",
      "eopch: 39 step: 12 loss: 0.008302001282572746\n",
      "eopch: 39 step: 13 loss: 0.008119765669107437\n",
      "eopch: 39 step: 14 loss: 0.008297600783407688\n",
      "eopch: 39 step: 15 loss: 0.008448462933301926\n",
      "eopch: 39 step: 16 loss: 0.00839146040380001\n",
      "eopch: 39 step: 17 loss: 0.007391485385596752\n",
      "eopch: 40 step: 1 loss: 0.008286608383059502\n",
      "eopch: 40 step: 2 loss: 0.007984097115695477\n",
      "eopch: 40 step: 3 loss: 0.008219342678785324\n",
      "eopch: 40 step: 4 loss: 0.008196758106350899\n",
      "eopch: 40 step: 5 loss: 0.008064355701208115\n",
      "eopch: 40 step: 6 loss: 0.008249809965491295\n",
      "eopch: 40 step: 7 loss: 0.008290131576359272\n",
      "eopch: 40 step: 8 loss: 0.008480234071612358\n",
      "eopch: 40 step: 9 loss: 0.008190197870135307\n",
      "eopch: 40 step: 10 loss: 0.00826125219464302\n",
      "eopch: 40 step: 11 loss: 0.00817832350730896\n",
      "eopch: 40 step: 12 loss: 0.008035512641072273\n",
      "eopch: 40 step: 13 loss: 0.007867716252803802\n",
      "eopch: 40 step: 14 loss: 0.008045608177781105\n",
      "eopch: 40 step: 15 loss: 0.00818653218448162\n",
      "eopch: 40 step: 16 loss: 0.00811980850994587\n",
      "eopch: 40 step: 17 loss: 0.00714532658457756\n",
      "eopch: 41 step: 1 loss: 0.007997817359864712\n",
      "eopch: 41 step: 2 loss: 0.007711595855653286\n",
      "eopch: 41 step: 3 loss: 0.007946659810841084\n",
      "eopch: 41 step: 4 loss: 0.007931331172585487\n",
      "eopch: 41 step: 5 loss: 0.00781935639679432\n",
      "eopch: 41 step: 6 loss: 0.00800562184303999\n",
      "eopch: 41 step: 7 loss: 0.00804523192346096\n",
      "eopch: 41 step: 8 loss: 0.008220800198614597\n",
      "eopch: 41 step: 9 loss: 0.007921194657683372\n",
      "eopch: 41 step: 10 loss: 0.00797608494758606\n",
      "eopch: 41 step: 11 loss: 0.007894356735050678\n",
      "eopch: 41 step: 12 loss: 0.007763292174786329\n",
      "eopch: 41 step: 13 loss: 0.0076185851357877254\n",
      "eopch: 41 step: 14 loss: 0.007808675989508629\n",
      "eopch: 41 step: 15 loss: 0.007951484993100166\n",
      "eopch: 41 step: 16 loss: 0.00788947008550167\n",
      "eopch: 41 step: 17 loss: 0.006934016942977905\n",
      "eopch: 42 step: 1 loss: 0.007741405628621578\n",
      "eopch: 42 step: 2 loss: 0.007447374053299427\n",
      "eopch: 42 step: 3 loss: 0.0076669324189424515\n",
      "eopch: 42 step: 4 loss: 0.007660641800612211\n",
      "eopch: 42 step: 5 loss: 0.007560343481600285\n",
      "eopch: 42 step: 6 loss: 0.007758135907351971\n",
      "eopch: 42 step: 7 loss: 0.007816942408680916\n",
      "eopch: 42 step: 8 loss: 0.007994714193046093\n",
      "eopch: 42 step: 9 loss: 0.007694362662732601\n",
      "eopch: 42 step: 10 loss: 0.007728954311460257\n",
      "eopch: 42 step: 11 loss: 0.0076370928436517715\n",
      "eopch: 42 step: 12 loss: 0.007497216574847698\n",
      "eopch: 42 step: 13 loss: 0.007355228997766972\n",
      "eopch: 42 step: 14 loss: 0.00755005469545722\n",
      "eopch: 42 step: 15 loss: 0.007702487055212259\n",
      "eopch: 42 step: 16 loss: 0.007658158428966999\n",
      "eopch: 42 step: 17 loss: 0.00673741614446044\n",
      "eopch: 43 step: 1 loss: 0.007526072673499584\n",
      "eopch: 43 step: 2 loss: 0.00722226407378912\n",
      "eopch: 43 step: 3 loss: 0.007418354041874409\n",
      "eopch: 43 step: 4 loss: 0.007403270341455936\n",
      "eopch: 43 step: 5 loss: 0.007294909097254276\n",
      "eopch: 43 step: 6 loss: 0.007491008378565311\n",
      "eopch: 43 step: 7 loss: 0.007566021289676428\n",
      "eopch: 43 step: 8 loss: 0.00775210140272975\n",
      "eopch: 43 step: 9 loss: 0.007471431978046894\n",
      "eopch: 43 step: 10 loss: 0.007510761730372906\n",
      "eopch: 43 step: 11 loss: 0.007411540485918522\n",
      "eopch: 43 step: 12 loss: 0.0072669656947255135\n",
      "eopch: 43 step: 13 loss: 0.0071145230904221535\n",
      "eopch: 43 step: 14 loss: 0.0072932252660393715\n",
      "eopch: 43 step: 15 loss: 0.007441956549882889\n",
      "eopch: 43 step: 16 loss: 0.0074098738841712475\n",
      "eopch: 43 step: 17 loss: 0.00652419775724411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 44 step: 1 loss: 0.007300559431314468\n",
      "eopch: 44 step: 2 loss: 0.007006799802184105\n",
      "eopch: 44 step: 3 loss: 0.007196848746389151\n",
      "eopch: 44 step: 4 loss: 0.007173876278102398\n",
      "eopch: 44 step: 5 loss: 0.007059003692120314\n",
      "eopch: 44 step: 6 loss: 0.007244831882417202\n",
      "eopch: 44 step: 7 loss: 0.007319769822061062\n",
      "eopch: 44 step: 8 loss: 0.007497848477214575\n",
      "eopch: 44 step: 9 loss: 0.007233960088342428\n",
      "eopch: 44 step: 10 loss: 0.007284587249159813\n",
      "eopch: 44 step: 11 loss: 0.007186760660260916\n",
      "eopch: 44 step: 12 loss: 0.007046157028526068\n",
      "eopch: 44 step: 13 loss: 0.006897257175296545\n",
      "eopch: 44 step: 14 loss: 0.007063171826303005\n",
      "eopch: 44 step: 15 loss: 0.007202118635177612\n",
      "eopch: 44 step: 16 loss: 0.007175489328801632\n",
      "eopch: 44 step: 17 loss: 0.00631604203954339\n",
      "eopch: 45 step: 1 loss: 0.0070723360404372215\n",
      "eopch: 45 step: 2 loss: 0.006791436579078436\n",
      "eopch: 45 step: 3 loss: 0.006976485252380371\n",
      "eopch: 45 step: 4 loss: 0.0069471923634409904\n",
      "eopch: 45 step: 5 loss: 0.006837249267846346\n",
      "eopch: 45 step: 6 loss: 0.0070214346051216125\n",
      "eopch: 45 step: 7 loss: 0.007099020294845104\n",
      "eopch: 45 step: 8 loss: 0.007267695385962725\n",
      "eopch: 45 step: 9 loss: 0.007011258043348789\n",
      "eopch: 45 step: 10 loss: 0.007065660320222378\n",
      "eopch: 45 step: 11 loss: 0.006965525448322296\n",
      "eopch: 45 step: 12 loss: 0.006826644763350487\n",
      "eopch: 45 step: 13 loss: 0.006682027131319046\n",
      "eopch: 45 step: 14 loss: 0.0068418532609939575\n",
      "eopch: 45 step: 15 loss: 0.006975430063903332\n",
      "eopch: 45 step: 16 loss: 0.006957507226616144\n",
      "eopch: 45 step: 17 loss: 0.006123676430433989\n",
      "eopch: 46 step: 1 loss: 0.006864310707896948\n",
      "eopch: 46 step: 2 loss: 0.006593418773263693\n",
      "eopch: 46 step: 3 loss: 0.0067727151326835155\n",
      "eopch: 46 step: 4 loss: 0.006731507834047079\n",
      "eopch: 46 step: 5 loss: 0.006620786618441343\n",
      "eopch: 46 step: 6 loss: 0.006797981448471546\n",
      "eopch: 46 step: 7 loss: 0.006879022810608149\n",
      "eopch: 46 step: 8 loss: 0.007050581742078066\n",
      "eopch: 46 step: 9 loss: 0.006804971024394035\n",
      "eopch: 46 step: 10 loss: 0.00686232652515173\n",
      "eopch: 46 step: 11 loss: 0.006763087119907141\n",
      "eopch: 46 step: 12 loss: 0.006623089779168367\n",
      "eopch: 46 step: 13 loss: 0.006477738730609417\n",
      "eopch: 46 step: 14 loss: 0.006628816016018391\n",
      "eopch: 46 step: 15 loss: 0.00675725843757391\n",
      "eopch: 46 step: 16 loss: 0.006746973842382431\n",
      "eopch: 46 step: 17 loss: 0.0059398869052529335\n",
      "eopch: 47 step: 1 loss: 0.006662738975137472\n",
      "eopch: 47 step: 2 loss: 0.006403475534170866\n",
      "eopch: 47 step: 3 loss: 0.006585867144167423\n",
      "eopch: 47 step: 4 loss: 0.006532549858093262\n",
      "eopch: 47 step: 5 loss: 0.006420567631721497\n",
      "eopch: 47 step: 6 loss: 0.00658744340762496\n",
      "eopch: 47 step: 7 loss: 0.006666007451713085\n",
      "eopch: 47 step: 8 loss: 0.006837837398052216\n",
      "eopch: 47 step: 9 loss: 0.006603783927857876\n",
      "eopch: 47 step: 10 loss: 0.006668665446341038\n",
      "eopch: 47 step: 11 loss: 0.006575273349881172\n",
      "eopch: 47 step: 12 loss: 0.006432843394577503\n",
      "eopch: 47 step: 13 loss: 0.006287495139986277\n",
      "eopch: 47 step: 14 loss: 0.0064282650128006935\n",
      "eopch: 47 step: 15 loss: 0.006551160477101803\n",
      "eopch: 47 step: 16 loss: 0.006549013778567314\n",
      "eopch: 47 step: 17 loss: 0.0057672495022416115\n",
      "eopch: 48 step: 1 loss: 0.00647282088175416\n",
      "eopch: 48 step: 2 loss: 0.006222302094101906\n",
      "eopch: 48 step: 3 loss: 0.006406010594218969\n",
      "eopch: 48 step: 4 loss: 0.0063482895493507385\n",
      "eopch: 48 step: 5 loss: 0.00623357342556119\n",
      "eopch: 48 step: 6 loss: 0.006388259585946798\n",
      "eopch: 48 step: 7 loss: 0.006461641751229763\n",
      "eopch: 48 step: 8 loss: 0.006634688004851341\n",
      "eopch: 48 step: 9 loss: 0.006409087218344212\n",
      "eopch: 48 step: 10 loss: 0.006482412107288837\n",
      "eopch: 48 step: 11 loss: 0.006399420090019703\n",
      "eopch: 48 step: 12 loss: 0.006257509812712669\n",
      "eopch: 48 step: 13 loss: 0.00611256156116724\n",
      "eopch: 48 step: 14 loss: 0.006240205839276314\n",
      "eopch: 48 step: 15 loss: 0.006352599710226059\n",
      "eopch: 48 step: 16 loss: 0.006350179202854633\n",
      "eopch: 48 step: 17 loss: 0.005596352741122246\n",
      "eopch: 49 step: 1 loss: 0.006286450661718845\n",
      "eopch: 49 step: 2 loss: 0.006052413024008274\n",
      "eopch: 49 step: 3 loss: 0.006237450521439314\n",
      "eopch: 49 step: 4 loss: 0.0061806365847587585\n",
      "eopch: 49 step: 5 loss: 0.006062266416847706\n",
      "eopch: 49 step: 6 loss: 0.00620461069047451\n",
      "eopch: 49 step: 7 loss: 0.006265513598918915\n",
      "eopch: 49 step: 8 loss: 0.006431336980313063\n",
      "eopch: 49 step: 9 loss: 0.006214365363121033\n",
      "eopch: 49 step: 10 loss: 0.00629819743335247\n",
      "eopch: 49 step: 11 loss: 0.006231753155589104\n",
      "eopch: 49 step: 12 loss: 0.006099207792431116\n",
      "eopch: 49 step: 13 loss: 0.005955323111265898\n",
      "eopch: 49 step: 14 loss: 0.006071262992918491\n",
      "eopch: 49 step: 15 loss: 0.0061700898222625256\n",
      "eopch: 49 step: 16 loss: 0.006157536059617996\n",
      "eopch: 49 step: 17 loss: 0.005427401512861252\n",
      "eopch: 50 step: 1 loss: 0.0061003658920526505\n",
      "eopch: 50 step: 2 loss: 0.0058823381550610065\n",
      "eopch: 50 step: 3 loss: 0.00606971699744463\n",
      "eopch: 50 step: 4 loss: 0.006018619518727064\n",
      "eopch: 50 step: 5 loss: 0.005902774631977081\n",
      "eopch: 50 step: 6 loss: 0.006039245054125786\n",
      "eopch: 50 step: 7 loss: 0.006092016119509935\n",
      "eopch: 50 step: 8 loss: 0.006242576986551285\n",
      "eopch: 50 step: 9 loss: 0.00602509081363678\n",
      "eopch: 50 step: 10 loss: 0.0061111003160476685\n",
      "eopch: 50 step: 11 loss: 0.006054304074496031\n",
      "eopch: 50 step: 12 loss: 0.005934637971222401\n",
      "eopch: 50 step: 13 loss: 0.005801402032375336\n",
      "eopch: 50 step: 14 loss: 0.005914282985031605\n",
      "eopch: 50 step: 15 loss: 0.006003302522003651\n",
      "eopch: 50 step: 16 loss: 0.005980212241411209\n",
      "eopch: 50 step: 17 loss: 0.005269205663353205\n",
      "eopch: 51 step: 1 loss: 0.005917314440011978\n",
      "eopch: 51 step: 2 loss: 0.005709020886570215\n",
      "eopch: 51 step: 3 loss: 0.005895661190152168\n",
      "eopch: 51 step: 4 loss: 0.005850302521139383\n",
      "eopch: 51 step: 5 loss: 0.005743685178458691\n",
      "eopch: 51 step: 6 loss: 0.005879539996385574\n",
      "eopch: 51 step: 7 loss: 0.005931043066084385\n",
      "eopch: 51 step: 8 loss: 0.0060693491250276566\n",
      "eopch: 51 step: 9 loss: 0.005850990302860737\n",
      "eopch: 51 step: 10 loss: 0.005931784398853779\n",
      "eopch: 51 step: 11 loss: 0.005876381881535053\n",
      "eopch: 51 step: 12 loss: 0.005764869041740894\n",
      "eopch: 51 step: 13 loss: 0.005642722360789776\n",
      "eopch: 51 step: 14 loss: 0.005758697632700205\n",
      "eopch: 51 step: 15 loss: 0.005842138081789017\n",
      "eopch: 51 step: 16 loss: 0.005811966024339199\n",
      "eopch: 51 step: 17 loss: 0.005120531655848026\n",
      "eopch: 52 step: 1 loss: 0.0057425303384661674\n",
      "eopch: 52 step: 2 loss: 0.005541045218706131\n",
      "eopch: 52 step: 3 loss: 0.005723233334720135\n",
      "eopch: 52 step: 4 loss: 0.005683063063770533\n",
      "eopch: 52 step: 5 loss: 0.00558594660833478\n",
      "eopch: 52 step: 6 loss: 0.005722852423787117\n",
      "eopch: 52 step: 7 loss: 0.005775792058557272\n",
      "eopch: 52 step: 8 loss: 0.00590402539819479\n",
      "eopch: 52 step: 9 loss: 0.005685066804289818\n",
      "eopch: 52 step: 10 loss: 0.005760516971349716\n",
      "eopch: 52 step: 11 loss: 0.005704380106180906\n",
      "eopch: 52 step: 12 loss: 0.005599759053438902\n",
      "eopch: 52 step: 13 loss: 0.005485630128532648\n",
      "eopch: 52 step: 14 loss: 0.005604105070233345\n",
      "eopch: 52 step: 15 loss: 0.005687402561306953\n",
      "eopch: 52 step: 16 loss: 0.005654064938426018\n",
      "eopch: 52 step: 17 loss: 0.004979715682566166\n",
      "eopch: 53 step: 1 loss: 0.005575940944254398\n",
      "eopch: 53 step: 2 loss: 0.005379670299589634\n",
      "eopch: 53 step: 3 loss: 0.005554948002099991\n",
      "eopch: 53 step: 4 loss: 0.00551959965378046\n",
      "eopch: 53 step: 5 loss: 0.005430807359516621\n",
      "eopch: 53 step: 6 loss: 0.005568367429077625\n",
      "eopch: 53 step: 7 loss: 0.0056232186034321785\n",
      "eopch: 53 step: 8 loss: 0.005745952483266592\n",
      "eopch: 53 step: 9 loss: 0.005528635811060667\n",
      "eopch: 53 step: 10 loss: 0.005596783943474293\n",
      "eopch: 53 step: 11 loss: 0.005538419354707003\n",
      "eopch: 53 step: 12 loss: 0.005437744315713644\n",
      "eopch: 53 step: 13 loss: 0.005330569110810757\n",
      "eopch: 53 step: 14 loss: 0.005450143478810787\n",
      "eopch: 53 step: 15 loss: 0.005536047741770744\n",
      "eopch: 53 step: 16 loss: 0.0055060312151908875\n",
      "eopch: 53 step: 17 loss: 0.004846706986427307\n",
      "eopch: 54 step: 1 loss: 0.005421441979706287\n",
      "eopch: 54 step: 2 loss: 0.00522705027833581\n",
      "eopch: 54 step: 3 loss: 0.005394678097218275\n",
      "eopch: 54 step: 4 loss: 0.005360468290746212\n",
      "eopch: 54 step: 5 loss: 0.0052789244800806046\n",
      "eopch: 54 step: 6 loss: 0.00541628897190094\n",
      "eopch: 54 step: 7 loss: 0.00547115970402956\n",
      "eopch: 54 step: 8 loss: 0.005593101494014263\n",
      "eopch: 54 step: 9 loss: 0.0053790537640452385\n",
      "eopch: 54 step: 10 loss: 0.005442993715405464\n",
      "eopch: 54 step: 11 loss: 0.005380215123295784\n",
      "eopch: 54 step: 12 loss: 0.0052802409045398235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 54 step: 13 loss: 0.005179220344871283\n",
      "eopch: 54 step: 14 loss: 0.0052983760833740234\n",
      "eopch: 54 step: 15 loss: 0.0053858207538723946\n",
      "eopch: 54 step: 16 loss: 0.005360795184969902\n",
      "eopch: 54 step: 17 loss: 0.004717495758086443\n",
      "eopch: 55 step: 1 loss: 0.005277046002447605\n",
      "eopch: 55 step: 2 loss: 0.005084042437374592\n",
      "eopch: 55 step: 3 loss: 0.005242917221039534\n",
      "eopch: 55 step: 4 loss: 0.005205722525715828\n",
      "eopch: 55 step: 5 loss: 0.0051289829425513744\n",
      "eopch: 55 step: 6 loss: 0.005265918094664812\n",
      "eopch: 55 step: 7 loss: 0.005320873111486435\n",
      "eopch: 55 step: 8 loss: 0.005446747876703739\n",
      "eopch: 55 step: 9 loss: 0.005235888063907623\n",
      "eopch: 55 step: 10 loss: 0.0052989693358540535\n",
      "eopch: 55 step: 11 loss: 0.0052332826890051365\n",
      "eopch: 55 step: 12 loss: 0.005130033940076828\n",
      "eopch: 55 step: 13 loss: 0.005032469052821398\n",
      "eopch: 55 step: 14 loss: 0.005151201970875263\n",
      "eopch: 55 step: 15 loss: 0.005237950012087822\n",
      "eopch: 55 step: 16 loss: 0.005219852551817894\n",
      "eopch: 55 step: 17 loss: 0.004590864758938551\n",
      "eopch: 56 step: 1 loss: 0.005137932952493429\n",
      "eopch: 56 step: 2 loss: 0.004949579481035471\n",
      "eopch: 56 step: 3 loss: 0.005101141519844532\n",
      "eopch: 56 step: 4 loss: 0.005060448311269283\n",
      "eopch: 56 step: 5 loss: 0.004983546212315559\n",
      "eopch: 56 step: 6 loss: 0.005117639433592558\n",
      "eopch: 56 step: 7 loss: 0.005173483397811651\n",
      "eopch: 56 step: 8 loss: 0.005303442478179932\n",
      "eopch: 56 step: 9 loss: 0.005095979198813438\n",
      "eopch: 56 step: 10 loss: 0.005160166881978512\n",
      "eopch: 56 step: 11 loss: 0.005096421577036381\n",
      "eopch: 56 step: 12 loss: 0.00498991459608078\n",
      "eopch: 56 step: 13 loss: 0.0048921918496489525\n",
      "eopch: 56 step: 14 loss: 0.005007481202483177\n",
      "eopch: 56 step: 15 loss: 0.005090381484478712\n",
      "eopch: 56 step: 16 loss: 0.005078884307295084\n",
      "eopch: 56 step: 17 loss: 0.004465378820896149\n",
      "eopch: 57 step: 1 loss: 0.005000907927751541\n",
      "eopch: 57 step: 2 loss: 0.004820072092115879\n",
      "eopch: 57 step: 3 loss: 0.004967817571014166\n",
      "eopch: 57 step: 4 loss: 0.0049261050298810005\n",
      "eopch: 57 step: 5 loss: 0.004846823401749134\n",
      "eopch: 57 step: 6 loss: 0.004975433461368084\n",
      "eopch: 57 step: 7 loss: 0.00502996938303113\n",
      "eopch: 57 step: 8 loss: 0.00516152149066329\n",
      "eopch: 57 step: 9 loss: 0.004958681762218475\n",
      "eopch: 57 step: 10 loss: 0.005024528130888939\n",
      "eopch: 57 step: 11 loss: 0.0049652517773211\n",
      "eopch: 57 step: 12 loss: 0.004859233275055885\n",
      "eopch: 57 step: 13 loss: 0.00476265512406826\n",
      "eopch: 57 step: 14 loss: 0.004874133504927158\n",
      "eopch: 57 step: 15 loss: 0.004950270522385836\n",
      "eopch: 57 step: 16 loss: 0.00494071189314127\n",
      "eopch: 57 step: 17 loss: 0.004343894775956869\n",
      "eopch: 58 step: 1 loss: 0.004866955801844597\n",
      "eopch: 58 step: 2 loss: 0.0046926820650696754\n",
      "eopch: 58 step: 3 loss: 0.004840285517275333\n",
      "eopch: 58 step: 4 loss: 0.004799277521669865\n",
      "eopch: 58 step: 5 loss: 0.004720715805888176\n",
      "eopch: 58 step: 6 loss: 0.004843483678996563\n",
      "eopch: 58 step: 7 loss: 0.00489465706050396\n",
      "eopch: 58 step: 8 loss: 0.005024350248277187\n",
      "eopch: 58 step: 9 loss: 0.004825858399271965\n",
      "eopch: 58 step: 10 loss: 0.0048918332904577255\n",
      "eopch: 58 step: 11 loss: 0.004837539978325367\n",
      "eopch: 58 step: 12 loss: 0.004733516834676266\n",
      "eopch: 58 step: 13 loss: 0.0046397605910897255\n",
      "eopch: 58 step: 14 loss: 0.004750428721308708\n",
      "eopch: 58 step: 15 loss: 0.004820225294679403\n",
      "eopch: 58 step: 16 loss: 0.004809859208762646\n",
      "eopch: 58 step: 17 loss: 0.004228285513818264\n",
      "eopch: 59 step: 1 loss: 0.004737488925457001\n",
      "eopch: 59 step: 2 loss: 0.004568088799715042\n",
      "eopch: 59 step: 3 loss: 0.004714834503829479\n",
      "eopch: 59 step: 4 loss: 0.004673428367823362\n",
      "eopch: 59 step: 5 loss: 0.004599207546561956\n",
      "eopch: 59 step: 6 loss: 0.0047188107855618\n",
      "eopch: 59 step: 7 loss: 0.004768153186887503\n",
      "eopch: 59 step: 8 loss: 0.004894960671663284\n",
      "eopch: 59 step: 9 loss: 0.004698982462286949\n",
      "eopch: 59 step: 10 loss: 0.00476406654343009\n",
      "eopch: 59 step: 11 loss: 0.0047118933871388435\n",
      "eopch: 59 step: 12 loss: 0.0046108984388411045\n",
      "eopch: 59 step: 13 loss: 0.004519813694059849\n",
      "eopch: 59 step: 14 loss: 0.00463009113445878\n",
      "eopch: 59 step: 15 loss: 0.004697435535490513\n",
      "eopch: 59 step: 16 loss: 0.00468818936496973\n",
      "eopch: 59 step: 17 loss: 0.004120039753615856\n",
      "eopch: 60 step: 1 loss: 0.004614536184817553\n",
      "eopch: 60 step: 2 loss: 0.004448100458830595\n",
      "eopch: 60 step: 3 loss: 0.004592636600136757\n",
      "eopch: 60 step: 4 loss: 0.00455052824690938\n",
      "eopch: 60 step: 5 loss: 0.004479699768126011\n",
      "eopch: 60 step: 6 loss: 0.004598631523549557\n",
      "eopch: 60 step: 7 loss: 0.0046491739340126514\n",
      "eopch: 60 step: 8 loss: 0.004774490371346474\n",
      "eopch: 60 step: 9 loss: 0.004579558968544006\n",
      "eopch: 60 step: 10 loss: 0.004642868880182505\n",
      "eopch: 60 step: 11 loss: 0.004590187221765518\n",
      "eopch: 60 step: 12 loss: 0.004492428619414568\n",
      "eopch: 60 step: 13 loss: 0.00440220208838582\n",
      "eopch: 60 step: 14 loss: 0.004511799663305283\n",
      "eopch: 60 step: 15 loss: 0.004578299820423126\n",
      "eopch: 60 step: 16 loss: 0.004571658093482256\n",
      "eopch: 60 step: 17 loss: 0.00401763990521431\n",
      "eopch: 61 step: 1 loss: 0.0044993190094828606\n",
      "eopch: 61 step: 2 loss: 0.004335150122642517\n",
      "eopch: 61 step: 3 loss: 0.00447642058134079\n",
      "eopch: 61 step: 4 loss: 0.004433176945894957\n",
      "eopch: 61 step: 5 loss: 0.00436282716691494\n",
      "eopch: 61 step: 6 loss: 0.004480817820876837\n",
      "eopch: 61 step: 7 loss: 0.004533508792519569\n",
      "eopch: 61 step: 8 loss: 0.004658485297113657\n",
      "eopch: 61 step: 9 loss: 0.004466811195015907\n",
      "eopch: 61 step: 10 loss: 0.004529152065515518\n",
      "eopch: 61 step: 11 loss: 0.004475858993828297\n",
      "eopch: 61 step: 12 loss: 0.00437937444075942\n",
      "eopch: 61 step: 13 loss: 0.004289853386580944\n",
      "eopch: 61 step: 14 loss: 0.004396725445985794\n",
      "eopch: 61 step: 15 loss: 0.0044619301334023476\n",
      "eopch: 61 step: 16 loss: 0.004456916358321905\n",
      "eopch: 61 step: 17 loss: 0.003918140660971403\n",
      "eopch: 62 step: 1 loss: 0.004389806184917688\n",
      "eopch: 62 step: 2 loss: 0.004228406585752964\n",
      "eopch: 62 step: 3 loss: 0.0043673450127244\n",
      "eopch: 62 step: 4 loss: 0.004322461783885956\n",
      "eopch: 62 step: 5 loss: 0.004252235405147076\n",
      "eopch: 62 step: 6 loss: 0.004367112647742033\n",
      "eopch: 62 step: 7 loss: 0.0044202785938978195\n",
      "eopch: 62 step: 8 loss: 0.004543464630842209\n",
      "eopch: 62 step: 9 loss: 0.004356730729341507\n",
      "eopch: 62 step: 10 loss: 0.004419378004968166\n",
      "eopch: 62 step: 11 loss: 0.004367826972156763\n",
      "eopch: 62 step: 12 loss: 0.004272934049367905\n",
      "eopch: 62 step: 13 loss: 0.004183475859463215\n",
      "eopch: 62 step: 14 loss: 0.00428724754601717\n",
      "eopch: 62 step: 15 loss: 0.004349882714450359\n",
      "eopch: 62 step: 16 loss: 0.004344260320067406\n",
      "eopch: 62 step: 17 loss: 0.0038195897359400988\n",
      "eopch: 63 step: 1 loss: 0.0042822654359042645\n",
      "eopch: 63 step: 2 loss: 0.004124858416616917\n",
      "eopch: 63 step: 3 loss: 0.0042634205892682076\n",
      "eopch: 63 step: 4 loss: 0.004217392764985561\n",
      "eopch: 63 step: 5 loss: 0.0041484651155769825\n",
      "eopch: 63 step: 6 loss: 0.004259455017745495\n",
      "eopch: 63 step: 7 loss: 0.004311109893023968\n",
      "eopch: 63 step: 8 loss: 0.004430773667991161\n",
      "eopch: 63 step: 9 loss: 0.004248269367963076\n",
      "eopch: 63 step: 10 loss: 0.004311913624405861\n",
      "eopch: 63 step: 11 loss: 0.004263073205947876\n",
      "eopch: 63 step: 12 loss: 0.004170523025095463\n",
      "eopch: 63 step: 13 loss: 0.00408294377848506\n",
      "eopch: 63 step: 14 loss: 0.004183795303106308\n",
      "eopch: 63 step: 15 loss: 0.004244293551892042\n",
      "eopch: 63 step: 16 loss: 0.004237532615661621\n",
      "eopch: 63 step: 17 loss: 0.0037243894767016172\n",
      "eopch: 64 step: 1 loss: 0.004177622497081757\n",
      "eopch: 64 step: 2 loss: 0.004023844376206398\n",
      "eopch: 64 step: 3 loss: 0.004161483608186245\n",
      "eopch: 64 step: 4 loss: 0.004115932621061802\n",
      "eopch: 64 step: 5 loss: 0.004048836883157492\n",
      "eopch: 64 step: 6 loss: 0.004157511051744223\n",
      "eopch: 64 step: 7 loss: 0.004207664169371128\n",
      "eopch: 64 step: 8 loss: 0.00432279659435153\n",
      "eopch: 64 step: 9 loss: 0.004143759608268738\n",
      "eopch: 64 step: 10 loss: 0.004207950085401535\n",
      "eopch: 64 step: 11 loss: 0.004160361364483833\n",
      "eopch: 64 step: 12 loss: 0.00407033646479249\n",
      "eopch: 64 step: 13 loss: 0.003985135816037655\n",
      "eopch: 64 step: 14 loss: 0.004084093030542135\n",
      "eopch: 64 step: 15 loss: 0.004143727943301201\n",
      "eopch: 64 step: 16 loss: 0.00413611251860857\n",
      "eopch: 64 step: 17 loss: 0.003633793443441391\n",
      "eopch: 65 step: 1 loss: 0.004076930694282055\n",
      "eopch: 65 step: 2 loss: 0.003925942815840244\n",
      "eopch: 65 step: 3 loss: 0.004061372950673103\n",
      "eopch: 65 step: 4 loss: 0.004016629885882139\n",
      "eopch: 65 step: 5 loss: 0.003951319493353367\n",
      "eopch: 65 step: 6 loss: 0.004058284219354391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 65 step: 7 loss: 0.004108574241399765\n",
      "eopch: 65 step: 8 loss: 0.004220670089125633\n",
      "eopch: 65 step: 9 loss: 0.004044041037559509\n",
      "eopch: 65 step: 10 loss: 0.0041082510724663734\n",
      "eopch: 65 step: 11 loss: 0.00406090822070837\n",
      "eopch: 65 step: 12 loss: 0.00397265562787652\n",
      "eopch: 65 step: 13 loss: 0.0038903795648366213\n",
      "eopch: 65 step: 14 loss: 0.003987360745668411\n",
      "eopch: 65 step: 15 loss: 0.004046839661896229\n",
      "eopch: 65 step: 16 loss: 0.004039066843688488\n",
      "eopch: 65 step: 17 loss: 0.003547617932781577\n",
      "eopch: 66 step: 1 loss: 0.003980612847954035\n",
      "eopch: 66 step: 2 loss: 0.003832610324025154\n",
      "eopch: 66 step: 3 loss: 0.003964108414947987\n",
      "eopch: 66 step: 4 loss: 0.003920335788279772\n",
      "eopch: 66 step: 5 loss: 0.0038561129476875067\n",
      "eopch: 66 step: 6 loss: 0.003961419686675072\n",
      "eopch: 66 step: 7 loss: 0.004013136029243469\n",
      "eopch: 66 step: 8 loss: 0.004123052582144737\n",
      "eopch: 66 step: 9 loss: 0.003949185833334923\n",
      "eopch: 66 step: 10 loss: 0.00401303730905056\n",
      "eopch: 66 step: 11 loss: 0.003965835087001324\n",
      "eopch: 66 step: 12 loss: 0.0038785766810178757\n",
      "eopch: 66 step: 13 loss: 0.0037982845678925514\n",
      "eopch: 66 step: 14 loss: 0.0038927141577005386\n",
      "eopch: 66 step: 15 loss: 0.003951570019125938\n",
      "eopch: 66 step: 16 loss: 0.003944488242268562\n",
      "eopch: 66 step: 17 loss: 0.003465084359049797\n",
      "eopch: 67 step: 1 loss: 0.0038882396183907986\n",
      "eopch: 67 step: 2 loss: 0.0037444038316607475\n",
      "eopch: 67 step: 3 loss: 0.003871538443490863\n",
      "eopch: 67 step: 4 loss: 0.0038281078450381756\n",
      "eopch: 67 step: 5 loss: 0.003764378372579813\n",
      "eopch: 67 step: 6 loss: 0.0038674643728882074\n",
      "eopch: 67 step: 7 loss: 0.00391974113881588\n",
      "eopch: 67 step: 8 loss: 0.00402810238301754\n",
      "eopch: 67 step: 9 loss: 0.0038578235544264317\n",
      "eopch: 67 step: 10 loss: 0.003921938128769398\n",
      "eopch: 67 step: 11 loss: 0.003875366412103176\n",
      "eopch: 67 step: 12 loss: 0.0037894202396273613\n",
      "eopch: 67 step: 13 loss: 0.003709560725837946\n",
      "eopch: 67 step: 14 loss: 0.0038013439625501633\n",
      "eopch: 67 step: 15 loss: 0.0038586375303566456\n",
      "eopch: 67 step: 16 loss: 0.0038521226961165667\n",
      "eopch: 67 step: 17 loss: 0.0033848013263195753\n",
      "eopch: 68 step: 1 loss: 0.0037988098338246346\n",
      "eopch: 68 step: 2 loss: 0.0036595878191292286\n",
      "eopch: 68 step: 3 loss: 0.003783217165619135\n",
      "eopch: 68 step: 4 loss: 0.003740401938557625\n",
      "eopch: 68 step: 5 loss: 0.0036765444092452526\n",
      "eopch: 68 step: 6 loss: 0.0037766708992421627\n",
      "eopch: 68 step: 7 loss: 0.0038285162299871445\n",
      "eopch: 68 step: 8 loss: 0.0039346469566226006\n",
      "eopch: 68 step: 9 loss: 0.003769136732444167\n",
      "eopch: 68 step: 10 loss: 0.0038331844843924046\n",
      "eopch: 68 step: 11 loss: 0.0037880404852330685\n",
      "eopch: 68 step: 12 loss: 0.003704526461660862\n",
      "eopch: 68 step: 13 loss: 0.0036245936062186956\n",
      "eopch: 68 step: 14 loss: 0.003713748184964061\n",
      "eopch: 68 step: 15 loss: 0.003768621478229761\n",
      "eopch: 68 step: 16 loss: 0.0037627816200256348\n",
      "eopch: 68 step: 17 loss: 0.003307138569653034\n",
      "eopch: 69 step: 1 loss: 0.0037119395565241575\n",
      "eopch: 69 step: 2 loss: 0.0035772905685007572\n",
      "eopch: 69 step: 3 loss: 0.0036982824094593525\n",
      "eopch: 69 step: 4 loss: 0.003656465793028474\n",
      "eopch: 69 step: 5 loss: 0.0035931479651480913\n",
      "eopch: 69 step: 6 loss: 0.0036897866521030664\n",
      "eopch: 69 step: 7 loss: 0.003740405896678567\n",
      "eopch: 69 step: 8 loss: 0.0038437768816947937\n",
      "eopch: 69 step: 9 loss: 0.0036825230345129967\n",
      "eopch: 69 step: 10 loss: 0.0037467293441295624\n",
      "eopch: 69 step: 11 loss: 0.0037033038679510355\n",
      "eopch: 69 step: 12 loss: 0.0036233593709766865\n",
      "eopch: 69 step: 13 loss: 0.003543848404660821\n",
      "eopch: 69 step: 14 loss: 0.0036304232198745012\n",
      "eopch: 69 step: 15 loss: 0.003682418493553996\n",
      "eopch: 69 step: 16 loss: 0.0036767348647117615\n",
      "eopch: 69 step: 17 loss: 0.003231470473110676\n",
      "eopch: 70 step: 1 loss: 0.003627158235758543\n",
      "eopch: 70 step: 2 loss: 0.0034969965927302837\n",
      "eopch: 70 step: 3 loss: 0.003616178408265114\n",
      "eopch: 70 step: 4 loss: 0.003575582057237625\n",
      "eopch: 70 step: 5 loss: 0.003513150382786989\n",
      "eopch: 70 step: 6 loss: 0.0036068144254386425\n",
      "eopch: 70 step: 7 loss: 0.0036557307466864586\n",
      "eopch: 70 step: 8 loss: 0.003756376449018717\n",
      "eopch: 70 step: 9 loss: 0.0035988111048936844\n",
      "eopch: 70 step: 10 loss: 0.0036621345207095146\n",
      "eopch: 70 step: 11 loss: 0.0036203598137944937\n",
      "eopch: 70 step: 12 loss: 0.003544178791344166\n",
      "eopch: 70 step: 13 loss: 0.0034662350080907345\n",
      "eopch: 70 step: 14 loss: 0.0035506899002939463\n",
      "eopch: 70 step: 15 loss: 0.003600319614633918\n",
      "eopch: 70 step: 16 loss: 0.003594186156988144\n",
      "eopch: 70 step: 17 loss: 0.003158483188599348\n",
      "eopch: 71 step: 1 loss: 0.0035447932314127684\n",
      "eopch: 71 step: 2 loss: 0.003418328706175089\n",
      "eopch: 71 step: 3 loss: 0.0035361903719604015\n",
      "eopch: 71 step: 4 loss: 0.0034971660934388638\n",
      "eopch: 71 step: 5 loss: 0.0034362073056399822\n",
      "eopch: 71 step: 6 loss: 0.0035275996197015047\n",
      "eopch: 71 step: 7 loss: 0.003574803238734603\n",
      "eopch: 71 step: 8 loss: 0.0036729867570102215\n",
      "eopch: 71 step: 9 loss: 0.0035180128179490566\n",
      "eopch: 71 step: 10 loss: 0.0035803131759166718\n",
      "eopch: 71 step: 11 loss: 0.0035397822503000498\n",
      "eopch: 71 step: 12 loss: 0.003466981928795576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3a81bf3c3631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moptm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eopch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, ohev, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        ohev = Variable(ohev.float()).cuda()\n",
    "        pred = new_model(img)\n",
    "        loss = loss_func(pred, ohev)\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
