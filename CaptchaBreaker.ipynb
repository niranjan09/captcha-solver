{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CHAR_COUNT = 26 + 10\n",
    "TOTAL_CAPTCHA_LEN = 5\n",
    "CHAR_SET = []\n",
    "for num in range(10):\n",
    "    CHAR_SET.append(str(num))\n",
    "for chari in range(97, 97+26):\n",
    "    CHAR_SET.append(chr(chari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHotEncoding(s):\n",
    "    ohev = torch.zeros(TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, dtype = torch.float32)\n",
    "    for ind in range(TOTAL_CAPTCHA_LEN):\n",
    "        c = s[ind]\n",
    "        ohev[TOTAL_CHAR_COUNT*ind + CHAR_SET.index(c)] = 1\n",
    "    return ohev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_list = os.listdir(self.img_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        img = Image.open(self.img_path +'/'+ img_name)\n",
    "        img = img.convert('L')\n",
    "        label = (img_name)[:-4]\n",
    "        #print(label)\n",
    "        ohev = getOneHotEncoding(label)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, ohev, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H, IMG_W = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([IMG_H, IMG_W]),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CaptchaDataset('./CaptchaDataset', transform=transform)\n",
    "test_ds = CaptchaDataset('./Captcha_Dataset', transform = transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model = models.DenseNet(growth_rate=32, block_config=(2, 4, 12, 8), num_classes = TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT)\n",
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "        self.fcl = nn.Linear(in_features = 512,out_features=TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.model = models.resnet18(pretrained = False)\n",
    "        self.model = nn.Sequential(*list(model.children())[1:-1])\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.model(out)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fcl(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=True)\n",
    "# fcl = nn.Linear(in_features = 32768,out_features=TOTAL_CAPTCHA_LEN*TOTAL_CHAR_COUNT, bias=True)\n",
    "# new_model = nn.Sequential(conv0, *list(model.children())[1:-1], fcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optm = torch.optim.Adam(new_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (fcl): Linear(in_features=512, out_features=180, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (model): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1 loss: 0.9657447338104248\n",
      "epoch: 1 step: 2 loss: 0.9563207626342773\n",
      "epoch: 1 step: 3 loss: 0.9480096697807312\n",
      "epoch: 1 step: 4 loss: 0.939012885093689\n",
      "epoch: 1 step: 5 loss: 0.9301823377609253\n",
      "epoch: 1 step: 6 loss: 0.9213101267814636\n",
      "epoch: 1 step: 7 loss: 0.912197470664978\n",
      "epoch: 1 step: 8 loss: 0.9034605026245117\n",
      "epoch: 1 step: 9 loss: 0.895052969455719\n",
      "epoch: 1 step: 10 loss: 0.8869868516921997\n",
      "epoch: 1 step: 11 loss: 0.8794848918914795\n",
      "epoch: 1 step: 12 loss: 0.8719866275787354\n",
      "epoch: 1 step: 13 loss: 0.8640562295913696\n",
      "epoch: 1 step: 14 loss: 0.8570289611816406\n",
      "epoch: 1 step: 15 loss: 0.8502120971679688\n",
      "epoch: 1 step: 16 loss: 0.8437094688415527\n",
      "epoch: 1 step: 17 loss: 0.8368910551071167\n",
      "epoch: 1 step: 18 loss: 0.8307280540466309\n",
      "epoch: 1 step: 19 loss: 0.8246472477912903\n",
      "epoch: 1 step: 20 loss: 0.8187631368637085\n",
      "epoch: 1 step: 21 loss: 0.8134739398956299\n",
      "epoch: 1 step: 22 loss: 0.807634711265564\n",
      "epoch: 1 step: 23 loss: 0.802193284034729\n",
      "epoch: 1 step: 24 loss: 0.7975358963012695\n",
      "epoch: 1 step: 25 loss: 0.7926924228668213\n",
      "epoch: 1 step: 26 loss: 0.7882071137428284\n",
      "epoch: 1 step: 27 loss: 0.7836489081382751\n",
      "epoch: 1 step: 28 loss: 0.7793349027633667\n",
      "epoch: 1 step: 29 loss: 0.7755130529403687\n",
      "epoch: 1 step: 30 loss: 0.7713304758071899\n",
      "epoch: 1 step: 31 loss: 0.7677807807922363\n",
      "epoch: 1 step: 32 loss: 0.7641686797142029\n",
      "epoch: 1 step: 33 loss: 0.7611875534057617\n",
      "epoch: 1 step: 34 loss: 0.7578130960464478\n",
      "epoch: 1 step: 35 loss: 0.7546989917755127\n",
      "epoch: 1 step: 36 loss: 0.75163334608078\n",
      "epoch: 1 step: 37 loss: 0.7490547895431519\n",
      "epoch: 1 step: 38 loss: 0.7463647127151489\n",
      "epoch: 1 step: 39 loss: 0.7438629865646362\n",
      "epoch: 1 step: 40 loss: 0.7415443658828735\n",
      "epoch: 1 step: 41 loss: 0.7394098043441772\n",
      "epoch: 1 step: 42 loss: 0.7371953725814819\n",
      "epoch: 1 step: 43 loss: 0.7351935505867004\n",
      "epoch: 1 step: 44 loss: 0.7334296107292175\n",
      "epoch: 1 step: 45 loss: 0.7316651344299316\n",
      "epoch: 1 step: 46 loss: 0.7299372553825378\n",
      "epoch: 1 step: 47 loss: 0.7283243536949158\n",
      "epoch: 1 step: 48 loss: 0.7269810438156128\n",
      "epoch: 1 step: 49 loss: 0.7256150245666504\n",
      "epoch: 1 step: 50 loss: 0.7243267297744751\n",
      "epoch: 1 step: 51 loss: 0.7230184078216553\n",
      "epoch: 1 step: 52 loss: 0.7218631505966187\n",
      "epoch: 1 step: 53 loss: 0.7206981182098389\n",
      "epoch: 1 step: 54 loss: 0.7196624279022217\n",
      "epoch: 1 step: 55 loss: 0.7186641693115234\n",
      "epoch: 1 step: 56 loss: 0.7176917791366577\n",
      "epoch: 1 step: 57 loss: 0.7168732285499573\n",
      "epoch: 1 step: 58 loss: 0.7160131931304932\n",
      "epoch: 1 step: 59 loss: 0.7151608467102051\n",
      "epoch: 1 step: 60 loss: 0.7144252061843872\n",
      "epoch: 1 step: 61 loss: 0.7136549949645996\n",
      "epoch: 1 step: 62 loss: 0.7129608392715454\n",
      "epoch: 1 step: 63 loss: 0.7123441696166992\n",
      "epoch: 1 step: 64 loss: 0.7117725014686584\n",
      "epoch: 1 step: 65 loss: 0.7112613320350647\n",
      "epoch: 1 step: 66 loss: 0.7106084823608398\n",
      "epoch: 1 step: 67 loss: 0.710089921951294\n",
      "epoch: 1 step: 68 loss: 0.7096649408340454\n",
      "epoch: 1 step: 69 loss: 0.7091526389122009\n",
      "epoch: 1 step: 70 loss: 0.7086808085441589\n",
      "epoch: 1 step: 71 loss: 0.7082921266555786\n",
      "epoch: 1 step: 72 loss: 0.7078428268432617\n",
      "epoch: 1 step: 73 loss: 0.7074863910675049\n",
      "epoch: 1 step: 74 loss: 0.7071104049682617\n",
      "epoch: 1 step: 75 loss: 0.7067493200302124\n",
      "epoch: 1 step: 76 loss: 0.7064033150672913\n",
      "epoch: 1 step: 77 loss: 0.7060840725898743\n",
      "epoch: 1 step: 78 loss: 0.7057554721832275\n",
      "epoch: 1 step: 79 loss: 0.7054857611656189\n",
      "epoch: 1 step: 80 loss: 0.7051652669906616\n",
      "epoch: 1 step: 81 loss: 0.704901933670044\n",
      "epoch: 1 step: 82 loss: 0.7046176195144653\n",
      "epoch: 1 step: 83 loss: 0.7043737173080444\n",
      "epoch: 1 step: 84 loss: 0.7041263580322266\n",
      "epoch: 1 step: 85 loss: 0.7038988471031189\n",
      "epoch: 1 step: 86 loss: 0.7036647796630859\n",
      "epoch: 1 step: 87 loss: 0.7034337520599365\n",
      "epoch: 1 step: 88 loss: 0.7032362222671509\n",
      "epoch: 1 step: 89 loss: 0.7030287384986877\n",
      "epoch: 1 step: 90 loss: 0.7028224468231201\n",
      "epoch: 1 step: 91 loss: 0.7026263475418091\n",
      "epoch: 1 step: 92 loss: 0.70245760679245\n",
      "epoch: 1 step: 93 loss: 0.7022709846496582\n",
      "epoch: 1 step: 94 loss: 0.7021034955978394\n",
      "epoch: 1 step: 95 loss: 0.7019445896148682\n",
      "epoch: 1 step: 96 loss: 0.7017768621444702\n",
      "epoch: 1 step: 97 loss: 0.7016144394874573\n",
      "epoch: 1 step: 98 loss: 0.7014738321304321\n",
      "epoch: 1 step: 99 loss: 0.7013282179832458\n",
      "epoch: 1 step: 100 loss: 0.7011921405792236\n",
      "epoch: 1 step: 101 loss: 0.7010452747344971\n",
      "epoch: 1 step: 102 loss: 0.7009260654449463\n",
      "epoch: 1 step: 103 loss: 0.7007855772972107\n",
      "epoch: 1 step: 104 loss: 0.7006696462631226\n",
      "epoch: 1 step: 105 loss: 0.700543999671936\n",
      "epoch: 1 step: 106 loss: 0.7004154920578003\n",
      "epoch: 1 step: 107 loss: 0.7003186345100403\n",
      "epoch: 1 step: 108 loss: 0.7001920938491821\n",
      "epoch: 1 step: 109 loss: 0.700076162815094\n",
      "epoch: 1 step: 110 loss: 0.6999830007553101\n",
      "epoch: 1 step: 111 loss: 0.6998854875564575\n",
      "epoch: 1 step: 112 loss: 0.6997714042663574\n",
      "epoch: 1 step: 113 loss: 0.6996933221817017\n",
      "epoch: 1 step: 114 loss: 0.6995950937271118\n",
      "epoch: 1 step: 115 loss: 0.6994792222976685\n",
      "epoch: 1 step: 116 loss: 0.6993955373764038\n",
      "epoch: 1 step: 117 loss: 0.6993061900138855\n",
      "epoch: 1 step: 118 loss: 0.699209451675415\n",
      "epoch: 1 step: 119 loss: 0.6991294622421265\n",
      "epoch: 1 step: 120 loss: 0.6990506052970886\n",
      "epoch: 1 step: 121 loss: 0.6989641785621643\n",
      "epoch: 1 step: 122 loss: 0.698898434638977\n",
      "epoch: 1 step: 123 loss: 0.6988186836242676\n",
      "epoch: 1 step: 124 loss: 0.6987354755401611\n",
      "epoch: 1 step: 125 loss: 0.6986716389656067\n",
      "epoch: 1 step: 126 loss: 0.6985907554626465\n",
      "epoch: 1 step: 127 loss: 0.6985352635383606\n",
      "epoch: 1 step: 128 loss: 0.6984604597091675\n",
      "epoch: 1 step: 129 loss: 0.6983903050422668\n",
      "epoch: 1 step: 130 loss: 0.6983208060264587\n",
      "epoch: 1 step: 131 loss: 0.6982625722885132\n",
      "epoch: 1 step: 132 loss: 0.6981961727142334\n",
      "epoch: 1 step: 133 loss: 0.698140025138855\n",
      "epoch: 1 step: 134 loss: 0.6980675458908081\n",
      "epoch: 1 step: 135 loss: 0.6980117559432983\n",
      "epoch: 1 step: 136 loss: 0.6979577541351318\n",
      "epoch: 1 step: 137 loss: 0.6978970766067505\n",
      "epoch: 1 step: 138 loss: 0.6978406310081482\n",
      "epoch: 1 step: 139 loss: 0.697793185710907\n",
      "epoch: 1 step: 140 loss: 0.6977317929267883\n",
      "epoch: 1 step: 141 loss: 0.6976776123046875\n",
      "epoch: 1 step: 142 loss: 0.6976252198219299\n",
      "epoch: 1 step: 143 loss: 0.6975787878036499\n",
      "epoch: 1 step: 144 loss: 0.6975298523902893\n",
      "epoch: 1 step: 145 loss: 0.6974806785583496\n",
      "epoch: 1 step: 146 loss: 0.6974313259124756\n",
      "epoch: 1 step: 147 loss: 0.6973865628242493\n",
      "epoch: 1 step: 148 loss: 0.697332501411438\n",
      "epoch: 1 step: 149 loss: 0.6972939372062683\n",
      "epoch: 1 step: 150 loss: 0.6972447633743286\n",
      "epoch: 1 step: 151 loss: 0.697198212146759\n",
      "epoch: 1 step: 152 loss: 0.6971547603607178\n",
      "epoch: 1 step: 153 loss: 0.6971244812011719\n",
      "epoch: 1 step: 154 loss: 0.6970745325088501\n",
      "epoch: 1 step: 155 loss: 0.6970434188842773\n",
      "epoch: 1 step: 156 loss: 0.6969881057739258\n",
      "epoch: 1 step: 157 loss: 0.6969563364982605\n",
      "epoch: 1 step: 158 loss: 0.696918249130249\n",
      "epoch: 1 step: 159 loss: 0.6968767642974854\n",
      "epoch: 1 step: 160 loss: 0.6968410611152649\n",
      "epoch: 1 step: 161 loss: 0.6968083381652832\n",
      "epoch: 1 step: 162 loss: 0.6967698931694031\n",
      "epoch: 1 step: 163 loss: 0.6967339515686035\n",
      "epoch: 1 step: 164 loss: 0.696697473526001\n",
      "epoch: 1 step: 165 loss: 0.6966614723205566\n",
      "epoch: 1 step: 166 loss: 0.6966261863708496\n",
      "epoch: 1 step: 167 loss: 0.6965994834899902\n",
      "epoch: 1 step: 168 loss: 0.6965653896331787\n",
      "epoch: 1 step: 169 loss: 0.6965296864509583\n",
      "epoch: 1 step: 170 loss: 0.6964966058731079\n",
      "epoch: 1 step: 171 loss: 0.6964721083641052\n",
      "epoch: 1 step: 172 loss: 0.6964422464370728\n",
      "epoch: 1 step: 173 loss: 0.6964080333709717\n",
      "epoch: 1 step: 174 loss: 0.6963740587234497\n",
      "epoch: 1 step: 175 loss: 0.6963499784469604\n",
      "epoch: 1 step: 176 loss: 0.6963179707527161\n",
      "epoch: 1 step: 177 loss: 0.696289598941803\n",
      "epoch: 1 step: 178 loss: 0.696263313293457\n",
      "epoch: 1 step: 179 loss: 0.6962306499481201\n",
      "epoch: 1 step: 180 loss: 0.6962056159973145\n",
      "epoch: 1 step: 181 loss: 0.6961809396743774\n",
      "epoch: 1 step: 182 loss: 0.6961463689804077\n",
      "epoch: 1 step: 183 loss: 0.6961296796798706\n",
      "epoch: 1 step: 184 loss: 0.6961039304733276\n",
      "epoch: 1 step: 185 loss: 0.6960739493370056\n",
      "epoch: 1 step: 186 loss: 0.6960541009902954\n",
      "epoch: 1 step: 187 loss: 0.6960258483886719\n",
      "epoch: 1 step: 188 loss: 0.6960030794143677\n",
      "epoch: 1 step: 189 loss: 0.6959794759750366\n",
      "epoch: 1 step: 190 loss: 0.6959564089775085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 191 loss: 0.6959306001663208\n",
      "epoch: 1 step: 192 loss: 0.6959131956100464\n",
      "epoch: 1 step: 193 loss: 0.6958845257759094\n",
      "epoch: 1 step: 194 loss: 0.695857048034668\n",
      "epoch: 1 step: 195 loss: 0.6958396434783936\n",
      "epoch: 1 step: 196 loss: 0.6958187818527222\n",
      "epoch: 1 step: 197 loss: 0.6957980394363403\n",
      "epoch: 1 step: 198 loss: 0.6957738399505615\n",
      "epoch: 1 step: 199 loss: 0.6957542300224304\n",
      "epoch: 1 step: 200 loss: 0.6957309246063232\n",
      "epoch: 1 step: 201 loss: 0.6957130432128906\n",
      "epoch: 1 step: 202 loss: 0.695692777633667\n",
      "epoch: 1 step: 203 loss: 0.6956695914268494\n",
      "epoch: 1 step: 204 loss: 0.6956502199172974\n",
      "epoch: 1 step: 205 loss: 0.6956386566162109\n",
      "epoch: 1 step: 206 loss: 0.6956139802932739\n",
      "epoch: 1 step: 207 loss: 0.6955956220626831\n",
      "epoch: 1 step: 208 loss: 0.695579469203949\n",
      "epoch: 1 step: 209 loss: 0.695555567741394\n",
      "epoch: 1 step: 210 loss: 0.6955392360687256\n",
      "epoch: 1 step: 211 loss: 0.6955244541168213\n",
      "epoch: 1 step: 212 loss: 0.6955043077468872\n",
      "epoch: 1 step: 213 loss: 0.6954880356788635\n",
      "epoch: 1 step: 214 loss: 0.6954695582389832\n",
      "epoch: 1 step: 215 loss: 0.6954535245895386\n",
      "epoch: 1 step: 216 loss: 0.6954347491264343\n",
      "epoch: 1 step: 217 loss: 0.6954153180122375\n",
      "epoch: 1 step: 218 loss: 0.6954050064086914\n",
      "epoch: 1 step: 219 loss: 0.6953862309455872\n",
      "epoch: 1 step: 220 loss: 0.6953704357147217\n",
      "epoch: 1 step: 221 loss: 0.6953537464141846\n",
      "epoch: 1 step: 222 loss: 0.6953381896018982\n",
      "epoch: 1 step: 223 loss: 0.6953217387199402\n",
      "epoch: 1 step: 224 loss: 0.6953076720237732\n",
      "epoch: 1 step: 225 loss: 0.6952921748161316\n",
      "epoch: 1 step: 226 loss: 0.695275068283081\n",
      "epoch: 1 step: 227 loss: 0.6952601671218872\n",
      "epoch: 1 step: 228 loss: 0.6952462792396545\n",
      "epoch: 1 step: 229 loss: 0.6952345967292786\n",
      "epoch: 1 step: 230 loss: 0.695220947265625\n",
      "epoch: 1 step: 231 loss: 0.6952039003372192\n",
      "epoch: 1 step: 232 loss: 0.6951898336410522\n",
      "epoch: 1 step: 233 loss: 0.6951742172241211\n",
      "epoch: 1 step: 234 loss: 0.6951651573181152\n",
      "epoch: 1 step: 235 loss: 0.6951476335525513\n",
      "epoch: 1 step: 236 loss: 0.6951373815536499\n",
      "epoch: 1 step: 237 loss: 0.6951196789741516\n",
      "epoch: 1 step: 238 loss: 0.69510817527771\n",
      "epoch: 1 step: 239 loss: 0.6950962543487549\n",
      "epoch: 1 step: 240 loss: 0.6950830817222595\n",
      "epoch: 1 step: 241 loss: 0.6950697898864746\n",
      "epoch: 1 step: 242 loss: 0.6950607895851135\n",
      "epoch: 1 step: 243 loss: 0.6950451135635376\n",
      "epoch: 1 step: 244 loss: 0.6950336694717407\n",
      "epoch: 1 step: 245 loss: 0.6950197219848633\n",
      "epoch: 1 step: 246 loss: 0.6950080394744873\n",
      "epoch: 1 step: 247 loss: 0.6949976682662964\n",
      "epoch: 1 step: 248 loss: 0.6949843168258667\n",
      "epoch: 1 step: 249 loss: 0.6949726343154907\n",
      "epoch: 1 step: 250 loss: 0.6949601173400879\n",
      "epoch: 1 step: 251 loss: 0.6949516534805298\n",
      "epoch: 1 step: 252 loss: 0.6949384808540344\n",
      "epoch: 1 step: 253 loss: 0.6949288845062256\n",
      "epoch: 1 step: 254 loss: 0.6949151754379272\n",
      "epoch: 1 step: 255 loss: 0.6949079036712646\n",
      "epoch: 1 step: 256 loss: 0.6948947906494141\n",
      "epoch: 1 step: 257 loss: 0.6948802471160889\n",
      "epoch: 1 step: 258 loss: 0.6948727369308472\n",
      "epoch: 1 step: 259 loss: 0.6948614120483398\n",
      "epoch: 1 step: 260 loss: 0.6948477029800415\n",
      "epoch: 1 step: 261 loss: 0.694842517375946\n",
      "epoch: 1 step: 262 loss: 0.6948290467262268\n",
      "epoch: 1 step: 263 loss: 0.6948197484016418\n",
      "epoch: 1 step: 264 loss: 0.6948118209838867\n",
      "epoch: 1 step: 265 loss: 0.6948020458221436\n",
      "epoch: 1 step: 266 loss: 0.6947895288467407\n",
      "epoch: 1 step: 267 loss: 0.6947821378707886\n",
      "epoch: 1 step: 268 loss: 0.694770872592926\n",
      "epoch: 1 step: 269 loss: 0.6947639584541321\n",
      "epoch: 1 step: 270 loss: 0.6947523355484009\n",
      "epoch: 1 step: 271 loss: 0.6947433352470398\n",
      "epoch: 1 step: 272 loss: 0.6947323083877563\n",
      "epoch: 1 step: 273 loss: 0.6947227716445923\n",
      "epoch: 1 step: 274 loss: 0.6947144865989685\n",
      "epoch: 1 step: 275 loss: 0.6947054862976074\n",
      "epoch: 1 step: 276 loss: 0.6946980357170105\n",
      "epoch: 1 step: 277 loss: 0.6946873664855957\n",
      "epoch: 1 step: 278 loss: 0.6946748495101929\n",
      "epoch: 1 step: 279 loss: 0.6946700811386108\n",
      "epoch: 1 step: 280 loss: 0.6946609020233154\n",
      "epoch: 1 step: 281 loss: 0.6946545839309692\n",
      "epoch: 1 step: 282 loss: 0.6946431398391724\n",
      "epoch: 1 step: 283 loss: 0.6946364641189575\n",
      "epoch: 1 step: 284 loss: 0.6946274638175964\n",
      "epoch: 1 step: 285 loss: 0.6946200728416443\n",
      "epoch: 1 step: 286 loss: 0.6946130394935608\n",
      "epoch: 1 step: 287 loss: 0.6946032643318176\n",
      "epoch: 1 step: 288 loss: 0.6945953369140625\n",
      "epoch: 1 step: 289 loss: 0.6945885419845581\n",
      "epoch: 1 step: 290 loss: 0.6945789456367493\n",
      "epoch: 1 step: 291 loss: 0.6945716738700867\n",
      "epoch: 1 step: 292 loss: 0.6945630311965942\n",
      "epoch: 1 step: 293 loss: 0.6945574283599854\n",
      "epoch: 1 step: 294 loss: 0.6945470571517944\n",
      "epoch: 1 step: 295 loss: 0.6945409774780273\n",
      "epoch: 1 step: 296 loss: 0.6945326328277588\n",
      "epoch: 1 step: 297 loss: 0.6945253610610962\n",
      "epoch: 1 step: 298 loss: 0.6945188045501709\n",
      "epoch: 1 step: 299 loss: 0.6945112347602844\n",
      "epoch: 1 step: 300 loss: 0.6945031881332397\n",
      "epoch: 1 step: 301 loss: 0.69449782371521\n",
      "epoch: 1 step: 302 loss: 0.6944913268089294\n",
      "epoch: 1 step: 303 loss: 0.6944832801818848\n",
      "epoch: 1 step: 304 loss: 0.6944772601127625\n",
      "epoch: 1 step: 305 loss: 0.6944719552993774\n",
      "epoch: 1 step: 306 loss: 0.6944612860679626\n",
      "epoch: 1 step: 307 loss: 0.6944570541381836\n",
      "epoch: 1 step: 308 loss: 0.6944503784179688\n",
      "epoch: 1 step: 309 loss: 0.6944416165351868\n",
      "epoch: 1 step: 310 loss: 0.694436252117157\n",
      "epoch: 1 step: 311 loss: 0.6944316029548645\n",
      "epoch: 1 step: 312 loss: 0.6944249868392944\n",
      "epoch: 1 step: 313 loss: 0.6944152116775513\n",
      "epoch: 1 step: 314 loss: 0.6944091320037842\n",
      "epoch: 1 step: 315 loss: 0.6944057941436768\n",
      "epoch: 1 step: 316 loss: 0.6943979263305664\n",
      "epoch: 1 step: 317 loss: 0.6943882703781128\n",
      "epoch: 1 step: 318 loss: 0.6943850517272949\n",
      "epoch: 1 step: 319 loss: 0.6943773031234741\n",
      "epoch: 1 step: 320 loss: 0.6943725347518921\n",
      "epoch: 1 step: 321 loss: 0.6943657994270325\n",
      "epoch: 1 step: 322 loss: 0.694360077381134\n",
      "epoch: 1 step: 323 loss: 0.694355309009552\n",
      "epoch: 1 step: 324 loss: 0.6943466067314148\n",
      "epoch: 1 step: 325 loss: 0.6943429112434387\n",
      "epoch: 1 step: 326 loss: 0.6943349242210388\n",
      "epoch: 1 step: 327 loss: 0.6943302750587463\n",
      "epoch: 1 step: 328 loss: 0.6943260431289673\n",
      "epoch: 1 step: 329 loss: 0.6943191289901733\n",
      "epoch: 1 step: 330 loss: 0.6943120956420898\n",
      "epoch: 1 step: 331 loss: 0.6943085193634033\n",
      "epoch: 1 step: 332 loss: 0.6943018436431885\n",
      "epoch: 1 step: 333 loss: 0.694297194480896\n",
      "epoch: 1 step: 334 loss: 0.6942914724349976\n",
      "epoch: 1 step: 335 loss: 0.694286584854126\n",
      "epoch: 1 step: 336 loss: 0.6942789554595947\n",
      "epoch: 1 step: 337 loss: 0.6942753791809082\n",
      "epoch: 1 step: 338 loss: 0.6942703723907471\n",
      "epoch: 1 step: 339 loss: 0.6942652463912964\n",
      "epoch: 1 step: 340 loss: 0.6942567825317383\n",
      "epoch: 1 step: 341 loss: 0.694254994392395\n",
      "epoch: 1 step: 342 loss: 0.6942506432533264\n",
      "epoch: 1 step: 343 loss: 0.6942424178123474\n",
      "epoch: 1 step: 344 loss: 0.694238543510437\n",
      "epoch: 1 step: 345 loss: 0.6942331790924072\n",
      "epoch: 1 step: 346 loss: 0.6942269802093506\n",
      "epoch: 1 step: 347 loss: 0.6942243576049805\n",
      "epoch: 1 step: 348 loss: 0.6942188143730164\n",
      "epoch: 1 step: 349 loss: 0.6942158341407776\n",
      "epoch: 1 step: 350 loss: 0.6942076086997986\n",
      "epoch: 1 step: 351 loss: 0.6942045092582703\n",
      "epoch: 1 step: 352 loss: 0.6941993832588196\n",
      "epoch: 1 step: 353 loss: 0.6941954493522644\n",
      "epoch: 1 step: 354 loss: 0.6941909193992615\n",
      "epoch: 1 step: 355 loss: 0.6941843032836914\n",
      "epoch: 1 step: 356 loss: 0.694180965423584\n",
      "epoch: 1 step: 357 loss: 0.6941766738891602\n",
      "epoch: 1 step: 358 loss: 0.6941705942153931\n",
      "epoch: 1 step: 359 loss: 0.6941665410995483\n",
      "epoch: 1 step: 360 loss: 0.6941633224487305\n",
      "epoch: 1 step: 361 loss: 0.6941567659378052\n",
      "epoch: 1 step: 362 loss: 0.694153904914856\n",
      "epoch: 1 step: 363 loss: 0.6941483616828918\n",
      "epoch: 1 step: 364 loss: 0.6941457986831665\n",
      "epoch: 1 step: 365 loss: 0.6941404342651367\n",
      "epoch: 1 step: 366 loss: 0.6941357851028442\n",
      "epoch: 1 step: 367 loss: 0.6941312551498413\n",
      "epoch: 1 step: 368 loss: 0.6941269636154175\n",
      "epoch: 1 step: 369 loss: 0.6941226720809937\n",
      "epoch: 1 step: 370 loss: 0.6941179633140564\n",
      "epoch: 1 step: 371 loss: 0.6941157579421997\n",
      "epoch: 1 step: 372 loss: 0.6941102743148804\n",
      "epoch: 1 step: 373 loss: 0.694107174873352\n",
      "epoch: 1 step: 374 loss: 0.69410240650177\n",
      "epoch: 1 step: 375 loss: 0.6940993070602417\n",
      "epoch: 1 step: 376 loss: 0.6940940618515015\n",
      "epoch: 1 step: 377 loss: 0.6940916776657104\n",
      "epoch: 1 step: 378 loss: 0.6940851211547852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 379 loss: 0.6940817832946777\n",
      "epoch: 1 step: 380 loss: 0.694077730178833\n",
      "epoch: 1 step: 381 loss: 0.6940751671791077\n",
      "epoch: 1 step: 382 loss: 0.6940714716911316\n",
      "epoch: 1 step: 383 loss: 0.6940661668777466\n",
      "epoch: 1 step: 384 loss: 0.6940627098083496\n",
      "epoch: 1 step: 385 loss: 0.6940588355064392\n",
      "epoch: 1 step: 386 loss: 0.6940553188323975\n",
      "epoch: 1 step: 387 loss: 0.694051206111908\n",
      "epoch: 1 step: 388 loss: 0.6940478086471558\n",
      "epoch: 1 step: 389 loss: 0.694044828414917\n",
      "epoch: 1 step: 390 loss: 0.6940399408340454\n",
      "epoch: 1 step: 391 loss: 0.6940362453460693\n",
      "epoch: 1 step: 392 loss: 0.694034218788147\n",
      "epoch: 1 step: 393 loss: 0.6940310001373291\n",
      "epoch: 1 step: 394 loss: 0.6940263509750366\n",
      "epoch: 1 step: 395 loss: 0.6940244436264038\n",
      "epoch: 1 step: 396 loss: 0.6940188407897949\n",
      "epoch: 1 step: 397 loss: 0.6940162777900696\n",
      "epoch: 1 step: 398 loss: 0.6940112709999084\n",
      "epoch: 1 step: 399 loss: 0.6940077543258667\n",
      "epoch: 1 step: 400 loss: 0.6940048933029175\n",
      "epoch: 1 step: 401 loss: 0.6940008401870728\n",
      "epoch: 1 step: 402 loss: 0.693997859954834\n",
      "epoch: 1 step: 403 loss: 0.6939948797225952\n",
      "epoch: 1 step: 404 loss: 0.6939924955368042\n",
      "epoch: 1 step: 405 loss: 0.6939879059791565\n",
      "epoch: 1 step: 406 loss: 0.6939860582351685\n",
      "epoch: 1 step: 407 loss: 0.6939822435379028\n",
      "epoch: 1 step: 408 loss: 0.6939774751663208\n",
      "epoch: 1 step: 409 loss: 0.6939753293991089\n",
      "epoch: 1 step: 410 loss: 0.6939713954925537\n",
      "epoch: 1 step: 411 loss: 0.6939682960510254\n",
      "epoch: 1 step: 412 loss: 0.6939656734466553\n",
      "epoch: 1 step: 413 loss: 0.6939618587493896\n",
      "epoch: 1 step: 414 loss: 0.6939579248428345\n",
      "epoch: 1 step: 415 loss: 0.69395512342453\n",
      "epoch: 1 step: 416 loss: 0.6939524412155151\n",
      "epoch: 1 step: 417 loss: 0.693950355052948\n",
      "epoch: 1 step: 418 loss: 0.6939470767974854\n",
      "epoch: 1 step: 419 loss: 0.6939442157745361\n",
      "epoch: 1 step: 420 loss: 0.6939406394958496\n",
      "epoch: 1 step: 421 loss: 0.6939370632171631\n",
      "epoch: 1 step: 422 loss: 0.6939340829849243\n",
      "epoch: 1 step: 423 loss: 0.693930983543396\n",
      "epoch: 1 step: 424 loss: 0.6939287185668945\n",
      "epoch: 1 step: 425 loss: 0.6939256191253662\n",
      "epoch: 1 step: 426 loss: 0.6939233541488647\n",
      "epoch: 1 step: 427 loss: 0.6939197778701782\n",
      "epoch: 1 step: 428 loss: 0.6939159631729126\n",
      "epoch: 1 step: 429 loss: 0.6939144134521484\n",
      "epoch: 1 step: 430 loss: 0.6939114332199097\n",
      "epoch: 1 step: 431 loss: 0.6939088106155396\n",
      "epoch: 1 step: 432 loss: 0.6939050555229187\n",
      "epoch: 1 step: 433 loss: 0.6939018964767456\n",
      "epoch: 1 step: 434 loss: 0.693899393081665\n",
      "epoch: 1 step: 435 loss: 0.6938961148262024\n",
      "epoch: 1 step: 436 loss: 0.6938953399658203\n",
      "epoch: 1 step: 437 loss: 0.6938921213150024\n",
      "epoch: 1 step: 438 loss: 0.6938889622688293\n",
      "epoch: 1 step: 439 loss: 0.693886399269104\n",
      "epoch: 1 step: 440 loss: 0.6938825249671936\n",
      "epoch: 1 step: 441 loss: 0.6938804388046265\n",
      "epoch: 1 step: 442 loss: 0.693878173828125\n",
      "epoch: 1 step: 443 loss: 0.6938748359680176\n",
      "epoch: 1 step: 444 loss: 0.6938731074333191\n",
      "epoch: 1 step: 445 loss: 0.6938714981079102\n",
      "epoch: 1 step: 446 loss: 0.69386887550354\n",
      "epoch: 1 step: 447 loss: 0.6938651204109192\n",
      "epoch: 1 step: 448 loss: 0.6938632726669312\n",
      "epoch: 1 step: 449 loss: 0.6938589811325073\n",
      "epoch: 1 step: 450 loss: 0.6938578486442566\n",
      "epoch: 1 step: 451 loss: 0.6938557028770447\n",
      "epoch: 1 step: 452 loss: 0.6938521265983582\n",
      "epoch: 1 step: 453 loss: 0.6938501596450806\n",
      "epoch: 1 step: 454 loss: 0.6938474178314209\n",
      "epoch: 1 step: 455 loss: 0.693845272064209\n",
      "epoch: 1 step: 456 loss: 0.6938436627388\n",
      "epoch: 1 step: 457 loss: 0.6938390731811523\n",
      "epoch: 1 step: 458 loss: 0.6938369274139404\n",
      "epoch: 1 step: 459 loss: 0.6938340663909912\n",
      "epoch: 1 step: 460 loss: 0.6938332319259644\n",
      "epoch: 1 step: 461 loss: 0.6938308477401733\n",
      "epoch: 1 step: 462 loss: 0.6938282251358032\n",
      "epoch: 1 step: 463 loss: 0.6938262581825256\n",
      "epoch: 1 step: 464 loss: 0.6938235759735107\n",
      "epoch: 1 step: 465 loss: 0.6938210725784302\n",
      "epoch: 1 step: 466 loss: 0.6938190460205078\n",
      "epoch: 1 step: 467 loss: 0.6938169598579407\n",
      "epoch: 1 step: 468 loss: 0.6938148736953735\n",
      "epoch: 1 step: 469 loss: 0.6938120126724243\n",
      "epoch: 1 step: 470 loss: 0.6938096284866333\n",
      "epoch: 1 step: 471 loss: 0.6938076615333557\n",
      "epoch: 1 step: 472 loss: 0.6938055157661438\n",
      "epoch: 1 step: 473 loss: 0.6938034296035767\n",
      "epoch: 1 step: 474 loss: 0.6938002109527588\n",
      "epoch: 1 step: 475 loss: 0.6937982439994812\n",
      "epoch: 1 step: 476 loss: 0.6937953233718872\n",
      "epoch: 1 step: 477 loss: 0.693792998790741\n",
      "epoch: 1 step: 478 loss: 0.6937916874885559\n",
      "epoch: 1 step: 479 loss: 0.6937893033027649\n",
      "epoch: 1 step: 480 loss: 0.6937878727912903\n",
      "epoch: 1 step: 481 loss: 0.6937861442565918\n",
      "epoch: 1 step: 482 loss: 0.6937828660011292\n",
      "epoch: 1 step: 483 loss: 0.693780779838562\n",
      "epoch: 1 step: 484 loss: 0.693778932094574\n",
      "epoch: 1 step: 485 loss: 0.6937761902809143\n",
      "epoch: 1 step: 486 loss: 0.6937756538391113\n",
      "epoch: 1 step: 487 loss: 0.693773627281189\n",
      "epoch: 1 step: 488 loss: 0.6937713623046875\n",
      "epoch: 1 step: 489 loss: 0.6937685608863831\n",
      "epoch: 1 step: 490 loss: 0.6937665939331055\n",
      "epoch: 1 step: 491 loss: 0.693763792514801\n",
      "epoch: 1 step: 492 loss: 0.6937623023986816\n",
      "epoch: 1 step: 493 loss: 0.6937607526779175\n",
      "epoch: 1 step: 494 loss: 0.693759024143219\n",
      "epoch: 1 step: 495 loss: 0.6937562823295593\n",
      "epoch: 1 step: 496 loss: 0.6937552094459534\n",
      "epoch: 1 step: 497 loss: 0.6937523484230042\n",
      "epoch: 1 step: 498 loss: 0.6937512159347534\n",
      "epoch: 1 step: 499 loss: 0.693748950958252\n",
      "epoch: 1 step: 500 loss: 0.6937462687492371\n",
      "epoch: 1 step: 501 loss: 0.6937451958656311\n",
      "epoch: 1 step: 502 loss: 0.6937423944473267\n",
      "epoch: 1 step: 503 loss: 0.6937413811683655\n",
      "epoch: 1 step: 504 loss: 0.6937389373779297\n",
      "epoch: 1 step: 505 loss: 0.693738579750061\n",
      "epoch: 1 step: 506 loss: 0.6937355399131775\n",
      "epoch: 1 step: 507 loss: 0.6937328577041626\n",
      "epoch: 1 step: 508 loss: 0.6937317848205566\n",
      "epoch: 1 step: 509 loss: 0.6937292218208313\n",
      "epoch: 1 step: 510 loss: 0.6937274932861328\n",
      "epoch: 1 step: 511 loss: 0.6937259435653687\n",
      "epoch: 1 step: 512 loss: 0.6937236785888672\n",
      "epoch: 1 step: 513 loss: 0.6937219500541687\n",
      "epoch: 1 step: 514 loss: 0.6937205195426941\n",
      "epoch: 1 step: 515 loss: 0.6937187314033508\n",
      "epoch: 1 step: 516 loss: 0.6937171816825867\n",
      "epoch: 1 step: 517 loss: 0.6937149167060852\n",
      "epoch: 1 step: 518 loss: 0.6937127709388733\n",
      "epoch: 1 step: 519 loss: 0.6937111616134644\n",
      "epoch: 1 step: 520 loss: 0.6937097311019897\n",
      "epoch: 1 step: 521 loss: 0.693708598613739\n",
      "epoch: 1 step: 522 loss: 0.6937053799629211\n",
      "epoch: 1 step: 523 loss: 0.6937050819396973\n",
      "epoch: 1 step: 524 loss: 0.6937029361724854\n",
      "epoch: 1 step: 525 loss: 0.6937012076377869\n",
      "epoch: 1 step: 526 loss: 0.6936994791030884\n",
      "epoch: 1 step: 527 loss: 0.6936979293823242\n",
      "epoch: 1 step: 528 loss: 0.6936957836151123\n",
      "epoch: 1 step: 529 loss: 0.6936948299407959\n",
      "epoch: 1 step: 530 loss: 0.693692684173584\n",
      "epoch: 1 step: 531 loss: 0.6936915516853333\n",
      "epoch: 1 step: 532 loss: 0.6936895847320557\n",
      "epoch: 1 step: 533 loss: 0.6936872601509094\n",
      "epoch: 1 step: 534 loss: 0.693686842918396\n",
      "epoch: 1 step: 535 loss: 0.693684458732605\n",
      "epoch: 1 step: 536 loss: 0.6936830282211304\n",
      "epoch: 1 step: 537 loss: 0.6936817765235901\n",
      "epoch: 1 step: 538 loss: 0.6936795115470886\n",
      "epoch: 1 step: 539 loss: 0.6936780214309692\n",
      "epoch: 1 step: 540 loss: 0.6936765909194946\n",
      "epoch: 1 step: 541 loss: 0.6936750411987305\n",
      "epoch: 1 step: 542 loss: 0.6936733722686768\n",
      "epoch: 1 step: 543 loss: 0.6936713457107544\n",
      "epoch: 1 step: 544 loss: 0.6936703324317932\n",
      "epoch: 1 step: 545 loss: 0.6936689615249634\n",
      "epoch: 1 step: 546 loss: 0.693668007850647\n",
      "epoch: 1 step: 547 loss: 0.6936658620834351\n",
      "epoch: 1 step: 548 loss: 0.6936640739440918\n",
      "epoch: 1 step: 549 loss: 0.6936624646186829\n",
      "epoch: 1 step: 550 loss: 0.6936618089675903\n",
      "epoch: 1 step: 551 loss: 0.6936593055725098\n",
      "epoch: 1 step: 552 loss: 0.6936568021774292\n",
      "epoch: 1 step: 553 loss: 0.6936566829681396\n",
      "epoch: 1 step: 554 loss: 0.6936556100845337\n",
      "epoch: 1 step: 555 loss: 0.6936536431312561\n",
      "epoch: 1 step: 556 loss: 0.6936513185501099\n",
      "epoch: 1 step: 557 loss: 0.6936498284339905\n",
      "epoch: 1 step: 558 loss: 0.6936495900154114\n",
      "epoch: 1 step: 559 loss: 0.6936482191085815\n",
      "epoch: 1 step: 560 loss: 0.6936456561088562\n",
      "epoch: 1 step: 561 loss: 0.693644642829895\n",
      "epoch: 1 step: 562 loss: 0.6936430931091309\n",
      "epoch: 1 step: 563 loss: 0.6936420202255249\n",
      "epoch: 1 step: 564 loss: 0.6936408281326294\n",
      "epoch: 1 step: 565 loss: 0.6936380863189697\n",
      "epoch: 1 step: 566 loss: 0.6936377882957458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 567 loss: 0.6936357617378235\n",
      "epoch: 1 step: 568 loss: 0.6936349868774414\n",
      "epoch: 1 step: 569 loss: 0.6936330199241638\n",
      "epoch: 1 step: 570 loss: 0.6936326026916504\n",
      "epoch: 1 step: 571 loss: 0.6936309337615967\n",
      "epoch: 1 step: 572 loss: 0.6936286687850952\n",
      "epoch: 1 step: 573 loss: 0.6936275362968445\n",
      "epoch: 1 step: 574 loss: 0.6936261057853699\n",
      "epoch: 1 step: 575 loss: 0.6936255693435669\n",
      "epoch: 1 step: 576 loss: 0.6936228275299072\n",
      "epoch: 1 step: 577 loss: 0.6936219334602356\n",
      "epoch: 1 step: 578 loss: 0.6936208605766296\n",
      "epoch: 1 step: 579 loss: 0.6936203241348267\n",
      "epoch: 1 step: 580 loss: 0.6936181783676147\n",
      "epoch: 1 step: 581 loss: 0.6936172246932983\n",
      "epoch: 1 step: 582 loss: 0.6936159133911133\n",
      "epoch: 1 step: 583 loss: 0.6936147212982178\n",
      "epoch: 1 step: 584 loss: 0.6936125755310059\n",
      "epoch: 1 step: 585 loss: 0.6936126351356506\n",
      "epoch: 1 step: 586 loss: 0.6936113238334656\n",
      "epoch: 1 step: 587 loss: 0.6936095356941223\n",
      "epoch: 1 step: 588 loss: 0.6936085820198059\n",
      "epoch: 1 step: 589 loss: 0.6936063170433044\n",
      "epoch: 1 step: 590 loss: 0.693605899810791\n",
      "epoch: 1 step: 591 loss: 0.6936045289039612\n",
      "epoch: 1 step: 592 loss: 0.6936026811599731\n",
      "epoch: 1 step: 593 loss: 0.6936023235321045\n",
      "epoch: 1 step: 594 loss: 0.6936006546020508\n",
      "epoch: 1 step: 595 loss: 0.6935997009277344\n",
      "epoch: 1 step: 596 loss: 0.6935973763465881\n",
      "epoch: 1 step: 597 loss: 0.6935973167419434\n",
      "epoch: 1 step: 598 loss: 0.6935956478118896\n",
      "epoch: 1 step: 599 loss: 0.693594217300415\n",
      "epoch: 1 step: 600 loss: 0.6935936808586121\n",
      "epoch: 1 step: 601 loss: 0.6935920715332031\n",
      "epoch: 1 step: 602 loss: 0.6935908198356628\n",
      "epoch: 1 step: 603 loss: 0.6935901045799255\n",
      "epoch: 1 step: 604 loss: 0.6935874819755554\n",
      "epoch: 1 step: 605 loss: 0.6935873031616211\n",
      "epoch: 1 step: 606 loss: 0.6935861110687256\n",
      "epoch: 1 step: 607 loss: 0.693584680557251\n",
      "epoch: 1 step: 608 loss: 0.6935833096504211\n",
      "epoch: 1 step: 609 loss: 0.6935819387435913\n",
      "epoch: 1 step: 610 loss: 0.6935811042785645\n",
      "epoch: 1 step: 611 loss: 0.693579912185669\n",
      "epoch: 1 step: 612 loss: 0.6935787200927734\n",
      "epoch: 1 step: 613 loss: 0.6935781240463257\n",
      "epoch: 1 step: 614 loss: 0.6935765147209167\n",
      "epoch: 1 step: 615 loss: 0.6935751438140869\n",
      "epoch: 1 step: 616 loss: 0.6935743689537048\n",
      "epoch: 1 step: 617 loss: 0.6935732364654541\n",
      "epoch: 1 step: 618 loss: 0.6935722827911377\n",
      "epoch: 1 step: 619 loss: 0.6935707330703735\n",
      "epoch: 1 step: 620 loss: 0.6935698390007019\n",
      "epoch: 1 step: 621 loss: 0.6935683488845825\n",
      "epoch: 1 step: 622 loss: 0.6935675740242004\n",
      "epoch: 1 step: 623 loss: 0.6935659646987915\n",
      "epoch: 1 step: 624 loss: 0.6935651302337646\n",
      "epoch: 1 step: 625 loss: 0.6935639977455139\n",
      "epoch: 1 step: 626 loss: 0.6935634016990662\n",
      "epoch: 1 step: 627 loss: 0.6935621500015259\n",
      "epoch: 1 step: 628 loss: 0.693560779094696\n",
      "epoch: 1 step: 629 loss: 0.6935596466064453\n",
      "epoch: 1 step: 630 loss: 0.6935590505599976\n",
      "epoch: 1 step: 631 loss: 0.6935576796531677\n",
      "epoch: 1 step: 632 loss: 0.6935575604438782\n",
      "epoch: 1 step: 633 loss: 0.6935557126998901\n",
      "epoch: 1 step: 634 loss: 0.6935548782348633\n",
      "epoch: 1 step: 635 loss: 0.6935532093048096\n",
      "epoch: 1 step: 636 loss: 0.6935528516769409\n",
      "epoch: 1 step: 637 loss: 0.6935514807701111\n",
      "epoch: 1 step: 638 loss: 0.6935505270957947\n",
      "epoch: 1 step: 639 loss: 0.6935495138168335\n",
      "epoch: 1 step: 640 loss: 0.6935491561889648\n",
      "epoch: 1 step: 641 loss: 0.6935473680496216\n",
      "epoch: 1 step: 642 loss: 0.6935463547706604\n",
      "epoch: 1 step: 643 loss: 0.6935450434684753\n",
      "epoch: 1 step: 644 loss: 0.6935442686080933\n",
      "epoch: 1 step: 645 loss: 0.6935434341430664\n",
      "epoch: 1 step: 646 loss: 0.6935421228408813\n",
      "epoch: 1 step: 647 loss: 0.6935414671897888\n",
      "epoch: 1 step: 648 loss: 0.6935405731201172\n",
      "epoch: 1 step: 649 loss: 0.6935393810272217\n",
      "epoch: 1 step: 650 loss: 0.693537712097168\n",
      "epoch: 1 step: 651 loss: 0.6935369968414307\n",
      "epoch: 1 step: 652 loss: 0.693536102771759\n",
      "epoch: 1 step: 653 loss: 0.6935354471206665\n",
      "epoch: 1 step: 654 loss: 0.6935347318649292\n",
      "epoch: 1 step: 655 loss: 0.6935337781906128\n",
      "epoch: 1 step: 656 loss: 0.6935324668884277\n",
      "epoch: 1 step: 657 loss: 0.6935315132141113\n",
      "epoch: 1 step: 658 loss: 0.6935309171676636\n",
      "epoch: 1 step: 659 loss: 0.6935296654701233\n",
      "epoch: 1 step: 660 loss: 0.693528413772583\n",
      "epoch: 1 step: 661 loss: 0.6935279965400696\n",
      "epoch: 1 step: 662 loss: 0.6935268044471741\n",
      "epoch: 1 step: 663 loss: 0.6935257911682129\n",
      "epoch: 1 step: 664 loss: 0.693524956703186\n",
      "epoch: 1 step: 665 loss: 0.6935240030288696\n",
      "epoch: 1 step: 666 loss: 0.6935223937034607\n",
      "epoch: 1 step: 667 loss: 0.6935221552848816\n",
      "epoch: 1 step: 668 loss: 0.6935210227966309\n",
      "epoch: 1 step: 669 loss: 0.6935205459594727\n",
      "epoch: 1 step: 670 loss: 0.6935192942619324\n",
      "epoch: 1 step: 671 loss: 0.6935186386108398\n",
      "epoch: 1 step: 672 loss: 0.6935176849365234\n",
      "epoch: 1 step: 673 loss: 0.6935164928436279\n",
      "epoch: 1 step: 674 loss: 0.6935152411460876\n",
      "epoch: 1 step: 675 loss: 0.6935144066810608\n",
      "epoch: 1 step: 676 loss: 0.6935141086578369\n",
      "epoch: 1 step: 677 loss: 0.6935126185417175\n",
      "epoch: 1 step: 678 loss: 0.6935125589370728\n",
      "epoch: 1 step: 679 loss: 0.6935110092163086\n",
      "epoch: 1 step: 680 loss: 0.6935102343559265\n",
      "epoch: 1 step: 681 loss: 0.6935097575187683\n",
      "epoch: 1 step: 682 loss: 0.6935092210769653\n",
      "epoch: 1 step: 683 loss: 0.6935078501701355\n",
      "epoch: 1 step: 684 loss: 0.6935074329376221\n",
      "epoch: 1 step: 685 loss: 0.6935059428215027\n",
      "epoch: 1 step: 686 loss: 0.693504810333252\n",
      "epoch: 1 step: 687 loss: 0.6935038566589355\n",
      "epoch: 1 step: 688 loss: 0.6935036182403564\n",
      "epoch: 1 step: 689 loss: 0.6935025453567505\n",
      "epoch: 1 step: 690 loss: 0.6935014724731445\n",
      "epoch: 1 step: 691 loss: 0.6935009360313416\n",
      "epoch: 1 step: 692 loss: 0.6935001611709595\n",
      "epoch: 1 step: 693 loss: 0.6934995651245117\n",
      "epoch: 1 step: 694 loss: 0.6934983134269714\n",
      "epoch: 1 step: 695 loss: 0.6934974789619446\n",
      "epoch: 1 step: 696 loss: 0.693496823310852\n",
      "epoch: 1 step: 697 loss: 0.6934956908226013\n",
      "epoch: 1 step: 698 loss: 0.6934953927993774\n",
      "epoch: 1 step: 699 loss: 0.6934940814971924\n",
      "epoch: 1 step: 700 loss: 0.6934932470321655\n",
      "epoch: 1 step: 701 loss: 0.6934928894042969\n",
      "epoch: 1 step: 702 loss: 0.6934915781021118\n",
      "epoch: 1 step: 703 loss: 0.6934908628463745\n",
      "epoch: 1 step: 704 loss: 0.6934902667999268\n",
      "epoch: 1 step: 705 loss: 0.6934893727302551\n",
      "epoch: 1 step: 706 loss: 0.6934880614280701\n",
      "epoch: 1 step: 707 loss: 0.6934871077537537\n",
      "epoch: 1 step: 708 loss: 0.6934865713119507\n",
      "epoch: 1 step: 709 loss: 0.693486213684082\n",
      "epoch: 1 step: 710 loss: 0.6934859156608582\n",
      "epoch: 1 step: 711 loss: 0.6934844255447388\n",
      "epoch: 1 step: 712 loss: 0.6934837102890015\n",
      "epoch: 1 step: 713 loss: 0.6934830546379089\n",
      "epoch: 1 step: 714 loss: 0.6934822797775269\n",
      "epoch: 1 step: 715 loss: 0.6934818029403687\n",
      "epoch: 1 step: 716 loss: 0.6934808492660522\n",
      "epoch: 1 step: 717 loss: 0.693480372428894\n",
      "epoch: 1 step: 718 loss: 0.693479061126709\n",
      "epoch: 1 step: 719 loss: 0.6934784650802612\n",
      "epoch: 1 step: 720 loss: 0.693477213382721\n",
      "epoch: 1 step: 721 loss: 0.6934774518013\n",
      "epoch: 1 step: 722 loss: 0.6934763193130493\n",
      "epoch: 1 step: 723 loss: 0.6934758424758911\n",
      "epoch: 1 step: 724 loss: 0.6934746503829956\n",
      "epoch: 1 step: 725 loss: 0.6934739947319031\n",
      "epoch: 1 step: 726 loss: 0.693473219871521\n",
      "epoch: 1 step: 727 loss: 0.6934726238250732\n",
      "epoch: 1 step: 728 loss: 0.6934719085693359\n",
      "epoch: 1 step: 729 loss: 0.6934708952903748\n",
      "epoch: 1 step: 730 loss: 0.6934704780578613\n",
      "epoch: 1 step: 731 loss: 0.6934694051742554\n",
      "epoch: 1 step: 732 loss: 0.693468451499939\n",
      "epoch: 1 step: 733 loss: 0.6934680342674255\n",
      "epoch: 1 step: 734 loss: 0.6934671401977539\n",
      "epoch: 1 step: 735 loss: 0.6934669613838196\n",
      "epoch: 1 step: 736 loss: 0.6934657692909241\n",
      "epoch: 1 step: 737 loss: 0.6934649348258972\n",
      "epoch: 1 step: 738 loss: 0.6934641003608704\n",
      "epoch: 1 step: 739 loss: 0.6934632658958435\n",
      "epoch: 1 step: 740 loss: 0.693463146686554\n",
      "epoch: 1 step: 741 loss: 0.6934622526168823\n",
      "epoch: 1 step: 742 loss: 0.6934617161750793\n",
      "epoch: 1 step: 743 loss: 0.6934607028961182\n",
      "epoch: 1 step: 744 loss: 0.6934597492218018\n",
      "epoch: 1 step: 745 loss: 0.6934595704078674\n",
      "epoch: 1 step: 746 loss: 0.6934589743614197\n",
      "epoch: 1 step: 747 loss: 0.6934580206871033\n",
      "epoch: 1 step: 748 loss: 0.693456768989563\n",
      "epoch: 1 step: 749 loss: 0.6934568881988525\n",
      "epoch: 1 step: 750 loss: 0.6934558749198914\n",
      "epoch: 1 step: 751 loss: 0.6934553384780884\n",
      "epoch: 1 step: 752 loss: 0.693455159664154\n",
      "epoch: 1 step: 753 loss: 0.6934536695480347\n",
      "epoch: 1 step: 754 loss: 0.6934537887573242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 755 loss: 0.6934524774551392\n",
      "epoch: 1 step: 756 loss: 0.6934516429901123\n",
      "epoch: 1 step: 757 loss: 0.6934508085250854\n",
      "epoch: 1 step: 758 loss: 0.6934508681297302\n",
      "epoch: 1 step: 759 loss: 0.693449854850769\n",
      "epoch: 1 step: 760 loss: 0.6934487819671631\n",
      "epoch: 1 step: 761 loss: 0.6934487819671631\n",
      "epoch: 1 step: 762 loss: 0.6934480667114258\n",
      "epoch: 1 step: 763 loss: 0.6934472322463989\n",
      "epoch: 1 step: 764 loss: 0.6934466361999512\n",
      "epoch: 1 step: 765 loss: 0.6934459209442139\n",
      "epoch: 1 step: 766 loss: 0.6934452652931213\n",
      "epoch: 1 step: 767 loss: 0.6934444904327393\n",
      "epoch: 1 step: 768 loss: 0.693444013595581\n",
      "epoch: 1 step: 769 loss: 0.6934434771537781\n",
      "epoch: 1 step: 770 loss: 0.6934429407119751\n",
      "epoch: 1 step: 771 loss: 0.6934418678283691\n",
      "epoch: 1 step: 772 loss: 0.69344162940979\n",
      "epoch: 1 step: 773 loss: 0.6934412121772766\n",
      "epoch: 1 step: 774 loss: 0.6934404373168945\n",
      "epoch: 1 step: 775 loss: 0.6934396028518677\n",
      "epoch: 1 step: 776 loss: 0.693438708782196\n",
      "epoch: 1 step: 777 loss: 0.693438708782196\n",
      "epoch: 1 step: 778 loss: 0.6934374570846558\n",
      "epoch: 1 step: 779 loss: 0.6934369802474976\n",
      "epoch: 1 step: 780 loss: 0.6934366226196289\n",
      "epoch: 1 step: 781 loss: 0.693435549736023\n",
      "epoch: 2 step: 1 loss: 0.6934356689453125\n",
      "epoch: 2 step: 2 loss: 0.6934343576431274\n",
      "epoch: 2 step: 3 loss: 0.6934344172477722\n",
      "epoch: 2 step: 4 loss: 0.6934335231781006\n",
      "epoch: 2 step: 5 loss: 0.6934329271316528\n",
      "epoch: 2 step: 6 loss: 0.6934323906898499\n",
      "epoch: 2 step: 7 loss: 0.6934313774108887\n",
      "epoch: 2 step: 8 loss: 0.6934306621551514\n",
      "epoch: 2 step: 9 loss: 0.6934300661087036\n",
      "epoch: 2 step: 10 loss: 0.6934294700622559\n",
      "epoch: 2 step: 11 loss: 0.6934293508529663\n",
      "epoch: 2 step: 12 loss: 0.6934289932250977\n",
      "epoch: 2 step: 13 loss: 0.6934276819229126\n",
      "epoch: 2 step: 14 loss: 0.6934272646903992\n",
      "epoch: 2 step: 15 loss: 0.6934268474578857\n",
      "epoch: 2 step: 16 loss: 0.6934266090393066\n",
      "epoch: 2 step: 17 loss: 0.6934256553649902\n",
      "epoch: 2 step: 18 loss: 0.693425178527832\n",
      "epoch: 2 step: 19 loss: 0.6934245824813843\n",
      "epoch: 2 step: 20 loss: 0.6934239864349365\n",
      "epoch: 2 step: 21 loss: 0.693423867225647\n",
      "epoch: 2 step: 22 loss: 0.6934226155281067\n",
      "epoch: 2 step: 23 loss: 0.693421483039856\n",
      "epoch: 2 step: 24 loss: 0.6934217214584351\n",
      "epoch: 2 step: 25 loss: 0.6934208869934082\n",
      "epoch: 2 step: 26 loss: 0.6934206485748291\n",
      "epoch: 2 step: 27 loss: 0.6934196949005127\n",
      "epoch: 2 step: 28 loss: 0.6934190988540649\n",
      "epoch: 2 step: 29 loss: 0.6934189200401306\n",
      "epoch: 2 step: 30 loss: 0.6934177279472351\n",
      "epoch: 2 step: 31 loss: 0.6934174299240112\n",
      "epoch: 2 step: 32 loss: 0.6934168338775635\n",
      "epoch: 2 step: 33 loss: 0.6934171319007874\n",
      "epoch: 2 step: 34 loss: 0.6934162974357605\n",
      "epoch: 2 step: 35 loss: 0.6934155225753784\n",
      "epoch: 2 step: 36 loss: 0.6934145092964172\n",
      "epoch: 2 step: 37 loss: 0.6934143304824829\n",
      "epoch: 2 step: 38 loss: 0.6934136152267456\n",
      "epoch: 2 step: 39 loss: 0.6934130191802979\n",
      "epoch: 2 step: 40 loss: 0.6934124827384949\n",
      "epoch: 2 step: 41 loss: 0.6934123039245605\n",
      "epoch: 2 step: 42 loss: 0.6934112310409546\n",
      "epoch: 2 step: 43 loss: 0.6934105753898621\n",
      "epoch: 2 step: 44 loss: 0.6934103965759277\n",
      "epoch: 2 step: 45 loss: 0.6934097409248352\n",
      "epoch: 2 step: 46 loss: 0.6934092044830322\n",
      "epoch: 2 step: 47 loss: 0.6934082508087158\n",
      "epoch: 2 step: 48 loss: 0.6934083104133606\n",
      "epoch: 2 step: 49 loss: 0.6934080123901367\n",
      "epoch: 2 step: 50 loss: 0.6934075355529785\n",
      "epoch: 2 step: 51 loss: 0.6934068202972412\n",
      "epoch: 2 step: 52 loss: 0.6934065818786621\n",
      "epoch: 2 step: 53 loss: 0.6934056878089905\n",
      "epoch: 2 step: 54 loss: 0.693405270576477\n",
      "epoch: 2 step: 55 loss: 0.6934047937393188\n",
      "epoch: 2 step: 56 loss: 0.6934041976928711\n",
      "epoch: 2 step: 57 loss: 0.6934040188789368\n",
      "epoch: 2 step: 58 loss: 0.6934033632278442\n",
      "epoch: 2 step: 59 loss: 0.6934024095535278\n",
      "epoch: 2 step: 60 loss: 0.6934020519256592\n",
      "epoch: 2 step: 61 loss: 0.6934013366699219\n",
      "epoch: 2 step: 62 loss: 0.693400502204895\n",
      "epoch: 2 step: 63 loss: 0.6934002041816711\n",
      "epoch: 2 step: 64 loss: 0.6933999061584473\n",
      "epoch: 2 step: 65 loss: 0.6934000253677368\n",
      "epoch: 2 step: 66 loss: 0.6933987140655518\n",
      "epoch: 2 step: 67 loss: 0.6933982968330383\n",
      "epoch: 2 step: 68 loss: 0.6933982968330383\n",
      "epoch: 2 step: 69 loss: 0.6933974027633667\n",
      "epoch: 2 step: 70 loss: 0.6933967471122742\n",
      "epoch: 2 step: 71 loss: 0.6933967471122742\n",
      "epoch: 2 step: 72 loss: 0.6933958530426025\n",
      "epoch: 2 step: 73 loss: 0.6933958530426025\n",
      "epoch: 2 step: 74 loss: 0.6933951377868652\n",
      "epoch: 2 step: 75 loss: 0.693394660949707\n",
      "epoch: 2 step: 76 loss: 0.6933940052986145\n",
      "epoch: 2 step: 77 loss: 0.6933937072753906\n",
      "epoch: 2 step: 78 loss: 0.6933929920196533\n",
      "epoch: 2 step: 79 loss: 0.6933929920196533\n",
      "epoch: 2 step: 80 loss: 0.6933921575546265\n",
      "epoch: 2 step: 81 loss: 0.6933917999267578\n",
      "epoch: 2 step: 82 loss: 0.693390965461731\n",
      "epoch: 2 step: 83 loss: 0.6933908462524414\n",
      "epoch: 2 step: 84 loss: 0.6933901906013489\n",
      "epoch: 2 step: 85 loss: 0.6933898329734802\n",
      "epoch: 2 step: 86 loss: 0.6933892965316772\n",
      "epoch: 2 step: 87 loss: 0.6933887004852295\n",
      "epoch: 2 step: 88 loss: 0.6933884620666504\n",
      "epoch: 2 step: 89 loss: 0.6933879256248474\n",
      "epoch: 2 step: 90 loss: 0.6933872699737549\n",
      "epoch: 2 step: 91 loss: 0.6933867335319519\n",
      "epoch: 2 step: 92 loss: 0.6933865547180176\n",
      "epoch: 2 step: 93 loss: 0.693385899066925\n",
      "epoch: 2 step: 94 loss: 0.6933856010437012\n",
      "epoch: 2 step: 95 loss: 0.693385124206543\n",
      "epoch: 2 step: 96 loss: 0.69338458776474\n",
      "epoch: 2 step: 97 loss: 0.6933839321136475\n",
      "epoch: 2 step: 98 loss: 0.6933836340904236\n",
      "epoch: 2 step: 99 loss: 0.6933832764625549\n",
      "epoch: 2 step: 100 loss: 0.6933828592300415\n",
      "epoch: 2 step: 101 loss: 0.6933822631835938\n",
      "epoch: 2 step: 102 loss: 0.6933821439743042\n",
      "epoch: 2 step: 103 loss: 0.6933814287185669\n",
      "epoch: 2 step: 104 loss: 0.6933812499046326\n",
      "epoch: 2 step: 105 loss: 0.6933807134628296\n",
      "epoch: 2 step: 106 loss: 0.6933800578117371\n",
      "epoch: 2 step: 107 loss: 0.6933799982070923\n",
      "epoch: 2 step: 108 loss: 0.693379282951355\n",
      "epoch: 2 step: 109 loss: 0.6933785676956177\n",
      "epoch: 2 step: 110 loss: 0.6933786273002625\n",
      "epoch: 2 step: 111 loss: 0.693378210067749\n",
      "epoch: 2 step: 112 loss: 0.6933774352073669\n",
      "epoch: 2 step: 113 loss: 0.6933776140213013\n",
      "epoch: 2 step: 114 loss: 0.6933771371841431\n",
      "epoch: 2 step: 115 loss: 0.6933760643005371\n",
      "epoch: 2 step: 116 loss: 0.693375825881958\n",
      "epoch: 2 step: 117 loss: 0.6933753490447998\n",
      "epoch: 2 step: 118 loss: 0.6933746337890625\n",
      "epoch: 2 step: 119 loss: 0.6933743953704834\n",
      "epoch: 2 step: 120 loss: 0.6933739185333252\n",
      "epoch: 2 step: 121 loss: 0.6933733820915222\n",
      "epoch: 2 step: 122 loss: 0.6933733224868774\n",
      "epoch: 2 step: 123 loss: 0.6933728456497192\n",
      "epoch: 2 step: 124 loss: 0.6933721899986267\n",
      "epoch: 2 step: 125 loss: 0.6933721303939819\n",
      "epoch: 2 step: 126 loss: 0.6933714151382446\n",
      "epoch: 2 step: 127 loss: 0.6933714151382446\n",
      "epoch: 2 step: 128 loss: 0.6933708190917969\n",
      "epoch: 2 step: 129 loss: 0.6933702826499939\n",
      "epoch: 2 step: 130 loss: 0.6933698058128357\n",
      "epoch: 2 step: 131 loss: 0.6933696269989014\n",
      "epoch: 2 step: 132 loss: 0.6933690905570984\n",
      "epoch: 2 step: 133 loss: 0.6933688521385193\n",
      "epoch: 2 step: 134 loss: 0.6933679580688477\n",
      "epoch: 2 step: 135 loss: 0.6933677196502686\n",
      "epoch: 2 step: 136 loss: 0.6933674216270447\n",
      "epoch: 2 step: 137 loss: 0.6933669447898865\n",
      "epoch: 2 step: 138 loss: 0.693366527557373\n",
      "epoch: 2 step: 139 loss: 0.6933664083480835\n",
      "epoch: 2 step: 140 loss: 0.693365752696991\n",
      "epoch: 2 step: 141 loss: 0.6933652758598328\n",
      "epoch: 2 step: 142 loss: 0.6933648586273193\n",
      "epoch: 2 step: 143 loss: 0.6933646202087402\n",
      "epoch: 2 step: 144 loss: 0.6933642029762268\n",
      "epoch: 2 step: 145 loss: 0.6933637857437134\n",
      "epoch: 2 step: 146 loss: 0.6933634281158447\n",
      "epoch: 2 step: 147 loss: 0.6933630704879761\n",
      "epoch: 2 step: 148 loss: 0.6933623552322388\n",
      "epoch: 2 step: 149 loss: 0.6933622360229492\n",
      "epoch: 2 step: 150 loss: 0.6933616399765015\n",
      "epoch: 2 step: 151 loss: 0.6933611631393433\n",
      "epoch: 2 step: 152 loss: 0.6933606863021851\n",
      "epoch: 2 step: 153 loss: 0.6933608055114746\n",
      "epoch: 2 step: 154 loss: 0.6933600902557373\n",
      "epoch: 2 step: 155 loss: 0.6933601498603821\n",
      "epoch: 2 step: 156 loss: 0.6933590769767761\n",
      "epoch: 2 step: 157 loss: 0.6933588981628418\n",
      "epoch: 2 step: 158 loss: 0.6933586597442627\n",
      "epoch: 2 step: 159 loss: 0.6933581829071045\n",
      "epoch: 2 step: 160 loss: 0.6933578252792358\n",
      "epoch: 2 step: 161 loss: 0.6933576464653015\n",
      "epoch: 2 step: 162 loss: 0.6933571100234985\n",
      "epoch: 2 step: 163 loss: 0.6933567523956299\n",
      "epoch: 2 step: 164 loss: 0.6933562755584717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 165 loss: 0.6933556795120239\n",
      "epoch: 2 step: 166 loss: 0.6933554410934448\n",
      "epoch: 2 step: 167 loss: 0.6933554410934448\n",
      "epoch: 2 step: 168 loss: 0.6933549642562866\n",
      "epoch: 2 step: 169 loss: 0.6933543682098389\n",
      "epoch: 2 step: 170 loss: 0.6933540105819702\n",
      "epoch: 2 step: 171 loss: 0.6933538913726807\n",
      "epoch: 2 step: 172 loss: 0.6933536529541016\n",
      "epoch: 2 step: 173 loss: 0.693352997303009\n",
      "epoch: 2 step: 174 loss: 0.6933525204658508\n",
      "epoch: 2 step: 175 loss: 0.6933523416519165\n",
      "epoch: 2 step: 176 loss: 0.6933518052101135\n",
      "epoch: 2 step: 177 loss: 0.6933515667915344\n",
      "epoch: 2 step: 178 loss: 0.6933512687683105\n",
      "epoch: 2 step: 179 loss: 0.693350613117218\n",
      "epoch: 2 step: 180 loss: 0.6933504343032837\n",
      "epoch: 2 step: 181 loss: 0.6933501362800598\n",
      "epoch: 2 step: 182 loss: 0.6933494210243225\n",
      "epoch: 2 step: 183 loss: 0.6933495402336121\n",
      "epoch: 2 step: 184 loss: 0.6933491826057434\n",
      "epoch: 2 step: 185 loss: 0.6933486461639404\n",
      "epoch: 2 step: 186 loss: 0.6933485269546509\n",
      "epoch: 2 step: 187 loss: 0.6933479905128479\n",
      "epoch: 2 step: 188 loss: 0.6933477520942688\n",
      "epoch: 2 step: 189 loss: 0.6933473348617554\n",
      "epoch: 2 step: 190 loss: 0.6933470964431763\n",
      "epoch: 2 step: 191 loss: 0.6933465003967285\n",
      "epoch: 2 step: 192 loss: 0.6933465003967285\n",
      "epoch: 2 step: 193 loss: 0.6933459043502808\n",
      "epoch: 2 step: 194 loss: 0.6933451890945435\n",
      "epoch: 2 step: 195 loss: 0.6933451294898987\n",
      "epoch: 2 step: 196 loss: 0.6933448314666748\n",
      "epoch: 2 step: 197 loss: 0.6933445930480957\n",
      "epoch: 2 step: 198 loss: 0.693343997001648\n",
      "epoch: 2 step: 199 loss: 0.6933437585830688\n",
      "epoch: 2 step: 200 loss: 0.6933432221412659\n",
      "epoch: 2 step: 201 loss: 0.6933430433273315\n",
      "epoch: 2 step: 202 loss: 0.6933428049087524\n",
      "epoch: 2 step: 203 loss: 0.6933421492576599\n",
      "epoch: 2 step: 204 loss: 0.693341851234436\n",
      "epoch: 2 step: 205 loss: 0.6933420300483704\n",
      "epoch: 2 step: 206 loss: 0.6933413743972778\n",
      "epoch: 2 step: 207 loss: 0.6933410167694092\n",
      "epoch: 2 step: 208 loss: 0.6933408975601196\n",
      "epoch: 2 step: 209 loss: 0.6933401823043823\n",
      "epoch: 2 step: 210 loss: 0.6933399438858032\n",
      "epoch: 2 step: 211 loss: 0.6933399438858032\n",
      "epoch: 2 step: 212 loss: 0.6933392882347107\n",
      "epoch: 2 step: 213 loss: 0.6933391094207764\n",
      "epoch: 2 step: 214 loss: 0.6933387517929077\n",
      "epoch: 2 step: 215 loss: 0.6933384537696838\n",
      "epoch: 2 step: 216 loss: 0.6933380365371704\n",
      "epoch: 2 step: 217 loss: 0.6933374404907227\n",
      "epoch: 2 step: 218 loss: 0.6933375597000122\n",
      "epoch: 2 step: 219 loss: 0.693337082862854\n",
      "epoch: 2 step: 220 loss: 0.6933367252349854\n",
      "epoch: 2 step: 221 loss: 0.6933364272117615\n",
      "epoch: 2 step: 222 loss: 0.6933361291885376\n",
      "epoch: 2 step: 223 loss: 0.6933357119560242\n",
      "epoch: 2 step: 224 loss: 0.6933355331420898\n",
      "epoch: 2 step: 225 loss: 0.6933351755142212\n",
      "epoch: 2 step: 226 loss: 0.6933348178863525\n",
      "epoch: 2 step: 227 loss: 0.6933344006538391\n",
      "epoch: 2 step: 228 loss: 0.69333416223526\n",
      "epoch: 2 step: 229 loss: 0.6933339834213257\n",
      "epoch: 2 step: 230 loss: 0.6933338046073914\n",
      "epoch: 2 step: 231 loss: 0.6933332085609436\n",
      "epoch: 2 step: 232 loss: 0.6933329105377197\n",
      "epoch: 2 step: 233 loss: 0.6933324933052063\n",
      "epoch: 2 step: 234 loss: 0.6933324337005615\n",
      "epoch: 2 step: 235 loss: 0.6933318376541138\n",
      "epoch: 2 step: 236 loss: 0.6933318376541138\n",
      "epoch: 2 step: 237 loss: 0.6933311223983765\n",
      "epoch: 2 step: 238 loss: 0.6933309435844421\n",
      "epoch: 2 step: 239 loss: 0.6933307647705078\n",
      "epoch: 2 step: 240 loss: 0.6933304071426392\n",
      "epoch: 2 step: 241 loss: 0.6933301091194153\n",
      "epoch: 2 step: 242 loss: 0.6933300495147705\n",
      "epoch: 2 step: 243 loss: 0.6933294534683228\n",
      "epoch: 2 step: 244 loss: 0.6933292746543884\n",
      "epoch: 2 step: 245 loss: 0.6933287978172302\n",
      "epoch: 2 step: 246 loss: 0.6933284997940063\n",
      "epoch: 2 step: 247 loss: 0.6933283805847168\n",
      "epoch: 2 step: 248 loss: 0.6933279037475586\n",
      "epoch: 2 step: 249 loss: 0.6933277249336243\n",
      "epoch: 2 step: 250 loss: 0.6933272480964661\n",
      "epoch: 2 step: 251 loss: 0.6933271884918213\n",
      "epoch: 2 step: 252 loss: 0.6933268308639526\n",
      "epoch: 2 step: 253 loss: 0.6933265924453735\n",
      "epoch: 2 step: 254 loss: 0.6933260560035706\n",
      "epoch: 2 step: 255 loss: 0.6933261156082153\n",
      "epoch: 2 step: 256 loss: 0.6933256387710571\n",
      "epoch: 2 step: 257 loss: 0.6933249831199646\n",
      "epoch: 2 step: 258 loss: 0.6933249831199646\n",
      "epoch: 2 step: 259 loss: 0.693324625492096\n",
      "epoch: 2 step: 260 loss: 0.6933240294456482\n",
      "epoch: 2 step: 261 loss: 0.6933242082595825\n",
      "epoch: 2 step: 262 loss: 0.6933236122131348\n",
      "epoch: 2 step: 263 loss: 0.6933233141899109\n",
      "epoch: 2 step: 264 loss: 0.6933232545852661\n",
      "epoch: 2 step: 265 loss: 0.693323016166687\n",
      "epoch: 2 step: 266 loss: 0.6933224201202393\n",
      "epoch: 2 step: 267 loss: 0.6933224201202393\n",
      "epoch: 2 step: 268 loss: 0.6933220028877258\n",
      "epoch: 2 step: 269 loss: 0.693321943283081\n",
      "epoch: 2 step: 270 loss: 0.6933214664459229\n",
      "epoch: 2 step: 271 loss: 0.6933211088180542\n",
      "epoch: 2 step: 272 loss: 0.6933208107948303\n",
      "epoch: 2 step: 273 loss: 0.6933204531669617\n",
      "epoch: 2 step: 274 loss: 0.6933202147483826\n",
      "epoch: 2 step: 275 loss: 0.6933199167251587\n",
      "epoch: 2 step: 276 loss: 0.6933198571205139\n",
      "epoch: 2 step: 277 loss: 0.6933193206787109\n",
      "epoch: 2 step: 278 loss: 0.6933187246322632\n",
      "epoch: 2 step: 279 loss: 0.693318784236908\n",
      "epoch: 2 step: 280 loss: 0.6933184862136841\n",
      "epoch: 2 step: 281 loss: 0.6933184862136841\n",
      "epoch: 2 step: 282 loss: 0.6933178305625916\n",
      "epoch: 2 step: 283 loss: 0.6933177709579468\n",
      "epoch: 2 step: 284 loss: 0.6933173537254333\n",
      "epoch: 2 step: 285 loss: 0.693317174911499\n",
      "epoch: 2 step: 286 loss: 0.6933169960975647\n",
      "epoch: 2 step: 287 loss: 0.6933165788650513\n",
      "epoch: 2 step: 288 loss: 0.6933163404464722\n",
      "epoch: 2 step: 289 loss: 0.6933162212371826\n",
      "epoch: 2 step: 290 loss: 0.6933157444000244\n",
      "epoch: 2 step: 291 loss: 0.6933155059814453\n",
      "epoch: 2 step: 292 loss: 0.6933151483535767\n",
      "epoch: 2 step: 293 loss: 0.6933150887489319\n",
      "epoch: 2 step: 294 loss: 0.6933145523071289\n",
      "epoch: 2 step: 295 loss: 0.6933144330978394\n",
      "epoch: 2 step: 296 loss: 0.6933140754699707\n",
      "epoch: 2 step: 297 loss: 0.6933137774467468\n",
      "epoch: 2 step: 298 loss: 0.6933136582374573\n",
      "epoch: 2 step: 299 loss: 0.6933133006095886\n",
      "epoch: 2 step: 300 loss: 0.6933130025863647\n",
      "epoch: 2 step: 301 loss: 0.6933128833770752\n",
      "epoch: 2 step: 302 loss: 0.6933127641677856\n",
      "epoch: 2 step: 303 loss: 0.6933122873306274\n",
      "epoch: 2 step: 304 loss: 0.6933121681213379\n",
      "epoch: 2 step: 305 loss: 0.6933120489120483\n",
      "epoch: 2 step: 306 loss: 0.693311333656311\n",
      "epoch: 2 step: 307 loss: 0.6933113932609558\n",
      "epoch: 2 step: 308 loss: 0.6933112144470215\n",
      "epoch: 2 step: 309 loss: 0.6933106780052185\n",
      "epoch: 2 step: 310 loss: 0.6933106184005737\n",
      "epoch: 2 step: 311 loss: 0.6933106184005737\n",
      "epoch: 2 step: 312 loss: 0.6933102607727051\n",
      "epoch: 2 step: 313 loss: 0.6933096647262573\n",
      "epoch: 2 step: 314 loss: 0.6933093667030334\n",
      "epoch: 2 step: 315 loss: 0.693309485912323\n",
      "epoch: 2 step: 316 loss: 0.6933090686798096\n",
      "epoch: 2 step: 317 loss: 0.6933084726333618\n",
      "epoch: 2 step: 318 loss: 0.6933084726333618\n",
      "epoch: 2 step: 319 loss: 0.6933080554008484\n",
      "epoch: 2 step: 320 loss: 0.6933078765869141\n",
      "epoch: 2 step: 321 loss: 0.693307638168335\n",
      "epoch: 2 step: 322 loss: 0.6933074593544006\n",
      "epoch: 2 step: 323 loss: 0.6933072805404663\n",
      "epoch: 2 step: 324 loss: 0.6933067440986633\n",
      "epoch: 2 step: 325 loss: 0.6933066844940186\n",
      "epoch: 2 step: 326 loss: 0.6933062076568604\n",
      "epoch: 2 step: 327 loss: 0.6933060884475708\n",
      "epoch: 2 step: 328 loss: 0.6933060884475708\n",
      "epoch: 2 step: 329 loss: 0.6933056712150574\n",
      "epoch: 2 step: 330 loss: 0.693305253982544\n",
      "epoch: 2 step: 331 loss: 0.693305253982544\n",
      "epoch: 2 step: 332 loss: 0.6933048963546753\n",
      "epoch: 2 step: 333 loss: 0.6933046579360962\n",
      "epoch: 2 step: 334 loss: 0.6933044195175171\n",
      "epoch: 2 step: 335 loss: 0.6933042407035828\n",
      "epoch: 2 step: 336 loss: 0.6933037638664246\n",
      "epoch: 2 step: 337 loss: 0.6933038234710693\n",
      "epoch: 2 step: 338 loss: 0.6933035254478455\n",
      "epoch: 2 step: 339 loss: 0.6933032870292664\n",
      "epoch: 2 step: 340 loss: 0.6933026313781738\n",
      "epoch: 2 step: 341 loss: 0.6933028697967529\n",
      "epoch: 2 step: 342 loss: 0.6933026909828186\n",
      "epoch: 2 step: 343 loss: 0.6933020353317261\n",
      "epoch: 2 step: 344 loss: 0.6933019757270813\n",
      "epoch: 2 step: 345 loss: 0.6933016777038574\n",
      "epoch: 2 step: 346 loss: 0.6933012008666992\n",
      "epoch: 2 step: 347 loss: 0.6933013200759888\n",
      "epoch: 2 step: 348 loss: 0.6933010816574097\n",
      "epoch: 2 step: 349 loss: 0.6933010816574097\n",
      "epoch: 2 step: 350 loss: 0.6933003664016724\n",
      "epoch: 2 step: 351 loss: 0.6933003664016724\n",
      "epoch: 2 step: 352 loss: 0.6933000683784485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 353 loss: 0.6932999491691589\n",
      "epoch: 2 step: 354 loss: 0.6932997703552246\n",
      "epoch: 2 step: 355 loss: 0.6932992935180664\n",
      "epoch: 2 step: 356 loss: 0.6932991743087769\n",
      "epoch: 2 step: 357 loss: 0.6932990550994873\n",
      "epoch: 2 step: 358 loss: 0.6932985782623291\n",
      "epoch: 2 step: 359 loss: 0.6932983994483948\n",
      "epoch: 2 step: 360 loss: 0.69329833984375\n",
      "epoch: 2 step: 361 loss: 0.6932978630065918\n",
      "epoch: 2 step: 362 loss: 0.693297803401947\n",
      "epoch: 2 step: 363 loss: 0.6932974457740784\n",
      "epoch: 2 step: 364 loss: 0.6932975053787231\n",
      "epoch: 2 step: 365 loss: 0.6932970285415649\n",
      "epoch: 2 step: 366 loss: 0.6932967901229858\n",
      "epoch: 2 step: 367 loss: 0.6932965517044067\n",
      "epoch: 2 step: 368 loss: 0.6932963132858276\n",
      "epoch: 2 step: 369 loss: 0.6932960748672485\n",
      "epoch: 2 step: 370 loss: 0.6932958364486694\n",
      "epoch: 2 step: 371 loss: 0.6932958364486694\n",
      "epoch: 2 step: 372 loss: 0.6932953596115112\n",
      "epoch: 2 step: 373 loss: 0.6932953000068665\n",
      "epoch: 2 step: 374 loss: 0.6932950019836426\n",
      "epoch: 2 step: 375 loss: 0.693294882774353\n",
      "epoch: 2 step: 376 loss: 0.6932945251464844\n",
      "epoch: 2 step: 377 loss: 0.6932945251464844\n",
      "epoch: 2 step: 378 loss: 0.6932939291000366\n",
      "epoch: 2 step: 379 loss: 0.6932938098907471\n",
      "epoch: 2 step: 380 loss: 0.693293571472168\n",
      "epoch: 2 step: 381 loss: 0.693293571472168\n",
      "epoch: 2 step: 382 loss: 0.6932933926582336\n",
      "epoch: 2 step: 383 loss: 0.6932929754257202\n",
      "epoch: 2 step: 384 loss: 0.6932927370071411\n",
      "epoch: 2 step: 385 loss: 0.6932925581932068\n",
      "epoch: 2 step: 386 loss: 0.6932923793792725\n",
      "epoch: 2 step: 387 loss: 0.6932920813560486\n",
      "epoch: 2 step: 388 loss: 0.6932919025421143\n",
      "epoch: 2 step: 389 loss: 0.6932918429374695\n",
      "epoch: 2 step: 390 loss: 0.6932913064956665\n",
      "epoch: 2 step: 391 loss: 0.6932911276817322\n",
      "epoch: 2 step: 392 loss: 0.693291187286377\n",
      "epoch: 2 step: 393 loss: 0.6932910680770874\n",
      "epoch: 2 step: 394 loss: 0.6932907104492188\n",
      "epoch: 2 step: 395 loss: 0.6932907104492188\n",
      "epoch: 2 step: 396 loss: 0.6932902336120605\n",
      "epoch: 2 step: 397 loss: 0.693290114402771\n",
      "epoch: 2 step: 398 loss: 0.6932896375656128\n",
      "epoch: 2 step: 399 loss: 0.6932894587516785\n",
      "epoch: 2 step: 400 loss: 0.6932892799377441\n",
      "epoch: 2 step: 401 loss: 0.693289041519165\n",
      "epoch: 2 step: 402 loss: 0.6932888627052307\n",
      "epoch: 2 step: 403 loss: 0.6932886838912964\n",
      "epoch: 2 step: 404 loss: 0.6932886838912964\n",
      "epoch: 2 step: 405 loss: 0.693288266658783\n",
      "epoch: 2 step: 406 loss: 0.6932882070541382\n",
      "epoch: 2 step: 407 loss: 0.6932879686355591\n",
      "epoch: 2 step: 408 loss: 0.6932875514030457\n",
      "epoch: 2 step: 409 loss: 0.6932874917984009\n",
      "epoch: 2 step: 410 loss: 0.693287193775177\n",
      "epoch: 2 step: 411 loss: 0.6932870149612427\n",
      "epoch: 2 step: 412 loss: 0.6932868957519531\n",
      "epoch: 2 step: 413 loss: 0.6932865381240845\n",
      "epoch: 2 step: 414 loss: 0.6932862401008606\n",
      "epoch: 2 step: 415 loss: 0.6932860612869263\n",
      "epoch: 2 step: 416 loss: 0.6932859420776367\n",
      "epoch: 2 step: 417 loss: 0.6932859420776367\n",
      "epoch: 2 step: 418 loss: 0.6932856440544128\n",
      "epoch: 2 step: 419 loss: 0.6932854652404785\n",
      "epoch: 2 step: 420 loss: 0.6932852268218994\n",
      "epoch: 2 step: 421 loss: 0.6932848691940308\n",
      "epoch: 2 step: 422 loss: 0.6932847499847412\n",
      "epoch: 2 step: 423 loss: 0.6932845115661621\n",
      "epoch: 2 step: 424 loss: 0.6932843923568726\n",
      "epoch: 2 step: 425 loss: 0.6932841539382935\n",
      "epoch: 2 step: 426 loss: 0.6932840943336487\n",
      "epoch: 2 step: 427 loss: 0.6932837963104248\n",
      "epoch: 2 step: 428 loss: 0.6932834386825562\n",
      "epoch: 2 step: 429 loss: 0.6932834386825562\n",
      "epoch: 2 step: 430 loss: 0.6932833194732666\n",
      "epoch: 2 step: 431 loss: 0.6932830810546875\n",
      "epoch: 2 step: 432 loss: 0.6932827234268188\n",
      "epoch: 2 step: 433 loss: 0.6932824850082397\n",
      "epoch: 2 step: 434 loss: 0.6932822465896606\n",
      "epoch: 2 step: 435 loss: 0.6932820081710815\n",
      "epoch: 2 step: 436 loss: 0.6932821273803711\n",
      "epoch: 2 step: 437 loss: 0.693281888961792\n",
      "epoch: 2 step: 438 loss: 0.6932816505432129\n",
      "epoch: 2 step: 439 loss: 0.6932814121246338\n",
      "epoch: 2 step: 440 loss: 0.6932810544967651\n",
      "epoch: 2 step: 441 loss: 0.6932809948921204\n",
      "epoch: 2 step: 442 loss: 0.693280816078186\n",
      "epoch: 2 step: 443 loss: 0.6932805776596069\n",
      "epoch: 2 step: 444 loss: 0.6932805180549622\n",
      "epoch: 2 step: 445 loss: 0.6932804584503174\n",
      "epoch: 2 step: 446 loss: 0.6932802200317383\n",
      "epoch: 2 step: 447 loss: 0.6932798624038696\n",
      "epoch: 2 step: 448 loss: 0.6932798624038696\n",
      "epoch: 2 step: 449 loss: 0.6932792663574219\n",
      "epoch: 2 step: 450 loss: 0.6932793855667114\n",
      "epoch: 2 step: 451 loss: 0.6932792663574219\n",
      "epoch: 2 step: 452 loss: 0.6932788491249084\n",
      "epoch: 2 step: 453 loss: 0.6932787299156189\n",
      "epoch: 2 step: 454 loss: 0.6932784914970398\n",
      "epoch: 2 step: 455 loss: 0.693278431892395\n",
      "epoch: 2 step: 456 loss: 0.6932783722877502\n",
      "epoch: 2 step: 457 loss: 0.6932778358459473\n",
      "epoch: 2 step: 458 loss: 0.6932777166366577\n",
      "epoch: 2 step: 459 loss: 0.6932774186134338\n",
      "epoch: 2 step: 460 loss: 0.6932774782180786\n",
      "epoch: 2 step: 461 loss: 0.6932773590087891\n",
      "epoch: 2 step: 462 loss: 0.69327712059021\n",
      "epoch: 2 step: 463 loss: 0.6932770013809204\n",
      "epoch: 2 step: 464 loss: 0.6932767629623413\n",
      "epoch: 2 step: 465 loss: 0.6932765245437622\n",
      "epoch: 2 step: 466 loss: 0.6932763457298279\n",
      "epoch: 2 step: 467 loss: 0.6932762265205383\n",
      "epoch: 2 step: 468 loss: 0.6932761073112488\n",
      "epoch: 2 step: 469 loss: 0.6932758092880249\n",
      "epoch: 2 step: 470 loss: 0.6932755708694458\n",
      "epoch: 2 step: 471 loss: 0.6932754516601562\n",
      "epoch: 2 step: 472 loss: 0.6932753324508667\n",
      "epoch: 2 step: 473 loss: 0.6932751536369324\n",
      "epoch: 2 step: 474 loss: 0.6932747960090637\n",
      "epoch: 2 step: 475 loss: 0.6932746767997742\n",
      "epoch: 2 step: 476 loss: 0.6932743787765503\n",
      "epoch: 2 step: 477 loss: 0.6932741403579712\n",
      "epoch: 2 step: 478 loss: 0.6932740807533264\n",
      "epoch: 2 step: 479 loss: 0.6932739019393921\n",
      "epoch: 2 step: 480 loss: 0.6932739019393921\n",
      "epoch: 2 step: 481 loss: 0.6932737231254578\n",
      "epoch: 2 step: 482 loss: 0.6932733654975891\n",
      "epoch: 2 step: 483 loss: 0.6932731866836548\n",
      "epoch: 2 step: 484 loss: 0.6932730674743652\n",
      "epoch: 2 step: 485 loss: 0.6932727694511414\n",
      "epoch: 2 step: 486 loss: 0.6932728290557861\n",
      "epoch: 2 step: 487 loss: 0.6932727098464966\n",
      "epoch: 2 step: 488 loss: 0.6932724714279175\n",
      "epoch: 2 step: 489 loss: 0.6932722330093384\n",
      "epoch: 2 step: 490 loss: 0.693272054195404\n",
      "epoch: 2 step: 491 loss: 0.6932717561721802\n",
      "epoch: 2 step: 492 loss: 0.6932716369628906\n",
      "epoch: 2 step: 493 loss: 0.6932715177536011\n",
      "epoch: 2 step: 494 loss: 0.6932714581489563\n",
      "epoch: 2 step: 495 loss: 0.6932711601257324\n",
      "epoch: 2 step: 496 loss: 0.6932711005210876\n",
      "epoch: 2 step: 497 loss: 0.6932708024978638\n",
      "epoch: 2 step: 498 loss: 0.6932708024978638\n",
      "epoch: 2 step: 499 loss: 0.6932705044746399\n",
      "epoch: 2 step: 500 loss: 0.693270206451416\n",
      "epoch: 2 step: 501 loss: 0.693270206451416\n",
      "epoch: 2 step: 502 loss: 0.6932698488235474\n",
      "epoch: 2 step: 503 loss: 0.6932699084281921\n",
      "epoch: 2 step: 504 loss: 0.6932696104049683\n",
      "epoch: 2 step: 505 loss: 0.6932697296142578\n",
      "epoch: 2 step: 506 loss: 0.6932693719863892\n",
      "epoch: 2 step: 507 loss: 0.6932690143585205\n",
      "epoch: 2 step: 508 loss: 0.6932690143585205\n",
      "epoch: 2 step: 509 loss: 0.6932687163352966\n",
      "epoch: 2 step: 510 loss: 0.6932685375213623\n",
      "epoch: 2 step: 511 loss: 0.6932684183120728\n",
      "epoch: 2 step: 512 loss: 0.6932681798934937\n",
      "epoch: 2 step: 513 loss: 0.6932680010795593\n",
      "epoch: 2 step: 514 loss: 0.6932679414749146\n",
      "epoch: 2 step: 515 loss: 0.6932677626609802\n",
      "epoch: 2 step: 516 loss: 0.6932676434516907\n",
      "epoch: 2 step: 517 loss: 0.6932673454284668\n",
      "epoch: 2 step: 518 loss: 0.6932671666145325\n",
      "epoch: 2 step: 519 loss: 0.6932669878005981\n",
      "epoch: 2 step: 520 loss: 0.6932669878005981\n",
      "epoch: 2 step: 521 loss: 0.6932668685913086\n",
      "epoch: 2 step: 522 loss: 0.6932663917541504\n",
      "epoch: 2 step: 523 loss: 0.6932665109634399\n",
      "epoch: 2 step: 524 loss: 0.6932662725448608\n",
      "epoch: 2 step: 525 loss: 0.6932661533355713\n",
      "epoch: 2 step: 526 loss: 0.6932659149169922\n",
      "epoch: 2 step: 527 loss: 0.6932657957077026\n",
      "epoch: 2 step: 528 loss: 0.6932655572891235\n",
      "epoch: 2 step: 529 loss: 0.6932654976844788\n",
      "epoch: 2 step: 530 loss: 0.6932652592658997\n",
      "epoch: 2 step: 531 loss: 0.6932651996612549\n",
      "epoch: 2 step: 532 loss: 0.6932650208473206\n",
      "epoch: 2 step: 533 loss: 0.6932647228240967\n",
      "epoch: 2 step: 534 loss: 0.6932647824287415\n",
      "epoch: 2 step: 535 loss: 0.6932644844055176\n",
      "epoch: 2 step: 536 loss: 0.693264365196228\n",
      "epoch: 2 step: 537 loss: 0.6932642459869385\n",
      "epoch: 2 step: 538 loss: 0.6932640075683594\n",
      "epoch: 2 step: 539 loss: 0.6932638883590698\n",
      "epoch: 2 step: 540 loss: 0.6932637691497803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 541 loss: 0.693263590335846\n",
      "epoch: 2 step: 542 loss: 0.6932634115219116\n",
      "epoch: 2 step: 543 loss: 0.6932631731033325\n",
      "epoch: 2 step: 544 loss: 0.6932631134986877\n",
      "epoch: 2 step: 545 loss: 0.6932629942893982\n",
      "epoch: 2 step: 546 loss: 0.6932629346847534\n",
      "epoch: 2 step: 547 loss: 0.6932626962661743\n",
      "epoch: 2 step: 548 loss: 0.6932624578475952\n",
      "epoch: 2 step: 549 loss: 0.6932623386383057\n",
      "epoch: 2 step: 550 loss: 0.6932623386383057\n",
      "epoch: 2 step: 551 loss: 0.6932619214057922\n",
      "epoch: 2 step: 552 loss: 0.6932615637779236\n",
      "epoch: 2 step: 553 loss: 0.6932617425918579\n",
      "epoch: 2 step: 554 loss: 0.6932616233825684\n",
      "epoch: 2 step: 555 loss: 0.6932613849639893\n",
      "epoch: 2 step: 556 loss: 0.6932610869407654\n",
      "epoch: 2 step: 557 loss: 0.693260908126831\n",
      "epoch: 2 step: 558 loss: 0.6932610273361206\n",
      "epoch: 2 step: 559 loss: 0.693260908126831\n",
      "epoch: 2 step: 560 loss: 0.6932604908943176\n",
      "epoch: 2 step: 561 loss: 0.6932604312896729\n",
      "epoch: 2 step: 562 loss: 0.6932603120803833\n",
      "epoch: 2 step: 563 loss: 0.6932601928710938\n",
      "epoch: 2 step: 564 loss: 0.6932600736618042\n",
      "epoch: 2 step: 565 loss: 0.6932596564292908\n",
      "epoch: 2 step: 566 loss: 0.6932597756385803\n",
      "epoch: 2 step: 567 loss: 0.6932594776153564\n",
      "epoch: 2 step: 568 loss: 0.6932594776153564\n",
      "epoch: 2 step: 569 loss: 0.6932591199874878\n",
      "epoch: 2 step: 570 loss: 0.6932592391967773\n",
      "epoch: 2 step: 571 loss: 0.6932590007781982\n",
      "epoch: 2 step: 572 loss: 0.6932587027549744\n",
      "epoch: 2 step: 573 loss: 0.6932585835456848\n",
      "epoch: 2 step: 574 loss: 0.6932584047317505\n",
      "epoch: 2 step: 575 loss: 0.6932584643363953\n",
      "epoch: 2 step: 576 loss: 0.6932579874992371\n",
      "epoch: 2 step: 577 loss: 0.6932579278945923\n",
      "epoch: 2 step: 578 loss: 0.6932578682899475\n",
      "epoch: 2 step: 579 loss: 0.6932579278945923\n",
      "epoch: 2 step: 580 loss: 0.6932575702667236\n",
      "epoch: 2 step: 581 loss: 0.6932574510574341\n",
      "epoch: 2 step: 582 loss: 0.6932573318481445\n",
      "epoch: 2 step: 583 loss: 0.693257212638855\n",
      "epoch: 2 step: 584 loss: 0.6932569146156311\n",
      "epoch: 2 step: 585 loss: 0.6932570934295654\n",
      "epoch: 2 step: 586 loss: 0.6932569146156311\n",
      "epoch: 2 step: 587 loss: 0.6932567358016968\n",
      "epoch: 2 step: 588 loss: 0.6932566165924072\n",
      "epoch: 2 step: 589 loss: 0.6932561993598938\n",
      "epoch: 2 step: 590 loss: 0.6932562589645386\n",
      "epoch: 2 step: 591 loss: 0.693256139755249\n",
      "epoch: 2 step: 592 loss: 0.6932558417320251\n",
      "epoch: 2 step: 593 loss: 0.6932559013366699\n",
      "epoch: 2 step: 594 loss: 0.693255603313446\n",
      "epoch: 2 step: 595 loss: 0.6932555437088013\n",
      "epoch: 2 step: 596 loss: 0.6932551860809326\n",
      "epoch: 2 step: 597 loss: 0.6932553052902222\n",
      "epoch: 2 step: 598 loss: 0.6932550668716431\n",
      "epoch: 2 step: 599 loss: 0.6932548880577087\n",
      "epoch: 2 step: 600 loss: 0.6932548880577087\n",
      "epoch: 2 step: 601 loss: 0.6932546496391296\n",
      "epoch: 2 step: 602 loss: 0.6932544708251953\n",
      "epoch: 2 step: 603 loss: 0.6932544708251953\n",
      "epoch: 2 step: 604 loss: 0.6932539939880371\n",
      "epoch: 2 step: 605 loss: 0.6932541131973267\n",
      "epoch: 2 step: 606 loss: 0.6932539939880371\n",
      "epoch: 2 step: 607 loss: 0.693253755569458\n",
      "epoch: 2 step: 608 loss: 0.6932536363601685\n",
      "epoch: 2 step: 609 loss: 0.6932533979415894\n",
      "epoch: 2 step: 610 loss: 0.6932532787322998\n",
      "epoch: 2 step: 611 loss: 0.6932531595230103\n",
      "epoch: 2 step: 612 loss: 0.6932530403137207\n",
      "epoch: 2 step: 613 loss: 0.6932530403137207\n",
      "epoch: 2 step: 614 loss: 0.6932528018951416\n",
      "epoch: 2 step: 615 loss: 0.6932525634765625\n",
      "epoch: 2 step: 616 loss: 0.6932525634765625\n",
      "epoch: 2 step: 617 loss: 0.6932523846626282\n",
      "epoch: 2 step: 618 loss: 0.6932523250579834\n",
      "epoch: 2 step: 619 loss: 0.6932520866394043\n",
      "epoch: 2 step: 620 loss: 0.6932520270347595\n",
      "epoch: 2 step: 621 loss: 0.6932517290115356\n",
      "epoch: 2 step: 622 loss: 0.6932517290115356\n",
      "epoch: 2 step: 623 loss: 0.6932514905929565\n",
      "epoch: 2 step: 624 loss: 0.693251371383667\n",
      "epoch: 2 step: 625 loss: 0.6932512521743774\n",
      "epoch: 2 step: 626 loss: 0.6932512521743774\n",
      "epoch: 2 step: 627 loss: 0.6932510733604431\n",
      "epoch: 2 step: 628 loss: 0.6932508945465088\n",
      "epoch: 2 step: 629 loss: 0.6932507157325745\n",
      "epoch: 2 step: 630 loss: 0.6932506561279297\n",
      "epoch: 2 step: 631 loss: 0.6932504773139954\n",
      "epoch: 2 step: 632 loss: 0.6932505965232849\n",
      "epoch: 2 step: 633 loss: 0.693250298500061\n",
      "epoch: 2 step: 634 loss: 0.6932501792907715\n",
      "epoch: 2 step: 635 loss: 0.6932498812675476\n",
      "epoch: 2 step: 636 loss: 0.6932499408721924\n",
      "epoch: 2 step: 637 loss: 0.6932497620582581\n",
      "epoch: 2 step: 638 loss: 0.6932495832443237\n",
      "epoch: 2 step: 639 loss: 0.6932494640350342\n",
      "epoch: 2 step: 640 loss: 0.6932494640350342\n",
      "epoch: 2 step: 641 loss: 0.6932492256164551\n",
      "epoch: 2 step: 642 loss: 0.6932490468025208\n",
      "epoch: 2 step: 643 loss: 0.6932488679885864\n",
      "epoch: 2 step: 644 loss: 0.6932487487792969\n",
      "epoch: 2 step: 645 loss: 0.6932487487792969\n",
      "epoch: 2 step: 646 loss: 0.6932485103607178\n",
      "epoch: 2 step: 647 loss: 0.6932485103607178\n",
      "epoch: 2 step: 648 loss: 0.6932483911514282\n",
      "epoch: 2 step: 649 loss: 0.6932481527328491\n",
      "epoch: 2 step: 650 loss: 0.6932478547096252\n",
      "epoch: 2 step: 651 loss: 0.6932478547096252\n",
      "epoch: 2 step: 652 loss: 0.6932476758956909\n",
      "epoch: 2 step: 653 loss: 0.6932476758956909\n",
      "epoch: 2 step: 654 loss: 0.6932475566864014\n",
      "epoch: 2 step: 655 loss: 0.6932474970817566\n",
      "epoch: 2 step: 656 loss: 0.6932472586631775\n",
      "epoch: 2 step: 657 loss: 0.6932471990585327\n",
      "epoch: 2 step: 658 loss: 0.6932470798492432\n",
      "epoch: 2 step: 659 loss: 0.6932469606399536\n",
      "epoch: 2 step: 660 loss: 0.6932467222213745\n",
      "epoch: 2 step: 661 loss: 0.6932467222213745\n",
      "epoch: 2 step: 662 loss: 0.6932465434074402\n",
      "epoch: 2 step: 663 loss: 0.6932463645935059\n",
      "epoch: 2 step: 664 loss: 0.6932462453842163\n",
      "epoch: 2 step: 665 loss: 0.6932461857795715\n",
      "epoch: 2 step: 666 loss: 0.6932458877563477\n",
      "epoch: 2 step: 667 loss: 0.6932458877563477\n",
      "epoch: 2 step: 668 loss: 0.6932457685470581\n",
      "epoch: 2 step: 669 loss: 0.6932457685470581\n",
      "epoch: 2 step: 670 loss: 0.693245530128479\n",
      "epoch: 2 step: 671 loss: 0.6932454705238342\n",
      "epoch: 2 step: 672 loss: 0.6932453513145447\n",
      "epoch: 2 step: 673 loss: 0.6932451725006104\n",
      "epoch: 2 step: 674 loss: 0.6932449340820312\n",
      "epoch: 2 step: 675 loss: 0.6932448148727417\n",
      "epoch: 2 step: 676 loss: 0.6932448744773865\n",
      "epoch: 2 step: 677 loss: 0.6932445764541626\n",
      "epoch: 2 step: 678 loss: 0.6932446956634521\n",
      "epoch: 2 step: 679 loss: 0.6932443976402283\n",
      "epoch: 2 step: 680 loss: 0.6932443380355835\n",
      "epoch: 2 step: 681 loss: 0.6932442784309387\n",
      "epoch: 2 step: 682 loss: 0.693244218826294\n",
      "epoch: 2 step: 683 loss: 0.6932439804077148\n",
      "epoch: 2 step: 684 loss: 0.6932439804077148\n",
      "epoch: 2 step: 685 loss: 0.6932437419891357\n",
      "epoch: 2 step: 686 loss: 0.6932435035705566\n",
      "epoch: 2 step: 687 loss: 0.6932433843612671\n",
      "epoch: 2 step: 688 loss: 0.6932433843612671\n",
      "epoch: 2 step: 689 loss: 0.6932432055473328\n",
      "epoch: 2 step: 690 loss: 0.6932430267333984\n",
      "epoch: 2 step: 691 loss: 0.6932430267333984\n",
      "epoch: 2 step: 692 loss: 0.6932429075241089\n",
      "epoch: 2 step: 693 loss: 0.6932428479194641\n",
      "epoch: 2 step: 694 loss: 0.6932426691055298\n",
      "epoch: 2 step: 695 loss: 0.6932425498962402\n",
      "epoch: 2 step: 696 loss: 0.6932424306869507\n",
      "epoch: 2 step: 697 loss: 0.6932421922683716\n",
      "epoch: 2 step: 698 loss: 0.6932422518730164\n",
      "epoch: 2 step: 699 loss: 0.6932420134544373\n",
      "epoch: 2 step: 700 loss: 0.6932418942451477\n",
      "epoch: 2 step: 701 loss: 0.6932418942451477\n",
      "epoch: 2 step: 702 loss: 0.6932416558265686\n",
      "epoch: 2 step: 703 loss: 0.693241536617279\n",
      "epoch: 2 step: 704 loss: 0.6932414770126343\n",
      "epoch: 2 step: 705 loss: 0.6932413578033447\n",
      "epoch: 2 step: 706 loss: 0.6932411193847656\n",
      "epoch: 2 step: 707 loss: 0.6932409405708313\n",
      "epoch: 2 step: 708 loss: 0.6932408809661865\n",
      "epoch: 2 step: 709 loss: 0.6932408809661865\n",
      "epoch: 2 step: 710 loss: 0.6932409405708313\n",
      "epoch: 2 step: 711 loss: 0.6932405829429626\n",
      "epoch: 2 step: 712 loss: 0.6932405233383179\n",
      "epoch: 2 step: 713 loss: 0.6932404041290283\n",
      "epoch: 2 step: 714 loss: 0.6932403445243835\n",
      "epoch: 2 step: 715 loss: 0.6932402849197388\n",
      "epoch: 2 step: 716 loss: 0.6932401657104492\n",
      "epoch: 2 step: 717 loss: 0.6932401061058044\n",
      "epoch: 2 step: 718 loss: 0.6932398080825806\n",
      "epoch: 2 step: 719 loss: 0.6932397484779358\n",
      "epoch: 2 step: 720 loss: 0.6932395696640015\n",
      "epoch: 2 step: 721 loss: 0.693239688873291\n",
      "epoch: 2 step: 722 loss: 0.6932394504547119\n",
      "epoch: 2 step: 723 loss: 0.6932394504547119\n",
      "epoch: 2 step: 724 loss: 0.6932392120361328\n",
      "epoch: 2 step: 725 loss: 0.6932390928268433\n",
      "epoch: 2 step: 726 loss: 0.6932390332221985\n",
      "epoch: 2 step: 727 loss: 0.6932388544082642\n",
      "epoch: 2 step: 728 loss: 0.6932388544082642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 729 loss: 0.6932386159896851\n",
      "epoch: 2 step: 730 loss: 0.6932386159896851\n",
      "epoch: 2 step: 731 loss: 0.693238377571106\n",
      "epoch: 2 step: 732 loss: 0.6932382583618164\n",
      "epoch: 2 step: 733 loss: 0.6932382583618164\n",
      "epoch: 2 step: 734 loss: 0.6932380199432373\n",
      "epoch: 2 step: 735 loss: 0.6932381391525269\n",
      "epoch: 2 step: 736 loss: 0.6932379007339478\n",
      "epoch: 2 step: 737 loss: 0.6932377219200134\n",
      "epoch: 2 step: 738 loss: 0.6932375431060791\n",
      "epoch: 2 step: 739 loss: 0.6932374238967896\n",
      "epoch: 2 step: 740 loss: 0.6932374835014343\n",
      "epoch: 2 step: 741 loss: 0.6932373046875\n",
      "epoch: 2 step: 742 loss: 0.6932372450828552\n",
      "epoch: 2 step: 743 loss: 0.6932370662689209\n",
      "epoch: 2 step: 744 loss: 0.6932368874549866\n",
      "epoch: 2 step: 745 loss: 0.6932369470596313\n",
      "epoch: 2 step: 746 loss: 0.6932368278503418\n",
      "epoch: 2 step: 747 loss: 0.6932367086410522\n",
      "epoch: 2 step: 748 loss: 0.6932363510131836\n",
      "epoch: 2 step: 749 loss: 0.6932364702224731\n",
      "epoch: 2 step: 750 loss: 0.6932362914085388\n",
      "epoch: 2 step: 751 loss: 0.693236231803894\n",
      "epoch: 2 step: 752 loss: 0.6932362914085388\n",
      "epoch: 2 step: 753 loss: 0.6932359337806702\n",
      "epoch: 2 step: 754 loss: 0.6932360529899597\n",
      "epoch: 2 step: 755 loss: 0.6932357549667358\n",
      "epoch: 2 step: 756 loss: 0.6932356357574463\n",
      "epoch: 2 step: 757 loss: 0.693235456943512\n",
      "epoch: 2 step: 758 loss: 0.6932355761528015\n",
      "epoch: 2 step: 759 loss: 0.6932353973388672\n",
      "epoch: 2 step: 760 loss: 0.6932351589202881\n",
      "epoch: 2 step: 761 loss: 0.6932352185249329\n",
      "epoch: 2 step: 762 loss: 0.6932350993156433\n",
      "epoch: 2 step: 763 loss: 0.693234920501709\n",
      "epoch: 2 step: 764 loss: 0.6932348608970642\n",
      "epoch: 2 step: 765 loss: 0.6932348012924194\n",
      "epoch: 2 step: 766 loss: 0.6932345628738403\n",
      "epoch: 2 step: 767 loss: 0.6932344436645508\n",
      "epoch: 2 step: 768 loss: 0.6932344436645508\n",
      "epoch: 2 step: 769 loss: 0.6932343244552612\n",
      "epoch: 2 step: 770 loss: 0.6932342648506165\n",
      "epoch: 2 step: 771 loss: 0.6932340860366821\n",
      "epoch: 2 step: 772 loss: 0.6932340860366821\n",
      "epoch: 2 step: 773 loss: 0.6932340264320374\n",
      "epoch: 2 step: 774 loss: 0.693233847618103\n",
      "epoch: 2 step: 775 loss: 0.6932337284088135\n",
      "epoch: 2 step: 776 loss: 0.6932335495948792\n",
      "epoch: 2 step: 777 loss: 0.6932336091995239\n",
      "epoch: 2 step: 778 loss: 0.6932333707809448\n",
      "epoch: 2 step: 779 loss: 0.6932333111763\n",
      "epoch: 2 step: 780 loss: 0.6932332515716553\n",
      "epoch: 2 step: 781 loss: 0.6932330131530762\n",
      "epoch: 3 step: 1 loss: 0.6932331323623657\n",
      "epoch: 3 step: 2 loss: 0.6932328343391418\n",
      "epoch: 3 step: 3 loss: 0.6932329535484314\n",
      "epoch: 3 step: 4 loss: 0.6932327747344971\n",
      "epoch: 3 step: 5 loss: 0.6932326555252075\n",
      "epoch: 3 step: 6 loss: 0.6932325959205627\n",
      "epoch: 3 step: 7 loss: 0.6932323575019836\n",
      "epoch: 3 step: 8 loss: 0.6932322382926941\n",
      "epoch: 3 step: 9 loss: 0.6932321190834045\n",
      "epoch: 3 step: 10 loss: 0.6932320594787598\n",
      "epoch: 3 step: 11 loss: 0.6932320594787598\n",
      "epoch: 3 step: 12 loss: 0.6932320594787598\n",
      "epoch: 3 step: 13 loss: 0.6932317018508911\n",
      "epoch: 3 step: 14 loss: 0.6932317018508911\n",
      "epoch: 3 step: 15 loss: 0.6932315826416016\n",
      "epoch: 3 step: 16 loss: 0.6932315826416016\n",
      "epoch: 3 step: 17 loss: 0.6932314038276672\n",
      "epoch: 3 step: 18 loss: 0.6932313442230225\n",
      "epoch: 3 step: 19 loss: 0.6932312250137329\n",
      "epoch: 3 step: 20 loss: 0.6932311654090881\n",
      "epoch: 3 step: 21 loss: 0.6932311654090881\n",
      "epoch: 3 step: 22 loss: 0.6932308673858643\n",
      "epoch: 3 step: 23 loss: 0.6932306289672852\n",
      "epoch: 3 step: 24 loss: 0.6932307481765747\n",
      "epoch: 3 step: 25 loss: 0.6932306289672852\n",
      "epoch: 3 step: 26 loss: 0.6932306289672852\n",
      "epoch: 3 step: 27 loss: 0.693230390548706\n",
      "epoch: 3 step: 28 loss: 0.6932302713394165\n",
      "epoch: 3 step: 29 loss: 0.6932302713394165\n",
      "epoch: 3 step: 30 loss: 0.6932299733161926\n",
      "epoch: 3 step: 31 loss: 0.6932299733161926\n",
      "epoch: 3 step: 32 loss: 0.6932299137115479\n",
      "epoch: 3 step: 33 loss: 0.6932300329208374\n",
      "epoch: 3 step: 34 loss: 0.6932298541069031\n",
      "epoch: 3 step: 35 loss: 0.6932297348976135\n",
      "epoch: 3 step: 36 loss: 0.6932294368743896\n",
      "epoch: 3 step: 37 loss: 0.6932294964790344\n",
      "epoch: 3 step: 38 loss: 0.6932293176651001\n",
      "epoch: 3 step: 39 loss: 0.6932291984558105\n",
      "epoch: 3 step: 40 loss: 0.6932291984558105\n",
      "epoch: 3 step: 41 loss: 0.6932291388511658\n",
      "epoch: 3 step: 42 loss: 0.6932289004325867\n",
      "epoch: 3 step: 43 loss: 0.6932287216186523\n",
      "epoch: 3 step: 44 loss: 0.6932287216186523\n",
      "epoch: 3 step: 45 loss: 0.6932286024093628\n",
      "epoch: 3 step: 46 loss: 0.693228542804718\n",
      "epoch: 3 step: 47 loss: 0.6932283043861389\n",
      "epoch: 3 step: 48 loss: 0.6932284235954285\n",
      "epoch: 3 step: 49 loss: 0.6932284235954285\n",
      "epoch: 3 step: 50 loss: 0.6932283043861389\n",
      "epoch: 3 step: 51 loss: 0.6932281851768494\n",
      "epoch: 3 step: 52 loss: 0.6932281851768494\n",
      "epoch: 3 step: 53 loss: 0.6932279467582703\n",
      "epoch: 3 step: 54 loss: 0.6932278871536255\n",
      "epoch: 3 step: 55 loss: 0.6932277679443359\n",
      "epoch: 3 step: 56 loss: 0.6932277083396912\n",
      "epoch: 3 step: 57 loss: 0.6932277679443359\n",
      "epoch: 3 step: 58 loss: 0.6932275295257568\n",
      "epoch: 3 step: 59 loss: 0.6932272911071777\n",
      "epoch: 3 step: 60 loss: 0.6932272911071777\n",
      "epoch: 3 step: 61 loss: 0.6932271718978882\n",
      "epoch: 3 step: 62 loss: 0.6932269334793091\n",
      "epoch: 3 step: 63 loss: 0.6932269334793091\n",
      "epoch: 3 step: 64 loss: 0.6932269334793091\n",
      "epoch: 3 step: 65 loss: 0.6932269334793091\n",
      "epoch: 3 step: 66 loss: 0.6932266354560852\n",
      "epoch: 3 step: 67 loss: 0.6932265758514404\n",
      "epoch: 3 step: 68 loss: 0.6932266354560852\n",
      "epoch: 3 step: 69 loss: 0.6932264566421509\n",
      "epoch: 3 step: 70 loss: 0.6932263374328613\n",
      "epoch: 3 step: 71 loss: 0.6932263374328613\n",
      "epoch: 3 step: 72 loss: 0.6932260990142822\n",
      "epoch: 3 step: 73 loss: 0.6932262182235718\n",
      "epoch: 3 step: 74 loss: 0.6932260990142822\n",
      "epoch: 3 step: 75 loss: 0.6932259798049927\n",
      "epoch: 3 step: 76 loss: 0.6932258009910583\n",
      "epoch: 3 step: 77 loss: 0.6932258009910583\n",
      "epoch: 3 step: 78 loss: 0.693225622177124\n",
      "epoch: 3 step: 79 loss: 0.6932256817817688\n",
      "epoch: 3 step: 80 loss: 0.6932255029678345\n",
      "epoch: 3 step: 81 loss: 0.6932254433631897\n",
      "epoch: 3 step: 82 loss: 0.6932252645492554\n",
      "epoch: 3 step: 83 loss: 0.6932252645492554\n",
      "epoch: 3 step: 84 loss: 0.693225085735321\n",
      "epoch: 3 step: 85 loss: 0.6932250261306763\n",
      "epoch: 3 step: 86 loss: 0.6932249069213867\n",
      "epoch: 3 step: 87 loss: 0.6932247877120972\n",
      "epoch: 3 step: 88 loss: 0.6932247877120972\n",
      "epoch: 3 step: 89 loss: 0.6932246685028076\n",
      "epoch: 3 step: 90 loss: 0.6932245492935181\n",
      "epoch: 3 step: 91 loss: 0.6932244896888733\n",
      "epoch: 3 step: 92 loss: 0.6932244300842285\n",
      "epoch: 3 step: 93 loss: 0.693224310874939\n",
      "epoch: 3 step: 94 loss: 0.693224310874939\n",
      "epoch: 3 step: 95 loss: 0.6932241916656494\n",
      "epoch: 3 step: 96 loss: 0.6932240724563599\n",
      "epoch: 3 step: 97 loss: 0.6932239532470703\n",
      "epoch: 3 step: 98 loss: 0.6932238936424255\n",
      "epoch: 3 step: 99 loss: 0.6932238340377808\n",
      "epoch: 3 step: 100 loss: 0.6932237148284912\n",
      "epoch: 3 step: 101 loss: 0.6932236552238464\n",
      "epoch: 3 step: 102 loss: 0.6932235956192017\n",
      "epoch: 3 step: 103 loss: 0.6932234764099121\n",
      "epoch: 3 step: 104 loss: 0.6932234764099121\n",
      "epoch: 3 step: 105 loss: 0.6932233572006226\n",
      "epoch: 3 step: 106 loss: 0.693223237991333\n",
      "epoch: 3 step: 107 loss: 0.693223237991333\n",
      "epoch: 3 step: 108 loss: 0.6932229995727539\n",
      "epoch: 3 step: 109 loss: 0.6932228803634644\n",
      "epoch: 3 step: 110 loss: 0.6932229399681091\n",
      "epoch: 3 step: 111 loss: 0.6932228803634644\n",
      "epoch: 3 step: 112 loss: 0.6932226419448853\n",
      "epoch: 3 step: 113 loss: 0.6932227611541748\n",
      "epoch: 3 step: 114 loss: 0.6932227611541748\n",
      "epoch: 3 step: 115 loss: 0.6932224035263062\n",
      "epoch: 3 step: 116 loss: 0.6932224035263062\n",
      "epoch: 3 step: 117 loss: 0.6932222843170166\n",
      "epoch: 3 step: 118 loss: 0.6932221055030823\n",
      "epoch: 3 step: 119 loss: 0.693222165107727\n",
      "epoch: 3 step: 120 loss: 0.6932220458984375\n",
      "epoch: 3 step: 121 loss: 0.693221926689148\n",
      "epoch: 3 step: 122 loss: 0.693221926689148\n",
      "epoch: 3 step: 123 loss: 0.6932218074798584\n",
      "epoch: 3 step: 124 loss: 0.6932216286659241\n",
      "epoch: 3 step: 125 loss: 0.6932216882705688\n",
      "epoch: 3 step: 126 loss: 0.6932215690612793\n",
      "epoch: 3 step: 127 loss: 0.6932215690612793\n",
      "epoch: 3 step: 128 loss: 0.6932214498519897\n",
      "epoch: 3 step: 129 loss: 0.6932212710380554\n",
      "epoch: 3 step: 130 loss: 0.6932212114334106\n",
      "epoch: 3 step: 131 loss: 0.6932212114334106\n",
      "epoch: 3 step: 132 loss: 0.6932210922241211\n",
      "epoch: 3 step: 133 loss: 0.6932210326194763\n",
      "epoch: 3 step: 134 loss: 0.693220853805542\n",
      "epoch: 3 step: 135 loss: 0.6932207942008972\n",
      "epoch: 3 step: 136 loss: 0.6932207345962524\n",
      "epoch: 3 step: 137 loss: 0.6932206749916077\n",
      "epoch: 3 step: 138 loss: 0.6932205557823181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 139 loss: 0.6932206153869629\n",
      "epoch: 3 step: 140 loss: 0.6932204365730286\n",
      "epoch: 3 step: 141 loss: 0.6932202577590942\n",
      "epoch: 3 step: 142 loss: 0.6932202577590942\n",
      "epoch: 3 step: 143 loss: 0.6932201385498047\n",
      "epoch: 3 step: 144 loss: 0.6932201385498047\n",
      "epoch: 3 step: 145 loss: 0.6932200193405151\n",
      "epoch: 3 step: 146 loss: 0.6932199001312256\n",
      "epoch: 3 step: 147 loss: 0.6932199001312256\n",
      "epoch: 3 step: 148 loss: 0.6932196617126465\n",
      "epoch: 3 step: 149 loss: 0.6932197213172913\n",
      "epoch: 3 step: 150 loss: 0.6932195425033569\n",
      "epoch: 3 step: 151 loss: 0.6932194828987122\n",
      "epoch: 3 step: 152 loss: 0.6932193636894226\n",
      "epoch: 3 step: 153 loss: 0.6932194232940674\n",
      "epoch: 3 step: 154 loss: 0.6932192444801331\n",
      "epoch: 3 step: 155 loss: 0.6932193040847778\n",
      "epoch: 3 step: 156 loss: 0.6932190656661987\n",
      "epoch: 3 step: 157 loss: 0.693219006061554\n",
      "epoch: 3 step: 158 loss: 0.6932189464569092\n",
      "epoch: 3 step: 159 loss: 0.6932188272476196\n",
      "epoch: 3 step: 160 loss: 0.6932188272476196\n",
      "epoch: 3 step: 161 loss: 0.6932188272476196\n",
      "epoch: 3 step: 162 loss: 0.6932187080383301\n",
      "epoch: 3 step: 163 loss: 0.6932185888290405\n",
      "epoch: 3 step: 164 loss: 0.693218469619751\n",
      "epoch: 3 step: 165 loss: 0.6932183504104614\n",
      "epoch: 3 step: 166 loss: 0.6932182312011719\n",
      "epoch: 3 step: 167 loss: 0.6932183504104614\n",
      "epoch: 3 step: 168 loss: 0.6932182312011719\n",
      "epoch: 3 step: 169 loss: 0.6932181119918823\n",
      "epoch: 3 step: 170 loss: 0.6932179927825928\n",
      "epoch: 3 step: 171 loss: 0.6932179927825928\n",
      "epoch: 3 step: 172 loss: 0.6932179927825928\n",
      "epoch: 3 step: 173 loss: 0.6932177543640137\n",
      "epoch: 3 step: 174 loss: 0.6932176947593689\n",
      "epoch: 3 step: 175 loss: 0.6932176351547241\n",
      "epoch: 3 step: 176 loss: 0.6932175159454346\n",
      "epoch: 3 step: 177 loss: 0.6932175159454346\n",
      "epoch: 3 step: 178 loss: 0.6932174563407898\n",
      "epoch: 3 step: 179 loss: 0.6932172775268555\n",
      "epoch: 3 step: 180 loss: 0.6932172775268555\n",
      "epoch: 3 step: 181 loss: 0.6932172179222107\n",
      "epoch: 3 step: 182 loss: 0.6932170391082764\n",
      "epoch: 3 step: 183 loss: 0.6932170391082764\n",
      "epoch: 3 step: 184 loss: 0.6932169795036316\n",
      "epoch: 3 step: 185 loss: 0.6932169198989868\n",
      "epoch: 3 step: 186 loss: 0.693216860294342\n",
      "epoch: 3 step: 187 loss: 0.6932167410850525\n",
      "epoch: 3 step: 188 loss: 0.6932167410850525\n",
      "epoch: 3 step: 189 loss: 0.6932166814804077\n",
      "epoch: 3 step: 190 loss: 0.6932165622711182\n",
      "epoch: 3 step: 191 loss: 0.6932164430618286\n",
      "epoch: 3 step: 192 loss: 0.6932164430618286\n",
      "epoch: 3 step: 193 loss: 0.6932163238525391\n",
      "epoch: 3 step: 194 loss: 0.69321608543396\n",
      "epoch: 3 step: 195 loss: 0.6932161450386047\n",
      "epoch: 3 step: 196 loss: 0.69321608543396\n",
      "epoch: 3 step: 197 loss: 0.6932160258293152\n",
      "epoch: 3 step: 198 loss: 0.6932159066200256\n",
      "epoch: 3 step: 199 loss: 0.6932159066200256\n",
      "epoch: 3 step: 200 loss: 0.6932157278060913\n",
      "epoch: 3 step: 201 loss: 0.6932156682014465\n",
      "epoch: 3 step: 202 loss: 0.6932156085968018\n",
      "epoch: 3 step: 203 loss: 0.6932154893875122\n",
      "epoch: 3 step: 204 loss: 0.6932153701782227\n",
      "epoch: 3 step: 205 loss: 0.6932154893875122\n",
      "epoch: 3 step: 206 loss: 0.6932153105735779\n",
      "epoch: 3 step: 207 loss: 0.6932152509689331\n",
      "epoch: 3 step: 208 loss: 0.6932152509689331\n",
      "epoch: 3 step: 209 loss: 0.6932150721549988\n",
      "epoch: 3 step: 210 loss: 0.693215012550354\n",
      "epoch: 3 step: 211 loss: 0.693215012550354\n",
      "epoch: 3 step: 212 loss: 0.6932148933410645\n",
      "epoch: 3 step: 213 loss: 0.6932148933410645\n",
      "epoch: 3 step: 214 loss: 0.6932147741317749\n",
      "epoch: 3 step: 215 loss: 0.6932147145271301\n",
      "epoch: 3 step: 216 loss: 0.6932145953178406\n",
      "epoch: 3 step: 217 loss: 0.6932144165039062\n",
      "epoch: 3 step: 218 loss: 0.6932145357131958\n",
      "epoch: 3 step: 219 loss: 0.6932144165039062\n",
      "epoch: 3 step: 220 loss: 0.6932142972946167\n",
      "epoch: 3 step: 221 loss: 0.6932142376899719\n",
      "epoch: 3 step: 222 loss: 0.6932141780853271\n",
      "epoch: 3 step: 223 loss: 0.6932141184806824\n",
      "epoch: 3 step: 224 loss: 0.6932140588760376\n",
      "epoch: 3 step: 225 loss: 0.693213939666748\n",
      "epoch: 3 step: 226 loss: 0.6932138800621033\n",
      "epoch: 3 step: 227 loss: 0.6932137608528137\n",
      "epoch: 3 step: 228 loss: 0.6932137608528137\n",
      "epoch: 3 step: 229 loss: 0.693213701248169\n",
      "epoch: 3 step: 230 loss: 0.693213701248169\n",
      "epoch: 3 step: 231 loss: 0.6932135820388794\n",
      "epoch: 3 step: 232 loss: 0.6932134628295898\n",
      "epoch: 3 step: 233 loss: 0.6932133436203003\n",
      "epoch: 3 step: 234 loss: 0.6932133436203003\n",
      "epoch: 3 step: 235 loss: 0.6932132244110107\n",
      "epoch: 3 step: 236 loss: 0.6932132244110107\n",
      "epoch: 3 step: 237 loss: 0.6932130455970764\n",
      "epoch: 3 step: 238 loss: 0.6932129859924316\n",
      "epoch: 3 step: 239 loss: 0.6932129859924316\n",
      "epoch: 3 step: 240 loss: 0.6932129263877869\n",
      "epoch: 3 step: 241 loss: 0.6932128667831421\n",
      "epoch: 3 step: 242 loss: 0.6932128667831421\n",
      "epoch: 3 step: 243 loss: 0.6932126879692078\n",
      "epoch: 3 step: 244 loss: 0.693212628364563\n",
      "epoch: 3 step: 245 loss: 0.6932125091552734\n",
      "epoch: 3 step: 246 loss: 0.6932125091552734\n",
      "epoch: 3 step: 247 loss: 0.6932125091552734\n",
      "epoch: 3 step: 248 loss: 0.6932123899459839\n",
      "epoch: 3 step: 249 loss: 0.6932123303413391\n",
      "epoch: 3 step: 250 loss: 0.6932122111320496\n",
      "epoch: 3 step: 251 loss: 0.6932121515274048\n",
      "epoch: 3 step: 252 loss: 0.6932121515274048\n",
      "epoch: 3 step: 253 loss: 0.6932120323181152\n",
      "epoch: 3 step: 254 loss: 0.6932119131088257\n",
      "epoch: 3 step: 255 loss: 0.6932120323181152\n",
      "epoch: 3 step: 256 loss: 0.6932118535041809\n",
      "epoch: 3 step: 257 loss: 0.6932116746902466\n",
      "epoch: 3 step: 258 loss: 0.6932116746902466\n",
      "epoch: 3 step: 259 loss: 0.693211555480957\n",
      "epoch: 3 step: 260 loss: 0.6932114362716675\n",
      "epoch: 3 step: 261 loss: 0.6932114958763123\n",
      "epoch: 3 step: 262 loss: 0.6932113170623779\n",
      "epoch: 3 step: 263 loss: 0.6932113170623779\n",
      "epoch: 3 step: 264 loss: 0.6932113170623779\n",
      "epoch: 3 step: 265 loss: 0.6932111978530884\n",
      "epoch: 3 step: 266 loss: 0.6932110786437988\n",
      "epoch: 3 step: 267 loss: 0.6932110786437988\n",
      "epoch: 3 step: 268 loss: 0.6932109594345093\n",
      "epoch: 3 step: 269 loss: 0.693211019039154\n",
      "epoch: 3 step: 270 loss: 0.6932108998298645\n",
      "epoch: 3 step: 271 loss: 0.693210780620575\n",
      "epoch: 3 step: 272 loss: 0.6932107210159302\n",
      "epoch: 3 step: 273 loss: 0.6932106018066406\n",
      "epoch: 3 step: 274 loss: 0.6932106018066406\n",
      "epoch: 3 step: 275 loss: 0.6932104825973511\n",
      "epoch: 3 step: 276 loss: 0.6932104825973511\n",
      "epoch: 3 step: 277 loss: 0.6932103633880615\n",
      "epoch: 3 step: 278 loss: 0.6932101249694824\n",
      "epoch: 3 step: 279 loss: 0.693210244178772\n",
      "epoch: 3 step: 280 loss: 0.6932101845741272\n",
      "epoch: 3 step: 281 loss: 0.6932101845741272\n",
      "epoch: 3 step: 282 loss: 0.6932100057601929\n",
      "epoch: 3 step: 283 loss: 0.6932100057601929\n",
      "epoch: 3 step: 284 loss: 0.6932098865509033\n",
      "epoch: 3 step: 285 loss: 0.6932098269462585\n",
      "epoch: 3 step: 286 loss: 0.6932098865509033\n",
      "epoch: 3 step: 287 loss: 0.6932096481323242\n",
      "epoch: 3 step: 288 loss: 0.693209707736969\n",
      "epoch: 3 step: 289 loss: 0.6932096481323242\n",
      "epoch: 3 step: 290 loss: 0.6932095289230347\n",
      "epoch: 3 step: 291 loss: 0.6932094097137451\n",
      "epoch: 3 step: 292 loss: 0.6932094097137451\n",
      "epoch: 3 step: 293 loss: 0.6932094097137451\n",
      "epoch: 3 step: 294 loss: 0.693209171295166\n",
      "epoch: 3 step: 295 loss: 0.693209171295166\n",
      "epoch: 3 step: 296 loss: 0.6932090520858765\n",
      "epoch: 3 step: 297 loss: 0.6932090520858765\n",
      "epoch: 3 step: 298 loss: 0.6932090520858765\n",
      "epoch: 3 step: 299 loss: 0.6932089328765869\n",
      "epoch: 3 step: 300 loss: 0.6932088136672974\n",
      "epoch: 3 step: 301 loss: 0.6932088136672974\n",
      "epoch: 3 step: 302 loss: 0.6932088136672974\n",
      "epoch: 3 step: 303 loss: 0.6932086944580078\n",
      "epoch: 3 step: 304 loss: 0.6932086944580078\n",
      "epoch: 3 step: 305 loss: 0.6932086944580078\n",
      "epoch: 3 step: 306 loss: 0.6932084560394287\n",
      "epoch: 3 step: 307 loss: 0.6932084560394287\n",
      "epoch: 3 step: 308 loss: 0.6932084560394287\n",
      "epoch: 3 step: 309 loss: 0.6932083368301392\n",
      "epoch: 3 step: 310 loss: 0.6932082772254944\n",
      "epoch: 3 step: 311 loss: 0.6932083368301392\n",
      "epoch: 3 step: 312 loss: 0.6932082176208496\n",
      "epoch: 3 step: 313 loss: 0.6932080984115601\n",
      "epoch: 3 step: 314 loss: 0.6932079792022705\n",
      "epoch: 3 step: 315 loss: 0.6932080984115601\n",
      "epoch: 3 step: 316 loss: 0.6932079195976257\n",
      "epoch: 3 step: 317 loss: 0.6932077407836914\n",
      "epoch: 3 step: 318 loss: 0.6932078003883362\n",
      "epoch: 3 step: 319 loss: 0.6932076215744019\n",
      "epoch: 3 step: 320 loss: 0.6932076215744019\n",
      "epoch: 3 step: 321 loss: 0.6932075619697571\n",
      "epoch: 3 step: 322 loss: 0.6932075023651123\n",
      "epoch: 3 step: 323 loss: 0.6932075023651123\n",
      "epoch: 3 step: 324 loss: 0.693207323551178\n",
      "epoch: 3 step: 325 loss: 0.6932073831558228\n",
      "epoch: 3 step: 326 loss: 0.6932072639465332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 327 loss: 0.6932072043418884\n",
      "epoch: 3 step: 328 loss: 0.6932072639465332\n",
      "epoch: 3 step: 329 loss: 0.6932070851325989\n",
      "epoch: 3 step: 330 loss: 0.6932069659233093\n",
      "epoch: 3 step: 331 loss: 0.6932070255279541\n",
      "epoch: 3 step: 332 loss: 0.6932069063186646\n",
      "epoch: 3 step: 333 loss: 0.6932069063186646\n",
      "epoch: 3 step: 334 loss: 0.693206787109375\n",
      "epoch: 3 step: 335 loss: 0.6932067275047302\n",
      "epoch: 3 step: 336 loss: 0.6932066082954407\n",
      "epoch: 3 step: 337 loss: 0.6932066679000854\n",
      "epoch: 3 step: 338 loss: 0.6932065486907959\n",
      "epoch: 3 step: 339 loss: 0.6932065486907959\n",
      "epoch: 3 step: 340 loss: 0.6932063102722168\n",
      "epoch: 3 step: 341 loss: 0.6932064294815063\n",
      "epoch: 3 step: 342 loss: 0.6932064294815063\n",
      "epoch: 3 step: 343 loss: 0.6932061910629272\n",
      "epoch: 3 step: 344 loss: 0.6932061910629272\n",
      "epoch: 3 step: 345 loss: 0.6932061314582825\n",
      "epoch: 3 step: 346 loss: 0.6932059526443481\n",
      "epoch: 3 step: 347 loss: 0.6932060718536377\n",
      "epoch: 3 step: 348 loss: 0.6932059526443481\n",
      "epoch: 3 step: 349 loss: 0.6932059526443481\n",
      "epoch: 3 step: 350 loss: 0.6932058334350586\n",
      "epoch: 3 step: 351 loss: 0.6932058334350586\n",
      "epoch: 3 step: 352 loss: 0.693205714225769\n",
      "epoch: 3 step: 353 loss: 0.693205714225769\n",
      "epoch: 3 step: 354 loss: 0.6932056546211243\n",
      "epoch: 3 step: 355 loss: 0.6932054758071899\n",
      "epoch: 3 step: 356 loss: 0.6932054758071899\n",
      "epoch: 3 step: 357 loss: 0.6932054758071899\n",
      "epoch: 3 step: 358 loss: 0.6932053565979004\n",
      "epoch: 3 step: 359 loss: 0.6932052969932556\n",
      "epoch: 3 step: 360 loss: 0.6932052969932556\n",
      "epoch: 3 step: 361 loss: 0.6932051777839661\n",
      "epoch: 3 step: 362 loss: 0.6932051777839661\n",
      "epoch: 3 step: 363 loss: 0.6932049989700317\n",
      "epoch: 3 step: 364 loss: 0.6932051181793213\n",
      "epoch: 3 step: 365 loss: 0.6932049989700317\n",
      "epoch: 3 step: 366 loss: 0.6932048797607422\n",
      "epoch: 3 step: 367 loss: 0.6932048797607422\n",
      "epoch: 3 step: 368 loss: 0.6932047605514526\n",
      "epoch: 3 step: 369 loss: 0.6932047009468079\n",
      "epoch: 3 step: 370 loss: 0.6932046413421631\n",
      "epoch: 3 step: 371 loss: 0.6932046413421631\n",
      "epoch: 3 step: 372 loss: 0.6932045221328735\n",
      "epoch: 3 step: 373 loss: 0.6932045221328735\n",
      "epoch: 3 step: 374 loss: 0.693204402923584\n",
      "epoch: 3 step: 375 loss: 0.693204402923584\n",
      "epoch: 3 step: 376 loss: 0.6932042837142944\n",
      "epoch: 3 step: 377 loss: 0.6932043433189392\n",
      "epoch: 3 step: 378 loss: 0.6932041645050049\n",
      "epoch: 3 step: 379 loss: 0.6932041645050049\n",
      "epoch: 3 step: 380 loss: 0.6932040452957153\n",
      "epoch: 3 step: 381 loss: 0.6932040452957153\n",
      "epoch: 3 step: 382 loss: 0.6932040452957153\n",
      "epoch: 3 step: 383 loss: 0.6932039260864258\n",
      "epoch: 3 step: 384 loss: 0.693203866481781\n",
      "epoch: 3 step: 385 loss: 0.6932038068771362\n",
      "epoch: 3 step: 386 loss: 0.6932037472724915\n",
      "epoch: 3 step: 387 loss: 0.6932036876678467\n",
      "epoch: 3 step: 388 loss: 0.6932036280632019\n",
      "epoch: 3 step: 389 loss: 0.6932036280632019\n",
      "epoch: 3 step: 390 loss: 0.6932034492492676\n",
      "epoch: 3 step: 391 loss: 0.6932034492492676\n",
      "epoch: 3 step: 392 loss: 0.6932034492492676\n",
      "epoch: 3 step: 393 loss: 0.6932034492492676\n",
      "epoch: 3 step: 394 loss: 0.693203330039978\n",
      "epoch: 3 step: 395 loss: 0.693203330039978\n",
      "epoch: 3 step: 396 loss: 0.6932032108306885\n",
      "epoch: 3 step: 397 loss: 0.6932032108306885\n",
      "epoch: 3 step: 398 loss: 0.6932030916213989\n",
      "epoch: 3 step: 399 loss: 0.6932029724121094\n",
      "epoch: 3 step: 400 loss: 0.6932029724121094\n",
      "epoch: 3 step: 401 loss: 0.6932028532028198\n",
      "epoch: 3 step: 402 loss: 0.6932028532028198\n",
      "epoch: 3 step: 403 loss: 0.6932027339935303\n",
      "epoch: 3 step: 404 loss: 0.693202793598175\n",
      "epoch: 3 step: 405 loss: 0.6932026743888855\n",
      "epoch: 3 step: 406 loss: 0.6932027339935303\n",
      "epoch: 3 step: 407 loss: 0.6932026147842407\n",
      "epoch: 3 step: 408 loss: 0.6932024955749512\n",
      "epoch: 3 step: 409 loss: 0.6932024955749512\n",
      "epoch: 3 step: 410 loss: 0.6932023763656616\n",
      "epoch: 3 step: 411 loss: 0.6932023763656616\n",
      "epoch: 3 step: 412 loss: 0.6932023167610168\n",
      "epoch: 3 step: 413 loss: 0.6932022571563721\n",
      "epoch: 3 step: 414 loss: 0.6932021379470825\n",
      "epoch: 3 step: 415 loss: 0.6932020783424377\n",
      "epoch: 3 step: 416 loss: 0.6932020783424377\n",
      "epoch: 3 step: 417 loss: 0.6932020783424377\n",
      "epoch: 3 step: 418 loss: 0.693202018737793\n",
      "epoch: 3 step: 419 loss: 0.6932019591331482\n",
      "epoch: 3 step: 420 loss: 0.6932018399238586\n",
      "epoch: 3 step: 421 loss: 0.6932017803192139\n",
      "epoch: 3 step: 422 loss: 0.6932017803192139\n",
      "epoch: 3 step: 423 loss: 0.6932016611099243\n",
      "epoch: 3 step: 424 loss: 0.6932016611099243\n",
      "epoch: 3 step: 425 loss: 0.6932016015052795\n",
      "epoch: 3 step: 426 loss: 0.6932016015052795\n",
      "epoch: 3 step: 427 loss: 0.6932015419006348\n",
      "epoch: 3 step: 428 loss: 0.6932014226913452\n",
      "epoch: 3 step: 429 loss: 0.6932014226913452\n",
      "epoch: 3 step: 430 loss: 0.6932013630867004\n",
      "epoch: 3 step: 431 loss: 0.6932013034820557\n",
      "epoch: 3 step: 432 loss: 0.6932012438774109\n",
      "epoch: 3 step: 433 loss: 0.6932011246681213\n",
      "epoch: 3 step: 434 loss: 0.6932010650634766\n",
      "epoch: 3 step: 435 loss: 0.6932010650634766\n",
      "epoch: 3 step: 436 loss: 0.6932010650634766\n",
      "epoch: 3 step: 437 loss: 0.6932010054588318\n",
      "epoch: 3 step: 438 loss: 0.693200945854187\n",
      "epoch: 3 step: 439 loss: 0.6932008862495422\n",
      "epoch: 3 step: 440 loss: 0.6932007670402527\n",
      "epoch: 3 step: 441 loss: 0.6932007074356079\n",
      "epoch: 3 step: 442 loss: 0.6932007074356079\n",
      "epoch: 3 step: 443 loss: 0.6932006478309631\n",
      "epoch: 3 step: 444 loss: 0.6932005882263184\n",
      "epoch: 3 step: 445 loss: 0.6932006478309631\n",
      "epoch: 3 step: 446 loss: 0.6932005882263184\n",
      "epoch: 3 step: 447 loss: 0.6932004690170288\n",
      "epoch: 3 step: 448 loss: 0.6932004690170288\n",
      "epoch: 3 step: 449 loss: 0.6932002902030945\n",
      "epoch: 3 step: 450 loss: 0.6932003498077393\n",
      "epoch: 3 step: 451 loss: 0.6932002902030945\n",
      "epoch: 3 step: 452 loss: 0.6932001709938049\n",
      "epoch: 3 step: 453 loss: 0.6932001113891602\n",
      "epoch: 3 step: 454 loss: 0.6932001113891602\n",
      "epoch: 3 step: 455 loss: 0.6932001113891602\n",
      "epoch: 3 step: 456 loss: 0.6932001113891602\n",
      "epoch: 3 step: 457 loss: 0.693199872970581\n",
      "epoch: 3 step: 458 loss: 0.6931998133659363\n",
      "epoch: 3 step: 459 loss: 0.6931997537612915\n",
      "epoch: 3 step: 460 loss: 0.6931997537612915\n",
      "epoch: 3 step: 461 loss: 0.6931997537612915\n",
      "epoch: 3 step: 462 loss: 0.693199634552002\n",
      "epoch: 3 step: 463 loss: 0.693199634552002\n",
      "epoch: 3 step: 464 loss: 0.693199634552002\n",
      "epoch: 3 step: 465 loss: 0.6931995153427124\n",
      "epoch: 3 step: 466 loss: 0.6931995153427124\n",
      "epoch: 3 step: 467 loss: 0.6931994557380676\n",
      "epoch: 3 step: 468 loss: 0.6931993961334229\n",
      "epoch: 3 step: 469 loss: 0.6931993365287781\n",
      "epoch: 3 step: 470 loss: 0.6931992769241333\n",
      "epoch: 3 step: 471 loss: 0.6931992769241333\n",
      "epoch: 3 step: 472 loss: 0.6931992769241333\n",
      "epoch: 3 step: 473 loss: 0.6931991577148438\n",
      "epoch: 3 step: 474 loss: 0.6931990385055542\n",
      "epoch: 3 step: 475 loss: 0.6931990385055542\n",
      "epoch: 3 step: 476 loss: 0.6931989192962646\n",
      "epoch: 3 step: 477 loss: 0.6931988596916199\n",
      "epoch: 3 step: 478 loss: 0.6931989192962646\n",
      "epoch: 3 step: 479 loss: 0.6931988000869751\n",
      "epoch: 3 step: 480 loss: 0.6931988000869751\n",
      "epoch: 3 step: 481 loss: 0.6931988000869751\n",
      "epoch: 3 step: 482 loss: 0.6931986808776855\n",
      "epoch: 3 step: 483 loss: 0.693198561668396\n",
      "epoch: 3 step: 484 loss: 0.693198561668396\n",
      "epoch: 3 step: 485 loss: 0.6931984424591064\n",
      "epoch: 3 step: 486 loss: 0.693198561668396\n",
      "epoch: 3 step: 487 loss: 0.6931985020637512\n",
      "epoch: 3 step: 488 loss: 0.6931984424591064\n",
      "epoch: 3 step: 489 loss: 0.6931983232498169\n",
      "epoch: 3 step: 490 loss: 0.6931983232498169\n",
      "epoch: 3 step: 491 loss: 0.6931982040405273\n",
      "epoch: 3 step: 492 loss: 0.6931982040405273\n",
      "epoch: 3 step: 493 loss: 0.6931982040405273\n",
      "epoch: 3 step: 494 loss: 0.6931982040405273\n",
      "epoch: 3 step: 495 loss: 0.693198025226593\n",
      "epoch: 3 step: 496 loss: 0.693198025226593\n",
      "epoch: 3 step: 497 loss: 0.6931979060173035\n",
      "epoch: 3 step: 498 loss: 0.6931979656219482\n",
      "epoch: 3 step: 499 loss: 0.6931978464126587\n",
      "epoch: 3 step: 500 loss: 0.6931977868080139\n",
      "epoch: 3 step: 501 loss: 0.6931977272033691\n",
      "epoch: 3 step: 502 loss: 0.6931976675987244\n",
      "epoch: 3 step: 503 loss: 0.6931977272033691\n",
      "epoch: 3 step: 504 loss: 0.6931976079940796\n",
      "epoch: 3 step: 505 loss: 0.6931976675987244\n",
      "epoch: 3 step: 506 loss: 0.6931975483894348\n",
      "epoch: 3 step: 507 loss: 0.6931973695755005\n",
      "epoch: 3 step: 508 loss: 0.69319748878479\n",
      "epoch: 3 step: 509 loss: 0.6931973695755005\n",
      "epoch: 3 step: 510 loss: 0.6931973099708557\n",
      "epoch: 3 step: 511 loss: 0.6931972503662109\n",
      "epoch: 3 step: 512 loss: 0.6931972503662109\n",
      "epoch: 3 step: 513 loss: 0.6931971311569214\n",
      "epoch: 3 step: 514 loss: 0.6931971311569214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 515 loss: 0.6931971311569214\n",
      "epoch: 3 step: 516 loss: 0.6931970715522766\n",
      "epoch: 3 step: 517 loss: 0.6931970119476318\n",
      "epoch: 3 step: 518 loss: 0.6931968927383423\n",
      "epoch: 3 step: 519 loss: 0.6931968331336975\n",
      "epoch: 3 step: 520 loss: 0.6931968331336975\n",
      "epoch: 3 step: 521 loss: 0.6931968331336975\n",
      "epoch: 3 step: 522 loss: 0.6931966543197632\n",
      "epoch: 3 step: 523 loss: 0.6931967735290527\n",
      "epoch: 3 step: 524 loss: 0.6931966543197632\n",
      "epoch: 3 step: 525 loss: 0.6931966543197632\n",
      "epoch: 3 step: 526 loss: 0.6931965351104736\n",
      "epoch: 3 step: 527 loss: 0.6931965351104736\n",
      "epoch: 3 step: 528 loss: 0.6931964159011841\n",
      "epoch: 3 step: 529 loss: 0.6931964159011841\n",
      "epoch: 3 step: 530 loss: 0.6931963562965393\n",
      "epoch: 3 step: 531 loss: 0.6931964159011841\n",
      "epoch: 3 step: 532 loss: 0.6931962966918945\n",
      "epoch: 3 step: 533 loss: 0.6931962370872498\n",
      "epoch: 3 step: 534 loss: 0.6931962966918945\n",
      "epoch: 3 step: 535 loss: 0.693196177482605\n",
      "epoch: 3 step: 536 loss: 0.6931960582733154\n",
      "epoch: 3 step: 537 loss: 0.6931961178779602\n",
      "epoch: 3 step: 538 loss: 0.6931959986686707\n",
      "epoch: 3 step: 539 loss: 0.6931959390640259\n",
      "epoch: 3 step: 540 loss: 0.6931959390640259\n",
      "epoch: 3 step: 541 loss: 0.6931958794593811\n",
      "epoch: 3 step: 542 loss: 0.6931958198547363\n",
      "epoch: 3 step: 543 loss: 0.6931957006454468\n",
      "epoch: 3 step: 544 loss: 0.6931957602500916\n",
      "epoch: 3 step: 545 loss: 0.6931957006454468\n",
      "epoch: 3 step: 546 loss: 0.6931957006454468\n",
      "epoch: 3 step: 547 loss: 0.6931955814361572\n",
      "epoch: 3 step: 548 loss: 0.6931955814361572\n",
      "epoch: 3 step: 549 loss: 0.6931955218315125\n",
      "epoch: 3 step: 550 loss: 0.6931955814361572\n",
      "epoch: 3 step: 551 loss: 0.6931954026222229\n",
      "epoch: 3 step: 552 loss: 0.6931952834129333\n",
      "epoch: 3 step: 553 loss: 0.6931953430175781\n",
      "epoch: 3 step: 554 loss: 0.6931953430175781\n",
      "epoch: 3 step: 555 loss: 0.6931952238082886\n",
      "epoch: 3 step: 556 loss: 0.693195104598999\n",
      "epoch: 3 step: 557 loss: 0.693195104598999\n",
      "epoch: 3 step: 558 loss: 0.693195104598999\n",
      "epoch: 3 step: 559 loss: 0.693195104598999\n",
      "epoch: 3 step: 560 loss: 0.6931949853897095\n",
      "epoch: 3 step: 561 loss: 0.6931949257850647\n",
      "epoch: 3 step: 562 loss: 0.6931948661804199\n",
      "epoch: 3 step: 563 loss: 0.6931948661804199\n",
      "epoch: 3 step: 564 loss: 0.6931948661804199\n",
      "epoch: 3 step: 565 loss: 0.6931946873664856\n",
      "epoch: 3 step: 566 loss: 0.6931947469711304\n",
      "epoch: 3 step: 567 loss: 0.6931946277618408\n",
      "epoch: 3 step: 568 loss: 0.6931946277618408\n",
      "epoch: 3 step: 569 loss: 0.693194568157196\n",
      "epoch: 3 step: 570 loss: 0.6931946277618408\n",
      "epoch: 3 step: 571 loss: 0.6931945085525513\n",
      "epoch: 3 step: 572 loss: 0.6931943893432617\n",
      "epoch: 3 step: 573 loss: 0.6931943893432617\n",
      "epoch: 3 step: 574 loss: 0.6931943297386169\n",
      "epoch: 3 step: 575 loss: 0.6931943893432617\n",
      "epoch: 3 step: 576 loss: 0.6931942105293274\n",
      "epoch: 3 step: 577 loss: 0.6931942105293274\n",
      "epoch: 3 step: 578 loss: 0.6931942105293274\n",
      "epoch: 3 step: 579 loss: 0.6931942701339722\n",
      "epoch: 3 step: 580 loss: 0.6931941509246826\n",
      "epoch: 3 step: 581 loss: 0.6931940317153931\n",
      "epoch: 3 step: 582 loss: 0.6931940317153931\n",
      "epoch: 3 step: 583 loss: 0.6931940317153931\n",
      "epoch: 3 step: 584 loss: 0.6931938529014587\n",
      "epoch: 3 step: 585 loss: 0.6931939721107483\n",
      "epoch: 3 step: 586 loss: 0.6931939125061035\n",
      "epoch: 3 step: 587 loss: 0.6931938529014587\n",
      "epoch: 3 step: 588 loss: 0.693193793296814\n",
      "epoch: 3 step: 589 loss: 0.6931936740875244\n",
      "epoch: 3 step: 590 loss: 0.6931937336921692\n",
      "epoch: 3 step: 591 loss: 0.6931936740875244\n",
      "epoch: 3 step: 592 loss: 0.6931935548782349\n",
      "epoch: 3 step: 593 loss: 0.6931936144828796\n",
      "epoch: 3 step: 594 loss: 0.6931934952735901\n",
      "epoch: 3 step: 595 loss: 0.6931934952735901\n",
      "epoch: 3 step: 596 loss: 0.6931933760643005\n",
      "epoch: 3 step: 597 loss: 0.6931934356689453\n",
      "epoch: 3 step: 598 loss: 0.6931933164596558\n",
      "epoch: 3 step: 599 loss: 0.693193256855011\n",
      "epoch: 3 step: 600 loss: 0.6931933164596558\n",
      "epoch: 3 step: 601 loss: 0.693193256855011\n",
      "epoch: 3 step: 602 loss: 0.6931931972503662\n",
      "epoch: 3 step: 603 loss: 0.6931931972503662\n",
      "epoch: 3 step: 604 loss: 0.6931930184364319\n",
      "epoch: 3 step: 605 loss: 0.6931930780410767\n",
      "epoch: 3 step: 606 loss: 0.6931930184364319\n",
      "epoch: 3 step: 607 loss: 0.6931929588317871\n",
      "epoch: 3 step: 608 loss: 0.6931928396224976\n",
      "epoch: 3 step: 609 loss: 0.6931928396224976\n",
      "epoch: 3 step: 610 loss: 0.6931928396224976\n",
      "epoch: 3 step: 611 loss: 0.6931928396224976\n",
      "epoch: 3 step: 612 loss: 0.693192720413208\n",
      "epoch: 3 step: 613 loss: 0.693192720413208\n",
      "epoch: 3 step: 614 loss: 0.6931926608085632\n",
      "epoch: 3 step: 615 loss: 0.6931925415992737\n",
      "epoch: 3 step: 616 loss: 0.6931926012039185\n",
      "epoch: 3 step: 617 loss: 0.6931925415992737\n",
      "epoch: 3 step: 618 loss: 0.6931924819946289\n",
      "epoch: 3 step: 619 loss: 0.6931924223899841\n",
      "epoch: 3 step: 620 loss: 0.6931924223899841\n",
      "epoch: 3 step: 621 loss: 0.6931923627853394\n",
      "epoch: 3 step: 622 loss: 0.6931923627853394\n",
      "epoch: 3 step: 623 loss: 0.6931922435760498\n",
      "epoch: 3 step: 624 loss: 0.6931922435760498\n",
      "epoch: 3 step: 625 loss: 0.6931921243667603\n",
      "epoch: 3 step: 626 loss: 0.6931922435760498\n",
      "epoch: 3 step: 627 loss: 0.6931921243667603\n",
      "epoch: 3 step: 628 loss: 0.6931921243667603\n",
      "epoch: 3 step: 629 loss: 0.6931920051574707\n",
      "epoch: 3 step: 630 loss: 0.6931920051574707\n",
      "epoch: 3 step: 631 loss: 0.6931920051574707\n",
      "epoch: 3 step: 632 loss: 0.6931920051574707\n",
      "epoch: 3 step: 633 loss: 0.6931918859481812\n",
      "epoch: 3 step: 634 loss: 0.6931918263435364\n",
      "epoch: 3 step: 635 loss: 0.6931917667388916\n",
      "epoch: 3 step: 636 loss: 0.6931917667388916\n",
      "epoch: 3 step: 637 loss: 0.6931917071342468\n",
      "epoch: 3 step: 638 loss: 0.693191647529602\n",
      "epoch: 3 step: 639 loss: 0.693191647529602\n",
      "epoch: 3 step: 640 loss: 0.693191647529602\n",
      "epoch: 3 step: 641 loss: 0.6931915283203125\n",
      "epoch: 3 step: 642 loss: 0.6931915283203125\n",
      "epoch: 3 step: 643 loss: 0.693191409111023\n",
      "epoch: 3 step: 644 loss: 0.693191409111023\n",
      "epoch: 3 step: 645 loss: 0.693191409111023\n",
      "epoch: 3 step: 646 loss: 0.6931912899017334\n",
      "epoch: 3 step: 647 loss: 0.6931913495063782\n",
      "epoch: 3 step: 648 loss: 0.6931912899017334\n",
      "epoch: 3 step: 649 loss: 0.6931912302970886\n",
      "epoch: 3 step: 650 loss: 0.6931911706924438\n",
      "epoch: 3 step: 651 loss: 0.6931911110877991\n",
      "epoch: 3 step: 652 loss: 0.6931910514831543\n",
      "epoch: 3 step: 653 loss: 0.6931910514831543\n",
      "epoch: 3 step: 654 loss: 0.6931911110877991\n",
      "epoch: 3 step: 655 loss: 0.6931910514831543\n",
      "epoch: 3 step: 656 loss: 0.6931909322738647\n",
      "epoch: 3 step: 657 loss: 0.6931909322738647\n",
      "epoch: 3 step: 658 loss: 0.69319087266922\n",
      "epoch: 3 step: 659 loss: 0.69319087266922\n",
      "epoch: 3 step: 660 loss: 0.6931908130645752\n",
      "epoch: 3 step: 661 loss: 0.6931908130645752\n",
      "epoch: 3 step: 662 loss: 0.6931906938552856\n",
      "epoch: 3 step: 663 loss: 0.6931906938552856\n",
      "epoch: 3 step: 664 loss: 0.6931906938552856\n",
      "epoch: 3 step: 665 loss: 0.6931905746459961\n",
      "epoch: 3 step: 666 loss: 0.6931904554367065\n",
      "epoch: 3 step: 667 loss: 0.6931905746459961\n",
      "epoch: 3 step: 668 loss: 0.6931904554367065\n",
      "epoch: 3 step: 669 loss: 0.6931904554367065\n",
      "epoch: 3 step: 670 loss: 0.6931903958320618\n",
      "epoch: 3 step: 671 loss: 0.6931903958320618\n",
      "epoch: 3 step: 672 loss: 0.693190336227417\n",
      "epoch: 3 step: 673 loss: 0.6931902766227722\n",
      "epoch: 3 step: 674 loss: 0.6931902170181274\n",
      "epoch: 3 step: 675 loss: 0.6931901574134827\n",
      "epoch: 3 step: 676 loss: 0.6931902170181274\n",
      "epoch: 3 step: 677 loss: 0.6931900978088379\n",
      "epoch: 3 step: 678 loss: 0.6931900978088379\n",
      "epoch: 3 step: 679 loss: 0.6931900382041931\n",
      "epoch: 3 step: 680 loss: 0.6931899785995483\n",
      "epoch: 3 step: 681 loss: 0.6931900382041931\n",
      "epoch: 3 step: 682 loss: 0.6931899785995483\n",
      "epoch: 3 step: 683 loss: 0.6931899189949036\n",
      "epoch: 3 step: 684 loss: 0.6931899189949036\n",
      "epoch: 3 step: 685 loss: 0.693189799785614\n",
      "epoch: 3 step: 686 loss: 0.6931897401809692\n",
      "epoch: 3 step: 687 loss: 0.6931897401809692\n",
      "epoch: 3 step: 688 loss: 0.6931897401809692\n",
      "epoch: 3 step: 689 loss: 0.6931896805763245\n",
      "epoch: 3 step: 690 loss: 0.6931896209716797\n",
      "epoch: 3 step: 691 loss: 0.6931896209716797\n",
      "epoch: 3 step: 692 loss: 0.6931895613670349\n",
      "epoch: 3 step: 693 loss: 0.6931895613670349\n",
      "epoch: 3 step: 694 loss: 0.6931895017623901\n",
      "epoch: 3 step: 695 loss: 0.6931894421577454\n",
      "epoch: 3 step: 696 loss: 0.6931893825531006\n",
      "epoch: 3 step: 697 loss: 0.6931893825531006\n",
      "epoch: 3 step: 698 loss: 0.6931893825531006\n",
      "epoch: 3 step: 699 loss: 0.6931893229484558\n",
      "epoch: 3 step: 700 loss: 0.6931892037391663\n",
      "epoch: 3 step: 701 loss: 0.693189263343811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 702 loss: 0.6931891441345215\n",
      "epoch: 3 step: 703 loss: 0.6931891441345215\n",
      "epoch: 3 step: 704 loss: 0.6931890845298767\n",
      "epoch: 3 step: 705 loss: 0.6931890845298767\n",
      "epoch: 3 step: 706 loss: 0.6931889653205872\n",
      "epoch: 3 step: 707 loss: 0.6931889057159424\n",
      "epoch: 3 step: 708 loss: 0.6931889057159424\n",
      "epoch: 3 step: 709 loss: 0.6931889057159424\n",
      "epoch: 3 step: 710 loss: 0.6931889653205872\n",
      "epoch: 3 step: 711 loss: 0.6931887865066528\n",
      "epoch: 3 step: 712 loss: 0.6931887865066528\n",
      "epoch: 3 step: 713 loss: 0.6931887865066528\n",
      "epoch: 3 step: 714 loss: 0.6931887865066528\n",
      "epoch: 3 step: 715 loss: 0.6931887269020081\n",
      "epoch: 3 step: 716 loss: 0.6931886672973633\n",
      "epoch: 3 step: 717 loss: 0.6931886672973633\n",
      "epoch: 3 step: 718 loss: 0.6931885480880737\n",
      "epoch: 3 step: 719 loss: 0.6931885480880737\n",
      "epoch: 3 step: 720 loss: 0.6931884288787842\n",
      "epoch: 3 step: 721 loss: 0.6931885480880737\n",
      "epoch: 3 step: 722 loss: 0.6931884288787842\n",
      "epoch: 3 step: 723 loss: 0.693188488483429\n",
      "epoch: 3 step: 724 loss: 0.6931883692741394\n",
      "epoch: 3 step: 725 loss: 0.6931883096694946\n",
      "epoch: 3 step: 726 loss: 0.6931883096694946\n",
      "epoch: 3 step: 727 loss: 0.6931883096694946\n",
      "epoch: 3 step: 728 loss: 0.6931882500648499\n",
      "epoch: 3 step: 729 loss: 0.6931881904602051\n",
      "epoch: 3 step: 730 loss: 0.6931881904602051\n",
      "epoch: 3 step: 731 loss: 0.6931881308555603\n",
      "epoch: 3 step: 732 loss: 0.6931880712509155\n",
      "epoch: 3 step: 733 loss: 0.6931880712509155\n",
      "epoch: 3 step: 734 loss: 0.6931880116462708\n",
      "epoch: 3 step: 735 loss: 0.6931880116462708\n",
      "epoch: 3 step: 736 loss: 0.693187952041626\n",
      "epoch: 3 step: 737 loss: 0.6931878328323364\n",
      "epoch: 3 step: 738 loss: 0.6931878328323364\n",
      "epoch: 3 step: 739 loss: 0.6931877732276917\n",
      "epoch: 3 step: 740 loss: 0.6931877732276917\n",
      "epoch: 3 step: 741 loss: 0.6931877732276917\n",
      "epoch: 3 step: 742 loss: 0.6931877136230469\n",
      "epoch: 3 step: 743 loss: 0.6931876540184021\n",
      "epoch: 3 step: 744 loss: 0.6931875944137573\n",
      "epoch: 3 step: 745 loss: 0.6931875944137573\n",
      "epoch: 3 step: 746 loss: 0.6931875944137573\n",
      "epoch: 3 step: 747 loss: 0.6931875348091125\n",
      "epoch: 3 step: 748 loss: 0.6931873559951782\n",
      "epoch: 3 step: 749 loss: 0.6931874752044678\n",
      "epoch: 3 step: 750 loss: 0.6931873559951782\n",
      "epoch: 3 step: 751 loss: 0.6931873559951782\n",
      "epoch: 3 step: 752 loss: 0.693187415599823\n",
      "epoch: 3 step: 753 loss: 0.6931872367858887\n",
      "epoch: 3 step: 754 loss: 0.6931873559951782\n",
      "epoch: 3 step: 755 loss: 0.6931872367858887\n",
      "epoch: 3 step: 756 loss: 0.6931872367858887\n",
      "epoch: 3 step: 757 loss: 0.6931871175765991\n",
      "epoch: 3 step: 758 loss: 0.6931871771812439\n",
      "epoch: 3 step: 759 loss: 0.6931871175765991\n",
      "epoch: 3 step: 760 loss: 0.6931869983673096\n",
      "epoch: 3 step: 761 loss: 0.6931870579719543\n",
      "epoch: 3 step: 762 loss: 0.6931869983673096\n",
      "epoch: 3 step: 763 loss: 0.6931869387626648\n",
      "epoch: 3 step: 764 loss: 0.6931869387626648\n",
      "epoch: 3 step: 765 loss: 0.69318687915802\n",
      "epoch: 3 step: 766 loss: 0.69318687915802\n",
      "epoch: 3 step: 767 loss: 0.6931868195533752\n",
      "epoch: 3 step: 768 loss: 0.6931867599487305\n",
      "epoch: 3 step: 769 loss: 0.6931867599487305\n",
      "epoch: 3 step: 770 loss: 0.6931867599487305\n",
      "epoch: 3 step: 771 loss: 0.6931866407394409\n",
      "epoch: 3 step: 772 loss: 0.6931866407394409\n",
      "epoch: 3 step: 773 loss: 0.6931866407394409\n",
      "epoch: 3 step: 774 loss: 0.6931866407394409\n",
      "epoch: 3 step: 775 loss: 0.6931865215301514\n",
      "epoch: 3 step: 776 loss: 0.6931865215301514\n",
      "epoch: 3 step: 777 loss: 0.6931865215301514\n",
      "epoch: 3 step: 778 loss: 0.6931864023208618\n",
      "epoch: 3 step: 779 loss: 0.6931864023208618\n",
      "epoch: 3 step: 780 loss: 0.6931864023208618\n",
      "epoch: 3 step: 781 loss: 0.693186342716217\n",
      "epoch: 4 step: 1 loss: 0.6931864023208618\n",
      "epoch: 4 step: 2 loss: 0.6931862831115723\n",
      "epoch: 4 step: 3 loss: 0.6931862831115723\n",
      "epoch: 4 step: 4 loss: 0.6931862235069275\n",
      "epoch: 4 step: 5 loss: 0.6931862235069275\n",
      "epoch: 4 step: 6 loss: 0.6931861639022827\n",
      "epoch: 4 step: 7 loss: 0.6931860446929932\n",
      "epoch: 4 step: 8 loss: 0.6931860446929932\n",
      "epoch: 4 step: 9 loss: 0.6931859850883484\n",
      "epoch: 4 step: 10 loss: 0.6931859850883484\n",
      "epoch: 4 step: 11 loss: 0.6931860446929932\n",
      "epoch: 4 step: 12 loss: 0.6931859254837036\n",
      "epoch: 4 step: 13 loss: 0.6931858062744141\n",
      "epoch: 4 step: 14 loss: 0.6931858658790588\n",
      "epoch: 4 step: 15 loss: 0.6931858658790588\n",
      "epoch: 4 step: 16 loss: 0.6931858658790588\n",
      "epoch: 4 step: 17 loss: 0.6931858062744141\n",
      "epoch: 4 step: 18 loss: 0.6931857466697693\n",
      "epoch: 4 step: 19 loss: 0.6931856870651245\n",
      "epoch: 4 step: 20 loss: 0.6931856870651245\n",
      "epoch: 4 step: 21 loss: 0.6931856870651245\n",
      "epoch: 4 step: 22 loss: 0.6931856274604797\n",
      "epoch: 4 step: 23 loss: 0.6931854486465454\n",
      "epoch: 4 step: 24 loss: 0.693185567855835\n",
      "epoch: 4 step: 25 loss: 0.6931855082511902\n",
      "epoch: 4 step: 26 loss: 0.6931855082511902\n",
      "epoch: 4 step: 27 loss: 0.6931853890419006\n",
      "epoch: 4 step: 28 loss: 0.6931853890419006\n",
      "epoch: 4 step: 29 loss: 0.6931853890419006\n",
      "epoch: 4 step: 30 loss: 0.6931852698326111\n",
      "epoch: 4 step: 31 loss: 0.6931853294372559\n",
      "epoch: 4 step: 32 loss: 0.6931852102279663\n",
      "epoch: 4 step: 33 loss: 0.6931853294372559\n",
      "epoch: 4 step: 34 loss: 0.6931852698326111\n",
      "epoch: 4 step: 35 loss: 0.6931852102279663\n",
      "epoch: 4 step: 36 loss: 0.6931850910186768\n",
      "epoch: 4 step: 37 loss: 0.6931850910186768\n",
      "epoch: 4 step: 38 loss: 0.6931850910186768\n",
      "epoch: 4 step: 39 loss: 0.693185031414032\n",
      "epoch: 4 step: 40 loss: 0.6931849718093872\n",
      "epoch: 4 step: 41 loss: 0.6931849718093872\n",
      "epoch: 4 step: 42 loss: 0.6931848526000977\n",
      "epoch: 4 step: 43 loss: 0.6931848526000977\n",
      "epoch: 4 step: 44 loss: 0.6931848526000977\n",
      "epoch: 4 step: 45 loss: 0.6931848526000977\n",
      "epoch: 4 step: 46 loss: 0.6931848526000977\n",
      "epoch: 4 step: 47 loss: 0.6931847333908081\n",
      "epoch: 4 step: 48 loss: 0.6931847333908081\n",
      "epoch: 4 step: 49 loss: 0.6931847333908081\n",
      "epoch: 4 step: 50 loss: 0.6931847333908081\n",
      "epoch: 4 step: 51 loss: 0.6931846737861633\n",
      "epoch: 4 step: 52 loss: 0.6931846141815186\n",
      "epoch: 4 step: 53 loss: 0.6931846141815186\n",
      "epoch: 4 step: 54 loss: 0.6931845545768738\n",
      "epoch: 4 step: 55 loss: 0.6931845545768738\n",
      "epoch: 4 step: 56 loss: 0.693184494972229\n",
      "epoch: 4 step: 57 loss: 0.693184494972229\n",
      "epoch: 4 step: 58 loss: 0.693184494972229\n",
      "epoch: 4 step: 59 loss: 0.6931843757629395\n",
      "epoch: 4 step: 60 loss: 0.6931843757629395\n",
      "epoch: 4 step: 61 loss: 0.6931842565536499\n",
      "epoch: 4 step: 62 loss: 0.6931841969490051\n",
      "epoch: 4 step: 63 loss: 0.6931841969490051\n",
      "epoch: 4 step: 64 loss: 0.6931842565536499\n",
      "epoch: 4 step: 65 loss: 0.6931842565536499\n",
      "epoch: 4 step: 66 loss: 0.6931841373443604\n",
      "epoch: 4 step: 67 loss: 0.6931841373443604\n",
      "epoch: 4 step: 68 loss: 0.6931841373443604\n",
      "epoch: 4 step: 69 loss: 0.6931840181350708\n",
      "epoch: 4 step: 70 loss: 0.6931840181350708\n",
      "epoch: 4 step: 71 loss: 0.6931840181350708\n",
      "epoch: 4 step: 72 loss: 0.6931838989257812\n",
      "epoch: 4 step: 73 loss: 0.6931840181350708\n",
      "epoch: 4 step: 74 loss: 0.6931838989257812\n",
      "epoch: 4 step: 75 loss: 0.6931838989257812\n",
      "epoch: 4 step: 76 loss: 0.6931838393211365\n",
      "epoch: 4 step: 77 loss: 0.6931838393211365\n",
      "epoch: 4 step: 78 loss: 0.6931837797164917\n",
      "epoch: 4 step: 79 loss: 0.6931838393211365\n",
      "epoch: 4 step: 80 loss: 0.6931837797164917\n",
      "epoch: 4 step: 81 loss: 0.6931836605072021\n",
      "epoch: 4 step: 82 loss: 0.6931836605072021\n",
      "epoch: 4 step: 83 loss: 0.6931836605072021\n",
      "epoch: 4 step: 84 loss: 0.6931836009025574\n",
      "epoch: 4 step: 85 loss: 0.6931835412979126\n",
      "epoch: 4 step: 86 loss: 0.6931835412979126\n",
      "epoch: 4 step: 87 loss: 0.6931834816932678\n",
      "epoch: 4 step: 88 loss: 0.6931834816932678\n",
      "epoch: 4 step: 89 loss: 0.6931834816932678\n",
      "epoch: 4 step: 90 loss: 0.6931833624839783\n",
      "epoch: 4 step: 91 loss: 0.6931833624839783\n",
      "epoch: 4 step: 92 loss: 0.6931833624839783\n",
      "epoch: 4 step: 93 loss: 0.6931833028793335\n",
      "epoch: 4 step: 94 loss: 0.6931833028793335\n",
      "epoch: 4 step: 95 loss: 0.6931832432746887\n",
      "epoch: 4 step: 96 loss: 0.6931832432746887\n",
      "epoch: 4 step: 97 loss: 0.693183183670044\n",
      "epoch: 4 step: 98 loss: 0.6931831240653992\n",
      "epoch: 4 step: 99 loss: 0.693183183670044\n",
      "epoch: 4 step: 100 loss: 0.6931831240653992\n",
      "epoch: 4 step: 101 loss: 0.6931830644607544\n",
      "epoch: 4 step: 102 loss: 0.6931830644607544\n",
      "epoch: 4 step: 103 loss: 0.6931830048561096\n",
      "epoch: 4 step: 104 loss: 0.6931830048561096\n",
      "epoch: 4 step: 105 loss: 0.6931829452514648\n",
      "epoch: 4 step: 106 loss: 0.6931829452514648\n",
      "epoch: 4 step: 107 loss: 0.6931829452514648\n",
      "epoch: 4 step: 108 loss: 0.6931828856468201\n",
      "epoch: 4 step: 109 loss: 0.6931827664375305\n",
      "epoch: 4 step: 110 loss: 0.6931828260421753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 111 loss: 0.6931828260421753\n",
      "epoch: 4 step: 112 loss: 0.6931827068328857\n",
      "epoch: 4 step: 113 loss: 0.6931828260421753\n",
      "epoch: 4 step: 114 loss: 0.6931827664375305\n",
      "epoch: 4 step: 115 loss: 0.6931825876235962\n",
      "epoch: 4 step: 116 loss: 0.6931825876235962\n",
      "epoch: 4 step: 117 loss: 0.6931825876235962\n",
      "epoch: 4 step: 118 loss: 0.6931825280189514\n",
      "epoch: 4 step: 119 loss: 0.6931825280189514\n",
      "epoch: 4 step: 120 loss: 0.6931824684143066\n",
      "epoch: 4 step: 121 loss: 0.6931824684143066\n",
      "epoch: 4 step: 122 loss: 0.6931824684143066\n",
      "epoch: 4 step: 123 loss: 0.6931824684143066\n",
      "epoch: 4 step: 124 loss: 0.6931823492050171\n",
      "epoch: 4 step: 125 loss: 0.6931823492050171\n",
      "epoch: 4 step: 126 loss: 0.6931822896003723\n",
      "epoch: 4 step: 127 loss: 0.6931823492050171\n",
      "epoch: 4 step: 128 loss: 0.6931822896003723\n",
      "epoch: 4 step: 129 loss: 0.6931822299957275\n",
      "epoch: 4 step: 130 loss: 0.6931822299957275\n",
      "epoch: 4 step: 131 loss: 0.6931821703910828\n",
      "epoch: 4 step: 132 loss: 0.6931821703910828\n",
      "epoch: 4 step: 133 loss: 0.6931822299957275\n",
      "epoch: 4 step: 134 loss: 0.693182110786438\n",
      "epoch: 4 step: 135 loss: 0.6931820511817932\n",
      "epoch: 4 step: 136 loss: 0.6931820511817932\n",
      "epoch: 4 step: 137 loss: 0.6931819915771484\n",
      "epoch: 4 step: 138 loss: 0.6931819915771484\n",
      "epoch: 4 step: 139 loss: 0.6931819915771484\n",
      "epoch: 4 step: 140 loss: 0.6931818723678589\n",
      "epoch: 4 step: 141 loss: 0.6931818723678589\n",
      "epoch: 4 step: 142 loss: 0.6931818723678589\n",
      "epoch: 4 step: 143 loss: 0.6931818723678589\n",
      "epoch: 4 step: 144 loss: 0.6931817531585693\n",
      "epoch: 4 step: 145 loss: 0.6931817531585693\n",
      "epoch: 4 step: 146 loss: 0.6931817531585693\n",
      "epoch: 4 step: 147 loss: 0.6931817531585693\n",
      "epoch: 4 step: 148 loss: 0.6931816339492798\n",
      "epoch: 4 step: 149 loss: 0.6931816339492798\n",
      "epoch: 4 step: 150 loss: 0.6931816339492798\n",
      "epoch: 4 step: 151 loss: 0.693181574344635\n",
      "epoch: 4 step: 152 loss: 0.6931815147399902\n",
      "epoch: 4 step: 153 loss: 0.693181574344635\n",
      "epoch: 4 step: 154 loss: 0.6931815147399902\n",
      "epoch: 4 step: 155 loss: 0.6931815147399902\n",
      "epoch: 4 step: 156 loss: 0.6931813955307007\n",
      "epoch: 4 step: 157 loss: 0.6931813955307007\n",
      "epoch: 4 step: 158 loss: 0.6931813955307007\n",
      "epoch: 4 step: 159 loss: 0.6931813955307007\n",
      "epoch: 4 step: 160 loss: 0.6931813359260559\n",
      "epoch: 4 step: 161 loss: 0.6931812763214111\n",
      "epoch: 4 step: 162 loss: 0.6931812763214111\n",
      "epoch: 4 step: 163 loss: 0.6931812763214111\n",
      "epoch: 4 step: 164 loss: 0.6931812167167664\n",
      "epoch: 4 step: 165 loss: 0.6931811571121216\n",
      "epoch: 4 step: 166 loss: 0.6931811571121216\n",
      "epoch: 4 step: 167 loss: 0.6931811571121216\n",
      "epoch: 4 step: 168 loss: 0.6931811571121216\n",
      "epoch: 4 step: 169 loss: 0.693181037902832\n",
      "epoch: 4 step: 170 loss: 0.693181037902832\n",
      "epoch: 4 step: 171 loss: 0.693181037902832\n",
      "epoch: 4 step: 172 loss: 0.693181037902832\n",
      "epoch: 4 step: 173 loss: 0.6931809782981873\n",
      "epoch: 4 step: 174 loss: 0.6931809186935425\n",
      "epoch: 4 step: 175 loss: 0.6931809186935425\n",
      "epoch: 4 step: 176 loss: 0.6931809186935425\n",
      "epoch: 4 step: 177 loss: 0.6931807994842529\n",
      "epoch: 4 step: 178 loss: 0.6931807994842529\n",
      "epoch: 4 step: 179 loss: 0.6931806802749634\n",
      "epoch: 4 step: 180 loss: 0.6931807994842529\n",
      "epoch: 4 step: 181 loss: 0.6931807994842529\n",
      "epoch: 4 step: 182 loss: 0.6931806802749634\n",
      "epoch: 4 step: 183 loss: 0.6931807398796082\n",
      "epoch: 4 step: 184 loss: 0.6931806802749634\n",
      "epoch: 4 step: 185 loss: 0.6931806206703186\n",
      "epoch: 4 step: 186 loss: 0.6931806206703186\n",
      "epoch: 4 step: 187 loss: 0.6931806206703186\n",
      "epoch: 4 step: 188 loss: 0.6931805610656738\n",
      "epoch: 4 step: 189 loss: 0.6931805610656738\n",
      "epoch: 4 step: 190 loss: 0.6931805610656738\n",
      "epoch: 4 step: 191 loss: 0.6931804418563843\n",
      "epoch: 4 step: 192 loss: 0.6931804418563843\n",
      "epoch: 4 step: 193 loss: 0.6931803822517395\n",
      "epoch: 4 step: 194 loss: 0.6931803226470947\n",
      "epoch: 4 step: 195 loss: 0.6931803226470947\n",
      "epoch: 4 step: 196 loss: 0.6931803226470947\n",
      "epoch: 4 step: 197 loss: 0.6931803226470947\n",
      "epoch: 4 step: 198 loss: 0.6931802034378052\n",
      "epoch: 4 step: 199 loss: 0.69318026304245\n",
      "epoch: 4 step: 200 loss: 0.6931802034378052\n",
      "epoch: 4 step: 201 loss: 0.6931802034378052\n",
      "epoch: 4 step: 202 loss: 0.6931802034378052\n",
      "epoch: 4 step: 203 loss: 0.6931800842285156\n",
      "epoch: 4 step: 204 loss: 0.6931800842285156\n",
      "epoch: 4 step: 205 loss: 0.6931800842285156\n",
      "epoch: 4 step: 206 loss: 0.6931800842285156\n",
      "epoch: 4 step: 207 loss: 0.6931800842285156\n",
      "epoch: 4 step: 208 loss: 0.6931800842285156\n",
      "epoch: 4 step: 209 loss: 0.6931799650192261\n",
      "epoch: 4 step: 210 loss: 0.6931799650192261\n",
      "epoch: 4 step: 211 loss: 0.6931799650192261\n",
      "epoch: 4 step: 212 loss: 0.6931798458099365\n",
      "epoch: 4 step: 213 loss: 0.6931798458099365\n",
      "epoch: 4 step: 214 loss: 0.6931798458099365\n",
      "epoch: 4 step: 215 loss: 0.6931798458099365\n",
      "epoch: 4 step: 216 loss: 0.693179726600647\n",
      "epoch: 4 step: 217 loss: 0.693179726600647\n",
      "epoch: 4 step: 218 loss: 0.693179726600647\n",
      "epoch: 4 step: 219 loss: 0.6931796669960022\n",
      "epoch: 4 step: 220 loss: 0.693179726600647\n",
      "epoch: 4 step: 221 loss: 0.6931796669960022\n",
      "epoch: 4 step: 222 loss: 0.6931796073913574\n",
      "epoch: 4 step: 223 loss: 0.6931796073913574\n",
      "epoch: 4 step: 224 loss: 0.6931796073913574\n",
      "epoch: 4 step: 225 loss: 0.6931796073913574\n",
      "epoch: 4 step: 226 loss: 0.6931795477867126\n",
      "epoch: 4 step: 227 loss: 0.6931794881820679\n",
      "epoch: 4 step: 228 loss: 0.6931794881820679\n",
      "epoch: 4 step: 229 loss: 0.6931794881820679\n",
      "epoch: 4 step: 230 loss: 0.6931794881820679\n",
      "epoch: 4 step: 231 loss: 0.6931793689727783\n",
      "epoch: 4 step: 232 loss: 0.6931793689727783\n",
      "epoch: 4 step: 233 loss: 0.6931792497634888\n",
      "epoch: 4 step: 234 loss: 0.6931793689727783\n",
      "epoch: 4 step: 235 loss: 0.6931792497634888\n",
      "epoch: 4 step: 236 loss: 0.6931793093681335\n",
      "epoch: 4 step: 237 loss: 0.6931792497634888\n",
      "epoch: 4 step: 238 loss: 0.693179190158844\n",
      "epoch: 4 step: 239 loss: 0.6931791305541992\n",
      "epoch: 4 step: 240 loss: 0.6931791305541992\n",
      "epoch: 4 step: 241 loss: 0.6931791305541992\n",
      "epoch: 4 step: 242 loss: 0.6931791305541992\n",
      "epoch: 4 step: 243 loss: 0.6931790709495544\n",
      "epoch: 4 step: 244 loss: 0.6931790113449097\n",
      "epoch: 4 step: 245 loss: 0.6931790113449097\n",
      "epoch: 4 step: 246 loss: 0.6931790113449097\n",
      "epoch: 4 step: 247 loss: 0.6931789517402649\n",
      "epoch: 4 step: 248 loss: 0.6931790113449097\n",
      "epoch: 4 step: 249 loss: 0.6931788921356201\n",
      "epoch: 4 step: 250 loss: 0.6931788921356201\n",
      "epoch: 4 step: 251 loss: 0.6931788921356201\n",
      "epoch: 4 step: 252 loss: 0.6931788325309753\n",
      "epoch: 4 step: 253 loss: 0.6931788325309753\n",
      "epoch: 4 step: 254 loss: 0.6931787729263306\n",
      "epoch: 4 step: 255 loss: 0.6931788325309753\n",
      "epoch: 4 step: 256 loss: 0.6931787729263306\n",
      "epoch: 4 step: 257 loss: 0.693178653717041\n",
      "epoch: 4 step: 258 loss: 0.6931787133216858\n",
      "epoch: 4 step: 259 loss: 0.693178653717041\n",
      "epoch: 4 step: 260 loss: 0.6931785941123962\n",
      "epoch: 4 step: 261 loss: 0.693178653717041\n",
      "epoch: 4 step: 262 loss: 0.6931785941123962\n",
      "epoch: 4 step: 263 loss: 0.6931785345077515\n",
      "epoch: 4 step: 264 loss: 0.6931785345077515\n",
      "epoch: 4 step: 265 loss: 0.6931785345077515\n",
      "epoch: 4 step: 266 loss: 0.6931784152984619\n",
      "epoch: 4 step: 267 loss: 0.6931784152984619\n",
      "epoch: 4 step: 268 loss: 0.6931784152984619\n",
      "epoch: 4 step: 269 loss: 0.6931784152984619\n",
      "epoch: 4 step: 270 loss: 0.6931783556938171\n",
      "epoch: 4 step: 271 loss: 0.6931782960891724\n",
      "epoch: 4 step: 272 loss: 0.6931783556938171\n",
      "epoch: 4 step: 273 loss: 0.6931782960891724\n",
      "epoch: 4 step: 274 loss: 0.6931782364845276\n",
      "epoch: 4 step: 275 loss: 0.6931782364845276\n",
      "epoch: 4 step: 276 loss: 0.6931782960891724\n",
      "epoch: 4 step: 277 loss: 0.6931781768798828\n",
      "epoch: 4 step: 278 loss: 0.6931780576705933\n",
      "epoch: 4 step: 279 loss: 0.6931781768798828\n",
      "epoch: 4 step: 280 loss: 0.6931780576705933\n",
      "epoch: 4 step: 281 loss: 0.693178117275238\n",
      "epoch: 4 step: 282 loss: 0.6931780576705933\n",
      "epoch: 4 step: 283 loss: 0.6931780576705933\n",
      "epoch: 4 step: 284 loss: 0.6931779980659485\n",
      "epoch: 4 step: 285 loss: 0.6931779980659485\n",
      "epoch: 4 step: 286 loss: 0.6931779384613037\n",
      "epoch: 4 step: 287 loss: 0.6931779384613037\n",
      "epoch: 4 step: 288 loss: 0.6931779384613037\n",
      "epoch: 4 step: 289 loss: 0.6931779384613037\n",
      "epoch: 4 step: 290 loss: 0.6931778788566589\n",
      "epoch: 4 step: 291 loss: 0.6931778788566589\n",
      "epoch: 4 step: 292 loss: 0.6931778192520142\n",
      "epoch: 4 step: 293 loss: 0.6931778192520142\n",
      "epoch: 4 step: 294 loss: 0.6931777000427246\n",
      "epoch: 4 step: 295 loss: 0.6931777000427246\n",
      "epoch: 4 step: 296 loss: 0.6931777000427246\n",
      "epoch: 4 step: 297 loss: 0.6931776404380798\n",
      "epoch: 4 step: 298 loss: 0.6931777000427246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 299 loss: 0.6931776404380798\n",
      "epoch: 4 step: 300 loss: 0.6931775808334351\n",
      "epoch: 4 step: 301 loss: 0.6931775808334351\n",
      "epoch: 4 step: 302 loss: 0.6931775808334351\n",
      "epoch: 4 step: 303 loss: 0.6931775808334351\n",
      "epoch: 4 step: 304 loss: 0.6931775808334351\n",
      "epoch: 4 step: 305 loss: 0.6931775212287903\n",
      "epoch: 4 step: 306 loss: 0.6931774616241455\n",
      "epoch: 4 step: 307 loss: 0.6931774616241455\n",
      "epoch: 4 step: 308 loss: 0.6931774616241455\n",
      "epoch: 4 step: 309 loss: 0.693177342414856\n",
      "epoch: 4 step: 310 loss: 0.6931774020195007\n",
      "epoch: 4 step: 311 loss: 0.6931774616241455\n",
      "epoch: 4 step: 312 loss: 0.693177342414856\n",
      "epoch: 4 step: 313 loss: 0.6931772828102112\n",
      "epoch: 4 step: 314 loss: 0.6931772828102112\n",
      "epoch: 4 step: 315 loss: 0.6931772828102112\n",
      "epoch: 4 step: 316 loss: 0.6931772232055664\n",
      "epoch: 4 step: 317 loss: 0.6931771636009216\n",
      "epoch: 4 step: 318 loss: 0.6931772232055664\n",
      "epoch: 4 step: 319 loss: 0.6931771636009216\n",
      "epoch: 4 step: 320 loss: 0.6931771636009216\n",
      "epoch: 4 step: 321 loss: 0.6931771039962769\n",
      "epoch: 4 step: 322 loss: 0.6931771039962769\n",
      "epoch: 4 step: 323 loss: 0.6931771039962769\n",
      "epoch: 4 step: 324 loss: 0.6931769847869873\n",
      "epoch: 4 step: 325 loss: 0.6931769847869873\n",
      "epoch: 4 step: 326 loss: 0.6931769847869873\n",
      "epoch: 4 step: 327 loss: 0.6931769847869873\n",
      "epoch: 4 step: 328 loss: 0.6931769847869873\n",
      "epoch: 4 step: 329 loss: 0.6931769251823425\n",
      "epoch: 4 step: 330 loss: 0.6931768655776978\n",
      "epoch: 4 step: 331 loss: 0.6931769251823425\n",
      "epoch: 4 step: 332 loss: 0.6931768655776978\n",
      "epoch: 4 step: 333 loss: 0.6931768655776978\n",
      "epoch: 4 step: 334 loss: 0.693176805973053\n",
      "epoch: 4 step: 335 loss: 0.693176805973053\n",
      "epoch: 4 step: 336 loss: 0.6931767463684082\n",
      "epoch: 4 step: 337 loss: 0.6931767463684082\n",
      "epoch: 4 step: 338 loss: 0.6931767463684082\n",
      "epoch: 4 step: 339 loss: 0.6931766867637634\n",
      "epoch: 4 step: 340 loss: 0.6931766271591187\n",
      "epoch: 4 step: 341 loss: 0.6931766271591187\n",
      "epoch: 4 step: 342 loss: 0.6931766271591187\n",
      "epoch: 4 step: 343 loss: 0.6931765675544739\n",
      "epoch: 4 step: 344 loss: 0.6931765079498291\n",
      "epoch: 4 step: 345 loss: 0.6931765079498291\n",
      "epoch: 4 step: 346 loss: 0.6931764483451843\n",
      "epoch: 4 step: 347 loss: 0.6931765079498291\n",
      "epoch: 4 step: 348 loss: 0.6931764483451843\n",
      "epoch: 4 step: 349 loss: 0.6931765079498291\n",
      "epoch: 4 step: 350 loss: 0.6931763887405396\n",
      "epoch: 4 step: 351 loss: 0.6931763887405396\n",
      "epoch: 4 step: 352 loss: 0.6931763887405396\n",
      "epoch: 4 step: 353 loss: 0.6931763887405396\n",
      "epoch: 4 step: 354 loss: 0.6931763291358948\n",
      "epoch: 4 step: 355 loss: 0.69317626953125\n",
      "epoch: 4 step: 356 loss: 0.69317626953125\n",
      "epoch: 4 step: 357 loss: 0.69317626953125\n",
      "epoch: 4 step: 358 loss: 0.6931762099266052\n",
      "epoch: 4 step: 359 loss: 0.6931762099266052\n",
      "epoch: 4 step: 360 loss: 0.69317626953125\n",
      "epoch: 4 step: 361 loss: 0.6931761503219604\n",
      "epoch: 4 step: 362 loss: 0.6931761503219604\n",
      "epoch: 4 step: 363 loss: 0.6931761503219604\n",
      "epoch: 4 step: 364 loss: 0.6931761503219604\n",
      "epoch: 4 step: 365 loss: 0.6931760311126709\n",
      "epoch: 4 step: 366 loss: 0.6931760311126709\n",
      "epoch: 4 step: 367 loss: 0.6931760311126709\n",
      "epoch: 4 step: 368 loss: 0.6931760311126709\n",
      "epoch: 4 step: 369 loss: 0.6931759715080261\n",
      "epoch: 4 step: 370 loss: 0.6931759119033813\n",
      "epoch: 4 step: 371 loss: 0.6931759715080261\n",
      "epoch: 4 step: 372 loss: 0.6931759119033813\n",
      "epoch: 4 step: 373 loss: 0.6931759119033813\n",
      "epoch: 4 step: 374 loss: 0.6931759119033813\n",
      "epoch: 4 step: 375 loss: 0.6931759119033813\n",
      "epoch: 4 step: 376 loss: 0.6931758522987366\n",
      "epoch: 4 step: 377 loss: 0.6931758522987366\n",
      "epoch: 4 step: 378 loss: 0.6931757926940918\n",
      "epoch: 4 step: 379 loss: 0.693175733089447\n",
      "epoch: 4 step: 380 loss: 0.693175733089447\n",
      "epoch: 4 step: 381 loss: 0.693175733089447\n",
      "epoch: 4 step: 382 loss: 0.693175733089447\n",
      "epoch: 4 step: 383 loss: 0.6931756734848022\n",
      "epoch: 4 step: 384 loss: 0.6931756734848022\n",
      "epoch: 4 step: 385 loss: 0.6931756138801575\n",
      "epoch: 4 step: 386 loss: 0.6931756138801575\n",
      "epoch: 4 step: 387 loss: 0.6931755542755127\n",
      "epoch: 4 step: 388 loss: 0.6931755542755127\n",
      "epoch: 4 step: 389 loss: 0.6931755542755127\n",
      "epoch: 4 step: 390 loss: 0.6931754946708679\n",
      "epoch: 4 step: 391 loss: 0.6931754350662231\n",
      "epoch: 4 step: 392 loss: 0.6931754946708679\n",
      "epoch: 4 step: 393 loss: 0.6931754946708679\n",
      "epoch: 4 step: 394 loss: 0.6931754350662231\n",
      "epoch: 4 step: 395 loss: 0.6931754350662231\n",
      "epoch: 4 step: 396 loss: 0.6931753754615784\n",
      "epoch: 4 step: 397 loss: 0.6931754350662231\n",
      "epoch: 4 step: 398 loss: 0.6931753158569336\n",
      "epoch: 4 step: 399 loss: 0.6931753158569336\n",
      "epoch: 4 step: 400 loss: 0.6931753158569336\n",
      "epoch: 4 step: 401 loss: 0.693175196647644\n",
      "epoch: 4 step: 402 loss: 0.6931752562522888\n",
      "epoch: 4 step: 403 loss: 0.693175196647644\n",
      "epoch: 4 step: 404 loss: 0.693175196647644\n",
      "epoch: 4 step: 405 loss: 0.693175196647644\n",
      "epoch: 4 step: 406 loss: 0.693175196647644\n",
      "epoch: 4 step: 407 loss: 0.6931751370429993\n",
      "epoch: 4 step: 408 loss: 0.6931750774383545\n",
      "epoch: 4 step: 409 loss: 0.6931750774383545\n",
      "epoch: 4 step: 410 loss: 0.6931750774383545\n",
      "epoch: 4 step: 411 loss: 0.6931750774383545\n",
      "epoch: 4 step: 412 loss: 0.6931750774383545\n",
      "epoch: 4 step: 413 loss: 0.6931749582290649\n",
      "epoch: 4 step: 414 loss: 0.6931749582290649\n",
      "epoch: 4 step: 415 loss: 0.6931749582290649\n",
      "epoch: 4 step: 416 loss: 0.6931749582290649\n",
      "epoch: 4 step: 417 loss: 0.6931749582290649\n",
      "epoch: 4 step: 418 loss: 0.6931748986244202\n",
      "epoch: 4 step: 419 loss: 0.6931748390197754\n",
      "epoch: 4 step: 420 loss: 0.6931748390197754\n",
      "epoch: 4 step: 421 loss: 0.6931747794151306\n",
      "epoch: 4 step: 422 loss: 0.6931748390197754\n",
      "epoch: 4 step: 423 loss: 0.6931747794151306\n",
      "epoch: 4 step: 424 loss: 0.6931747794151306\n",
      "epoch: 4 step: 425 loss: 0.6931747794151306\n",
      "epoch: 4 step: 426 loss: 0.6931747198104858\n",
      "epoch: 4 step: 427 loss: 0.6931747198104858\n",
      "epoch: 4 step: 428 loss: 0.6931746602058411\n",
      "epoch: 4 step: 429 loss: 0.6931746602058411\n",
      "epoch: 4 step: 430 loss: 0.6931746602058411\n",
      "epoch: 4 step: 431 loss: 0.6931746006011963\n",
      "epoch: 4 step: 432 loss: 0.6931746006011963\n",
      "epoch: 4 step: 433 loss: 0.6931746006011963\n",
      "epoch: 4 step: 434 loss: 0.6931744813919067\n",
      "epoch: 4 step: 435 loss: 0.6931744813919067\n",
      "epoch: 4 step: 436 loss: 0.6931745409965515\n",
      "epoch: 4 step: 437 loss: 0.6931744813919067\n",
      "epoch: 4 step: 438 loss: 0.6931744813919067\n",
      "epoch: 4 step: 439 loss: 0.693174421787262\n",
      "epoch: 4 step: 440 loss: 0.6931743621826172\n",
      "epoch: 4 step: 441 loss: 0.6931743621826172\n",
      "epoch: 4 step: 442 loss: 0.6931743621826172\n",
      "epoch: 4 step: 443 loss: 0.6931743621826172\n",
      "epoch: 4 step: 444 loss: 0.6931743621826172\n",
      "epoch: 4 step: 445 loss: 0.6931743621826172\n",
      "epoch: 4 step: 446 loss: 0.6931743621826172\n",
      "epoch: 4 step: 447 loss: 0.6931742429733276\n",
      "epoch: 4 step: 448 loss: 0.6931742429733276\n",
      "epoch: 4 step: 449 loss: 0.6931741833686829\n",
      "epoch: 4 step: 450 loss: 0.6931741833686829\n",
      "epoch: 4 step: 451 loss: 0.6931741833686829\n",
      "epoch: 4 step: 452 loss: 0.6931741833686829\n",
      "epoch: 4 step: 453 loss: 0.6931741237640381\n",
      "epoch: 4 step: 454 loss: 0.6931741237640381\n",
      "epoch: 4 step: 455 loss: 0.6931741237640381\n",
      "epoch: 4 step: 456 loss: 0.6931741237640381\n",
      "epoch: 4 step: 457 loss: 0.6931740045547485\n",
      "epoch: 4 step: 458 loss: 0.6931740045547485\n",
      "epoch: 4 step: 459 loss: 0.6931739449501038\n",
      "epoch: 4 step: 460 loss: 0.6931740045547485\n",
      "epoch: 4 step: 461 loss: 0.6931740045547485\n",
      "epoch: 4 step: 462 loss: 0.6931739449501038\n",
      "epoch: 4 step: 463 loss: 0.6931739449501038\n",
      "epoch: 4 step: 464 loss: 0.693173885345459\n",
      "epoch: 4 step: 465 loss: 0.693173885345459\n",
      "epoch: 4 step: 466 loss: 0.693173885345459\n",
      "epoch: 4 step: 467 loss: 0.693173885345459\n",
      "epoch: 4 step: 468 loss: 0.693173885345459\n",
      "epoch: 4 step: 469 loss: 0.6931738257408142\n",
      "epoch: 4 step: 470 loss: 0.6931737661361694\n",
      "epoch: 4 step: 471 loss: 0.6931737661361694\n",
      "epoch: 4 step: 472 loss: 0.6931737661361694\n",
      "epoch: 4 step: 473 loss: 0.6931737661361694\n",
      "epoch: 4 step: 474 loss: 0.6931737661361694\n",
      "epoch: 4 step: 475 loss: 0.6931737065315247\n",
      "epoch: 4 step: 476 loss: 0.6931736469268799\n",
      "epoch: 4 step: 477 loss: 0.6931736469268799\n",
      "epoch: 4 step: 478 loss: 0.6931736469268799\n",
      "epoch: 4 step: 479 loss: 0.6931735873222351\n",
      "epoch: 4 step: 480 loss: 0.6931736469268799\n",
      "epoch: 4 step: 481 loss: 0.6931736469268799\n",
      "epoch: 4 step: 482 loss: 0.6931735277175903\n",
      "epoch: 4 step: 483 loss: 0.6931735277175903\n",
      "epoch: 4 step: 484 loss: 0.6931734681129456\n",
      "epoch: 4 step: 485 loss: 0.6931734681129456\n",
      "epoch: 4 step: 486 loss: 0.6931735277175903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 487 loss: 0.6931734681129456\n",
      "epoch: 4 step: 488 loss: 0.6931734681129456\n",
      "epoch: 4 step: 489 loss: 0.6931734085083008\n",
      "epoch: 4 step: 490 loss: 0.6931734085083008\n",
      "epoch: 4 step: 491 loss: 0.6931732892990112\n",
      "epoch: 4 step: 492 loss: 0.6931732892990112\n",
      "epoch: 4 step: 493 loss: 0.693173348903656\n",
      "epoch: 4 step: 494 loss: 0.693173348903656\n",
      "epoch: 4 step: 495 loss: 0.6931732892990112\n",
      "epoch: 4 step: 496 loss: 0.6931732892990112\n",
      "epoch: 4 step: 497 loss: 0.6931732892990112\n",
      "epoch: 4 step: 498 loss: 0.6931732892990112\n",
      "epoch: 4 step: 499 loss: 0.6931731700897217\n",
      "epoch: 4 step: 500 loss: 0.6931731700897217\n",
      "epoch: 4 step: 501 loss: 0.6931731700897217\n",
      "epoch: 4 step: 502 loss: 0.6931731700897217\n",
      "epoch: 4 step: 503 loss: 0.6931731700897217\n",
      "epoch: 4 step: 504 loss: 0.6931731104850769\n",
      "epoch: 4 step: 505 loss: 0.6931731700897217\n",
      "epoch: 4 step: 506 loss: 0.6931730508804321\n",
      "epoch: 4 step: 507 loss: 0.6931729912757874\n",
      "epoch: 4 step: 508 loss: 0.6931730508804321\n",
      "epoch: 4 step: 509 loss: 0.6931729316711426\n",
      "epoch: 4 step: 510 loss: 0.6931729316711426\n",
      "epoch: 4 step: 511 loss: 0.6931729316711426\n",
      "epoch: 4 step: 512 loss: 0.6931729316711426\n",
      "epoch: 4 step: 513 loss: 0.6931729316711426\n",
      "epoch: 4 step: 514 loss: 0.6931729316711426\n",
      "epoch: 4 step: 515 loss: 0.6931729316711426\n",
      "epoch: 4 step: 516 loss: 0.6931728720664978\n",
      "epoch: 4 step: 517 loss: 0.6931728720664978\n",
      "epoch: 4 step: 518 loss: 0.693172812461853\n",
      "epoch: 4 step: 519 loss: 0.693172812461853\n",
      "epoch: 4 step: 520 loss: 0.693172812461853\n",
      "epoch: 4 step: 521 loss: 0.693172812461853\n",
      "epoch: 4 step: 522 loss: 0.6931726932525635\n",
      "epoch: 4 step: 523 loss: 0.6931726932525635\n",
      "epoch: 4 step: 524 loss: 0.6931726932525635\n",
      "epoch: 4 step: 525 loss: 0.6931726932525635\n",
      "epoch: 4 step: 526 loss: 0.6931726932525635\n",
      "epoch: 4 step: 527 loss: 0.6931726932525635\n",
      "epoch: 4 step: 528 loss: 0.6931725740432739\n",
      "epoch: 4 step: 529 loss: 0.6931725740432739\n",
      "epoch: 4 step: 530 loss: 0.6931725740432739\n",
      "epoch: 4 step: 531 loss: 0.6931725740432739\n",
      "epoch: 4 step: 532 loss: 0.6931725740432739\n",
      "epoch: 4 step: 533 loss: 0.6931725144386292\n",
      "epoch: 4 step: 534 loss: 0.6931725740432739\n",
      "epoch: 4 step: 535 loss: 0.6931724548339844\n",
      "epoch: 4 step: 536 loss: 0.6931724548339844\n",
      "epoch: 4 step: 537 loss: 0.6931724548339844\n",
      "epoch: 4 step: 538 loss: 0.6931724548339844\n",
      "epoch: 4 step: 539 loss: 0.6931724548339844\n",
      "epoch: 4 step: 540 loss: 0.6931723356246948\n",
      "epoch: 4 step: 541 loss: 0.6931723356246948\n",
      "epoch: 4 step: 542 loss: 0.6931723952293396\n",
      "epoch: 4 step: 543 loss: 0.6931723356246948\n",
      "epoch: 4 step: 544 loss: 0.6931723356246948\n",
      "epoch: 4 step: 545 loss: 0.6931723356246948\n",
      "epoch: 4 step: 546 loss: 0.6931723356246948\n",
      "epoch: 4 step: 547 loss: 0.6931722164154053\n",
      "epoch: 4 step: 548 loss: 0.6931722164154053\n",
      "epoch: 4 step: 549 loss: 0.6931722164154053\n",
      "epoch: 4 step: 550 loss: 0.6931722164154053\n",
      "epoch: 4 step: 551 loss: 0.6931721568107605\n",
      "epoch: 4 step: 552 loss: 0.6931720972061157\n",
      "epoch: 4 step: 553 loss: 0.6931721568107605\n",
      "epoch: 4 step: 554 loss: 0.6931721568107605\n",
      "epoch: 4 step: 555 loss: 0.6931721568107605\n",
      "epoch: 4 step: 556 loss: 0.693172037601471\n",
      "epoch: 4 step: 557 loss: 0.693172037601471\n",
      "epoch: 4 step: 558 loss: 0.6931720972061157\n",
      "epoch: 4 step: 559 loss: 0.693172037601471\n",
      "epoch: 4 step: 560 loss: 0.6931719779968262\n",
      "epoch: 4 step: 561 loss: 0.6931719779968262\n",
      "epoch: 4 step: 562 loss: 0.6931719183921814\n",
      "epoch: 4 step: 563 loss: 0.6931719779968262\n",
      "epoch: 4 step: 564 loss: 0.6931719779968262\n",
      "epoch: 4 step: 565 loss: 0.6931718587875366\n",
      "epoch: 4 step: 566 loss: 0.6931718587875366\n",
      "epoch: 4 step: 567 loss: 0.6931718587875366\n",
      "epoch: 4 step: 568 loss: 0.6931718587875366\n",
      "epoch: 4 step: 569 loss: 0.6931718587875366\n",
      "epoch: 4 step: 570 loss: 0.6931718587875366\n",
      "epoch: 4 step: 571 loss: 0.6931717991828918\n",
      "epoch: 4 step: 572 loss: 0.6931717395782471\n",
      "epoch: 4 step: 573 loss: 0.6931717395782471\n",
      "epoch: 4 step: 574 loss: 0.6931717395782471\n",
      "epoch: 4 step: 575 loss: 0.6931717991828918\n",
      "epoch: 4 step: 576 loss: 0.6931716203689575\n",
      "epoch: 4 step: 577 loss: 0.6931716799736023\n",
      "epoch: 4 step: 578 loss: 0.6931716799736023\n",
      "epoch: 4 step: 579 loss: 0.6931717395782471\n",
      "epoch: 4 step: 580 loss: 0.6931716203689575\n",
      "epoch: 4 step: 581 loss: 0.6931716203689575\n",
      "epoch: 4 step: 582 loss: 0.6931716203689575\n",
      "epoch: 4 step: 583 loss: 0.6931716203689575\n",
      "epoch: 4 step: 584 loss: 0.693171501159668\n",
      "epoch: 4 step: 585 loss: 0.6931715607643127\n",
      "epoch: 4 step: 586 loss: 0.6931715607643127\n",
      "epoch: 4 step: 587 loss: 0.693171501159668\n",
      "epoch: 4 step: 588 loss: 0.693171501159668\n",
      "epoch: 4 step: 589 loss: 0.6931714415550232\n",
      "epoch: 4 step: 590 loss: 0.693171501159668\n",
      "epoch: 4 step: 591 loss: 0.6931714415550232\n",
      "epoch: 4 step: 592 loss: 0.6931713819503784\n",
      "epoch: 4 step: 593 loss: 0.6931714415550232\n",
      "epoch: 4 step: 594 loss: 0.6931713819503784\n",
      "epoch: 4 step: 595 loss: 0.6931713819503784\n",
      "epoch: 4 step: 596 loss: 0.6931713223457336\n",
      "epoch: 4 step: 597 loss: 0.6931713819503784\n",
      "epoch: 4 step: 598 loss: 0.6931713223457336\n",
      "epoch: 4 step: 599 loss: 0.6931712627410889\n",
      "epoch: 4 step: 600 loss: 0.6931713223457336\n",
      "epoch: 4 step: 601 loss: 0.6931712627410889\n",
      "epoch: 4 step: 602 loss: 0.6931712627410889\n",
      "epoch: 4 step: 603 loss: 0.6931712627410889\n",
      "epoch: 4 step: 604 loss: 0.6931711435317993\n",
      "epoch: 4 step: 605 loss: 0.6931712031364441\n",
      "epoch: 4 step: 606 loss: 0.6931711435317993\n",
      "epoch: 4 step: 607 loss: 0.6931711435317993\n",
      "epoch: 4 step: 608 loss: 0.6931711435317993\n",
      "epoch: 4 step: 609 loss: 0.6931710839271545\n",
      "epoch: 4 step: 610 loss: 0.6931710839271545\n",
      "epoch: 4 step: 611 loss: 0.6931710243225098\n",
      "epoch: 4 step: 612 loss: 0.6931710243225098\n",
      "epoch: 4 step: 613 loss: 0.6931710839271545\n",
      "epoch: 4 step: 614 loss: 0.6931710243225098\n",
      "epoch: 4 step: 615 loss: 0.6931710243225098\n",
      "epoch: 4 step: 616 loss: 0.693170964717865\n",
      "epoch: 4 step: 617 loss: 0.693170964717865\n",
      "epoch: 4 step: 618 loss: 0.693170964717865\n",
      "epoch: 4 step: 619 loss: 0.6931709051132202\n",
      "epoch: 4 step: 620 loss: 0.6931709051132202\n",
      "epoch: 4 step: 621 loss: 0.6931709051132202\n",
      "epoch: 4 step: 622 loss: 0.6931709051132202\n",
      "epoch: 4 step: 623 loss: 0.6931707859039307\n",
      "epoch: 4 step: 624 loss: 0.6931708455085754\n",
      "epoch: 4 step: 625 loss: 0.6931707859039307\n",
      "epoch: 4 step: 626 loss: 0.6931707859039307\n",
      "epoch: 4 step: 627 loss: 0.6931707859039307\n",
      "epoch: 4 step: 628 loss: 0.6931707859039307\n",
      "epoch: 4 step: 629 loss: 0.6931707262992859\n",
      "epoch: 4 step: 630 loss: 0.6931707859039307\n",
      "epoch: 4 step: 631 loss: 0.6931706666946411\n",
      "epoch: 4 step: 632 loss: 0.6931707859039307\n",
      "epoch: 4 step: 633 loss: 0.6931706666946411\n",
      "epoch: 4 step: 634 loss: 0.6931706666946411\n",
      "epoch: 4 step: 635 loss: 0.6931706666946411\n",
      "epoch: 4 step: 636 loss: 0.6931706666946411\n",
      "epoch: 4 step: 637 loss: 0.6931706070899963\n",
      "epoch: 4 step: 638 loss: 0.6931705474853516\n",
      "epoch: 4 step: 639 loss: 0.6931705474853516\n",
      "epoch: 4 step: 640 loss: 0.6931706070899963\n",
      "epoch: 4 step: 641 loss: 0.6931705474853516\n",
      "epoch: 4 step: 642 loss: 0.6931705474853516\n",
      "epoch: 4 step: 643 loss: 0.6931704878807068\n",
      "epoch: 4 step: 644 loss: 0.6931704878807068\n",
      "epoch: 4 step: 645 loss: 0.6931704878807068\n",
      "epoch: 4 step: 646 loss: 0.693170428276062\n",
      "epoch: 4 step: 647 loss: 0.693170428276062\n",
      "epoch: 4 step: 648 loss: 0.693170428276062\n",
      "epoch: 4 step: 649 loss: 0.693170428276062\n",
      "epoch: 4 step: 650 loss: 0.6931703686714172\n",
      "epoch: 4 step: 651 loss: 0.6931703090667725\n",
      "epoch: 4 step: 652 loss: 0.6931703090667725\n",
      "epoch: 4 step: 653 loss: 0.6931703686714172\n",
      "epoch: 4 step: 654 loss: 0.6931703090667725\n",
      "epoch: 4 step: 655 loss: 0.6931703090667725\n",
      "epoch: 4 step: 656 loss: 0.6931703090667725\n",
      "epoch: 4 step: 657 loss: 0.6931703090667725\n",
      "epoch: 4 step: 658 loss: 0.6931702494621277\n",
      "epoch: 4 step: 659 loss: 0.6931701898574829\n",
      "epoch: 4 step: 660 loss: 0.6931701898574829\n",
      "epoch: 4 step: 661 loss: 0.6931701898574829\n",
      "epoch: 4 step: 662 loss: 0.6931701898574829\n",
      "epoch: 4 step: 663 loss: 0.6931701898574829\n",
      "epoch: 4 step: 664 loss: 0.6931701302528381\n",
      "epoch: 4 step: 665 loss: 0.6931701302528381\n",
      "epoch: 4 step: 666 loss: 0.6931700706481934\n",
      "epoch: 4 step: 667 loss: 0.6931700706481934\n",
      "epoch: 4 step: 668 loss: 0.6931700706481934\n",
      "epoch: 4 step: 669 loss: 0.6931700706481934\n",
      "epoch: 4 step: 670 loss: 0.6931700110435486\n",
      "epoch: 4 step: 671 loss: 0.6931700706481934\n",
      "epoch: 4 step: 672 loss: 0.6931700110435486\n",
      "epoch: 4 step: 673 loss: 0.6931700110435486\n",
      "epoch: 4 step: 674 loss: 0.6931699514389038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 675 loss: 0.6931699514389038\n",
      "epoch: 4 step: 676 loss: 0.6931699514389038\n",
      "epoch: 4 step: 677 loss: 0.6931699514389038\n",
      "epoch: 4 step: 678 loss: 0.6931699514389038\n",
      "epoch: 4 step: 679 loss: 0.6931698322296143\n",
      "epoch: 4 step: 680 loss: 0.6931698322296143\n",
      "epoch: 4 step: 681 loss: 0.6931698322296143\n",
      "epoch: 4 step: 682 loss: 0.693169891834259\n",
      "epoch: 4 step: 683 loss: 0.6931698322296143\n",
      "epoch: 4 step: 684 loss: 0.6931698322296143\n",
      "epoch: 4 step: 685 loss: 0.6931697726249695\n",
      "epoch: 4 step: 686 loss: 0.6931697130203247\n",
      "epoch: 4 step: 687 loss: 0.6931697130203247\n",
      "epoch: 4 step: 688 loss: 0.6931697726249695\n",
      "epoch: 4 step: 689 loss: 0.6931697130203247\n",
      "epoch: 4 step: 690 loss: 0.6931697130203247\n",
      "epoch: 4 step: 691 loss: 0.6931697130203247\n",
      "epoch: 4 step: 692 loss: 0.6931697130203247\n",
      "epoch: 4 step: 693 loss: 0.6931696534156799\n",
      "epoch: 4 step: 694 loss: 0.6931695938110352\n",
      "epoch: 4 step: 695 loss: 0.6931695938110352\n",
      "epoch: 4 step: 696 loss: 0.6931695938110352\n",
      "epoch: 4 step: 697 loss: 0.6931695938110352\n",
      "epoch: 4 step: 698 loss: 0.6931695938110352\n",
      "epoch: 4 step: 699 loss: 0.6931695342063904\n",
      "epoch: 4 step: 700 loss: 0.6931695938110352\n",
      "epoch: 4 step: 701 loss: 0.6931695938110352\n",
      "epoch: 4 step: 702 loss: 0.6931694746017456\n",
      "epoch: 4 step: 703 loss: 0.6931694746017456\n",
      "epoch: 4 step: 704 loss: 0.6931694746017456\n",
      "epoch: 4 step: 705 loss: 0.6931694746017456\n",
      "epoch: 4 step: 706 loss: 0.693169355392456\n",
      "epoch: 4 step: 707 loss: 0.693169355392456\n",
      "epoch: 4 step: 708 loss: 0.693169355392456\n",
      "epoch: 4 step: 709 loss: 0.693169355392456\n",
      "epoch: 4 step: 710 loss: 0.6931694149971008\n",
      "epoch: 4 step: 711 loss: 0.693169355392456\n",
      "epoch: 4 step: 712 loss: 0.693169355392456\n",
      "epoch: 4 step: 713 loss: 0.693169355392456\n",
      "epoch: 4 step: 714 loss: 0.693169355392456\n",
      "epoch: 4 step: 715 loss: 0.6931692957878113\n",
      "epoch: 4 step: 716 loss: 0.6931692957878113\n",
      "epoch: 4 step: 717 loss: 0.6931692957878113\n",
      "epoch: 4 step: 718 loss: 0.6931692361831665\n",
      "epoch: 4 step: 719 loss: 0.6931692361831665\n",
      "epoch: 4 step: 720 loss: 0.6931691765785217\n",
      "epoch: 4 step: 721 loss: 0.6931692361831665\n",
      "epoch: 4 step: 722 loss: 0.6931691765785217\n",
      "epoch: 4 step: 723 loss: 0.6931691765785217\n",
      "epoch: 4 step: 724 loss: 0.6931691765785217\n",
      "epoch: 4 step: 725 loss: 0.6931691765785217\n",
      "epoch: 4 step: 726 loss: 0.693169116973877\n",
      "epoch: 4 step: 727 loss: 0.693169116973877\n",
      "epoch: 4 step: 728 loss: 0.693169116973877\n",
      "epoch: 4 step: 729 loss: 0.6931690573692322\n",
      "epoch: 4 step: 730 loss: 0.6931690573692322\n",
      "epoch: 4 step: 731 loss: 0.6931689977645874\n",
      "epoch: 4 step: 732 loss: 0.6931689977645874\n",
      "epoch: 4 step: 733 loss: 0.6931689977645874\n",
      "epoch: 4 step: 734 loss: 0.6931689977645874\n",
      "epoch: 4 step: 735 loss: 0.6931689977645874\n",
      "epoch: 4 step: 736 loss: 0.6931689381599426\n",
      "epoch: 4 step: 737 loss: 0.6931688785552979\n",
      "epoch: 4 step: 738 loss: 0.6931688785552979\n",
      "epoch: 4 step: 739 loss: 0.6931688785552979\n",
      "epoch: 4 step: 740 loss: 0.6931688785552979\n",
      "epoch: 4 step: 741 loss: 0.6931688785552979\n",
      "epoch: 4 step: 742 loss: 0.6931688785552979\n",
      "epoch: 4 step: 743 loss: 0.6931688189506531\n",
      "epoch: 4 step: 744 loss: 0.6931687593460083\n",
      "epoch: 4 step: 745 loss: 0.6931687593460083\n",
      "epoch: 4 step: 746 loss: 0.6931688189506531\n",
      "epoch: 4 step: 747 loss: 0.6931687593460083\n",
      "epoch: 4 step: 748 loss: 0.6931687593460083\n",
      "epoch: 4 step: 749 loss: 0.6931687593460083\n",
      "epoch: 4 step: 750 loss: 0.6931686997413635\n",
      "epoch: 4 step: 751 loss: 0.6931686997413635\n",
      "epoch: 4 step: 752 loss: 0.6931687593460083\n",
      "epoch: 4 step: 753 loss: 0.6931686401367188\n",
      "epoch: 4 step: 754 loss: 0.6931686401367188\n",
      "epoch: 4 step: 755 loss: 0.6931686401367188\n",
      "epoch: 4 step: 756 loss: 0.6931686401367188\n",
      "epoch: 4 step: 757 loss: 0.6931686401367188\n",
      "epoch: 4 step: 758 loss: 0.6931686401367188\n",
      "epoch: 4 step: 759 loss: 0.693168580532074\n",
      "epoch: 4 step: 760 loss: 0.6931685209274292\n",
      "epoch: 4 step: 761 loss: 0.6931685209274292\n",
      "epoch: 4 step: 762 loss: 0.6931685209274292\n",
      "epoch: 4 step: 763 loss: 0.6931685209274292\n",
      "epoch: 4 step: 764 loss: 0.6931685209274292\n",
      "epoch: 4 step: 765 loss: 0.6931685209274292\n",
      "epoch: 4 step: 766 loss: 0.6931684613227844\n",
      "epoch: 4 step: 767 loss: 0.6931684017181396\n",
      "epoch: 4 step: 768 loss: 0.6931684017181396\n",
      "epoch: 4 step: 769 loss: 0.6931684613227844\n",
      "epoch: 4 step: 770 loss: 0.6931684017181396\n",
      "epoch: 4 step: 771 loss: 0.6931684017181396\n",
      "epoch: 4 step: 772 loss: 0.6931684017181396\n",
      "epoch: 4 step: 773 loss: 0.6931684017181396\n",
      "epoch: 4 step: 774 loss: 0.6931683421134949\n",
      "epoch: 4 step: 775 loss: 0.6931683421134949\n",
      "epoch: 4 step: 776 loss: 0.6931682825088501\n",
      "epoch: 4 step: 777 loss: 0.6931682825088501\n",
      "epoch: 4 step: 778 loss: 0.6931682825088501\n",
      "epoch: 4 step: 779 loss: 0.6931682825088501\n",
      "epoch: 4 step: 780 loss: 0.6931682825088501\n",
      "epoch: 4 step: 781 loss: 0.6931682825088501\n",
      "epoch: 5 step: 1 loss: 0.6931682229042053\n",
      "epoch: 5 step: 2 loss: 0.6931681632995605\n",
      "epoch: 5 step: 3 loss: 0.6931682229042053\n",
      "epoch: 5 step: 4 loss: 0.6931681632995605\n",
      "epoch: 5 step: 5 loss: 0.6931681632995605\n",
      "epoch: 5 step: 6 loss: 0.6931681632995605\n",
      "epoch: 5 step: 7 loss: 0.6931681036949158\n",
      "epoch: 5 step: 8 loss: 0.6931681036949158\n",
      "epoch: 5 step: 9 loss: 0.693168044090271\n",
      "epoch: 5 step: 10 loss: 0.693168044090271\n",
      "epoch: 5 step: 11 loss: 0.6931681036949158\n",
      "epoch: 5 step: 12 loss: 0.6931681036949158\n",
      "epoch: 5 step: 13 loss: 0.693168044090271\n",
      "epoch: 5 step: 14 loss: 0.693168044090271\n",
      "epoch: 5 step: 15 loss: 0.6931679844856262\n",
      "epoch: 5 step: 16 loss: 0.693168044090271\n",
      "epoch: 5 step: 17 loss: 0.6931679844856262\n",
      "epoch: 5 step: 18 loss: 0.6931679248809814\n",
      "epoch: 5 step: 19 loss: 0.6931679248809814\n",
      "epoch: 5 step: 20 loss: 0.6931679248809814\n",
      "epoch: 5 step: 21 loss: 0.6931679248809814\n",
      "epoch: 5 step: 22 loss: 0.6931679248809814\n",
      "epoch: 5 step: 23 loss: 0.6931678056716919\n",
      "epoch: 5 step: 24 loss: 0.6931679248809814\n",
      "epoch: 5 step: 25 loss: 0.6931678652763367\n",
      "epoch: 5 step: 26 loss: 0.6931678056716919\n",
      "epoch: 5 step: 27 loss: 0.6931678056716919\n",
      "epoch: 5 step: 28 loss: 0.6931678056716919\n",
      "epoch: 5 step: 29 loss: 0.6931678056716919\n",
      "epoch: 5 step: 30 loss: 0.6931677460670471\n",
      "epoch: 5 step: 31 loss: 0.6931678056716919\n",
      "epoch: 5 step: 32 loss: 0.6931677460670471\n",
      "epoch: 5 step: 33 loss: 0.6931678056716919\n",
      "epoch: 5 step: 34 loss: 0.6931677460670471\n",
      "epoch: 5 step: 35 loss: 0.6931677460670471\n",
      "epoch: 5 step: 36 loss: 0.6931676864624023\n",
      "epoch: 5 step: 37 loss: 0.6931676864624023\n",
      "epoch: 5 step: 38 loss: 0.6931676268577576\n",
      "epoch: 5 step: 39 loss: 0.6931676268577576\n",
      "epoch: 5 step: 40 loss: 0.6931675672531128\n",
      "epoch: 5 step: 41 loss: 0.6931676268577576\n",
      "epoch: 5 step: 42 loss: 0.6931675672531128\n",
      "epoch: 5 step: 43 loss: 0.6931675672531128\n",
      "epoch: 5 step: 44 loss: 0.6931675672531128\n",
      "epoch: 5 step: 45 loss: 0.6931675672531128\n",
      "epoch: 5 step: 46 loss: 0.6931675672531128\n",
      "epoch: 5 step: 47 loss: 0.693167507648468\n",
      "epoch: 5 step: 48 loss: 0.6931675672531128\n",
      "epoch: 5 step: 49 loss: 0.693167507648468\n",
      "epoch: 5 step: 50 loss: 0.693167507648468\n",
      "epoch: 5 step: 51 loss: 0.6931674480438232\n",
      "epoch: 5 step: 52 loss: 0.6931674480438232\n",
      "epoch: 5 step: 53 loss: 0.6931674480438232\n",
      "epoch: 5 step: 54 loss: 0.6931674480438232\n",
      "epoch: 5 step: 55 loss: 0.6931674480438232\n",
      "epoch: 5 step: 56 loss: 0.6931674480438232\n",
      "epoch: 5 step: 57 loss: 0.6931673884391785\n",
      "epoch: 5 step: 58 loss: 0.6931674480438232\n",
      "epoch: 5 step: 59 loss: 0.6931673288345337\n",
      "epoch: 5 step: 60 loss: 0.6931673288345337\n",
      "epoch: 5 step: 61 loss: 0.6931673288345337\n",
      "epoch: 5 step: 62 loss: 0.6931672692298889\n",
      "epoch: 5 step: 63 loss: 0.6931673288345337\n",
      "epoch: 5 step: 64 loss: 0.6931673288345337\n",
      "epoch: 5 step: 65 loss: 0.6931673288345337\n",
      "epoch: 5 step: 66 loss: 0.6931672096252441\n",
      "epoch: 5 step: 67 loss: 0.6931672096252441\n",
      "epoch: 5 step: 68 loss: 0.6931672096252441\n",
      "epoch: 5 step: 69 loss: 0.6931672096252441\n",
      "epoch: 5 step: 70 loss: 0.6931671500205994\n",
      "epoch: 5 step: 71 loss: 0.6931672096252441\n",
      "epoch: 5 step: 72 loss: 0.6931671500205994\n",
      "epoch: 5 step: 73 loss: 0.6931671500205994\n",
      "epoch: 5 step: 74 loss: 0.6931671500205994\n",
      "epoch: 5 step: 75 loss: 0.6931670904159546\n",
      "epoch: 5 step: 76 loss: 0.6931670904159546\n",
      "epoch: 5 step: 77 loss: 0.6931670904159546\n",
      "epoch: 5 step: 78 loss: 0.6931670904159546\n",
      "epoch: 5 step: 79 loss: 0.6931670904159546\n",
      "epoch: 5 step: 80 loss: 0.6931670308113098\n",
      "epoch: 5 step: 81 loss: 0.6931670904159546\n",
      "epoch: 5 step: 82 loss: 0.693166971206665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 83 loss: 0.6931670308113098\n",
      "epoch: 5 step: 84 loss: 0.693166971206665\n",
      "epoch: 5 step: 85 loss: 0.693166971206665\n",
      "epoch: 5 step: 86 loss: 0.693166971206665\n",
      "epoch: 5 step: 87 loss: 0.693166971206665\n",
      "epoch: 5 step: 88 loss: 0.6931669116020203\n",
      "epoch: 5 step: 89 loss: 0.693166971206665\n",
      "epoch: 5 step: 90 loss: 0.6931668519973755\n",
      "epoch: 5 step: 91 loss: 0.6931668519973755\n",
      "epoch: 5 step: 92 loss: 0.6931668519973755\n",
      "epoch: 5 step: 93 loss: 0.6931668519973755\n",
      "epoch: 5 step: 94 loss: 0.6931668519973755\n",
      "epoch: 5 step: 95 loss: 0.6931668519973755\n",
      "epoch: 5 step: 96 loss: 0.6931668519973755\n",
      "epoch: 5 step: 97 loss: 0.6931667923927307\n",
      "epoch: 5 step: 98 loss: 0.6931667923927307\n",
      "epoch: 5 step: 99 loss: 0.6931667923927307\n",
      "epoch: 5 step: 100 loss: 0.6931667327880859\n",
      "epoch: 5 step: 101 loss: 0.6931667327880859\n",
      "epoch: 5 step: 102 loss: 0.6931667327880859\n",
      "epoch: 5 step: 103 loss: 0.6931667327880859\n",
      "epoch: 5 step: 104 loss: 0.6931667327880859\n",
      "epoch: 5 step: 105 loss: 0.6931667327880859\n",
      "epoch: 5 step: 106 loss: 0.6931666731834412\n",
      "epoch: 5 step: 107 loss: 0.6931666731834412\n",
      "epoch: 5 step: 108 loss: 0.6931666135787964\n",
      "epoch: 5 step: 109 loss: 0.6931666135787964\n",
      "epoch: 5 step: 110 loss: 0.6931666135787964\n",
      "epoch: 5 step: 111 loss: 0.6931666135787964\n",
      "epoch: 5 step: 112 loss: 0.6931666135787964\n",
      "epoch: 5 step: 113 loss: 0.6931666135787964\n",
      "epoch: 5 step: 114 loss: 0.6931666135787964\n",
      "epoch: 5 step: 115 loss: 0.6931665539741516\n",
      "epoch: 5 step: 116 loss: 0.6931664943695068\n",
      "epoch: 5 step: 117 loss: 0.6931665539741516\n",
      "epoch: 5 step: 118 loss: 0.6931664943695068\n",
      "epoch: 5 step: 119 loss: 0.6931664943695068\n",
      "epoch: 5 step: 120 loss: 0.6931664943695068\n",
      "epoch: 5 step: 121 loss: 0.6931664943695068\n",
      "epoch: 5 step: 122 loss: 0.6931664943695068\n",
      "epoch: 5 step: 123 loss: 0.6931664347648621\n",
      "epoch: 5 step: 124 loss: 0.6931664347648621\n",
      "epoch: 5 step: 125 loss: 0.6931664943695068\n",
      "epoch: 5 step: 126 loss: 0.6931663751602173\n",
      "epoch: 5 step: 127 loss: 0.6931663751602173\n",
      "epoch: 5 step: 128 loss: 0.6931663751602173\n",
      "epoch: 5 step: 129 loss: 0.6931663751602173\n",
      "epoch: 5 step: 130 loss: 0.6931663751602173\n",
      "epoch: 5 step: 131 loss: 0.6931663751602173\n",
      "epoch: 5 step: 132 loss: 0.6931663751602173\n",
      "epoch: 5 step: 133 loss: 0.6931663751602173\n",
      "epoch: 5 step: 134 loss: 0.6931662559509277\n",
      "epoch: 5 step: 135 loss: 0.6931662559509277\n",
      "epoch: 5 step: 136 loss: 0.6931662559509277\n",
      "epoch: 5 step: 137 loss: 0.6931662559509277\n",
      "epoch: 5 step: 138 loss: 0.6931662559509277\n",
      "epoch: 5 step: 139 loss: 0.6931662559509277\n",
      "epoch: 5 step: 140 loss: 0.693166196346283\n",
      "epoch: 5 step: 141 loss: 0.693166196346283\n",
      "epoch: 5 step: 142 loss: 0.6931661367416382\n",
      "epoch: 5 step: 143 loss: 0.693166196346283\n",
      "epoch: 5 step: 144 loss: 0.6931661367416382\n",
      "epoch: 5 step: 145 loss: 0.6931661367416382\n",
      "epoch: 5 step: 146 loss: 0.6931661367416382\n",
      "epoch: 5 step: 147 loss: 0.6931661367416382\n",
      "epoch: 5 step: 148 loss: 0.6931661367416382\n",
      "epoch: 5 step: 149 loss: 0.6931660771369934\n",
      "epoch: 5 step: 150 loss: 0.6931660175323486\n",
      "epoch: 5 step: 151 loss: 0.6931660771369934\n",
      "epoch: 5 step: 152 loss: 0.6931660175323486\n",
      "epoch: 5 step: 153 loss: 0.6931660175323486\n",
      "epoch: 5 step: 154 loss: 0.6931660175323486\n",
      "epoch: 5 step: 155 loss: 0.6931660175323486\n",
      "epoch: 5 step: 156 loss: 0.6931660175323486\n",
      "epoch: 5 step: 157 loss: 0.6931660175323486\n",
      "epoch: 5 step: 158 loss: 0.6931660175323486\n",
      "epoch: 5 step: 159 loss: 0.6931659579277039\n",
      "epoch: 5 step: 160 loss: 0.6931659579277039\n",
      "epoch: 5 step: 161 loss: 0.6931659579277039\n",
      "epoch: 5 step: 162 loss: 0.6931658983230591\n",
      "epoch: 5 step: 163 loss: 0.6931658983230591\n",
      "epoch: 5 step: 164 loss: 0.6931658983230591\n",
      "epoch: 5 step: 165 loss: 0.6931658983230591\n",
      "epoch: 5 step: 166 loss: 0.6931658983230591\n",
      "epoch: 5 step: 167 loss: 0.6931658387184143\n",
      "epoch: 5 step: 168 loss: 0.6931658387184143\n",
      "epoch: 5 step: 169 loss: 0.6931658387184143\n",
      "epoch: 5 step: 170 loss: 0.6931657791137695\n",
      "epoch: 5 step: 171 loss: 0.6931658387184143\n",
      "epoch: 5 step: 172 loss: 0.6931658387184143\n",
      "epoch: 5 step: 173 loss: 0.6931657791137695\n",
      "epoch: 5 step: 174 loss: 0.6931657791137695\n",
      "epoch: 5 step: 175 loss: 0.6931657195091248\n",
      "epoch: 5 step: 176 loss: 0.6931657791137695\n",
      "epoch: 5 step: 177 loss: 0.6931657195091248\n",
      "epoch: 5 step: 178 loss: 0.6931657195091248\n",
      "epoch: 5 step: 179 loss: 0.69316565990448\n",
      "epoch: 5 step: 180 loss: 0.69316565990448\n",
      "epoch: 5 step: 181 loss: 0.69316565990448\n",
      "epoch: 5 step: 182 loss: 0.69316565990448\n",
      "epoch: 5 step: 183 loss: 0.69316565990448\n",
      "epoch: 5 step: 184 loss: 0.69316565990448\n",
      "epoch: 5 step: 185 loss: 0.6931656002998352\n",
      "epoch: 5 step: 186 loss: 0.69316565990448\n",
      "epoch: 5 step: 187 loss: 0.6931656002998352\n",
      "epoch: 5 step: 188 loss: 0.6931656002998352\n",
      "epoch: 5 step: 189 loss: 0.6931655406951904\n",
      "epoch: 5 step: 190 loss: 0.6931656002998352\n",
      "epoch: 5 step: 191 loss: 0.6931655406951904\n",
      "epoch: 5 step: 192 loss: 0.6931655406951904\n",
      "epoch: 5 step: 193 loss: 0.6931655406951904\n",
      "epoch: 5 step: 194 loss: 0.6931654810905457\n",
      "epoch: 5 step: 195 loss: 0.6931654810905457\n",
      "epoch: 5 step: 196 loss: 0.6931654810905457\n",
      "epoch: 5 step: 197 loss: 0.6931654810905457\n",
      "epoch: 5 step: 198 loss: 0.6931654214859009\n",
      "epoch: 5 step: 199 loss: 0.6931654214859009\n",
      "epoch: 5 step: 200 loss: 0.6931654214859009\n",
      "epoch: 5 step: 201 loss: 0.6931654214859009\n",
      "epoch: 5 step: 202 loss: 0.6931654214859009\n",
      "epoch: 5 step: 203 loss: 0.6931653618812561\n",
      "epoch: 5 step: 204 loss: 0.6931653022766113\n",
      "epoch: 5 step: 205 loss: 0.6931654214859009\n",
      "epoch: 5 step: 206 loss: 0.6931653618812561\n",
      "epoch: 5 step: 207 loss: 0.6931653022766113\n",
      "epoch: 5 step: 208 loss: 0.6931653618812561\n",
      "epoch: 5 step: 209 loss: 0.6931653022766113\n",
      "epoch: 5 step: 210 loss: 0.6931653022766113\n",
      "epoch: 5 step: 211 loss: 0.6931653022766113\n",
      "epoch: 5 step: 212 loss: 0.6931652426719666\n",
      "epoch: 5 step: 213 loss: 0.6931653022766113\n",
      "epoch: 5 step: 214 loss: 0.6931652426719666\n",
      "epoch: 5 step: 215 loss: 0.6931653022766113\n",
      "epoch: 5 step: 216 loss: 0.6931652426719666\n",
      "epoch: 5 step: 217 loss: 0.6931652426719666\n",
      "epoch: 5 step: 218 loss: 0.6931651830673218\n",
      "epoch: 5 step: 219 loss: 0.6931651830673218\n",
      "epoch: 5 step: 220 loss: 0.6931651830673218\n",
      "epoch: 5 step: 221 loss: 0.6931651830673218\n",
      "epoch: 5 step: 222 loss: 0.6931651830673218\n",
      "epoch: 5 step: 223 loss: 0.6931651830673218\n",
      "epoch: 5 step: 224 loss: 0.693165123462677\n",
      "epoch: 5 step: 225 loss: 0.6931650638580322\n",
      "epoch: 5 step: 226 loss: 0.6931650638580322\n",
      "epoch: 5 step: 227 loss: 0.6931650638580322\n",
      "epoch: 5 step: 228 loss: 0.6931650638580322\n",
      "epoch: 5 step: 229 loss: 0.6931650638580322\n",
      "epoch: 5 step: 230 loss: 0.6931650638580322\n",
      "epoch: 5 step: 231 loss: 0.6931650042533875\n",
      "epoch: 5 step: 232 loss: 0.6931650042533875\n",
      "epoch: 5 step: 233 loss: 0.6931650042533875\n",
      "epoch: 5 step: 234 loss: 0.6931650042533875\n",
      "epoch: 5 step: 235 loss: 0.6931649446487427\n",
      "epoch: 5 step: 236 loss: 0.6931649446487427\n",
      "epoch: 5 step: 237 loss: 0.6931649446487427\n",
      "epoch: 5 step: 238 loss: 0.6931649446487427\n",
      "epoch: 5 step: 239 loss: 0.6931649446487427\n",
      "epoch: 5 step: 240 loss: 0.6931648850440979\n",
      "epoch: 5 step: 241 loss: 0.6931649446487427\n",
      "epoch: 5 step: 242 loss: 0.6931648850440979\n",
      "epoch: 5 step: 243 loss: 0.6931648850440979\n",
      "epoch: 5 step: 244 loss: 0.6931648850440979\n",
      "epoch: 5 step: 245 loss: 0.6931648254394531\n",
      "epoch: 5 step: 246 loss: 0.6931648254394531\n",
      "epoch: 5 step: 247 loss: 0.6931648254394531\n",
      "epoch: 5 step: 248 loss: 0.6931648254394531\n",
      "epoch: 5 step: 249 loss: 0.6931648254394531\n",
      "epoch: 5 step: 250 loss: 0.6931647658348083\n",
      "epoch: 5 step: 251 loss: 0.6931648254394531\n",
      "epoch: 5 step: 252 loss: 0.6931647658348083\n",
      "epoch: 5 step: 253 loss: 0.6931647658348083\n",
      "epoch: 5 step: 254 loss: 0.6931647658348083\n",
      "epoch: 5 step: 255 loss: 0.6931647062301636\n",
      "epoch: 5 step: 256 loss: 0.6931647062301636\n",
      "epoch: 5 step: 257 loss: 0.6931647062301636\n",
      "epoch: 5 step: 258 loss: 0.6931647062301636\n",
      "epoch: 5 step: 259 loss: 0.6931647062301636\n",
      "epoch: 5 step: 260 loss: 0.6931646466255188\n",
      "epoch: 5 step: 261 loss: 0.6931647062301636\n",
      "epoch: 5 step: 262 loss: 0.693164587020874\n",
      "epoch: 5 step: 263 loss: 0.693164587020874\n",
      "epoch: 5 step: 264 loss: 0.6931646466255188\n",
      "epoch: 5 step: 265 loss: 0.693164587020874\n",
      "epoch: 5 step: 266 loss: 0.693164587020874\n",
      "epoch: 5 step: 267 loss: 0.693164587020874\n",
      "epoch: 5 step: 268 loss: 0.693164587020874\n",
      "epoch: 5 step: 269 loss: 0.693164587020874\n",
      "epoch: 5 step: 270 loss: 0.6931645274162292\n",
      "epoch: 5 step: 271 loss: 0.6931645274162292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 272 loss: 0.6931644678115845\n",
      "epoch: 5 step: 273 loss: 0.6931644678115845\n",
      "epoch: 5 step: 274 loss: 0.6931645274162292\n",
      "epoch: 5 step: 275 loss: 0.6931644678115845\n",
      "epoch: 5 step: 276 loss: 0.6931644678115845\n",
      "epoch: 5 step: 277 loss: 0.6931644678115845\n",
      "epoch: 5 step: 278 loss: 0.6931644082069397\n",
      "epoch: 5 step: 279 loss: 0.6931644678115845\n",
      "epoch: 5 step: 280 loss: 0.6931644082069397\n",
      "epoch: 5 step: 281 loss: 0.6931644678115845\n",
      "epoch: 5 step: 282 loss: 0.6931643486022949\n",
      "epoch: 5 step: 283 loss: 0.6931644082069397\n",
      "epoch: 5 step: 284 loss: 0.6931643486022949\n",
      "epoch: 5 step: 285 loss: 0.6931643486022949\n",
      "epoch: 5 step: 286 loss: 0.6931643486022949\n",
      "epoch: 5 step: 287 loss: 0.6931643486022949\n",
      "epoch: 5 step: 288 loss: 0.6931642889976501\n",
      "epoch: 5 step: 289 loss: 0.6931643486022949\n",
      "epoch: 5 step: 290 loss: 0.6931643486022949\n",
      "epoch: 5 step: 291 loss: 0.6931642293930054\n",
      "epoch: 5 step: 292 loss: 0.6931642889976501\n",
      "epoch: 5 step: 293 loss: 0.6931642889976501\n",
      "epoch: 5 step: 294 loss: 0.6931642293930054\n",
      "epoch: 5 step: 295 loss: 0.6931642293930054\n",
      "epoch: 5 step: 296 loss: 0.6931642293930054\n",
      "epoch: 5 step: 297 loss: 0.6931642293930054\n",
      "epoch: 5 step: 298 loss: 0.6931642293930054\n",
      "epoch: 5 step: 299 loss: 0.6931641697883606\n",
      "epoch: 5 step: 300 loss: 0.6931641101837158\n",
      "epoch: 5 step: 301 loss: 0.6931641697883606\n",
      "epoch: 5 step: 302 loss: 0.6931642293930054\n",
      "epoch: 5 step: 303 loss: 0.6931641101837158\n",
      "epoch: 5 step: 304 loss: 0.6931641697883606\n",
      "epoch: 5 step: 305 loss: 0.6931641101837158\n",
      "epoch: 5 step: 306 loss: 0.6931641101837158\n",
      "epoch: 5 step: 307 loss: 0.6931641101837158\n",
      "epoch: 5 step: 308 loss: 0.6931641101837158\n",
      "epoch: 5 step: 309 loss: 0.693164050579071\n",
      "epoch: 5 step: 310 loss: 0.6931641101837158\n",
      "epoch: 5 step: 311 loss: 0.693164050579071\n",
      "epoch: 5 step: 312 loss: 0.693164050579071\n",
      "epoch: 5 step: 313 loss: 0.6931639909744263\n",
      "epoch: 5 step: 314 loss: 0.6931639909744263\n",
      "epoch: 5 step: 315 loss: 0.693164050579071\n",
      "epoch: 5 step: 316 loss: 0.6931639909744263\n",
      "epoch: 5 step: 317 loss: 0.6931639909744263\n",
      "epoch: 5 step: 318 loss: 0.6931639909744263\n",
      "epoch: 5 step: 319 loss: 0.6931639909744263\n",
      "epoch: 5 step: 320 loss: 0.6931639909744263\n",
      "epoch: 5 step: 321 loss: 0.6931638717651367\n",
      "epoch: 5 step: 322 loss: 0.6931639313697815\n",
      "epoch: 5 step: 323 loss: 0.6931639909744263\n",
      "epoch: 5 step: 324 loss: 0.6931638717651367\n",
      "epoch: 5 step: 325 loss: 0.6931638717651367\n",
      "epoch: 5 step: 326 loss: 0.6931638717651367\n",
      "epoch: 5 step: 327 loss: 0.6931638717651367\n",
      "epoch: 5 step: 328 loss: 0.6931638717651367\n",
      "epoch: 5 step: 329 loss: 0.6931638717651367\n",
      "epoch: 5 step: 330 loss: 0.6931638717651367\n",
      "epoch: 5 step: 331 loss: 0.6931638717651367\n",
      "epoch: 5 step: 332 loss: 0.6931637525558472\n",
      "epoch: 5 step: 333 loss: 0.6931638121604919\n",
      "epoch: 5 step: 334 loss: 0.6931638121604919\n",
      "epoch: 5 step: 335 loss: 0.6931637525558472\n",
      "epoch: 5 step: 336 loss: 0.6931637525558472\n",
      "epoch: 5 step: 337 loss: 0.6931637525558472\n",
      "epoch: 5 step: 338 loss: 0.6931637525558472\n",
      "epoch: 5 step: 339 loss: 0.6931637525558472\n",
      "epoch: 5 step: 340 loss: 0.6931636929512024\n",
      "epoch: 5 step: 341 loss: 0.6931637525558472\n",
      "epoch: 5 step: 342 loss: 0.6931636929512024\n",
      "epoch: 5 step: 343 loss: 0.6931636333465576\n",
      "epoch: 5 step: 344 loss: 0.6931637525558472\n",
      "epoch: 5 step: 345 loss: 0.6931636929512024\n",
      "epoch: 5 step: 346 loss: 0.6931636333465576\n",
      "epoch: 5 step: 347 loss: 0.6931636333465576\n",
      "epoch: 5 step: 348 loss: 0.6931636333465576\n",
      "epoch: 5 step: 349 loss: 0.6931636333465576\n",
      "epoch: 5 step: 350 loss: 0.6931636333465576\n",
      "epoch: 5 step: 351 loss: 0.6931636333465576\n",
      "epoch: 5 step: 352 loss: 0.6931635737419128\n",
      "epoch: 5 step: 353 loss: 0.6931635737419128\n",
      "epoch: 5 step: 354 loss: 0.6931635737419128\n",
      "epoch: 5 step: 355 loss: 0.6931635141372681\n",
      "epoch: 5 step: 356 loss: 0.6931635737419128\n",
      "epoch: 5 step: 357 loss: 0.6931635141372681\n",
      "epoch: 5 step: 358 loss: 0.6931635141372681\n",
      "epoch: 5 step: 359 loss: 0.6931635141372681\n",
      "epoch: 5 step: 360 loss: 0.6931635141372681\n",
      "epoch: 5 step: 361 loss: 0.6931634545326233\n",
      "epoch: 5 step: 362 loss: 0.6931635141372681\n",
      "epoch: 5 step: 363 loss: 0.6931634545326233\n",
      "epoch: 5 step: 364 loss: 0.6931635141372681\n",
      "epoch: 5 step: 365 loss: 0.6931634545326233\n",
      "epoch: 5 step: 366 loss: 0.6931633949279785\n",
      "epoch: 5 step: 367 loss: 0.6931633949279785\n",
      "epoch: 5 step: 368 loss: 0.6931633949279785\n",
      "epoch: 5 step: 369 loss: 0.6931633949279785\n",
      "epoch: 5 step: 370 loss: 0.6931633949279785\n",
      "epoch: 5 step: 371 loss: 0.6931633949279785\n",
      "epoch: 5 step: 372 loss: 0.6931633353233337\n",
      "epoch: 5 step: 373 loss: 0.6931633949279785\n",
      "epoch: 5 step: 374 loss: 0.6931633353233337\n",
      "epoch: 5 step: 375 loss: 0.6931633949279785\n",
      "epoch: 5 step: 376 loss: 0.693163275718689\n",
      "epoch: 5 step: 377 loss: 0.693163275718689\n",
      "epoch: 5 step: 378 loss: 0.693163275718689\n",
      "epoch: 5 step: 379 loss: 0.693163275718689\n",
      "epoch: 5 step: 380 loss: 0.693163275718689\n",
      "epoch: 5 step: 381 loss: 0.693163275718689\n",
      "epoch: 5 step: 382 loss: 0.693163275718689\n",
      "epoch: 5 step: 383 loss: 0.6931632161140442\n",
      "epoch: 5 step: 384 loss: 0.6931632161140442\n",
      "epoch: 5 step: 385 loss: 0.6931632161140442\n",
      "epoch: 5 step: 386 loss: 0.6931631565093994\n",
      "epoch: 5 step: 387 loss: 0.6931632161140442\n",
      "epoch: 5 step: 388 loss: 0.6931632161140442\n",
      "epoch: 5 step: 389 loss: 0.6931631565093994\n",
      "epoch: 5 step: 390 loss: 0.6931631565093994\n",
      "epoch: 5 step: 391 loss: 0.6931631565093994\n",
      "epoch: 5 step: 392 loss: 0.6931631565093994\n",
      "epoch: 5 step: 393 loss: 0.6931631565093994\n",
      "epoch: 5 step: 394 loss: 0.6931631565093994\n",
      "epoch: 5 step: 395 loss: 0.6931631565093994\n",
      "epoch: 5 step: 396 loss: 0.6931630969047546\n",
      "epoch: 5 step: 397 loss: 0.6931631565093994\n",
      "epoch: 5 step: 398 loss: 0.6931630969047546\n",
      "epoch: 5 step: 399 loss: 0.6931630373001099\n",
      "epoch: 5 step: 400 loss: 0.6931630373001099\n",
      "epoch: 5 step: 401 loss: 0.6931630373001099\n",
      "epoch: 5 step: 402 loss: 0.6931630373001099\n",
      "epoch: 5 step: 403 loss: 0.6931630373001099\n",
      "epoch: 5 step: 404 loss: 0.6931630373001099\n",
      "epoch: 5 step: 405 loss: 0.6931629776954651\n",
      "epoch: 5 step: 406 loss: 0.6931630373001099\n",
      "epoch: 5 step: 407 loss: 0.6931630373001099\n",
      "epoch: 5 step: 408 loss: 0.6931629180908203\n",
      "epoch: 5 step: 409 loss: 0.6931629180908203\n",
      "epoch: 5 step: 410 loss: 0.6931629180908203\n",
      "epoch: 5 step: 411 loss: 0.6931629180908203\n",
      "epoch: 5 step: 412 loss: 0.6931629180908203\n",
      "epoch: 5 step: 413 loss: 0.6931629180908203\n",
      "epoch: 5 step: 414 loss: 0.6931628584861755\n",
      "epoch: 5 step: 415 loss: 0.6931628584861755\n",
      "epoch: 5 step: 416 loss: 0.6931628584861755\n",
      "epoch: 5 step: 417 loss: 0.6931628584861755\n",
      "epoch: 5 step: 418 loss: 0.6931628584861755\n",
      "epoch: 5 step: 419 loss: 0.6931628584861755\n",
      "epoch: 5 step: 420 loss: 0.6931627988815308\n",
      "epoch: 5 step: 421 loss: 0.6931627988815308\n",
      "epoch: 5 step: 422 loss: 0.6931627988815308\n",
      "epoch: 5 step: 423 loss: 0.6931627988815308\n",
      "epoch: 5 step: 424 loss: 0.6931627988815308\n",
      "epoch: 5 step: 425 loss: 0.6931627988815308\n",
      "epoch: 5 step: 426 loss: 0.6931627988815308\n",
      "epoch: 5 step: 427 loss: 0.693162739276886\n",
      "epoch: 5 step: 428 loss: 0.693162739276886\n",
      "epoch: 5 step: 429 loss: 0.693162739276886\n",
      "epoch: 5 step: 430 loss: 0.693162739276886\n",
      "epoch: 5 step: 431 loss: 0.693162739276886\n",
      "epoch: 5 step: 432 loss: 0.6931626796722412\n",
      "epoch: 5 step: 433 loss: 0.6931626796722412\n",
      "epoch: 5 step: 434 loss: 0.6931626796722412\n",
      "epoch: 5 step: 435 loss: 0.6931626796722412\n",
      "epoch: 5 step: 436 loss: 0.6931626796722412\n",
      "epoch: 5 step: 437 loss: 0.6931626200675964\n",
      "epoch: 5 step: 438 loss: 0.6931626796722412\n",
      "epoch: 5 step: 439 loss: 0.6931626796722412\n",
      "epoch: 5 step: 440 loss: 0.6931626200675964\n",
      "epoch: 5 step: 441 loss: 0.6931626200675964\n",
      "epoch: 5 step: 442 loss: 0.6931625604629517\n",
      "epoch: 5 step: 443 loss: 0.6931625604629517\n",
      "epoch: 5 step: 444 loss: 0.6931625604629517\n",
      "epoch: 5 step: 445 loss: 0.6931625604629517\n",
      "epoch: 5 step: 446 loss: 0.6931625604629517\n",
      "epoch: 5 step: 447 loss: 0.6931625604629517\n",
      "epoch: 5 step: 448 loss: 0.6931625604629517\n",
      "epoch: 5 step: 449 loss: 0.6931625604629517\n",
      "epoch: 5 step: 450 loss: 0.6931625008583069\n",
      "epoch: 5 step: 451 loss: 0.6931624412536621\n",
      "epoch: 5 step: 452 loss: 0.6931624412536621\n",
      "epoch: 5 step: 453 loss: 0.6931624412536621\n",
      "epoch: 5 step: 454 loss: 0.6931624412536621\n",
      "epoch: 5 step: 455 loss: 0.6931624412536621\n",
      "epoch: 5 step: 456 loss: 0.6931625008583069\n",
      "epoch: 5 step: 457 loss: 0.6931624412536621\n",
      "epoch: 5 step: 458 loss: 0.6931624412536621\n",
      "epoch: 5 step: 459 loss: 0.6931624412536621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 460 loss: 0.6931624412536621\n",
      "epoch: 5 step: 461 loss: 0.6931624412536621\n",
      "epoch: 5 step: 462 loss: 0.6931624412536621\n",
      "epoch: 5 step: 463 loss: 0.6931623816490173\n",
      "epoch: 5 step: 464 loss: 0.6931623220443726\n",
      "epoch: 5 step: 465 loss: 0.6931623816490173\n",
      "epoch: 5 step: 466 loss: 0.6931623816490173\n",
      "epoch: 5 step: 467 loss: 0.6931623220443726\n",
      "epoch: 5 step: 468 loss: 0.6931623220443726\n",
      "epoch: 5 step: 469 loss: 0.6931623220443726\n",
      "epoch: 5 step: 470 loss: 0.6931623220443726\n",
      "epoch: 5 step: 471 loss: 0.6931623220443726\n",
      "epoch: 5 step: 472 loss: 0.6931623220443726\n",
      "epoch: 5 step: 473 loss: 0.6931623220443726\n",
      "epoch: 5 step: 474 loss: 0.6931622624397278\n",
      "epoch: 5 step: 475 loss: 0.6931623220443726\n",
      "epoch: 5 step: 476 loss: 0.693162202835083\n",
      "epoch: 5 step: 477 loss: 0.693162202835083\n",
      "epoch: 5 step: 478 loss: 0.693162202835083\n",
      "epoch: 5 step: 479 loss: 0.693162202835083\n",
      "epoch: 5 step: 480 loss: 0.693162202835083\n",
      "epoch: 5 step: 481 loss: 0.693162202835083\n",
      "epoch: 5 step: 482 loss: 0.693162202835083\n",
      "epoch: 5 step: 483 loss: 0.6931621432304382\n",
      "epoch: 5 step: 484 loss: 0.693162202835083\n",
      "epoch: 5 step: 485 loss: 0.6931621432304382\n",
      "epoch: 5 step: 486 loss: 0.693162202835083\n",
      "epoch: 5 step: 487 loss: 0.6931621432304382\n",
      "epoch: 5 step: 488 loss: 0.6931621432304382\n",
      "epoch: 5 step: 489 loss: 0.6931620836257935\n",
      "epoch: 5 step: 490 loss: 0.6931620836257935\n",
      "epoch: 5 step: 491 loss: 0.6931620836257935\n",
      "epoch: 5 step: 492 loss: 0.6931620836257935\n",
      "epoch: 5 step: 493 loss: 0.6931620836257935\n",
      "epoch: 5 step: 494 loss: 0.6931620836257935\n",
      "epoch: 5 step: 495 loss: 0.6931620836257935\n",
      "epoch: 5 step: 496 loss: 0.6931620836257935\n",
      "epoch: 5 step: 497 loss: 0.6931620836257935\n",
      "epoch: 5 step: 498 loss: 0.6931620836257935\n",
      "epoch: 5 step: 499 loss: 0.6931620240211487\n",
      "epoch: 5 step: 500 loss: 0.6931619644165039\n",
      "epoch: 5 step: 501 loss: 0.6931619644165039\n",
      "epoch: 5 step: 502 loss: 0.6931619644165039\n",
      "epoch: 5 step: 503 loss: 0.6931620240211487\n",
      "epoch: 5 step: 504 loss: 0.6931619644165039\n",
      "epoch: 5 step: 505 loss: 0.6931619644165039\n",
      "epoch: 5 step: 506 loss: 0.6931619644165039\n",
      "epoch: 5 step: 507 loss: 0.6931619644165039\n",
      "epoch: 5 step: 508 loss: 0.6931619644165039\n",
      "epoch: 5 step: 509 loss: 0.6931619644165039\n",
      "epoch: 5 step: 510 loss: 0.6931619048118591\n",
      "epoch: 5 step: 511 loss: 0.6931618452072144\n",
      "epoch: 5 step: 512 loss: 0.6931619048118591\n",
      "epoch: 5 step: 513 loss: 0.6931618452072144\n",
      "epoch: 5 step: 514 loss: 0.6931618452072144\n",
      "epoch: 5 step: 515 loss: 0.6931618452072144\n",
      "epoch: 5 step: 516 loss: 0.6931618452072144\n",
      "epoch: 5 step: 517 loss: 0.6931618452072144\n",
      "epoch: 5 step: 518 loss: 0.6931618452072144\n",
      "epoch: 5 step: 519 loss: 0.6931618452072144\n",
      "epoch: 5 step: 520 loss: 0.6931617856025696\n",
      "epoch: 5 step: 521 loss: 0.6931618452072144\n",
      "epoch: 5 step: 522 loss: 0.6931617856025696\n",
      "epoch: 5 step: 523 loss: 0.6931618452072144\n",
      "epoch: 5 step: 524 loss: 0.6931617856025696\n",
      "epoch: 5 step: 525 loss: 0.6931617856025696\n",
      "epoch: 5 step: 526 loss: 0.6931617259979248\n",
      "epoch: 5 step: 527 loss: 0.6931617259979248\n",
      "epoch: 5 step: 528 loss: 0.6931617259979248\n",
      "epoch: 5 step: 529 loss: 0.6931617259979248\n",
      "epoch: 5 step: 530 loss: 0.6931617259979248\n",
      "epoch: 5 step: 531 loss: 0.6931617259979248\n",
      "epoch: 5 step: 532 loss: 0.6931617259979248\n",
      "epoch: 5 step: 533 loss: 0.6931617259979248\n",
      "epoch: 5 step: 534 loss: 0.6931617259979248\n",
      "epoch: 5 step: 535 loss: 0.6931617259979248\n",
      "epoch: 5 step: 536 loss: 0.69316166639328\n",
      "epoch: 5 step: 537 loss: 0.69316166639328\n",
      "epoch: 5 step: 538 loss: 0.6931616067886353\n",
      "epoch: 5 step: 539 loss: 0.6931616067886353\n",
      "epoch: 5 step: 540 loss: 0.6931616067886353\n",
      "epoch: 5 step: 541 loss: 0.6931616067886353\n",
      "epoch: 5 step: 542 loss: 0.6931616067886353\n",
      "epoch: 5 step: 543 loss: 0.6931616067886353\n",
      "epoch: 5 step: 544 loss: 0.6931616067886353\n",
      "epoch: 5 step: 545 loss: 0.6931616067886353\n",
      "epoch: 5 step: 546 loss: 0.6931616067886353\n",
      "epoch: 5 step: 547 loss: 0.6931616067886353\n",
      "epoch: 5 step: 548 loss: 0.6931614875793457\n",
      "epoch: 5 step: 549 loss: 0.6931616067886353\n",
      "epoch: 5 step: 550 loss: 0.6931616067886353\n",
      "epoch: 5 step: 551 loss: 0.6931614875793457\n",
      "epoch: 5 step: 552 loss: 0.6931614875793457\n",
      "epoch: 5 step: 553 loss: 0.6931614875793457\n",
      "epoch: 5 step: 554 loss: 0.6931614875793457\n",
      "epoch: 5 step: 555 loss: 0.6931614875793457\n",
      "epoch: 5 step: 556 loss: 0.6931614875793457\n",
      "epoch: 5 step: 557 loss: 0.6931614279747009\n",
      "epoch: 5 step: 558 loss: 0.6931614875793457\n",
      "epoch: 5 step: 559 loss: 0.6931614279747009\n",
      "epoch: 5 step: 560 loss: 0.6931614279747009\n",
      "epoch: 5 step: 561 loss: 0.6931613683700562\n",
      "epoch: 5 step: 562 loss: 0.6931613683700562\n",
      "epoch: 5 step: 563 loss: 0.6931613683700562\n",
      "epoch: 5 step: 564 loss: 0.6931613683700562\n",
      "epoch: 5 step: 565 loss: 0.6931613683700562\n",
      "epoch: 5 step: 566 loss: 0.6931613683700562\n",
      "epoch: 5 step: 567 loss: 0.6931613683700562\n",
      "epoch: 5 step: 568 loss: 0.6931613683700562\n",
      "epoch: 5 step: 569 loss: 0.6931613683700562\n",
      "epoch: 5 step: 570 loss: 0.6931613683700562\n",
      "epoch: 5 step: 571 loss: 0.6931613683700562\n",
      "epoch: 5 step: 572 loss: 0.6931612491607666\n",
      "epoch: 5 step: 573 loss: 0.6931612491607666\n",
      "epoch: 5 step: 574 loss: 0.6931613087654114\n",
      "epoch: 5 step: 575 loss: 0.6931613087654114\n",
      "epoch: 5 step: 576 loss: 0.6931612491607666\n",
      "epoch: 5 step: 577 loss: 0.6931612491607666\n",
      "epoch: 5 step: 578 loss: 0.6931612491607666\n",
      "epoch: 5 step: 579 loss: 0.6931612491607666\n",
      "epoch: 5 step: 580 loss: 0.6931612491607666\n",
      "epoch: 5 step: 581 loss: 0.6931612491607666\n",
      "epoch: 5 step: 582 loss: 0.6931612491607666\n",
      "epoch: 5 step: 583 loss: 0.6931612491607666\n",
      "epoch: 5 step: 584 loss: 0.693161129951477\n",
      "epoch: 5 step: 585 loss: 0.6931611895561218\n",
      "epoch: 5 step: 586 loss: 0.6931611895561218\n",
      "epoch: 5 step: 587 loss: 0.693161129951477\n",
      "epoch: 5 step: 588 loss: 0.6931611895561218\n",
      "epoch: 5 step: 589 loss: 0.693161129951477\n",
      "epoch: 5 step: 590 loss: 0.693161129951477\n",
      "epoch: 5 step: 591 loss: 0.693161129951477\n",
      "epoch: 5 step: 592 loss: 0.693161129951477\n",
      "epoch: 5 step: 593 loss: 0.693161129951477\n",
      "epoch: 5 step: 594 loss: 0.693161129951477\n",
      "epoch: 5 step: 595 loss: 0.693161129951477\n",
      "epoch: 5 step: 596 loss: 0.6931610703468323\n",
      "epoch: 5 step: 597 loss: 0.693161129951477\n",
      "epoch: 5 step: 598 loss: 0.6931610703468323\n",
      "epoch: 5 step: 599 loss: 0.6931610703468323\n",
      "epoch: 5 step: 600 loss: 0.6931610107421875\n",
      "epoch: 5 step: 601 loss: 0.6931610107421875\n",
      "epoch: 5 step: 602 loss: 0.6931610107421875\n",
      "epoch: 5 step: 603 loss: 0.6931610703468323\n",
      "epoch: 5 step: 604 loss: 0.6931610107421875\n",
      "epoch: 5 step: 605 loss: 0.6931610107421875\n",
      "epoch: 5 step: 606 loss: 0.6931610107421875\n",
      "epoch: 5 step: 607 loss: 0.6931610107421875\n",
      "epoch: 5 step: 608 loss: 0.6931610107421875\n",
      "epoch: 5 step: 609 loss: 0.6931609511375427\n",
      "epoch: 5 step: 610 loss: 0.6931610107421875\n",
      "epoch: 5 step: 611 loss: 0.6931609511375427\n",
      "epoch: 5 step: 612 loss: 0.693160891532898\n",
      "epoch: 5 step: 613 loss: 0.693160891532898\n",
      "epoch: 5 step: 614 loss: 0.693160891532898\n",
      "epoch: 5 step: 615 loss: 0.693160891532898\n",
      "epoch: 5 step: 616 loss: 0.693160891532898\n",
      "epoch: 5 step: 617 loss: 0.693160891532898\n",
      "epoch: 5 step: 618 loss: 0.693160891532898\n",
      "epoch: 5 step: 619 loss: 0.693160891532898\n",
      "epoch: 5 step: 620 loss: 0.693160891532898\n",
      "epoch: 5 step: 621 loss: 0.693160891532898\n",
      "epoch: 5 step: 622 loss: 0.693160891532898\n",
      "epoch: 5 step: 623 loss: 0.6931608319282532\n",
      "epoch: 5 step: 624 loss: 0.6931607723236084\n",
      "epoch: 5 step: 625 loss: 0.6931607723236084\n",
      "epoch: 5 step: 626 loss: 0.6931608319282532\n",
      "epoch: 5 step: 627 loss: 0.6931607723236084\n",
      "epoch: 5 step: 628 loss: 0.6931607723236084\n",
      "epoch: 5 step: 629 loss: 0.6931607723236084\n",
      "epoch: 5 step: 630 loss: 0.6931607723236084\n",
      "epoch: 5 step: 631 loss: 0.6931607723236084\n",
      "epoch: 5 step: 632 loss: 0.6931607723236084\n",
      "epoch: 5 step: 633 loss: 0.6931607723236084\n",
      "epoch: 5 step: 634 loss: 0.6931607723236084\n",
      "epoch: 5 step: 635 loss: 0.6931607127189636\n",
      "epoch: 5 step: 636 loss: 0.6931607723236084\n",
      "epoch: 5 step: 637 loss: 0.6931607127189636\n",
      "epoch: 5 step: 638 loss: 0.6931607127189636\n",
      "epoch: 5 step: 639 loss: 0.6931607127189636\n",
      "epoch: 5 step: 640 loss: 0.6931607127189636\n",
      "epoch: 5 step: 641 loss: 0.6931606531143188\n",
      "epoch: 5 step: 642 loss: 0.6931606531143188\n",
      "epoch: 5 step: 643 loss: 0.6931606531143188\n",
      "epoch: 5 step: 644 loss: 0.6931606531143188\n",
      "epoch: 5 step: 645 loss: 0.6931606531143188\n",
      "epoch: 5 step: 646 loss: 0.6931606531143188\n",
      "epoch: 5 step: 647 loss: 0.6931606531143188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 648 loss: 0.6931606531143188\n",
      "epoch: 5 step: 649 loss: 0.6931606531143188\n",
      "epoch: 5 step: 650 loss: 0.6931605339050293\n",
      "epoch: 5 step: 651 loss: 0.6931605935096741\n",
      "epoch: 5 step: 652 loss: 0.6931605935096741\n",
      "epoch: 5 step: 653 loss: 0.6931605935096741\n",
      "epoch: 5 step: 654 loss: 0.6931605339050293\n",
      "epoch: 5 step: 655 loss: 0.6931605339050293\n",
      "epoch: 5 step: 656 loss: 0.6931605339050293\n",
      "epoch: 5 step: 657 loss: 0.6931605339050293\n",
      "epoch: 5 step: 658 loss: 0.6931605339050293\n",
      "epoch: 5 step: 659 loss: 0.6931605339050293\n",
      "epoch: 5 step: 660 loss: 0.6931604743003845\n",
      "epoch: 5 step: 661 loss: 0.6931604743003845\n",
      "epoch: 5 step: 662 loss: 0.6931605339050293\n",
      "epoch: 5 step: 663 loss: 0.6931605339050293\n",
      "epoch: 5 step: 664 loss: 0.6931605339050293\n",
      "epoch: 5 step: 665 loss: 0.6931604743003845\n",
      "epoch: 5 step: 666 loss: 0.6931604146957397\n",
      "epoch: 5 step: 667 loss: 0.6931604743003845\n",
      "epoch: 5 step: 668 loss: 0.6931604146957397\n",
      "epoch: 5 step: 669 loss: 0.6931604146957397\n",
      "epoch: 5 step: 670 loss: 0.6931604146957397\n",
      "epoch: 5 step: 671 loss: 0.6931604146957397\n",
      "epoch: 5 step: 672 loss: 0.6931604146957397\n",
      "epoch: 5 step: 673 loss: 0.693160355091095\n",
      "epoch: 5 step: 674 loss: 0.6931604146957397\n",
      "epoch: 5 step: 675 loss: 0.693160355091095\n",
      "epoch: 5 step: 676 loss: 0.6931604146957397\n",
      "epoch: 5 step: 677 loss: 0.693160355091095\n",
      "epoch: 5 step: 678 loss: 0.693160355091095\n",
      "epoch: 5 step: 679 loss: 0.6931602954864502\n",
      "epoch: 5 step: 680 loss: 0.693160355091095\n",
      "epoch: 5 step: 681 loss: 0.6931602954864502\n",
      "epoch: 5 step: 682 loss: 0.693160355091095\n",
      "epoch: 5 step: 683 loss: 0.6931602954864502\n",
      "epoch: 5 step: 684 loss: 0.6931602954864502\n",
      "epoch: 5 step: 685 loss: 0.6931602954864502\n",
      "epoch: 5 step: 686 loss: 0.6931602954864502\n",
      "epoch: 5 step: 687 loss: 0.6931602954864502\n",
      "epoch: 5 step: 688 loss: 0.6931602954864502\n",
      "epoch: 5 step: 689 loss: 0.6931602954864502\n",
      "epoch: 5 step: 690 loss: 0.6931602358818054\n",
      "epoch: 5 step: 691 loss: 0.6931602358818054\n",
      "epoch: 5 step: 692 loss: 0.6931602358818054\n",
      "epoch: 5 step: 693 loss: 0.6931602358818054\n",
      "epoch: 5 step: 694 loss: 0.6931601762771606\n",
      "epoch: 5 step: 695 loss: 0.6931601762771606\n",
      "epoch: 5 step: 696 loss: 0.6931601762771606\n",
      "epoch: 5 step: 697 loss: 0.6931601762771606\n",
      "epoch: 5 step: 698 loss: 0.6931601762771606\n",
      "epoch: 5 step: 699 loss: 0.6931601762771606\n",
      "epoch: 5 step: 700 loss: 0.6931601762771606\n",
      "epoch: 5 step: 701 loss: 0.6931601762771606\n",
      "epoch: 5 step: 702 loss: 0.6931601762771606\n",
      "epoch: 5 step: 703 loss: 0.6931601166725159\n",
      "epoch: 5 step: 704 loss: 0.6931601762771606\n",
      "epoch: 5 step: 705 loss: 0.6931601762771606\n",
      "epoch: 5 step: 706 loss: 0.6931600570678711\n",
      "epoch: 5 step: 707 loss: 0.6931600570678711\n",
      "epoch: 5 step: 708 loss: 0.6931600570678711\n",
      "epoch: 5 step: 709 loss: 0.6931600570678711\n",
      "epoch: 5 step: 710 loss: 0.6931600570678711\n",
      "epoch: 5 step: 711 loss: 0.6931600570678711\n",
      "epoch: 5 step: 712 loss: 0.6931600570678711\n",
      "epoch: 5 step: 713 loss: 0.6931600570678711\n",
      "epoch: 5 step: 714 loss: 0.6931600570678711\n",
      "epoch: 5 step: 715 loss: 0.6931600570678711\n",
      "epoch: 5 step: 716 loss: 0.6931600570678711\n",
      "epoch: 5 step: 717 loss: 0.6931600570678711\n",
      "epoch: 5 step: 718 loss: 0.6931599974632263\n",
      "epoch: 5 step: 719 loss: 0.6931599974632263\n",
      "epoch: 5 step: 720 loss: 0.6931599974632263\n",
      "epoch: 5 step: 721 loss: 0.6931599974632263\n",
      "epoch: 5 step: 722 loss: 0.6931599378585815\n",
      "epoch: 5 step: 723 loss: 0.6931600570678711\n",
      "epoch: 5 step: 724 loss: 0.6931599378585815\n",
      "epoch: 5 step: 725 loss: 0.6931599378585815\n",
      "epoch: 5 step: 726 loss: 0.6931599378585815\n",
      "epoch: 5 step: 727 loss: 0.6931599378585815\n",
      "epoch: 5 step: 728 loss: 0.6931599378585815\n",
      "epoch: 5 step: 729 loss: 0.6931599378585815\n",
      "epoch: 5 step: 730 loss: 0.6931599378585815\n",
      "epoch: 5 step: 731 loss: 0.6931599378585815\n",
      "epoch: 5 step: 732 loss: 0.6931598782539368\n",
      "epoch: 5 step: 733 loss: 0.6931599378585815\n",
      "epoch: 5 step: 734 loss: 0.6931598782539368\n",
      "epoch: 5 step: 735 loss: 0.6931598782539368\n",
      "epoch: 5 step: 736 loss: 0.693159818649292\n",
      "epoch: 5 step: 737 loss: 0.693159818649292\n",
      "epoch: 5 step: 738 loss: 0.693159818649292\n",
      "epoch: 5 step: 739 loss: 0.693159818649292\n",
      "epoch: 5 step: 740 loss: 0.693159818649292\n",
      "epoch: 5 step: 741 loss: 0.693159818649292\n",
      "epoch: 5 step: 742 loss: 0.693159818649292\n",
      "epoch: 5 step: 743 loss: 0.693159818649292\n",
      "epoch: 5 step: 744 loss: 0.693159818649292\n",
      "epoch: 5 step: 745 loss: 0.693159818649292\n",
      "epoch: 5 step: 746 loss: 0.693159818649292\n",
      "epoch: 5 step: 747 loss: 0.6931597590446472\n",
      "epoch: 5 step: 748 loss: 0.6931596994400024\n",
      "epoch: 5 step: 749 loss: 0.693159818649292\n",
      "epoch: 5 step: 750 loss: 0.6931597590446472\n",
      "epoch: 5 step: 751 loss: 0.6931596994400024\n",
      "epoch: 5 step: 752 loss: 0.6931597590446472\n",
      "epoch: 5 step: 753 loss: 0.6931596994400024\n",
      "epoch: 5 step: 754 loss: 0.6931596994400024\n",
      "epoch: 5 step: 755 loss: 0.6931596994400024\n",
      "epoch: 5 step: 756 loss: 0.6931596994400024\n",
      "epoch: 5 step: 757 loss: 0.6931596398353577\n",
      "epoch: 5 step: 758 loss: 0.6931596994400024\n",
      "epoch: 5 step: 759 loss: 0.6931596398353577\n",
      "epoch: 5 step: 760 loss: 0.6931595802307129\n",
      "epoch: 5 step: 761 loss: 0.6931596398353577\n",
      "epoch: 5 step: 762 loss: 0.6931596994400024\n",
      "epoch: 5 step: 763 loss: 0.6931596994400024\n",
      "epoch: 5 step: 764 loss: 0.6931596398353577\n",
      "epoch: 5 step: 765 loss: 0.6931595802307129\n",
      "epoch: 5 step: 766 loss: 0.6931596398353577\n",
      "epoch: 5 step: 767 loss: 0.6931595802307129\n",
      "epoch: 5 step: 768 loss: 0.6931595802307129\n",
      "epoch: 5 step: 769 loss: 0.6931595802307129\n",
      "epoch: 5 step: 770 loss: 0.6931596398353577\n",
      "epoch: 5 step: 771 loss: 0.6931595802307129\n",
      "epoch: 5 step: 772 loss: 0.6931595802307129\n",
      "epoch: 5 step: 773 loss: 0.6931595206260681\n",
      "epoch: 5 step: 774 loss: 0.6931595802307129\n",
      "epoch: 5 step: 775 loss: 0.6931595802307129\n",
      "epoch: 5 step: 776 loss: 0.6931595206260681\n",
      "epoch: 5 step: 777 loss: 0.6931595802307129\n",
      "epoch: 5 step: 778 loss: 0.6931595206260681\n",
      "epoch: 5 step: 779 loss: 0.6931594610214233\n",
      "epoch: 5 step: 780 loss: 0.6931595206260681\n",
      "epoch: 5 step: 781 loss: 0.6931594610214233\n",
      "epoch: 6 step: 1 loss: 0.6931595206260681\n",
      "epoch: 6 step: 2 loss: 0.6931594610214233\n",
      "epoch: 6 step: 3 loss: 0.6931594610214233\n",
      "epoch: 6 step: 4 loss: 0.6931594610214233\n",
      "epoch: 6 step: 5 loss: 0.6931594610214233\n",
      "epoch: 6 step: 6 loss: 0.6931594610214233\n",
      "epoch: 6 step: 7 loss: 0.6931594610214233\n",
      "epoch: 6 step: 8 loss: 0.6931594014167786\n",
      "epoch: 6 step: 9 loss: 0.6931594610214233\n",
      "epoch: 6 step: 10 loss: 0.6931594014167786\n",
      "epoch: 6 step: 11 loss: 0.6931594610214233\n",
      "epoch: 6 step: 12 loss: 0.6931594014167786\n",
      "epoch: 6 step: 13 loss: 0.6931593418121338\n",
      "epoch: 6 step: 14 loss: 0.6931594014167786\n",
      "epoch: 6 step: 15 loss: 0.6931593418121338\n",
      "epoch: 6 step: 16 loss: 0.6931593418121338\n",
      "epoch: 6 step: 17 loss: 0.6931593418121338\n",
      "epoch: 6 step: 18 loss: 0.6931593418121338\n",
      "epoch: 6 step: 19 loss: 0.6931593418121338\n",
      "epoch: 6 step: 20 loss: 0.6931593418121338\n",
      "epoch: 6 step: 21 loss: 0.6931593418121338\n",
      "epoch: 6 step: 22 loss: 0.6931593418121338\n",
      "epoch: 6 step: 23 loss: 0.693159282207489\n",
      "epoch: 6 step: 24 loss: 0.6931593418121338\n",
      "epoch: 6 step: 25 loss: 0.693159282207489\n",
      "epoch: 6 step: 26 loss: 0.6931593418121338\n",
      "epoch: 6 step: 27 loss: 0.6931592226028442\n",
      "epoch: 6 step: 28 loss: 0.6931592226028442\n",
      "epoch: 6 step: 29 loss: 0.693159282207489\n",
      "epoch: 6 step: 30 loss: 0.6931592226028442\n",
      "epoch: 6 step: 31 loss: 0.6931592226028442\n",
      "epoch: 6 step: 32 loss: 0.6931592226028442\n",
      "epoch: 6 step: 33 loss: 0.6931592226028442\n",
      "epoch: 6 step: 34 loss: 0.6931592226028442\n",
      "epoch: 6 step: 35 loss: 0.6931592226028442\n",
      "epoch: 6 step: 36 loss: 0.6931592226028442\n",
      "epoch: 6 step: 37 loss: 0.6931592226028442\n",
      "epoch: 6 step: 38 loss: 0.6931592226028442\n",
      "epoch: 6 step: 39 loss: 0.6931591629981995\n",
      "epoch: 6 step: 40 loss: 0.6931591629981995\n",
      "epoch: 6 step: 41 loss: 0.6931592226028442\n",
      "epoch: 6 step: 42 loss: 0.6931591033935547\n",
      "epoch: 6 step: 43 loss: 0.6931591033935547\n",
      "epoch: 6 step: 44 loss: 0.6931591033935547\n",
      "epoch: 6 step: 45 loss: 0.6931591033935547\n",
      "epoch: 6 step: 46 loss: 0.6931591033935547\n",
      "epoch: 6 step: 47 loss: 0.6931591033935547\n",
      "epoch: 6 step: 48 loss: 0.6931591033935547\n",
      "epoch: 6 step: 49 loss: 0.6931591033935547\n",
      "epoch: 6 step: 50 loss: 0.6931591033935547\n",
      "epoch: 6 step: 51 loss: 0.6931591033935547\n",
      "epoch: 6 step: 52 loss: 0.6931591033935547\n",
      "epoch: 6 step: 53 loss: 0.6931591033935547\n",
      "epoch: 6 step: 54 loss: 0.6931591033935547\n",
      "epoch: 6 step: 55 loss: 0.6931590437889099\n",
      "epoch: 6 step: 56 loss: 0.6931590437889099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 57 loss: 0.6931591033935547\n",
      "epoch: 6 step: 58 loss: 0.6931591033935547\n",
      "epoch: 6 step: 59 loss: 0.6931589841842651\n",
      "epoch: 6 step: 60 loss: 0.6931589841842651\n",
      "epoch: 6 step: 61 loss: 0.6931590437889099\n",
      "epoch: 6 step: 62 loss: 0.6931589841842651\n",
      "epoch: 6 step: 63 loss: 0.6931589841842651\n",
      "epoch: 6 step: 64 loss: 0.6931589841842651\n",
      "epoch: 6 step: 65 loss: 0.6931589841842651\n",
      "epoch: 6 step: 66 loss: 0.6931589245796204\n",
      "epoch: 6 step: 67 loss: 0.6931589841842651\n",
      "epoch: 6 step: 68 loss: 0.6931589841842651\n",
      "epoch: 6 step: 69 loss: 0.6931589841842651\n",
      "epoch: 6 step: 70 loss: 0.6931589841842651\n",
      "epoch: 6 step: 71 loss: 0.6931589841842651\n",
      "epoch: 6 step: 72 loss: 0.6931589245796204\n",
      "epoch: 6 step: 73 loss: 0.6931589841842651\n",
      "epoch: 6 step: 74 loss: 0.6931589245796204\n",
      "epoch: 6 step: 75 loss: 0.6931589245796204\n",
      "epoch: 6 step: 76 loss: 0.6931588649749756\n",
      "epoch: 6 step: 77 loss: 0.6931588649749756\n",
      "epoch: 6 step: 78 loss: 0.6931588649749756\n",
      "epoch: 6 step: 79 loss: 0.6931588649749756\n",
      "epoch: 6 step: 80 loss: 0.6931588649749756\n",
      "epoch: 6 step: 81 loss: 0.6931588649749756\n",
      "epoch: 6 step: 82 loss: 0.6931588649749756\n",
      "epoch: 6 step: 83 loss: 0.6931588649749756\n",
      "epoch: 6 step: 84 loss: 0.6931588649749756\n",
      "epoch: 6 step: 85 loss: 0.6931588053703308\n",
      "epoch: 6 step: 86 loss: 0.6931588053703308\n",
      "epoch: 6 step: 87 loss: 0.6931588649749756\n",
      "epoch: 6 step: 88 loss: 0.693158745765686\n",
      "epoch: 6 step: 89 loss: 0.693158745765686\n",
      "epoch: 6 step: 90 loss: 0.693158745765686\n",
      "epoch: 6 step: 91 loss: 0.6931588053703308\n",
      "epoch: 6 step: 92 loss: 0.693158745765686\n",
      "epoch: 6 step: 93 loss: 0.693158745765686\n",
      "epoch: 6 step: 94 loss: 0.6931588053703308\n",
      "epoch: 6 step: 95 loss: 0.693158745765686\n",
      "epoch: 6 step: 96 loss: 0.693158745765686\n",
      "epoch: 6 step: 97 loss: 0.693158745765686\n",
      "epoch: 6 step: 98 loss: 0.693158745765686\n",
      "epoch: 6 step: 99 loss: 0.6931586861610413\n",
      "epoch: 6 step: 100 loss: 0.693158745765686\n",
      "epoch: 6 step: 101 loss: 0.693158745765686\n",
      "epoch: 6 step: 102 loss: 0.693158745765686\n",
      "epoch: 6 step: 103 loss: 0.6931586861610413\n",
      "epoch: 6 step: 104 loss: 0.6931586861610413\n",
      "epoch: 6 step: 105 loss: 0.6931586265563965\n",
      "epoch: 6 step: 106 loss: 0.6931586265563965\n",
      "epoch: 6 step: 107 loss: 0.6931586265563965\n",
      "epoch: 6 step: 108 loss: 0.6931586265563965\n",
      "epoch: 6 step: 109 loss: 0.6931586265563965\n",
      "epoch: 6 step: 110 loss: 0.6931586861610413\n",
      "epoch: 6 step: 111 loss: 0.6931586265563965\n",
      "epoch: 6 step: 112 loss: 0.6931586265563965\n",
      "epoch: 6 step: 113 loss: 0.6931586265563965\n",
      "epoch: 6 step: 114 loss: 0.6931586265563965\n",
      "epoch: 6 step: 115 loss: 0.6931585669517517\n",
      "epoch: 6 step: 116 loss: 0.6931586265563965\n",
      "epoch: 6 step: 117 loss: 0.6931586265563965\n",
      "epoch: 6 step: 118 loss: 0.6931585073471069\n",
      "epoch: 6 step: 119 loss: 0.6931585669517517\n",
      "epoch: 6 step: 120 loss: 0.6931585669517517\n",
      "epoch: 6 step: 121 loss: 0.6931585669517517\n",
      "epoch: 6 step: 122 loss: 0.6931585669517517\n",
      "epoch: 6 step: 123 loss: 0.6931585073471069\n",
      "epoch: 6 step: 124 loss: 0.6931585073471069\n",
      "epoch: 6 step: 125 loss: 0.6931585073471069\n",
      "epoch: 6 step: 126 loss: 0.6931585073471069\n",
      "epoch: 6 step: 127 loss: 0.6931585073471069\n",
      "epoch: 6 step: 128 loss: 0.6931585073471069\n",
      "epoch: 6 step: 129 loss: 0.6931585073471069\n",
      "epoch: 6 step: 130 loss: 0.6931585073471069\n",
      "epoch: 6 step: 131 loss: 0.6931585073471069\n",
      "epoch: 6 step: 132 loss: 0.6931585073471069\n",
      "epoch: 6 step: 133 loss: 0.6931585073471069\n",
      "epoch: 6 step: 134 loss: 0.6931584477424622\n",
      "epoch: 6 step: 135 loss: 0.6931585073471069\n",
      "epoch: 6 step: 136 loss: 0.6931585073471069\n",
      "epoch: 6 step: 137 loss: 0.6931584477424622\n",
      "epoch: 6 step: 138 loss: 0.6931584477424622\n",
      "epoch: 6 step: 139 loss: 0.6931584477424622\n",
      "epoch: 6 step: 140 loss: 0.6931584477424622\n",
      "epoch: 6 step: 141 loss: 0.6931583881378174\n",
      "epoch: 6 step: 142 loss: 0.6931583881378174\n",
      "epoch: 6 step: 143 loss: 0.6931583881378174\n",
      "epoch: 6 step: 144 loss: 0.6931583881378174\n",
      "epoch: 6 step: 145 loss: 0.6931583881378174\n",
      "epoch: 6 step: 146 loss: 0.6931583881378174\n",
      "epoch: 6 step: 147 loss: 0.6931583881378174\n",
      "epoch: 6 step: 148 loss: 0.6931583881378174\n",
      "epoch: 6 step: 149 loss: 0.6931583881378174\n",
      "epoch: 6 step: 150 loss: 0.6931583881378174\n",
      "epoch: 6 step: 151 loss: 0.6931583285331726\n",
      "epoch: 6 step: 152 loss: 0.6931583285331726\n",
      "epoch: 6 step: 153 loss: 0.6931583285331726\n",
      "epoch: 6 step: 154 loss: 0.6931582689285278\n",
      "epoch: 6 step: 155 loss: 0.6931583881378174\n",
      "epoch: 6 step: 156 loss: 0.6931583285331726\n",
      "epoch: 6 step: 157 loss: 0.6931582689285278\n",
      "epoch: 6 step: 158 loss: 0.6931582689285278\n",
      "epoch: 6 step: 159 loss: 0.6931582689285278\n",
      "epoch: 6 step: 160 loss: 0.6931582689285278\n",
      "epoch: 6 step: 161 loss: 0.6931582689285278\n",
      "epoch: 6 step: 162 loss: 0.6931582689285278\n",
      "epoch: 6 step: 163 loss: 0.6931582689285278\n",
      "epoch: 6 step: 164 loss: 0.6931582689285278\n",
      "epoch: 6 step: 165 loss: 0.6931582689285278\n",
      "epoch: 6 step: 166 loss: 0.6931582093238831\n",
      "epoch: 6 step: 167 loss: 0.6931582689285278\n",
      "epoch: 6 step: 168 loss: 0.6931582689285278\n",
      "epoch: 6 step: 169 loss: 0.6931582093238831\n",
      "epoch: 6 step: 170 loss: 0.6931582093238831\n",
      "epoch: 6 step: 171 loss: 0.6931581497192383\n",
      "epoch: 6 step: 172 loss: 0.6931582689285278\n",
      "epoch: 6 step: 173 loss: 0.6931582093238831\n",
      "epoch: 6 step: 174 loss: 0.6931581497192383\n",
      "epoch: 6 step: 175 loss: 0.6931581497192383\n",
      "epoch: 6 step: 176 loss: 0.6931581497192383\n",
      "epoch: 6 step: 177 loss: 0.6931581497192383\n",
      "epoch: 6 step: 178 loss: 0.6931581497192383\n",
      "epoch: 6 step: 179 loss: 0.6931581497192383\n",
      "epoch: 6 step: 180 loss: 0.6931581497192383\n",
      "epoch: 6 step: 181 loss: 0.6931581497192383\n",
      "epoch: 6 step: 182 loss: 0.6931581497192383\n",
      "epoch: 6 step: 183 loss: 0.6931581497192383\n",
      "epoch: 6 step: 184 loss: 0.6931581497192383\n",
      "epoch: 6 step: 185 loss: 0.6931581497192383\n",
      "epoch: 6 step: 186 loss: 0.6931581497192383\n",
      "epoch: 6 step: 187 loss: 0.6931580901145935\n",
      "epoch: 6 step: 188 loss: 0.6931580901145935\n",
      "epoch: 6 step: 189 loss: 0.6931581497192383\n",
      "epoch: 6 step: 190 loss: 0.6931580901145935\n",
      "epoch: 6 step: 191 loss: 0.6931580305099487\n",
      "epoch: 6 step: 192 loss: 0.6931580901145935\n",
      "epoch: 6 step: 193 loss: 0.6931580305099487\n",
      "epoch: 6 step: 194 loss: 0.6931580305099487\n",
      "epoch: 6 step: 195 loss: 0.6931580305099487\n",
      "epoch: 6 step: 196 loss: 0.6931580305099487\n",
      "epoch: 6 step: 197 loss: 0.6931580305099487\n",
      "epoch: 6 step: 198 loss: 0.6931580305099487\n",
      "epoch: 6 step: 199 loss: 0.6931580305099487\n",
      "epoch: 6 step: 200 loss: 0.6931580305099487\n",
      "epoch: 6 step: 201 loss: 0.6931580305099487\n",
      "epoch: 6 step: 202 loss: 0.693157970905304\n",
      "epoch: 6 step: 203 loss: 0.693157970905304\n",
      "epoch: 6 step: 204 loss: 0.6931580305099487\n",
      "epoch: 6 step: 205 loss: 0.693157970905304\n",
      "epoch: 6 step: 206 loss: 0.693157970905304\n",
      "epoch: 6 step: 207 loss: 0.6931579113006592\n",
      "epoch: 6 step: 208 loss: 0.693157970905304\n",
      "epoch: 6 step: 209 loss: 0.6931579113006592\n",
      "epoch: 6 step: 210 loss: 0.6931579113006592\n",
      "epoch: 6 step: 211 loss: 0.6931579113006592\n",
      "epoch: 6 step: 212 loss: 0.6931579113006592\n",
      "epoch: 6 step: 213 loss: 0.6931579113006592\n",
      "epoch: 6 step: 214 loss: 0.6931579113006592\n",
      "epoch: 6 step: 215 loss: 0.6931579113006592\n",
      "epoch: 6 step: 216 loss: 0.6931579113006592\n",
      "epoch: 6 step: 217 loss: 0.6931579113006592\n",
      "epoch: 6 step: 218 loss: 0.6931579113006592\n",
      "epoch: 6 step: 219 loss: 0.6931579113006592\n",
      "epoch: 6 step: 220 loss: 0.6931578516960144\n",
      "epoch: 6 step: 221 loss: 0.6931579113006592\n",
      "epoch: 6 step: 222 loss: 0.6931578516960144\n",
      "epoch: 6 step: 223 loss: 0.6931577920913696\n",
      "epoch: 6 step: 224 loss: 0.6931578516960144\n",
      "epoch: 6 step: 225 loss: 0.6931577920913696\n",
      "epoch: 6 step: 226 loss: 0.6931577920913696\n",
      "epoch: 6 step: 227 loss: 0.6931577920913696\n",
      "epoch: 6 step: 228 loss: 0.6931577920913696\n",
      "epoch: 6 step: 229 loss: 0.6931577920913696\n",
      "epoch: 6 step: 230 loss: 0.6931577920913696\n",
      "epoch: 6 step: 231 loss: 0.6931577920913696\n",
      "epoch: 6 step: 232 loss: 0.6931577920913696\n",
      "epoch: 6 step: 233 loss: 0.6931577920913696\n",
      "epoch: 6 step: 234 loss: 0.6931577920913696\n",
      "epoch: 6 step: 235 loss: 0.6931577920913696\n",
      "epoch: 6 step: 236 loss: 0.6931577920913696\n",
      "epoch: 6 step: 237 loss: 0.6931576728820801\n",
      "epoch: 6 step: 238 loss: 0.6931577920913696\n",
      "epoch: 6 step: 239 loss: 0.6931577920913696\n",
      "epoch: 6 step: 240 loss: 0.6931577920913696\n",
      "epoch: 6 step: 241 loss: 0.6931577324867249\n",
      "epoch: 6 step: 242 loss: 0.6931577324867249\n",
      "epoch: 6 step: 243 loss: 0.6931576728820801\n",
      "epoch: 6 step: 244 loss: 0.6931576728820801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 245 loss: 0.6931576728820801\n",
      "epoch: 6 step: 246 loss: 0.6931576728820801\n",
      "epoch: 6 step: 247 loss: 0.6931576728820801\n",
      "epoch: 6 step: 248 loss: 0.6931576728820801\n",
      "epoch: 6 step: 249 loss: 0.6931576728820801\n",
      "epoch: 6 step: 250 loss: 0.6931576728820801\n",
      "epoch: 6 step: 251 loss: 0.6931576728820801\n",
      "epoch: 6 step: 252 loss: 0.6931576728820801\n",
      "epoch: 6 step: 253 loss: 0.6931576728820801\n",
      "epoch: 6 step: 254 loss: 0.6931576728820801\n",
      "epoch: 6 step: 255 loss: 0.6931576728820801\n",
      "epoch: 6 step: 256 loss: 0.6931576728820801\n",
      "epoch: 6 step: 257 loss: 0.6931576728820801\n",
      "epoch: 6 step: 258 loss: 0.6931576132774353\n",
      "epoch: 6 step: 259 loss: 0.6931576132774353\n",
      "epoch: 6 step: 260 loss: 0.6931575536727905\n",
      "epoch: 6 step: 261 loss: 0.6931576132774353\n",
      "epoch: 6 step: 262 loss: 0.6931575536727905\n",
      "epoch: 6 step: 263 loss: 0.6931575536727905\n",
      "epoch: 6 step: 264 loss: 0.6931575536727905\n",
      "epoch: 6 step: 265 loss: 0.6931575536727905\n",
      "epoch: 6 step: 266 loss: 0.6931575536727905\n",
      "epoch: 6 step: 267 loss: 0.6931575536727905\n",
      "epoch: 6 step: 268 loss: 0.6931575536727905\n",
      "epoch: 6 step: 269 loss: 0.6931575536727905\n",
      "epoch: 6 step: 270 loss: 0.6931575536727905\n",
      "epoch: 6 step: 271 loss: 0.6931575536727905\n",
      "epoch: 6 step: 272 loss: 0.6931575536727905\n",
      "epoch: 6 step: 273 loss: 0.6931575536727905\n",
      "epoch: 6 step: 274 loss: 0.6931574940681458\n",
      "epoch: 6 step: 275 loss: 0.6931575536727905\n",
      "epoch: 6 step: 276 loss: 0.6931575536727905\n",
      "epoch: 6 step: 277 loss: 0.6931574940681458\n",
      "epoch: 6 step: 278 loss: 0.693157434463501\n",
      "epoch: 6 step: 279 loss: 0.693157434463501\n",
      "epoch: 6 step: 280 loss: 0.693157434463501\n",
      "epoch: 6 step: 281 loss: 0.693157434463501\n",
      "epoch: 6 step: 282 loss: 0.693157434463501\n",
      "epoch: 6 step: 283 loss: 0.693157434463501\n",
      "epoch: 6 step: 284 loss: 0.693157434463501\n",
      "epoch: 6 step: 285 loss: 0.693157434463501\n",
      "epoch: 6 step: 286 loss: 0.693157434463501\n",
      "epoch: 6 step: 287 loss: 0.693157434463501\n",
      "epoch: 6 step: 288 loss: 0.693157434463501\n",
      "epoch: 6 step: 289 loss: 0.693157434463501\n",
      "epoch: 6 step: 290 loss: 0.693157434463501\n",
      "epoch: 6 step: 291 loss: 0.693157434463501\n",
      "epoch: 6 step: 292 loss: 0.693157434463501\n",
      "epoch: 6 step: 293 loss: 0.6931573748588562\n",
      "epoch: 6 step: 294 loss: 0.6931573152542114\n",
      "epoch: 6 step: 295 loss: 0.6931573152542114\n",
      "epoch: 6 step: 296 loss: 0.6931573152542114\n",
      "epoch: 6 step: 297 loss: 0.6931573748588562\n",
      "epoch: 6 step: 298 loss: 0.6931573152542114\n",
      "epoch: 6 step: 299 loss: 0.6931573152542114\n",
      "epoch: 6 step: 300 loss: 0.6931573152542114\n",
      "epoch: 6 step: 301 loss: 0.6931573152542114\n",
      "epoch: 6 step: 302 loss: 0.6931573152542114\n",
      "epoch: 6 step: 303 loss: 0.6931573152542114\n",
      "epoch: 6 step: 304 loss: 0.6931573152542114\n",
      "epoch: 6 step: 305 loss: 0.6931573152542114\n",
      "epoch: 6 step: 306 loss: 0.6931573152542114\n",
      "epoch: 6 step: 307 loss: 0.6931572556495667\n",
      "epoch: 6 step: 308 loss: 0.6931573152542114\n",
      "epoch: 6 step: 309 loss: 0.6931573152542114\n",
      "epoch: 6 step: 310 loss: 0.6931573152542114\n",
      "epoch: 6 step: 311 loss: 0.6931573152542114\n",
      "epoch: 6 step: 312 loss: 0.6931573152542114\n",
      "epoch: 6 step: 313 loss: 0.6931571960449219\n",
      "epoch: 6 step: 314 loss: 0.6931572556495667\n",
      "epoch: 6 step: 315 loss: 0.6931572556495667\n",
      "epoch: 6 step: 316 loss: 0.6931572556495667\n",
      "epoch: 6 step: 317 loss: 0.6931571960449219\n",
      "epoch: 6 step: 318 loss: 0.6931572556495667\n",
      "epoch: 6 step: 319 loss: 0.6931571960449219\n",
      "epoch: 6 step: 320 loss: 0.6931571960449219\n",
      "epoch: 6 step: 321 loss: 0.6931571960449219\n",
      "epoch: 6 step: 322 loss: 0.6931571960449219\n",
      "epoch: 6 step: 323 loss: 0.6931571960449219\n",
      "epoch: 6 step: 324 loss: 0.6931571960449219\n",
      "epoch: 6 step: 325 loss: 0.6931571960449219\n",
      "epoch: 6 step: 326 loss: 0.6931571364402771\n",
      "epoch: 6 step: 327 loss: 0.6931571960449219\n",
      "epoch: 6 step: 328 loss: 0.6931571960449219\n",
      "epoch: 6 step: 329 loss: 0.6931571960449219\n",
      "epoch: 6 step: 330 loss: 0.6931570768356323\n",
      "epoch: 6 step: 331 loss: 0.6931571960449219\n",
      "epoch: 6 step: 332 loss: 0.6931570768356323\n",
      "epoch: 6 step: 333 loss: 0.6931570768356323\n",
      "epoch: 6 step: 334 loss: 0.6931570768356323\n",
      "epoch: 6 step: 335 loss: 0.6931570768356323\n",
      "epoch: 6 step: 336 loss: 0.6931570768356323\n",
      "epoch: 6 step: 337 loss: 0.6931570768356323\n",
      "epoch: 6 step: 338 loss: 0.6931570768356323\n",
      "epoch: 6 step: 339 loss: 0.6931570768356323\n",
      "epoch: 6 step: 340 loss: 0.6931570768356323\n",
      "epoch: 6 step: 341 loss: 0.6931570768356323\n",
      "epoch: 6 step: 342 loss: 0.6931570768356323\n",
      "epoch: 6 step: 343 loss: 0.6931570768356323\n",
      "epoch: 6 step: 344 loss: 0.6931570768356323\n",
      "epoch: 6 step: 345 loss: 0.6931570172309875\n",
      "epoch: 6 step: 346 loss: 0.6931570768356323\n",
      "epoch: 6 step: 347 loss: 0.6931570768356323\n",
      "epoch: 6 step: 348 loss: 0.6931570768356323\n",
      "epoch: 6 step: 349 loss: 0.6931570172309875\n",
      "epoch: 6 step: 350 loss: 0.6931570172309875\n",
      "epoch: 6 step: 351 loss: 0.6931570172309875\n",
      "epoch: 6 step: 352 loss: 0.6931570172309875\n",
      "epoch: 6 step: 353 loss: 0.6931569576263428\n",
      "epoch: 6 step: 354 loss: 0.6931570172309875\n",
      "epoch: 6 step: 355 loss: 0.6931569576263428\n",
      "epoch: 6 step: 356 loss: 0.6931569576263428\n",
      "epoch: 6 step: 357 loss: 0.6931569576263428\n",
      "epoch: 6 step: 358 loss: 0.6931569576263428\n",
      "epoch: 6 step: 359 loss: 0.6931569576263428\n",
      "epoch: 6 step: 360 loss: 0.6931569576263428\n",
      "epoch: 6 step: 361 loss: 0.6931569576263428\n",
      "epoch: 6 step: 362 loss: 0.6931569576263428\n",
      "epoch: 6 step: 363 loss: 0.6931569576263428\n",
      "epoch: 6 step: 364 loss: 0.6931569576263428\n",
      "epoch: 6 step: 365 loss: 0.6931569576263428\n",
      "epoch: 6 step: 366 loss: 0.6931569576263428\n",
      "epoch: 6 step: 367 loss: 0.693156898021698\n",
      "epoch: 6 step: 368 loss: 0.693156898021698\n",
      "epoch: 6 step: 369 loss: 0.693156898021698\n",
      "epoch: 6 step: 370 loss: 0.6931569576263428\n",
      "epoch: 6 step: 371 loss: 0.6931569576263428\n",
      "epoch: 6 step: 372 loss: 0.6931568384170532\n",
      "epoch: 6 step: 373 loss: 0.693156898021698\n",
      "epoch: 6 step: 374 loss: 0.6931568384170532\n",
      "epoch: 6 step: 375 loss: 0.6931568384170532\n",
      "epoch: 6 step: 376 loss: 0.6931568384170532\n",
      "epoch: 6 step: 377 loss: 0.6931568384170532\n",
      "epoch: 6 step: 378 loss: 0.6931568384170532\n",
      "epoch: 6 step: 379 loss: 0.6931568384170532\n",
      "epoch: 6 step: 380 loss: 0.6931568384170532\n",
      "epoch: 6 step: 381 loss: 0.6931568384170532\n",
      "epoch: 6 step: 382 loss: 0.6931568384170532\n",
      "epoch: 6 step: 383 loss: 0.6931568384170532\n",
      "epoch: 6 step: 384 loss: 0.6931568384170532\n",
      "epoch: 6 step: 385 loss: 0.6931568384170532\n",
      "epoch: 6 step: 386 loss: 0.6931568384170532\n",
      "epoch: 6 step: 387 loss: 0.6931568384170532\n",
      "epoch: 6 step: 388 loss: 0.6931567788124084\n",
      "epoch: 6 step: 389 loss: 0.6931567788124084\n",
      "epoch: 6 step: 390 loss: 0.6931567788124084\n",
      "epoch: 6 step: 391 loss: 0.6931567788124084\n",
      "epoch: 6 step: 392 loss: 0.6931567788124084\n",
      "epoch: 6 step: 393 loss: 0.6931567788124084\n",
      "epoch: 6 step: 394 loss: 0.6931567192077637\n",
      "epoch: 6 step: 395 loss: 0.6931567192077637\n",
      "epoch: 6 step: 396 loss: 0.6931567192077637\n",
      "epoch: 6 step: 397 loss: 0.6931567192077637\n",
      "epoch: 6 step: 398 loss: 0.6931567192077637\n",
      "epoch: 6 step: 399 loss: 0.6931567192077637\n",
      "epoch: 6 step: 400 loss: 0.6931566596031189\n",
      "epoch: 6 step: 401 loss: 0.6931567192077637\n",
      "epoch: 6 step: 402 loss: 0.6931567192077637\n",
      "epoch: 6 step: 403 loss: 0.6931567192077637\n",
      "epoch: 6 step: 404 loss: 0.6931567192077637\n",
      "epoch: 6 step: 405 loss: 0.6931567192077637\n",
      "epoch: 6 step: 406 loss: 0.6931567192077637\n",
      "epoch: 6 step: 407 loss: 0.6931567192077637\n",
      "epoch: 6 step: 408 loss: 0.6931565999984741\n",
      "epoch: 6 step: 409 loss: 0.6931566596031189\n",
      "epoch: 6 step: 410 loss: 0.6931565999984741\n",
      "epoch: 6 step: 411 loss: 0.6931566596031189\n",
      "epoch: 6 step: 412 loss: 0.6931565999984741\n",
      "epoch: 6 step: 413 loss: 0.6931566596031189\n",
      "epoch: 6 step: 414 loss: 0.6931565999984741\n",
      "epoch: 6 step: 415 loss: 0.6931565999984741\n",
      "epoch: 6 step: 416 loss: 0.6931565999984741\n",
      "epoch: 6 step: 417 loss: 0.6931566596031189\n",
      "epoch: 6 step: 418 loss: 0.6931565999984741\n",
      "epoch: 6 step: 419 loss: 0.6931565999984741\n",
      "epoch: 6 step: 420 loss: 0.6931565999984741\n",
      "epoch: 6 step: 421 loss: 0.6931565999984741\n",
      "epoch: 6 step: 422 loss: 0.6931565999984741\n",
      "epoch: 6 step: 423 loss: 0.6931565999984741\n",
      "epoch: 6 step: 424 loss: 0.6931565999984741\n",
      "epoch: 6 step: 425 loss: 0.6931565999984741\n",
      "epoch: 6 step: 426 loss: 0.6931565999984741\n",
      "epoch: 6 step: 427 loss: 0.6931565403938293\n",
      "epoch: 6 step: 428 loss: 0.6931565999984741\n",
      "epoch: 6 step: 429 loss: 0.6931565403938293\n",
      "epoch: 6 step: 430 loss: 0.6931565999984741\n",
      "epoch: 6 step: 431 loss: 0.6931565403938293\n",
      "epoch: 6 step: 432 loss: 0.6931565403938293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 433 loss: 0.6931564807891846\n",
      "epoch: 6 step: 434 loss: 0.6931564807891846\n",
      "epoch: 6 step: 435 loss: 0.6931564807891846\n",
      "epoch: 6 step: 436 loss: 0.6931564807891846\n",
      "epoch: 6 step: 437 loss: 0.6931564807891846\n",
      "epoch: 6 step: 438 loss: 0.6931564807891846\n",
      "epoch: 6 step: 439 loss: 0.6931564807891846\n",
      "epoch: 6 step: 440 loss: 0.6931564807891846\n",
      "epoch: 6 step: 441 loss: 0.6931564807891846\n",
      "epoch: 6 step: 442 loss: 0.6931564807891846\n",
      "epoch: 6 step: 443 loss: 0.6931564807891846\n",
      "epoch: 6 step: 444 loss: 0.6931564807891846\n",
      "epoch: 6 step: 445 loss: 0.6931564807891846\n",
      "epoch: 6 step: 446 loss: 0.6931564807891846\n",
      "epoch: 6 step: 447 loss: 0.6931564211845398\n",
      "epoch: 6 step: 448 loss: 0.6931564807891846\n",
      "epoch: 6 step: 449 loss: 0.693156361579895\n",
      "epoch: 6 step: 450 loss: 0.693156361579895\n",
      "epoch: 6 step: 451 loss: 0.693156361579895\n",
      "epoch: 6 step: 452 loss: 0.6931564211845398\n",
      "epoch: 6 step: 453 loss: 0.6931564211845398\n",
      "epoch: 6 step: 454 loss: 0.693156361579895\n",
      "epoch: 6 step: 455 loss: 0.693156361579895\n",
      "epoch: 6 step: 456 loss: 0.693156361579895\n",
      "epoch: 6 step: 457 loss: 0.693156361579895\n",
      "epoch: 6 step: 458 loss: 0.693156361579895\n",
      "epoch: 6 step: 459 loss: 0.693156361579895\n",
      "epoch: 6 step: 460 loss: 0.693156361579895\n",
      "epoch: 6 step: 461 loss: 0.693156361579895\n",
      "epoch: 6 step: 462 loss: 0.693156361579895\n",
      "epoch: 6 step: 463 loss: 0.693156361579895\n",
      "epoch: 6 step: 464 loss: 0.693156361579895\n",
      "epoch: 6 step: 465 loss: 0.693156361579895\n",
      "epoch: 6 step: 466 loss: 0.693156361579895\n",
      "epoch: 6 step: 467 loss: 0.693156361579895\n",
      "epoch: 6 step: 468 loss: 0.693156361579895\n",
      "epoch: 6 step: 469 loss: 0.693156361579895\n",
      "epoch: 6 step: 470 loss: 0.6931563019752502\n",
      "epoch: 6 step: 471 loss: 0.693156361579895\n",
      "epoch: 6 step: 472 loss: 0.6931563019752502\n",
      "epoch: 6 step: 473 loss: 0.6931562423706055\n",
      "epoch: 6 step: 474 loss: 0.6931563019752502\n",
      "epoch: 6 step: 475 loss: 0.6931562423706055\n",
      "epoch: 6 step: 476 loss: 0.6931562423706055\n",
      "epoch: 6 step: 477 loss: 0.6931562423706055\n",
      "epoch: 6 step: 478 loss: 0.6931562423706055\n",
      "epoch: 6 step: 479 loss: 0.6931562423706055\n",
      "epoch: 6 step: 480 loss: 0.6931562423706055\n",
      "epoch: 6 step: 481 loss: 0.6931562423706055\n",
      "epoch: 6 step: 482 loss: 0.6931562423706055\n",
      "epoch: 6 step: 483 loss: 0.6931562423706055\n",
      "epoch: 6 step: 484 loss: 0.6931562423706055\n",
      "epoch: 6 step: 485 loss: 0.6931562423706055\n",
      "epoch: 6 step: 486 loss: 0.6931562423706055\n",
      "epoch: 6 step: 487 loss: 0.6931562423706055\n",
      "epoch: 6 step: 488 loss: 0.6931562423706055\n",
      "epoch: 6 step: 489 loss: 0.6931562423706055\n",
      "epoch: 6 step: 490 loss: 0.6931562423706055\n",
      "epoch: 6 step: 491 loss: 0.6931562423706055\n",
      "epoch: 6 step: 492 loss: 0.6931561827659607\n",
      "epoch: 6 step: 493 loss: 0.6931562423706055\n",
      "epoch: 6 step: 494 loss: 0.6931562423706055\n",
      "epoch: 6 step: 495 loss: 0.6931561827659607\n",
      "epoch: 6 step: 496 loss: 0.6931561827659607\n",
      "epoch: 6 step: 497 loss: 0.6931561231613159\n",
      "epoch: 6 step: 498 loss: 0.6931561231613159\n",
      "epoch: 6 step: 499 loss: 0.6931561231613159\n",
      "epoch: 6 step: 500 loss: 0.6931561231613159\n",
      "epoch: 6 step: 501 loss: 0.6931561231613159\n",
      "epoch: 6 step: 502 loss: 0.6931561231613159\n",
      "epoch: 6 step: 503 loss: 0.6931561231613159\n",
      "epoch: 6 step: 504 loss: 0.6931561231613159\n",
      "epoch: 6 step: 505 loss: 0.6931561231613159\n",
      "epoch: 6 step: 506 loss: 0.6931561231613159\n",
      "epoch: 6 step: 507 loss: 0.6931561231613159\n",
      "epoch: 6 step: 508 loss: 0.6931561231613159\n",
      "epoch: 6 step: 509 loss: 0.6931561231613159\n",
      "epoch: 6 step: 510 loss: 0.6931561231613159\n",
      "epoch: 6 step: 511 loss: 0.6931561231613159\n",
      "epoch: 6 step: 512 loss: 0.6931560635566711\n",
      "epoch: 6 step: 513 loss: 0.6931560635566711\n",
      "epoch: 6 step: 514 loss: 0.6931561231613159\n",
      "epoch: 6 step: 515 loss: 0.6931560635566711\n",
      "epoch: 6 step: 516 loss: 0.6931560635566711\n",
      "epoch: 6 step: 517 loss: 0.6931560039520264\n",
      "epoch: 6 step: 518 loss: 0.6931560039520264\n",
      "epoch: 6 step: 519 loss: 0.6931560039520264\n",
      "epoch: 6 step: 520 loss: 0.6931560635566711\n",
      "epoch: 6 step: 521 loss: 0.6931560039520264\n",
      "epoch: 6 step: 522 loss: 0.6931560039520264\n",
      "epoch: 6 step: 523 loss: 0.6931560039520264\n",
      "epoch: 6 step: 524 loss: 0.6931560039520264\n",
      "epoch: 6 step: 525 loss: 0.6931560039520264\n",
      "epoch: 6 step: 526 loss: 0.6931560039520264\n",
      "epoch: 6 step: 527 loss: 0.6931560039520264\n",
      "epoch: 6 step: 528 loss: 0.6931560039520264\n",
      "epoch: 6 step: 529 loss: 0.6931560039520264\n",
      "epoch: 6 step: 530 loss: 0.6931560039520264\n",
      "epoch: 6 step: 531 loss: 0.6931560039520264\n",
      "epoch: 6 step: 532 loss: 0.6931560039520264\n",
      "epoch: 6 step: 533 loss: 0.6931559443473816\n",
      "epoch: 6 step: 534 loss: 0.6931560039520264\n",
      "epoch: 6 step: 535 loss: 0.6931559443473816\n",
      "epoch: 6 step: 536 loss: 0.6931560039520264\n",
      "epoch: 6 step: 537 loss: 0.6931560039520264\n",
      "epoch: 6 step: 538 loss: 0.6931559443473816\n",
      "epoch: 6 step: 539 loss: 0.6931559443473816\n",
      "epoch: 6 step: 540 loss: 0.6931558847427368\n",
      "epoch: 6 step: 541 loss: 0.6931559443473816\n",
      "epoch: 6 step: 542 loss: 0.6931558847427368\n",
      "epoch: 6 step: 543 loss: 0.6931558847427368\n",
      "epoch: 6 step: 544 loss: 0.6931558847427368\n",
      "epoch: 6 step: 545 loss: 0.6931558847427368\n",
      "epoch: 6 step: 546 loss: 0.6931558847427368\n",
      "epoch: 6 step: 547 loss: 0.6931558847427368\n",
      "epoch: 6 step: 548 loss: 0.6931558847427368\n",
      "epoch: 6 step: 549 loss: 0.6931558847427368\n",
      "epoch: 6 step: 550 loss: 0.6931558847427368\n",
      "epoch: 6 step: 551 loss: 0.6931558847427368\n",
      "epoch: 6 step: 552 loss: 0.6931558847427368\n",
      "epoch: 6 step: 553 loss: 0.6931558847427368\n",
      "epoch: 6 step: 554 loss: 0.6931558847427368\n",
      "epoch: 6 step: 555 loss: 0.6931558847427368\n",
      "epoch: 6 step: 556 loss: 0.6931558847427368\n",
      "epoch: 6 step: 557 loss: 0.693155825138092\n",
      "epoch: 6 step: 558 loss: 0.693155825138092\n",
      "epoch: 6 step: 559 loss: 0.6931558847427368\n",
      "epoch: 6 step: 560 loss: 0.693155825138092\n",
      "epoch: 6 step: 561 loss: 0.6931557655334473\n",
      "epoch: 6 step: 562 loss: 0.6931557655334473\n",
      "epoch: 6 step: 563 loss: 0.6931557655334473\n",
      "epoch: 6 step: 564 loss: 0.693155825138092\n",
      "epoch: 6 step: 565 loss: 0.6931557655334473\n",
      "epoch: 6 step: 566 loss: 0.6931557655334473\n",
      "epoch: 6 step: 567 loss: 0.6931557655334473\n",
      "epoch: 6 step: 568 loss: 0.6931557655334473\n",
      "epoch: 6 step: 569 loss: 0.6931557655334473\n",
      "epoch: 6 step: 570 loss: 0.693155825138092\n",
      "epoch: 6 step: 571 loss: 0.6931557655334473\n",
      "epoch: 6 step: 572 loss: 0.6931557655334473\n",
      "epoch: 6 step: 573 loss: 0.6931557655334473\n",
      "epoch: 6 step: 574 loss: 0.6931557655334473\n",
      "epoch: 6 step: 575 loss: 0.6931557655334473\n",
      "epoch: 6 step: 576 loss: 0.6931557655334473\n",
      "epoch: 6 step: 577 loss: 0.6931557059288025\n",
      "epoch: 6 step: 578 loss: 0.6931557655334473\n",
      "epoch: 6 step: 579 loss: 0.6931557655334473\n",
      "epoch: 6 step: 580 loss: 0.6931557655334473\n",
      "epoch: 6 step: 581 loss: 0.6931557059288025\n",
      "epoch: 6 step: 582 loss: 0.6931557059288025\n",
      "epoch: 6 step: 583 loss: 0.6931557655334473\n",
      "epoch: 6 step: 584 loss: 0.6931556463241577\n",
      "epoch: 6 step: 585 loss: 0.6931557059288025\n",
      "epoch: 6 step: 586 loss: 0.6931557059288025\n",
      "epoch: 6 step: 587 loss: 0.6931556463241577\n",
      "epoch: 6 step: 588 loss: 0.6931557059288025\n",
      "epoch: 6 step: 589 loss: 0.6931556463241577\n",
      "epoch: 6 step: 590 loss: 0.6931556463241577\n",
      "epoch: 6 step: 591 loss: 0.6931556463241577\n",
      "epoch: 6 step: 592 loss: 0.6931556463241577\n",
      "epoch: 6 step: 593 loss: 0.6931556463241577\n",
      "epoch: 6 step: 594 loss: 0.6931556463241577\n",
      "epoch: 6 step: 595 loss: 0.6931556463241577\n",
      "epoch: 6 step: 596 loss: 0.6931556463241577\n",
      "epoch: 6 step: 597 loss: 0.6931556463241577\n",
      "epoch: 6 step: 598 loss: 0.6931556463241577\n",
      "epoch: 6 step: 599 loss: 0.6931556463241577\n",
      "epoch: 6 step: 600 loss: 0.6931556463241577\n",
      "epoch: 6 step: 601 loss: 0.6931556463241577\n",
      "epoch: 6 step: 602 loss: 0.6931555867195129\n",
      "epoch: 6 step: 603 loss: 0.6931555867195129\n",
      "epoch: 6 step: 604 loss: 0.6931555271148682\n",
      "epoch: 6 step: 605 loss: 0.6931555867195129\n",
      "epoch: 6 step: 606 loss: 0.6931555271148682\n",
      "epoch: 6 step: 607 loss: 0.6931555271148682\n",
      "epoch: 6 step: 608 loss: 0.6931555271148682\n",
      "epoch: 6 step: 609 loss: 0.6931555271148682\n",
      "epoch: 6 step: 610 loss: 0.6931555271148682\n",
      "epoch: 6 step: 611 loss: 0.6931555271148682\n",
      "epoch: 6 step: 612 loss: 0.6931555271148682\n",
      "epoch: 6 step: 613 loss: 0.6931555271148682\n",
      "epoch: 6 step: 614 loss: 0.6931555271148682\n",
      "epoch: 6 step: 615 loss: 0.6931555271148682\n",
      "epoch: 6 step: 616 loss: 0.6931555867195129\n",
      "epoch: 6 step: 617 loss: 0.6931555271148682\n",
      "epoch: 6 step: 618 loss: 0.6931555271148682\n",
      "epoch: 6 step: 619 loss: 0.6931555271148682\n",
      "epoch: 6 step: 620 loss: 0.6931555271148682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 621 loss: 0.6931555271148682\n",
      "epoch: 6 step: 622 loss: 0.6931555271148682\n",
      "epoch: 6 step: 623 loss: 0.6931554675102234\n",
      "epoch: 6 step: 624 loss: 0.6931554675102234\n",
      "epoch: 6 step: 625 loss: 0.6931555271148682\n",
      "epoch: 6 step: 626 loss: 0.6931554675102234\n",
      "epoch: 6 step: 627 loss: 0.6931555271148682\n",
      "epoch: 6 step: 628 loss: 0.6931554079055786\n",
      "epoch: 6 step: 629 loss: 0.6931554079055786\n",
      "epoch: 6 step: 630 loss: 0.6931555271148682\n",
      "epoch: 6 step: 631 loss: 0.6931554675102234\n",
      "epoch: 6 step: 632 loss: 0.6931554079055786\n",
      "epoch: 6 step: 633 loss: 0.6931554675102234\n",
      "epoch: 6 step: 634 loss: 0.6931554079055786\n",
      "epoch: 6 step: 635 loss: 0.6931554079055786\n",
      "epoch: 6 step: 636 loss: 0.6931554079055786\n",
      "epoch: 6 step: 637 loss: 0.6931554079055786\n",
      "epoch: 6 step: 638 loss: 0.6931554079055786\n",
      "epoch: 6 step: 639 loss: 0.6931554079055786\n",
      "epoch: 6 step: 640 loss: 0.6931554079055786\n",
      "epoch: 6 step: 641 loss: 0.6931554079055786\n",
      "epoch: 6 step: 642 loss: 0.6931554079055786\n",
      "epoch: 6 step: 643 loss: 0.6931554079055786\n",
      "epoch: 6 step: 644 loss: 0.6931554079055786\n",
      "epoch: 6 step: 645 loss: 0.6931554079055786\n",
      "epoch: 6 step: 646 loss: 0.6931554079055786\n",
      "epoch: 6 step: 647 loss: 0.6931553483009338\n",
      "epoch: 6 step: 648 loss: 0.6931553483009338\n",
      "epoch: 6 step: 649 loss: 0.6931554079055786\n",
      "epoch: 6 step: 650 loss: 0.6931554079055786\n",
      "epoch: 6 step: 651 loss: 0.6931553483009338\n",
      "epoch: 6 step: 652 loss: 0.6931552886962891\n",
      "epoch: 6 step: 653 loss: 0.6931553483009338\n",
      "epoch: 6 step: 654 loss: 0.6931553483009338\n",
      "epoch: 6 step: 655 loss: 0.6931552886962891\n",
      "epoch: 6 step: 656 loss: 0.6931553483009338\n",
      "epoch: 6 step: 657 loss: 0.6931552886962891\n",
      "epoch: 6 step: 658 loss: 0.6931552886962891\n",
      "epoch: 6 step: 659 loss: 0.6931552886962891\n",
      "epoch: 6 step: 660 loss: 0.6931552886962891\n",
      "epoch: 6 step: 661 loss: 0.6931552886962891\n",
      "epoch: 6 step: 662 loss: 0.6931552886962891\n",
      "epoch: 6 step: 663 loss: 0.6931552886962891\n",
      "epoch: 6 step: 664 loss: 0.6931552886962891\n",
      "epoch: 6 step: 665 loss: 0.6931552290916443\n",
      "epoch: 6 step: 666 loss: 0.6931552886962891\n",
      "epoch: 6 step: 667 loss: 0.6931552886962891\n",
      "epoch: 6 step: 668 loss: 0.6931552886962891\n",
      "epoch: 6 step: 669 loss: 0.6931552290916443\n",
      "epoch: 6 step: 670 loss: 0.6931552886962891\n",
      "epoch: 6 step: 671 loss: 0.6931552886962891\n",
      "epoch: 6 step: 672 loss: 0.6931552886962891\n",
      "epoch: 6 step: 673 loss: 0.6931551694869995\n",
      "epoch: 6 step: 674 loss: 0.6931552886962891\n",
      "epoch: 6 step: 675 loss: 0.6931552290916443\n",
      "epoch: 6 step: 676 loss: 0.6931552886962891\n",
      "epoch: 6 step: 677 loss: 0.6931551694869995\n",
      "epoch: 6 step: 678 loss: 0.6931552290916443\n",
      "epoch: 6 step: 679 loss: 0.6931551694869995\n",
      "epoch: 6 step: 680 loss: 0.6931551694869995\n",
      "epoch: 6 step: 681 loss: 0.6931552290916443\n",
      "epoch: 6 step: 682 loss: 0.6931552290916443\n",
      "epoch: 6 step: 683 loss: 0.6931551694869995\n",
      "epoch: 6 step: 684 loss: 0.6931551694869995\n",
      "epoch: 6 step: 685 loss: 0.6931551694869995\n",
      "epoch: 6 step: 686 loss: 0.6931551694869995\n",
      "epoch: 6 step: 687 loss: 0.6931551694869995\n",
      "epoch: 6 step: 688 loss: 0.6931551694869995\n",
      "epoch: 6 step: 689 loss: 0.6931551694869995\n",
      "epoch: 6 step: 690 loss: 0.6931551694869995\n",
      "epoch: 6 step: 691 loss: 0.6931551694869995\n",
      "epoch: 6 step: 692 loss: 0.6931551694869995\n",
      "epoch: 6 step: 693 loss: 0.6931551694869995\n",
      "epoch: 6 step: 694 loss: 0.6931551694869995\n",
      "epoch: 6 step: 695 loss: 0.6931551694869995\n",
      "epoch: 6 step: 696 loss: 0.6931551694869995\n",
      "epoch: 6 step: 697 loss: 0.6931551694869995\n",
      "epoch: 6 step: 698 loss: 0.6931551694869995\n",
      "epoch: 6 step: 699 loss: 0.6931551694869995\n",
      "epoch: 6 step: 700 loss: 0.6931551098823547\n",
      "epoch: 6 step: 701 loss: 0.6931551098823547\n",
      "epoch: 6 step: 702 loss: 0.6931551098823547\n",
      "epoch: 6 step: 703 loss: 0.6931551694869995\n",
      "epoch: 6 step: 704 loss: 0.69315505027771\n",
      "epoch: 6 step: 705 loss: 0.6931551098823547\n",
      "epoch: 6 step: 706 loss: 0.69315505027771\n",
      "epoch: 6 step: 707 loss: 0.69315505027771\n",
      "epoch: 6 step: 708 loss: 0.69315505027771\n",
      "epoch: 6 step: 709 loss: 0.69315505027771\n",
      "epoch: 6 step: 710 loss: 0.69315505027771\n",
      "epoch: 6 step: 711 loss: 0.69315505027771\n",
      "epoch: 6 step: 712 loss: 0.69315505027771\n",
      "epoch: 6 step: 713 loss: 0.69315505027771\n",
      "epoch: 6 step: 714 loss: 0.69315505027771\n",
      "epoch: 6 step: 715 loss: 0.69315505027771\n",
      "epoch: 6 step: 716 loss: 0.69315505027771\n",
      "epoch: 6 step: 717 loss: 0.69315505027771\n",
      "epoch: 6 step: 718 loss: 0.69315505027771\n",
      "epoch: 6 step: 719 loss: 0.69315505027771\n",
      "epoch: 6 step: 720 loss: 0.69315505027771\n",
      "epoch: 6 step: 721 loss: 0.69315505027771\n",
      "epoch: 6 step: 722 loss: 0.69315505027771\n",
      "epoch: 6 step: 723 loss: 0.69315505027771\n",
      "epoch: 6 step: 724 loss: 0.6931549906730652\n",
      "epoch: 6 step: 725 loss: 0.6931549906730652\n",
      "epoch: 6 step: 726 loss: 0.6931549906730652\n",
      "epoch: 6 step: 727 loss: 0.6931549310684204\n",
      "epoch: 6 step: 728 loss: 0.6931549310684204\n",
      "epoch: 6 step: 729 loss: 0.6931549310684204\n",
      "epoch: 6 step: 730 loss: 0.6931549906730652\n",
      "epoch: 6 step: 731 loss: 0.6931549310684204\n",
      "epoch: 6 step: 732 loss: 0.6931549310684204\n",
      "epoch: 6 step: 733 loss: 0.6931549310684204\n",
      "epoch: 6 step: 734 loss: 0.6931549310684204\n",
      "epoch: 6 step: 735 loss: 0.6931549310684204\n",
      "epoch: 6 step: 736 loss: 0.6931549310684204\n",
      "epoch: 6 step: 737 loss: 0.6931549310684204\n",
      "epoch: 6 step: 738 loss: 0.6931549310684204\n",
      "epoch: 6 step: 739 loss: 0.6931549310684204\n",
      "epoch: 6 step: 740 loss: 0.6931549310684204\n",
      "epoch: 6 step: 741 loss: 0.6931549310684204\n",
      "epoch: 6 step: 742 loss: 0.6931549310684204\n",
      "epoch: 6 step: 743 loss: 0.6931549310684204\n",
      "epoch: 6 step: 744 loss: 0.6931549310684204\n",
      "epoch: 6 step: 745 loss: 0.6931549310684204\n",
      "epoch: 6 step: 746 loss: 0.6931549310684204\n",
      "epoch: 6 step: 747 loss: 0.6931549310684204\n",
      "epoch: 6 step: 748 loss: 0.6931549310684204\n",
      "epoch: 6 step: 749 loss: 0.6931549310684204\n",
      "epoch: 6 step: 750 loss: 0.6931548714637756\n",
      "epoch: 6 step: 751 loss: 0.6931548118591309\n",
      "epoch: 6 step: 752 loss: 0.6931548714637756\n",
      "epoch: 6 step: 753 loss: 0.6931548714637756\n",
      "epoch: 6 step: 754 loss: 0.6931548118591309\n",
      "epoch: 6 step: 755 loss: 0.6931548118591309\n",
      "epoch: 6 step: 756 loss: 0.6931548714637756\n",
      "epoch: 6 step: 757 loss: 0.6931548118591309\n",
      "epoch: 6 step: 758 loss: 0.6931548118591309\n",
      "epoch: 6 step: 759 loss: 0.6931548118591309\n",
      "epoch: 6 step: 760 loss: 0.6931548118591309\n",
      "epoch: 6 step: 761 loss: 0.6931548118591309\n",
      "epoch: 6 step: 762 loss: 0.6931548118591309\n",
      "epoch: 6 step: 763 loss: 0.6931548118591309\n",
      "epoch: 6 step: 764 loss: 0.6931548118591309\n",
      "epoch: 6 step: 765 loss: 0.6931548118591309\n",
      "epoch: 6 step: 766 loss: 0.6931548118591309\n",
      "epoch: 6 step: 767 loss: 0.6931548118591309\n",
      "epoch: 6 step: 768 loss: 0.6931548118591309\n",
      "epoch: 6 step: 769 loss: 0.6931548118591309\n",
      "epoch: 6 step: 770 loss: 0.6931548118591309\n",
      "epoch: 6 step: 771 loss: 0.6931547522544861\n",
      "epoch: 6 step: 772 loss: 0.6931547522544861\n",
      "epoch: 6 step: 773 loss: 0.6931548118591309\n",
      "epoch: 6 step: 774 loss: 0.6931548118591309\n",
      "epoch: 6 step: 775 loss: 0.6931547522544861\n",
      "epoch: 6 step: 776 loss: 0.6931546926498413\n",
      "epoch: 6 step: 777 loss: 0.6931547522544861\n",
      "epoch: 6 step: 778 loss: 0.6931546926498413\n",
      "epoch: 6 step: 779 loss: 0.6931547522544861\n",
      "epoch: 6 step: 780 loss: 0.6931548118591309\n",
      "epoch: 6 step: 781 loss: 0.6931547522544861\n",
      "epoch: 7 step: 1 loss: 0.6931547522544861\n",
      "epoch: 7 step: 2 loss: 0.6931546926498413\n",
      "epoch: 7 step: 3 loss: 0.6931547522544861\n",
      "epoch: 7 step: 4 loss: 0.6931546926498413\n",
      "epoch: 7 step: 5 loss: 0.6931547522544861\n",
      "epoch: 7 step: 6 loss: 0.6931546926498413\n",
      "epoch: 7 step: 7 loss: 0.6931546926498413\n",
      "epoch: 7 step: 8 loss: 0.6931546926498413\n",
      "epoch: 7 step: 9 loss: 0.6931546926498413\n",
      "epoch: 7 step: 10 loss: 0.6931546926498413\n",
      "epoch: 7 step: 11 loss: 0.6931546926498413\n",
      "epoch: 7 step: 12 loss: 0.6931546926498413\n",
      "epoch: 7 step: 13 loss: 0.6931546926498413\n",
      "epoch: 7 step: 14 loss: 0.6931546926498413\n",
      "epoch: 7 step: 15 loss: 0.6931546926498413\n",
      "epoch: 7 step: 16 loss: 0.6931546926498413\n",
      "epoch: 7 step: 17 loss: 0.6931546926498413\n",
      "epoch: 7 step: 18 loss: 0.6931546926498413\n",
      "epoch: 7 step: 19 loss: 0.6931546926498413\n",
      "epoch: 7 step: 20 loss: 0.6931546926498413\n",
      "epoch: 7 step: 21 loss: 0.6931546926498413\n",
      "epoch: 7 step: 22 loss: 0.6931546926498413\n",
      "epoch: 7 step: 23 loss: 0.6931546330451965\n",
      "epoch: 7 step: 24 loss: 0.6931546330451965\n",
      "epoch: 7 step: 25 loss: 0.6931545734405518\n",
      "epoch: 7 step: 26 loss: 0.6931546330451965\n",
      "epoch: 7 step: 27 loss: 0.6931545734405518\n",
      "epoch: 7 step: 28 loss: 0.6931545734405518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 29 loss: 0.6931545734405518\n",
      "epoch: 7 step: 30 loss: 0.6931545734405518\n",
      "epoch: 7 step: 31 loss: 0.6931545734405518\n",
      "epoch: 7 step: 32 loss: 0.6931545734405518\n",
      "epoch: 7 step: 33 loss: 0.6931545734405518\n",
      "epoch: 7 step: 34 loss: 0.6931545734405518\n",
      "epoch: 7 step: 35 loss: 0.6931545734405518\n",
      "epoch: 7 step: 36 loss: 0.6931545734405518\n",
      "epoch: 7 step: 37 loss: 0.6931545734405518\n",
      "epoch: 7 step: 38 loss: 0.6931545734405518\n",
      "epoch: 7 step: 39 loss: 0.6931545734405518\n",
      "epoch: 7 step: 40 loss: 0.6931545734405518\n",
      "epoch: 7 step: 41 loss: 0.6931545734405518\n",
      "epoch: 7 step: 42 loss: 0.6931545734405518\n",
      "epoch: 7 step: 43 loss: 0.6931545734405518\n",
      "epoch: 7 step: 44 loss: 0.6931545734405518\n",
      "epoch: 7 step: 45 loss: 0.6931545734405518\n",
      "epoch: 7 step: 46 loss: 0.693154513835907\n",
      "epoch: 7 step: 47 loss: 0.6931545734405518\n",
      "epoch: 7 step: 48 loss: 0.693154513835907\n",
      "epoch: 7 step: 49 loss: 0.6931544542312622\n",
      "epoch: 7 step: 50 loss: 0.693154513835907\n",
      "epoch: 7 step: 51 loss: 0.693154513835907\n",
      "epoch: 7 step: 52 loss: 0.6931544542312622\n",
      "epoch: 7 step: 53 loss: 0.6931544542312622\n",
      "epoch: 7 step: 54 loss: 0.6931544542312622\n",
      "epoch: 7 step: 55 loss: 0.6931544542312622\n",
      "epoch: 7 step: 56 loss: 0.6931544542312622\n",
      "epoch: 7 step: 57 loss: 0.6931544542312622\n",
      "epoch: 7 step: 58 loss: 0.6931544542312622\n",
      "epoch: 7 step: 59 loss: 0.6931544542312622\n",
      "epoch: 7 step: 60 loss: 0.6931544542312622\n",
      "epoch: 7 step: 61 loss: 0.6931544542312622\n",
      "epoch: 7 step: 62 loss: 0.6931544542312622\n",
      "epoch: 7 step: 63 loss: 0.6931544542312622\n",
      "epoch: 7 step: 64 loss: 0.6931544542312622\n",
      "epoch: 7 step: 65 loss: 0.6931544542312622\n",
      "epoch: 7 step: 66 loss: 0.6931544542312622\n",
      "epoch: 7 step: 67 loss: 0.6931543946266174\n",
      "epoch: 7 step: 68 loss: 0.6931544542312622\n",
      "epoch: 7 step: 69 loss: 0.6931544542312622\n",
      "epoch: 7 step: 70 loss: 0.6931543946266174\n",
      "epoch: 7 step: 71 loss: 0.6931544542312622\n",
      "epoch: 7 step: 72 loss: 0.6931544542312622\n",
      "epoch: 7 step: 73 loss: 0.6931544542312622\n",
      "epoch: 7 step: 74 loss: 0.6931544542312622\n",
      "epoch: 7 step: 75 loss: 0.6931543946266174\n",
      "epoch: 7 step: 76 loss: 0.6931543946266174\n",
      "epoch: 7 step: 77 loss: 0.6931543946266174\n",
      "epoch: 7 step: 78 loss: 0.6931543350219727\n",
      "epoch: 7 step: 79 loss: 0.6931543350219727\n",
      "epoch: 7 step: 80 loss: 0.6931543350219727\n",
      "epoch: 7 step: 81 loss: 0.6931543350219727\n",
      "epoch: 7 step: 82 loss: 0.6931543350219727\n",
      "epoch: 7 step: 83 loss: 0.6931543350219727\n",
      "epoch: 7 step: 84 loss: 0.6931543350219727\n",
      "epoch: 7 step: 85 loss: 0.6931543350219727\n",
      "epoch: 7 step: 86 loss: 0.6931543350219727\n",
      "epoch: 7 step: 87 loss: 0.6931543350219727\n",
      "epoch: 7 step: 88 loss: 0.6931543350219727\n",
      "epoch: 7 step: 89 loss: 0.6931543350219727\n",
      "epoch: 7 step: 90 loss: 0.6931543350219727\n",
      "epoch: 7 step: 91 loss: 0.6931543350219727\n",
      "epoch: 7 step: 92 loss: 0.6931543350219727\n",
      "epoch: 7 step: 93 loss: 0.6931543350219727\n",
      "epoch: 7 step: 94 loss: 0.6931543350219727\n",
      "epoch: 7 step: 95 loss: 0.6931543350219727\n",
      "epoch: 7 step: 96 loss: 0.6931543350219727\n",
      "epoch: 7 step: 97 loss: 0.6931543350219727\n",
      "epoch: 7 step: 98 loss: 0.6931543350219727\n",
      "epoch: 7 step: 99 loss: 0.6931543350219727\n",
      "epoch: 7 step: 100 loss: 0.6931543350219727\n",
      "epoch: 7 step: 101 loss: 0.6931543350219727\n",
      "epoch: 7 step: 102 loss: 0.6931542754173279\n",
      "epoch: 7 step: 103 loss: 0.6931543350219727\n",
      "epoch: 7 step: 104 loss: 0.6931542158126831\n",
      "epoch: 7 step: 105 loss: 0.6931542754173279\n",
      "epoch: 7 step: 106 loss: 0.6931542158126831\n",
      "epoch: 7 step: 107 loss: 0.6931542158126831\n",
      "epoch: 7 step: 108 loss: 0.6931542754173279\n",
      "epoch: 7 step: 109 loss: 0.6931542158126831\n",
      "epoch: 7 step: 110 loss: 0.6931542754173279\n",
      "epoch: 7 step: 111 loss: 0.6931542158126831\n",
      "epoch: 7 step: 112 loss: 0.6931542158126831\n",
      "epoch: 7 step: 113 loss: 0.6931542158126831\n",
      "epoch: 7 step: 114 loss: 0.6931542158126831\n",
      "epoch: 7 step: 115 loss: 0.6931542158126831\n",
      "epoch: 7 step: 116 loss: 0.6931542158126831\n",
      "epoch: 7 step: 117 loss: 0.6931542158126831\n",
      "epoch: 7 step: 118 loss: 0.6931542158126831\n",
      "epoch: 7 step: 119 loss: 0.6931542158126831\n",
      "epoch: 7 step: 120 loss: 0.6931542158126831\n",
      "epoch: 7 step: 121 loss: 0.6931542158126831\n",
      "epoch: 7 step: 122 loss: 0.6931542158126831\n",
      "epoch: 7 step: 123 loss: 0.6931542158126831\n",
      "epoch: 7 step: 124 loss: 0.6931542158126831\n",
      "epoch: 7 step: 125 loss: 0.6931542158126831\n",
      "epoch: 7 step: 126 loss: 0.6931542158126831\n",
      "epoch: 7 step: 127 loss: 0.6931542158126831\n",
      "epoch: 7 step: 128 loss: 0.6931542158126831\n",
      "epoch: 7 step: 129 loss: 0.6931542158126831\n",
      "epoch: 7 step: 130 loss: 0.6931540966033936\n",
      "epoch: 7 step: 131 loss: 0.6931541562080383\n",
      "epoch: 7 step: 132 loss: 0.6931542158126831\n",
      "epoch: 7 step: 133 loss: 0.6931540966033936\n",
      "epoch: 7 step: 134 loss: 0.6931540966033936\n",
      "epoch: 7 step: 135 loss: 0.6931540966033936\n",
      "epoch: 7 step: 136 loss: 0.6931540966033936\n",
      "epoch: 7 step: 137 loss: 0.6931541562080383\n",
      "epoch: 7 step: 138 loss: 0.6931540966033936\n",
      "epoch: 7 step: 139 loss: 0.6931541562080383\n",
      "epoch: 7 step: 140 loss: 0.6931540966033936\n",
      "epoch: 7 step: 141 loss: 0.6931540966033936\n",
      "epoch: 7 step: 142 loss: 0.6931540966033936\n",
      "epoch: 7 step: 143 loss: 0.6931540966033936\n",
      "epoch: 7 step: 144 loss: 0.6931540966033936\n",
      "epoch: 7 step: 145 loss: 0.6931540966033936\n",
      "epoch: 7 step: 146 loss: 0.6931540966033936\n",
      "epoch: 7 step: 147 loss: 0.6931540966033936\n",
      "epoch: 7 step: 148 loss: 0.6931540966033936\n",
      "epoch: 7 step: 149 loss: 0.6931540966033936\n",
      "epoch: 7 step: 150 loss: 0.6931540966033936\n",
      "epoch: 7 step: 151 loss: 0.6931540966033936\n",
      "epoch: 7 step: 152 loss: 0.6931540966033936\n",
      "epoch: 7 step: 153 loss: 0.6931540966033936\n",
      "epoch: 7 step: 154 loss: 0.6931540966033936\n",
      "epoch: 7 step: 155 loss: 0.6931540966033936\n",
      "epoch: 7 step: 156 loss: 0.6931540966033936\n",
      "epoch: 7 step: 157 loss: 0.6931540966033936\n",
      "epoch: 7 step: 158 loss: 0.6931540966033936\n",
      "epoch: 7 step: 159 loss: 0.6931540369987488\n",
      "epoch: 7 step: 160 loss: 0.6931540369987488\n",
      "epoch: 7 step: 161 loss: 0.6931540966033936\n",
      "epoch: 7 step: 162 loss: 0.6931540369987488\n",
      "epoch: 7 step: 163 loss: 0.693153977394104\n",
      "epoch: 7 step: 164 loss: 0.693153977394104\n",
      "epoch: 7 step: 165 loss: 0.693153977394104\n",
      "epoch: 7 step: 166 loss: 0.693153977394104\n",
      "epoch: 7 step: 167 loss: 0.693153977394104\n",
      "epoch: 7 step: 168 loss: 0.6931540369987488\n",
      "epoch: 7 step: 169 loss: 0.693153977394104\n",
      "epoch: 7 step: 170 loss: 0.693153977394104\n",
      "epoch: 7 step: 171 loss: 0.693153977394104\n",
      "epoch: 7 step: 172 loss: 0.693153977394104\n",
      "epoch: 7 step: 173 loss: 0.693153977394104\n",
      "epoch: 7 step: 174 loss: 0.693153977394104\n",
      "epoch: 7 step: 175 loss: 0.693153977394104\n",
      "epoch: 7 step: 176 loss: 0.693153977394104\n",
      "epoch: 7 step: 177 loss: 0.693153977394104\n",
      "epoch: 7 step: 178 loss: 0.693153977394104\n",
      "epoch: 7 step: 179 loss: 0.693153977394104\n",
      "epoch: 7 step: 180 loss: 0.693153977394104\n",
      "epoch: 7 step: 181 loss: 0.693153977394104\n",
      "epoch: 7 step: 182 loss: 0.693153977394104\n",
      "epoch: 7 step: 183 loss: 0.693153977394104\n",
      "epoch: 7 step: 184 loss: 0.693153977394104\n",
      "epoch: 7 step: 185 loss: 0.693153977394104\n",
      "epoch: 7 step: 186 loss: 0.693153977394104\n",
      "epoch: 7 step: 187 loss: 0.693153977394104\n",
      "epoch: 7 step: 188 loss: 0.693153977394104\n",
      "epoch: 7 step: 189 loss: 0.6931539177894592\n",
      "epoch: 7 step: 190 loss: 0.6931539177894592\n",
      "epoch: 7 step: 191 loss: 0.6931539177894592\n",
      "epoch: 7 step: 192 loss: 0.6931539177894592\n",
      "epoch: 7 step: 193 loss: 0.6931538581848145\n",
      "epoch: 7 step: 194 loss: 0.6931538581848145\n",
      "epoch: 7 step: 195 loss: 0.6931538581848145\n",
      "epoch: 7 step: 196 loss: 0.6931538581848145\n",
      "epoch: 7 step: 197 loss: 0.6931539177894592\n",
      "epoch: 7 step: 198 loss: 0.6931538581848145\n",
      "epoch: 7 step: 199 loss: 0.6931538581848145\n",
      "epoch: 7 step: 200 loss: 0.6931538581848145\n",
      "epoch: 7 step: 201 loss: 0.6931538581848145\n",
      "epoch: 7 step: 202 loss: 0.6931538581848145\n",
      "epoch: 7 step: 203 loss: 0.6931538581848145\n",
      "epoch: 7 step: 204 loss: 0.6931538581848145\n",
      "epoch: 7 step: 205 loss: 0.6931538581848145\n",
      "epoch: 7 step: 206 loss: 0.6931538581848145\n",
      "epoch: 7 step: 207 loss: 0.6931538581848145\n",
      "epoch: 7 step: 208 loss: 0.6931538581848145\n",
      "epoch: 7 step: 209 loss: 0.6931538581848145\n",
      "epoch: 7 step: 210 loss: 0.6931538581848145\n",
      "epoch: 7 step: 211 loss: 0.6931538581848145\n",
      "epoch: 7 step: 212 loss: 0.6931538581848145\n",
      "epoch: 7 step: 213 loss: 0.6931538581848145\n",
      "epoch: 7 step: 214 loss: 0.6931538581848145\n",
      "epoch: 7 step: 215 loss: 0.6931538581848145\n",
      "epoch: 7 step: 216 loss: 0.6931537389755249\n",
      "epoch: 7 step: 217 loss: 0.6931538581848145\n",
      "epoch: 7 step: 218 loss: 0.6931538581848145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 219 loss: 0.6931538581848145\n",
      "epoch: 7 step: 220 loss: 0.6931537985801697\n",
      "epoch: 7 step: 221 loss: 0.6931537985801697\n",
      "epoch: 7 step: 222 loss: 0.6931537389755249\n",
      "epoch: 7 step: 223 loss: 0.6931537985801697\n",
      "epoch: 7 step: 224 loss: 0.6931537389755249\n",
      "epoch: 7 step: 225 loss: 0.6931537389755249\n",
      "epoch: 7 step: 226 loss: 0.6931537389755249\n",
      "epoch: 7 step: 227 loss: 0.6931537389755249\n",
      "epoch: 7 step: 228 loss: 0.6931537389755249\n",
      "epoch: 7 step: 229 loss: 0.6931537389755249\n",
      "epoch: 7 step: 230 loss: 0.6931537389755249\n",
      "epoch: 7 step: 231 loss: 0.6931537389755249\n",
      "epoch: 7 step: 232 loss: 0.6931537389755249\n",
      "epoch: 7 step: 233 loss: 0.6931537389755249\n",
      "epoch: 7 step: 234 loss: 0.6931537389755249\n",
      "epoch: 7 step: 235 loss: 0.6931537389755249\n",
      "epoch: 7 step: 236 loss: 0.6931537389755249\n",
      "epoch: 7 step: 237 loss: 0.6931537389755249\n",
      "epoch: 7 step: 238 loss: 0.6931537389755249\n",
      "epoch: 7 step: 239 loss: 0.6931537389755249\n",
      "epoch: 7 step: 240 loss: 0.6931537389755249\n",
      "epoch: 7 step: 241 loss: 0.6931537389755249\n",
      "epoch: 7 step: 242 loss: 0.6931537389755249\n",
      "epoch: 7 step: 243 loss: 0.6931537389755249\n",
      "epoch: 7 step: 244 loss: 0.6931537389755249\n",
      "epoch: 7 step: 245 loss: 0.6931537389755249\n",
      "epoch: 7 step: 246 loss: 0.6931537389755249\n",
      "epoch: 7 step: 247 loss: 0.6931537389755249\n",
      "epoch: 7 step: 248 loss: 0.6931537389755249\n",
      "epoch: 7 step: 249 loss: 0.6931537389755249\n",
      "epoch: 7 step: 250 loss: 0.6931536793708801\n",
      "epoch: 7 step: 251 loss: 0.6931536793708801\n",
      "epoch: 7 step: 252 loss: 0.6931536793708801\n",
      "epoch: 7 step: 253 loss: 0.6931537389755249\n",
      "epoch: 7 step: 254 loss: 0.6931536197662354\n",
      "epoch: 7 step: 255 loss: 0.6931536793708801\n",
      "epoch: 7 step: 256 loss: 0.6931536197662354\n",
      "epoch: 7 step: 257 loss: 0.6931536197662354\n",
      "epoch: 7 step: 258 loss: 0.6931536197662354\n",
      "epoch: 7 step: 259 loss: 0.6931536197662354\n",
      "epoch: 7 step: 260 loss: 0.6931536197662354\n",
      "epoch: 7 step: 261 loss: 0.6931536197662354\n",
      "epoch: 7 step: 262 loss: 0.6931536197662354\n",
      "epoch: 7 step: 263 loss: 0.6931536197662354\n",
      "epoch: 7 step: 264 loss: 0.6931536197662354\n",
      "epoch: 7 step: 265 loss: 0.6931536197662354\n",
      "epoch: 7 step: 266 loss: 0.6931536197662354\n",
      "epoch: 7 step: 267 loss: 0.6931536197662354\n",
      "epoch: 7 step: 268 loss: 0.6931536197662354\n",
      "epoch: 7 step: 269 loss: 0.6931536197662354\n",
      "epoch: 7 step: 270 loss: 0.6931536197662354\n",
      "epoch: 7 step: 271 loss: 0.6931536197662354\n",
      "epoch: 7 step: 272 loss: 0.6931536197662354\n",
      "epoch: 7 step: 273 loss: 0.6931536197662354\n",
      "epoch: 7 step: 274 loss: 0.6931536197662354\n",
      "epoch: 7 step: 275 loss: 0.6931536197662354\n",
      "epoch: 7 step: 276 loss: 0.6931536197662354\n",
      "epoch: 7 step: 277 loss: 0.6931536197662354\n",
      "epoch: 7 step: 278 loss: 0.6931535601615906\n",
      "epoch: 7 step: 279 loss: 0.6931536197662354\n",
      "epoch: 7 step: 280 loss: 0.6931536197662354\n",
      "epoch: 7 step: 281 loss: 0.6931536197662354\n",
      "epoch: 7 step: 282 loss: 0.6931535601615906\n",
      "epoch: 7 step: 283 loss: 0.6931535601615906\n",
      "epoch: 7 step: 284 loss: 0.6931535601615906\n",
      "epoch: 7 step: 285 loss: 0.6931535005569458\n",
      "epoch: 7 step: 286 loss: 0.6931535601615906\n",
      "epoch: 7 step: 287 loss: 0.6931535005569458\n",
      "epoch: 7 step: 288 loss: 0.6931535601615906\n",
      "epoch: 7 step: 289 loss: 0.6931535005569458\n",
      "epoch: 7 step: 290 loss: 0.6931535005569458\n",
      "epoch: 7 step: 291 loss: 0.6931535005569458\n",
      "epoch: 7 step: 292 loss: 0.6931535005569458\n",
      "epoch: 7 step: 293 loss: 0.6931535005569458\n",
      "epoch: 7 step: 294 loss: 0.6931535005569458\n",
      "epoch: 7 step: 295 loss: 0.6931535005569458\n",
      "epoch: 7 step: 296 loss: 0.6931535005569458\n",
      "epoch: 7 step: 297 loss: 0.6931535005569458\n",
      "epoch: 7 step: 298 loss: 0.6931535005569458\n",
      "epoch: 7 step: 299 loss: 0.6931535005569458\n",
      "epoch: 7 step: 300 loss: 0.6931535005569458\n",
      "epoch: 7 step: 301 loss: 0.6931535005569458\n",
      "epoch: 7 step: 302 loss: 0.6931535005569458\n",
      "epoch: 7 step: 303 loss: 0.6931535005569458\n",
      "epoch: 7 step: 304 loss: 0.6931535005569458\n",
      "epoch: 7 step: 305 loss: 0.6931535005569458\n",
      "epoch: 7 step: 306 loss: 0.6931535005569458\n",
      "epoch: 7 step: 307 loss: 0.6931535005569458\n",
      "epoch: 7 step: 308 loss: 0.6931535005569458\n",
      "epoch: 7 step: 309 loss: 0.6931535005569458\n",
      "epoch: 7 step: 310 loss: 0.6931535005569458\n",
      "epoch: 7 step: 311 loss: 0.6931535005569458\n",
      "epoch: 7 step: 312 loss: 0.6931535005569458\n",
      "epoch: 7 step: 313 loss: 0.693153440952301\n",
      "epoch: 7 step: 314 loss: 0.6931535005569458\n",
      "epoch: 7 step: 315 loss: 0.6931535005569458\n",
      "epoch: 7 step: 316 loss: 0.693153440952301\n",
      "epoch: 7 step: 317 loss: 0.6931533813476562\n",
      "epoch: 7 step: 318 loss: 0.6931533813476562\n",
      "epoch: 7 step: 319 loss: 0.6931533813476562\n",
      "epoch: 7 step: 320 loss: 0.6931533813476562\n",
      "epoch: 7 step: 321 loss: 0.6931533813476562\n",
      "epoch: 7 step: 322 loss: 0.693153440952301\n",
      "epoch: 7 step: 323 loss: 0.6931533813476562\n",
      "epoch: 7 step: 324 loss: 0.6931533813476562\n",
      "epoch: 7 step: 325 loss: 0.6931533813476562\n",
      "epoch: 7 step: 326 loss: 0.6931533813476562\n",
      "epoch: 7 step: 327 loss: 0.6931533813476562\n",
      "epoch: 7 step: 328 loss: 0.6931533813476562\n",
      "epoch: 7 step: 329 loss: 0.6931533813476562\n",
      "epoch: 7 step: 330 loss: 0.6931533813476562\n",
      "epoch: 7 step: 331 loss: 0.6931533813476562\n",
      "epoch: 7 step: 332 loss: 0.6931533813476562\n",
      "epoch: 7 step: 333 loss: 0.6931533813476562\n",
      "epoch: 7 step: 334 loss: 0.6931533813476562\n",
      "epoch: 7 step: 335 loss: 0.6931533813476562\n",
      "epoch: 7 step: 336 loss: 0.6931533813476562\n",
      "epoch: 7 step: 337 loss: 0.6931533813476562\n",
      "epoch: 7 step: 338 loss: 0.6931533813476562\n",
      "epoch: 7 step: 339 loss: 0.6931533217430115\n",
      "epoch: 7 step: 340 loss: 0.6931533217430115\n",
      "epoch: 7 step: 341 loss: 0.6931533813476562\n",
      "epoch: 7 step: 342 loss: 0.6931533813476562\n",
      "epoch: 7 step: 343 loss: 0.6931533813476562\n",
      "epoch: 7 step: 344 loss: 0.6931533217430115\n",
      "epoch: 7 step: 345 loss: 0.6931533217430115\n",
      "epoch: 7 step: 346 loss: 0.6931533217430115\n",
      "epoch: 7 step: 347 loss: 0.6931533217430115\n",
      "epoch: 7 step: 348 loss: 0.6931533217430115\n",
      "epoch: 7 step: 349 loss: 0.6931533217430115\n",
      "epoch: 7 step: 350 loss: 0.6931532621383667\n",
      "epoch: 7 step: 351 loss: 0.6931532621383667\n",
      "epoch: 7 step: 352 loss: 0.6931533217430115\n",
      "epoch: 7 step: 353 loss: 0.6931532621383667\n",
      "epoch: 7 step: 354 loss: 0.6931532621383667\n",
      "epoch: 7 step: 355 loss: 0.6931532621383667\n",
      "epoch: 7 step: 356 loss: 0.6931532621383667\n",
      "epoch: 7 step: 357 loss: 0.6931532621383667\n",
      "epoch: 7 step: 358 loss: 0.6931532621383667\n",
      "epoch: 7 step: 359 loss: 0.6931532621383667\n",
      "epoch: 7 step: 360 loss: 0.6931532621383667\n",
      "epoch: 7 step: 361 loss: 0.6931532621383667\n",
      "epoch: 7 step: 362 loss: 0.6931532621383667\n",
      "epoch: 7 step: 363 loss: 0.6931532621383667\n",
      "epoch: 7 step: 364 loss: 0.6931532621383667\n",
      "epoch: 7 step: 365 loss: 0.6931532621383667\n",
      "epoch: 7 step: 366 loss: 0.6931532621383667\n",
      "epoch: 7 step: 367 loss: 0.6931532025337219\n",
      "epoch: 7 step: 368 loss: 0.6931532621383667\n",
      "epoch: 7 step: 369 loss: 0.6931532621383667\n",
      "epoch: 7 step: 370 loss: 0.6931532621383667\n",
      "epoch: 7 step: 371 loss: 0.6931532621383667\n",
      "epoch: 7 step: 372 loss: 0.6931532025337219\n",
      "epoch: 7 step: 373 loss: 0.6931532025337219\n",
      "epoch: 7 step: 374 loss: 0.6931532621383667\n",
      "epoch: 7 step: 375 loss: 0.6931532621383667\n",
      "epoch: 7 step: 376 loss: 0.6931532621383667\n",
      "epoch: 7 step: 377 loss: 0.6931532621383667\n",
      "epoch: 7 step: 378 loss: 0.6931532025337219\n",
      "epoch: 7 step: 379 loss: 0.6931532025337219\n",
      "epoch: 7 step: 380 loss: 0.6931531429290771\n",
      "epoch: 7 step: 381 loss: 0.6931531429290771\n",
      "epoch: 7 step: 382 loss: 0.6931532025337219\n",
      "epoch: 7 step: 383 loss: 0.6931531429290771\n",
      "epoch: 7 step: 384 loss: 0.6931531429290771\n",
      "epoch: 7 step: 385 loss: 0.6931531429290771\n",
      "epoch: 7 step: 386 loss: 0.6931531429290771\n",
      "epoch: 7 step: 387 loss: 0.6931531429290771\n",
      "epoch: 7 step: 388 loss: 0.6931531429290771\n",
      "epoch: 7 step: 389 loss: 0.6931532025337219\n",
      "epoch: 7 step: 390 loss: 0.6931531429290771\n",
      "epoch: 7 step: 391 loss: 0.6931531429290771\n",
      "epoch: 7 step: 392 loss: 0.6931531429290771\n",
      "epoch: 7 step: 393 loss: 0.6931531429290771\n",
      "epoch: 7 step: 394 loss: 0.6931531429290771\n",
      "epoch: 7 step: 395 loss: 0.6931531429290771\n",
      "epoch: 7 step: 396 loss: 0.6931531429290771\n",
      "epoch: 7 step: 397 loss: 0.6931531429290771\n",
      "epoch: 7 step: 398 loss: 0.6931531429290771\n",
      "epoch: 7 step: 399 loss: 0.6931531429290771\n",
      "epoch: 7 step: 400 loss: 0.6931531429290771\n",
      "epoch: 7 step: 401 loss: 0.6931531429290771\n",
      "epoch: 7 step: 402 loss: 0.6931531429290771\n",
      "epoch: 7 step: 403 loss: 0.6931531429290771\n",
      "epoch: 7 step: 404 loss: 0.6931531429290771\n",
      "epoch: 7 step: 405 loss: 0.6931531429290771\n",
      "epoch: 7 step: 406 loss: 0.6931531429290771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 407 loss: 0.6931531429290771\n",
      "epoch: 7 step: 408 loss: 0.6931531429290771\n",
      "epoch: 7 step: 409 loss: 0.6931531429290771\n",
      "epoch: 7 step: 410 loss: 0.6931531429290771\n",
      "epoch: 7 step: 411 loss: 0.6931530833244324\n",
      "epoch: 7 step: 412 loss: 0.6931531429290771\n",
      "epoch: 7 step: 413 loss: 0.6931530833244324\n",
      "epoch: 7 step: 414 loss: 0.6931530833244324\n",
      "epoch: 7 step: 415 loss: 0.6931530237197876\n",
      "epoch: 7 step: 416 loss: 0.6931530237197876\n",
      "epoch: 7 step: 417 loss: 0.6931530237197876\n",
      "epoch: 7 step: 418 loss: 0.6931531429290771\n",
      "epoch: 7 step: 419 loss: 0.6931530237197876\n",
      "epoch: 7 step: 420 loss: 0.6931530237197876\n",
      "epoch: 7 step: 421 loss: 0.6931530237197876\n",
      "epoch: 7 step: 422 loss: 0.6931530237197876\n",
      "epoch: 7 step: 423 loss: 0.6931530237197876\n",
      "epoch: 7 step: 424 loss: 0.6931530237197876\n",
      "epoch: 7 step: 425 loss: 0.6931530237197876\n",
      "epoch: 7 step: 426 loss: 0.6931530237197876\n",
      "epoch: 7 step: 427 loss: 0.6931530237197876\n",
      "epoch: 7 step: 428 loss: 0.6931530237197876\n",
      "epoch: 7 step: 429 loss: 0.6931530237197876\n",
      "epoch: 7 step: 430 loss: 0.6931530237197876\n",
      "epoch: 7 step: 431 loss: 0.6931530237197876\n",
      "epoch: 7 step: 432 loss: 0.6931530237197876\n",
      "epoch: 7 step: 433 loss: 0.6931530237197876\n",
      "epoch: 7 step: 434 loss: 0.6931530237197876\n",
      "epoch: 7 step: 435 loss: 0.6931530237197876\n",
      "epoch: 7 step: 436 loss: 0.6931530237197876\n",
      "epoch: 7 step: 437 loss: 0.6931530237197876\n",
      "epoch: 7 step: 438 loss: 0.6931530237197876\n",
      "epoch: 7 step: 439 loss: 0.6931530237197876\n",
      "epoch: 7 step: 440 loss: 0.6931530237197876\n",
      "epoch: 7 step: 441 loss: 0.6931529641151428\n",
      "epoch: 7 step: 442 loss: 0.6931530237197876\n",
      "epoch: 7 step: 443 loss: 0.6931530237197876\n",
      "epoch: 7 step: 444 loss: 0.6931530237197876\n",
      "epoch: 7 step: 445 loss: 0.6931530237197876\n",
      "epoch: 7 step: 446 loss: 0.6931530237197876\n",
      "epoch: 7 step: 447 loss: 0.6931530237197876\n",
      "epoch: 7 step: 448 loss: 0.6931530237197876\n",
      "epoch: 7 step: 449 loss: 0.6931529641151428\n",
      "epoch: 7 step: 450 loss: 0.6931529641151428\n",
      "epoch: 7 step: 451 loss: 0.693152904510498\n",
      "epoch: 7 step: 452 loss: 0.693152904510498\n",
      "epoch: 7 step: 453 loss: 0.6931529641151428\n",
      "epoch: 7 step: 454 loss: 0.693152904510498\n",
      "epoch: 7 step: 455 loss: 0.693152904510498\n",
      "epoch: 7 step: 456 loss: 0.693152904510498\n",
      "epoch: 7 step: 457 loss: 0.693152904510498\n",
      "epoch: 7 step: 458 loss: 0.693152904510498\n",
      "epoch: 7 step: 459 loss: 0.693152904510498\n",
      "epoch: 7 step: 460 loss: 0.693152904510498\n",
      "epoch: 7 step: 461 loss: 0.693152904510498\n",
      "epoch: 7 step: 462 loss: 0.693152904510498\n",
      "epoch: 7 step: 463 loss: 0.693152904510498\n",
      "epoch: 7 step: 464 loss: 0.693152904510498\n",
      "epoch: 7 step: 465 loss: 0.693152904510498\n",
      "epoch: 7 step: 466 loss: 0.693152904510498\n",
      "epoch: 7 step: 467 loss: 0.693152904510498\n",
      "epoch: 7 step: 468 loss: 0.693152904510498\n",
      "epoch: 7 step: 469 loss: 0.693152904510498\n",
      "epoch: 7 step: 470 loss: 0.693152904510498\n",
      "epoch: 7 step: 471 loss: 0.693152904510498\n",
      "epoch: 7 step: 472 loss: 0.693152904510498\n",
      "epoch: 7 step: 473 loss: 0.693152904510498\n",
      "epoch: 7 step: 474 loss: 0.693152904510498\n",
      "epoch: 7 step: 475 loss: 0.693152904510498\n",
      "epoch: 7 step: 476 loss: 0.693152904510498\n",
      "epoch: 7 step: 477 loss: 0.6931528449058533\n",
      "epoch: 7 step: 478 loss: 0.693152904510498\n",
      "epoch: 7 step: 479 loss: 0.6931528449058533\n",
      "epoch: 7 step: 480 loss: 0.693152904510498\n",
      "epoch: 7 step: 481 loss: 0.693152904510498\n",
      "epoch: 7 step: 482 loss: 0.6931528449058533\n",
      "epoch: 7 step: 483 loss: 0.6931528449058533\n",
      "epoch: 7 step: 484 loss: 0.6931528449058533\n",
      "epoch: 7 step: 485 loss: 0.6931527853012085\n",
      "epoch: 7 step: 486 loss: 0.6931528449058533\n",
      "epoch: 7 step: 487 loss: 0.6931528449058533\n",
      "epoch: 7 step: 488 loss: 0.6931528449058533\n",
      "epoch: 7 step: 489 loss: 0.6931527853012085\n",
      "epoch: 7 step: 490 loss: 0.6931527853012085\n",
      "epoch: 7 step: 491 loss: 0.6931527853012085\n",
      "epoch: 7 step: 492 loss: 0.6931527853012085\n",
      "epoch: 7 step: 493 loss: 0.6931527853012085\n",
      "epoch: 7 step: 494 loss: 0.6931527853012085\n",
      "epoch: 7 step: 495 loss: 0.6931527853012085\n",
      "epoch: 7 step: 496 loss: 0.6931527853012085\n",
      "epoch: 7 step: 497 loss: 0.6931527853012085\n",
      "epoch: 7 step: 498 loss: 0.6931527853012085\n",
      "epoch: 7 step: 499 loss: 0.6931527853012085\n",
      "epoch: 7 step: 500 loss: 0.6931527853012085\n",
      "epoch: 7 step: 501 loss: 0.6931527853012085\n",
      "epoch: 7 step: 502 loss: 0.6931527853012085\n",
      "epoch: 7 step: 503 loss: 0.6931527853012085\n",
      "epoch: 7 step: 504 loss: 0.6931527853012085\n",
      "epoch: 7 step: 505 loss: 0.6931527853012085\n",
      "epoch: 7 step: 506 loss: 0.6931527853012085\n",
      "epoch: 7 step: 507 loss: 0.6931527853012085\n",
      "epoch: 7 step: 508 loss: 0.6931527256965637\n",
      "epoch: 7 step: 509 loss: 0.6931527853012085\n",
      "epoch: 7 step: 510 loss: 0.6931527853012085\n",
      "epoch: 7 step: 511 loss: 0.6931527853012085\n",
      "epoch: 7 step: 512 loss: 0.6931527853012085\n",
      "epoch: 7 step: 513 loss: 0.6931527853012085\n",
      "epoch: 7 step: 514 loss: 0.6931527853012085\n",
      "epoch: 7 step: 515 loss: 0.6931527853012085\n",
      "epoch: 7 step: 516 loss: 0.6931527853012085\n",
      "epoch: 7 step: 517 loss: 0.6931527853012085\n",
      "epoch: 7 step: 518 loss: 0.693152666091919\n",
      "epoch: 7 step: 519 loss: 0.6931527256965637\n",
      "epoch: 7 step: 520 loss: 0.6931527256965637\n",
      "epoch: 7 step: 521 loss: 0.693152666091919\n",
      "epoch: 7 step: 522 loss: 0.693152666091919\n",
      "epoch: 7 step: 523 loss: 0.693152666091919\n",
      "epoch: 7 step: 524 loss: 0.693152666091919\n",
      "epoch: 7 step: 525 loss: 0.693152666091919\n",
      "epoch: 7 step: 526 loss: 0.693152666091919\n",
      "epoch: 7 step: 527 loss: 0.693152666091919\n",
      "epoch: 7 step: 528 loss: 0.693152666091919\n",
      "epoch: 7 step: 529 loss: 0.693152666091919\n",
      "epoch: 7 step: 530 loss: 0.693152666091919\n",
      "epoch: 7 step: 531 loss: 0.693152666091919\n",
      "epoch: 7 step: 532 loss: 0.693152666091919\n",
      "epoch: 7 step: 533 loss: 0.693152666091919\n",
      "epoch: 7 step: 534 loss: 0.693152666091919\n",
      "epoch: 7 step: 535 loss: 0.693152666091919\n",
      "epoch: 7 step: 536 loss: 0.693152666091919\n",
      "epoch: 7 step: 537 loss: 0.693152666091919\n",
      "epoch: 7 step: 538 loss: 0.693152666091919\n",
      "epoch: 7 step: 539 loss: 0.693152666091919\n",
      "epoch: 7 step: 540 loss: 0.693152666091919\n",
      "epoch: 7 step: 541 loss: 0.693152666091919\n",
      "epoch: 7 step: 542 loss: 0.693152666091919\n",
      "epoch: 7 step: 543 loss: 0.693152666091919\n",
      "epoch: 7 step: 544 loss: 0.6931526064872742\n",
      "epoch: 7 step: 545 loss: 0.693152666091919\n",
      "epoch: 7 step: 546 loss: 0.693152666091919\n",
      "epoch: 7 step: 547 loss: 0.693152666091919\n",
      "epoch: 7 step: 548 loss: 0.693152666091919\n",
      "epoch: 7 step: 549 loss: 0.693152666091919\n",
      "epoch: 7 step: 550 loss: 0.693152666091919\n",
      "epoch: 7 step: 551 loss: 0.693152666091919\n",
      "epoch: 7 step: 552 loss: 0.6931526064872742\n",
      "epoch: 7 step: 553 loss: 0.6931526064872742\n",
      "epoch: 7 step: 554 loss: 0.6931526064872742\n",
      "epoch: 7 step: 555 loss: 0.693152666091919\n",
      "epoch: 7 step: 556 loss: 0.6931526064872742\n",
      "epoch: 7 step: 557 loss: 0.6931526064872742\n",
      "epoch: 7 step: 558 loss: 0.6931526064872742\n",
      "epoch: 7 step: 559 loss: 0.6931525468826294\n",
      "epoch: 7 step: 560 loss: 0.6931525468826294\n",
      "epoch: 7 step: 561 loss: 0.6931525468826294\n",
      "epoch: 7 step: 562 loss: 0.6931525468826294\n",
      "epoch: 7 step: 563 loss: 0.6931526064872742\n",
      "epoch: 7 step: 564 loss: 0.6931525468826294\n",
      "epoch: 7 step: 565 loss: 0.6931525468826294\n",
      "epoch: 7 step: 566 loss: 0.6931525468826294\n",
      "epoch: 7 step: 567 loss: 0.6931525468826294\n",
      "epoch: 7 step: 568 loss: 0.6931525468826294\n",
      "epoch: 7 step: 569 loss: 0.6931525468826294\n",
      "epoch: 7 step: 570 loss: 0.6931525468826294\n",
      "epoch: 7 step: 571 loss: 0.6931525468826294\n",
      "epoch: 7 step: 572 loss: 0.6931525468826294\n",
      "epoch: 7 step: 573 loss: 0.6931525468826294\n",
      "epoch: 7 step: 574 loss: 0.6931525468826294\n",
      "epoch: 7 step: 575 loss: 0.6931525468826294\n",
      "epoch: 7 step: 576 loss: 0.6931525468826294\n",
      "epoch: 7 step: 577 loss: 0.6931525468826294\n",
      "epoch: 7 step: 578 loss: 0.6931525468826294\n",
      "epoch: 7 step: 579 loss: 0.6931525468826294\n",
      "epoch: 7 step: 580 loss: 0.6931525468826294\n",
      "epoch: 7 step: 581 loss: 0.6931525468826294\n",
      "epoch: 7 step: 582 loss: 0.6931525468826294\n",
      "epoch: 7 step: 583 loss: 0.6931525468826294\n",
      "epoch: 7 step: 584 loss: 0.6931525468826294\n",
      "epoch: 7 step: 585 loss: 0.6931525468826294\n",
      "epoch: 7 step: 586 loss: 0.6931525468826294\n",
      "epoch: 7 step: 587 loss: 0.6931525468826294\n",
      "epoch: 7 step: 588 loss: 0.6931525468826294\n",
      "epoch: 7 step: 589 loss: 0.6931524872779846\n",
      "epoch: 7 step: 590 loss: 0.6931525468826294\n",
      "epoch: 7 step: 591 loss: 0.6931525468826294\n",
      "epoch: 7 step: 592 loss: 0.6931525468826294\n",
      "epoch: 7 step: 593 loss: 0.6931525468826294\n",
      "epoch: 7 step: 594 loss: 0.6931525468826294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 595 loss: 0.6931525468826294\n",
      "epoch: 7 step: 596 loss: 0.6931524872779846\n",
      "epoch: 7 step: 597 loss: 0.6931525468826294\n",
      "epoch: 7 step: 598 loss: 0.6931524276733398\n",
      "epoch: 7 step: 599 loss: 0.6931524276733398\n",
      "epoch: 7 step: 600 loss: 0.6931524872779846\n",
      "epoch: 7 step: 601 loss: 0.6931524276733398\n",
      "epoch: 7 step: 602 loss: 0.6931524872779846\n",
      "epoch: 7 step: 603 loss: 0.6931524276733398\n",
      "epoch: 7 step: 604 loss: 0.6931524872779846\n",
      "epoch: 7 step: 605 loss: 0.6931524276733398\n",
      "epoch: 7 step: 606 loss: 0.6931524276733398\n",
      "epoch: 7 step: 607 loss: 0.6931524276733398\n",
      "epoch: 7 step: 608 loss: 0.6931524276733398\n",
      "epoch: 7 step: 609 loss: 0.6931524276733398\n",
      "epoch: 7 step: 610 loss: 0.6931524276733398\n",
      "epoch: 7 step: 611 loss: 0.6931524276733398\n",
      "epoch: 7 step: 612 loss: 0.6931524276733398\n",
      "epoch: 7 step: 613 loss: 0.6931524276733398\n",
      "epoch: 7 step: 614 loss: 0.6931524276733398\n",
      "epoch: 7 step: 615 loss: 0.6931524276733398\n",
      "epoch: 7 step: 616 loss: 0.6931524276733398\n",
      "epoch: 7 step: 617 loss: 0.6931524276733398\n",
      "epoch: 7 step: 618 loss: 0.6931524276733398\n",
      "epoch: 7 step: 619 loss: 0.6931524276733398\n",
      "epoch: 7 step: 620 loss: 0.6931524276733398\n",
      "epoch: 7 step: 621 loss: 0.6931524276733398\n",
      "epoch: 7 step: 622 loss: 0.6931524276733398\n",
      "epoch: 7 step: 623 loss: 0.6931524276733398\n",
      "epoch: 7 step: 624 loss: 0.6931524276733398\n",
      "epoch: 7 step: 625 loss: 0.6931524276733398\n",
      "epoch: 7 step: 626 loss: 0.6931524276733398\n",
      "epoch: 7 step: 627 loss: 0.6931524276733398\n",
      "epoch: 7 step: 628 loss: 0.6931524276733398\n",
      "epoch: 7 step: 629 loss: 0.6931524276733398\n",
      "epoch: 7 step: 630 loss: 0.6931524276733398\n",
      "epoch: 7 step: 631 loss: 0.6931524276733398\n",
      "epoch: 7 step: 632 loss: 0.6931524276733398\n",
      "epoch: 7 step: 633 loss: 0.6931524276733398\n",
      "epoch: 7 step: 634 loss: 0.6931523680686951\n",
      "epoch: 7 step: 635 loss: 0.6931523680686951\n",
      "epoch: 7 step: 636 loss: 0.6931524276733398\n",
      "epoch: 7 step: 637 loss: 0.6931523680686951\n",
      "epoch: 7 step: 638 loss: 0.6931524276733398\n",
      "epoch: 7 step: 639 loss: 0.6931523084640503\n",
      "epoch: 7 step: 640 loss: 0.6931523680686951\n",
      "epoch: 7 step: 641 loss: 0.6931523084640503\n",
      "epoch: 7 step: 642 loss: 0.6931523084640503\n",
      "epoch: 7 step: 643 loss: 0.6931523084640503\n",
      "epoch: 7 step: 644 loss: 0.6931523084640503\n",
      "epoch: 7 step: 645 loss: 0.6931523084640503\n",
      "epoch: 7 step: 646 loss: 0.6931523084640503\n",
      "epoch: 7 step: 647 loss: 0.6931523084640503\n",
      "epoch: 7 step: 648 loss: 0.6931523084640503\n",
      "epoch: 7 step: 649 loss: 0.6931523084640503\n",
      "epoch: 7 step: 650 loss: 0.6931523084640503\n",
      "epoch: 7 step: 651 loss: 0.6931523084640503\n",
      "epoch: 7 step: 652 loss: 0.6931523084640503\n",
      "epoch: 7 step: 653 loss: 0.6931523084640503\n",
      "epoch: 7 step: 654 loss: 0.6931523084640503\n",
      "epoch: 7 step: 655 loss: 0.6931523084640503\n",
      "epoch: 7 step: 656 loss: 0.6931523084640503\n",
      "epoch: 7 step: 657 loss: 0.6931523084640503\n",
      "epoch: 7 step: 658 loss: 0.6931523084640503\n",
      "epoch: 7 step: 659 loss: 0.6931523084640503\n",
      "epoch: 7 step: 660 loss: 0.6931523084640503\n",
      "epoch: 7 step: 661 loss: 0.6931523084640503\n",
      "epoch: 7 step: 662 loss: 0.6931523084640503\n",
      "epoch: 7 step: 663 loss: 0.6931523084640503\n",
      "epoch: 7 step: 664 loss: 0.6931523084640503\n",
      "epoch: 7 step: 665 loss: 0.6931522488594055\n",
      "epoch: 7 step: 666 loss: 0.6931523084640503\n",
      "epoch: 7 step: 667 loss: 0.6931523084640503\n",
      "epoch: 7 step: 668 loss: 0.6931523084640503\n",
      "epoch: 7 step: 669 loss: 0.6931522488594055\n",
      "epoch: 7 step: 670 loss: 0.6931523084640503\n",
      "epoch: 7 step: 671 loss: 0.6931523084640503\n",
      "epoch: 7 step: 672 loss: 0.6931523084640503\n",
      "epoch: 7 step: 673 loss: 0.6931522488594055\n",
      "epoch: 7 step: 674 loss: 0.6931522488594055\n",
      "epoch: 7 step: 675 loss: 0.6931521892547607\n",
      "epoch: 7 step: 676 loss: 0.6931522488594055\n",
      "epoch: 7 step: 677 loss: 0.6931521892547607\n",
      "epoch: 7 step: 678 loss: 0.6931523084640503\n",
      "epoch: 7 step: 679 loss: 0.6931521892547607\n",
      "epoch: 7 step: 680 loss: 0.6931521892547607\n",
      "epoch: 7 step: 681 loss: 0.6931521892547607\n",
      "epoch: 7 step: 682 loss: 0.6931522488594055\n",
      "epoch: 7 step: 683 loss: 0.6931521892547607\n",
      "epoch: 7 step: 684 loss: 0.6931521892547607\n",
      "epoch: 7 step: 685 loss: 0.6931521892547607\n",
      "epoch: 7 step: 686 loss: 0.6931521892547607\n",
      "epoch: 7 step: 687 loss: 0.6931521892547607\n",
      "epoch: 7 step: 688 loss: 0.6931521892547607\n",
      "epoch: 7 step: 689 loss: 0.6931521892547607\n",
      "epoch: 7 step: 690 loss: 0.6931521892547607\n",
      "epoch: 7 step: 691 loss: 0.6931521892547607\n",
      "epoch: 7 step: 692 loss: 0.6931521892547607\n",
      "epoch: 7 step: 693 loss: 0.6931521892547607\n",
      "epoch: 7 step: 694 loss: 0.6931521892547607\n",
      "epoch: 7 step: 695 loss: 0.6931521892547607\n",
      "epoch: 7 step: 696 loss: 0.6931521892547607\n",
      "epoch: 7 step: 697 loss: 0.6931521892547607\n",
      "epoch: 7 step: 698 loss: 0.6931521892547607\n",
      "epoch: 7 step: 699 loss: 0.6931521892547607\n",
      "epoch: 7 step: 700 loss: 0.6931521892547607\n",
      "epoch: 7 step: 701 loss: 0.6931521892547607\n",
      "epoch: 7 step: 702 loss: 0.6931521892547607\n",
      "epoch: 7 step: 703 loss: 0.6931521892547607\n",
      "epoch: 7 step: 704 loss: 0.6931521892547607\n",
      "epoch: 7 step: 705 loss: 0.6931521892547607\n",
      "epoch: 7 step: 706 loss: 0.6931521892547607\n",
      "epoch: 7 step: 707 loss: 0.6931521892547607\n",
      "epoch: 7 step: 708 loss: 0.6931521892547607\n",
      "epoch: 7 step: 709 loss: 0.6931521892547607\n",
      "epoch: 7 step: 710 loss: 0.6931521892547607\n",
      "epoch: 7 step: 711 loss: 0.6931521892547607\n",
      "epoch: 7 step: 712 loss: 0.693152129650116\n",
      "epoch: 7 step: 713 loss: 0.6931521892547607\n",
      "epoch: 7 step: 714 loss: 0.6931521892547607\n",
      "epoch: 7 step: 715 loss: 0.6931521892547607\n",
      "epoch: 7 step: 716 loss: 0.693152129650116\n",
      "epoch: 7 step: 717 loss: 0.6931521892547607\n",
      "epoch: 7 step: 718 loss: 0.693152129650116\n",
      "epoch: 7 step: 719 loss: 0.693152129650116\n",
      "epoch: 7 step: 720 loss: 0.6931520700454712\n",
      "epoch: 7 step: 721 loss: 0.6931520700454712\n",
      "epoch: 7 step: 722 loss: 0.6931520700454712\n",
      "epoch: 7 step: 723 loss: 0.6931520700454712\n",
      "epoch: 7 step: 724 loss: 0.6931520700454712\n",
      "epoch: 7 step: 725 loss: 0.6931520700454712\n",
      "epoch: 7 step: 726 loss: 0.693152129650116\n",
      "epoch: 7 step: 727 loss: 0.6931520700454712\n",
      "epoch: 7 step: 728 loss: 0.6931520700454712\n",
      "epoch: 7 step: 729 loss: 0.6931520700454712\n",
      "epoch: 7 step: 730 loss: 0.6931520700454712\n",
      "epoch: 7 step: 731 loss: 0.6931520700454712\n",
      "epoch: 7 step: 732 loss: 0.6931520700454712\n",
      "epoch: 7 step: 733 loss: 0.6931520700454712\n",
      "epoch: 7 step: 734 loss: 0.6931520700454712\n",
      "epoch: 7 step: 735 loss: 0.6931520700454712\n",
      "epoch: 7 step: 736 loss: 0.6931520700454712\n",
      "epoch: 7 step: 737 loss: 0.6931520700454712\n",
      "epoch: 7 step: 738 loss: 0.6931520700454712\n",
      "epoch: 7 step: 739 loss: 0.6931520700454712\n",
      "epoch: 7 step: 740 loss: 0.6931520700454712\n",
      "epoch: 7 step: 741 loss: 0.6931520700454712\n",
      "epoch: 7 step: 742 loss: 0.6931520700454712\n",
      "epoch: 7 step: 743 loss: 0.6931520700454712\n",
      "epoch: 7 step: 744 loss: 0.6931520700454712\n",
      "epoch: 7 step: 745 loss: 0.6931520700454712\n",
      "epoch: 7 step: 746 loss: 0.6931520700454712\n",
      "epoch: 7 step: 747 loss: 0.6931520700454712\n",
      "epoch: 7 step: 748 loss: 0.6931520700454712\n",
      "epoch: 7 step: 749 loss: 0.6931520700454712\n",
      "epoch: 7 step: 750 loss: 0.6931520700454712\n",
      "epoch: 7 step: 751 loss: 0.6931520700454712\n",
      "epoch: 7 step: 752 loss: 0.6931520700454712\n",
      "epoch: 7 step: 753 loss: 0.6931520700454712\n",
      "epoch: 7 step: 754 loss: 0.6931520700454712\n",
      "epoch: 7 step: 755 loss: 0.6931520104408264\n",
      "epoch: 7 step: 756 loss: 0.6931520104408264\n",
      "epoch: 7 step: 757 loss: 0.6931520104408264\n",
      "epoch: 7 step: 758 loss: 0.6931520104408264\n",
      "epoch: 7 step: 759 loss: 0.6931520700454712\n",
      "epoch: 7 step: 760 loss: 0.6931520104408264\n",
      "epoch: 7 step: 761 loss: 0.6931520104408264\n",
      "epoch: 7 step: 762 loss: 0.6931520700454712\n",
      "epoch: 7 step: 763 loss: 0.6931520700454712\n",
      "epoch: 7 step: 764 loss: 0.6931520104408264\n",
      "epoch: 7 step: 765 loss: 0.6931520104408264\n",
      "epoch: 7 step: 766 loss: 0.6931519508361816\n",
      "epoch: 7 step: 767 loss: 0.6931519508361816\n",
      "epoch: 7 step: 768 loss: 0.6931519508361816\n",
      "epoch: 7 step: 769 loss: 0.6931519508361816\n",
      "epoch: 7 step: 770 loss: 0.6931519508361816\n",
      "epoch: 7 step: 771 loss: 0.6931519508361816\n",
      "epoch: 7 step: 772 loss: 0.6931519508361816\n",
      "epoch: 7 step: 773 loss: 0.6931519508361816\n",
      "epoch: 7 step: 774 loss: 0.6931519508361816\n",
      "epoch: 7 step: 775 loss: 0.6931519508361816\n",
      "epoch: 7 step: 776 loss: 0.6931519508361816\n",
      "epoch: 7 step: 777 loss: 0.6931519508361816\n",
      "epoch: 7 step: 778 loss: 0.6931519508361816\n",
      "epoch: 7 step: 779 loss: 0.6931519508361816\n",
      "epoch: 7 step: 780 loss: 0.6931519508361816\n",
      "epoch: 7 step: 781 loss: 0.6931519508361816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 1 loss: 0.6931519508361816\n",
      "epoch: 8 step: 2 loss: 0.6931519508361816\n",
      "epoch: 8 step: 3 loss: 0.6931519508361816\n",
      "epoch: 8 step: 4 loss: 0.6931519508361816\n",
      "epoch: 8 step: 5 loss: 0.6931519508361816\n",
      "epoch: 8 step: 6 loss: 0.6931519508361816\n",
      "epoch: 8 step: 7 loss: 0.6931519508361816\n",
      "epoch: 8 step: 8 loss: 0.6931519508361816\n",
      "epoch: 8 step: 9 loss: 0.6931519508361816\n",
      "epoch: 8 step: 10 loss: 0.6931519508361816\n",
      "epoch: 8 step: 11 loss: 0.6931519508361816\n",
      "epoch: 8 step: 12 loss: 0.6931519508361816\n",
      "epoch: 8 step: 13 loss: 0.6931519508361816\n",
      "epoch: 8 step: 14 loss: 0.6931519508361816\n",
      "epoch: 8 step: 15 loss: 0.6931519508361816\n",
      "epoch: 8 step: 16 loss: 0.6931518912315369\n",
      "epoch: 8 step: 17 loss: 0.6931519508361816\n",
      "epoch: 8 step: 18 loss: 0.6931518912315369\n",
      "epoch: 8 step: 19 loss: 0.6931519508361816\n",
      "epoch: 8 step: 20 loss: 0.6931519508361816\n",
      "epoch: 8 step: 21 loss: 0.6931519508361816\n",
      "epoch: 8 step: 22 loss: 0.6931519508361816\n",
      "epoch: 8 step: 23 loss: 0.6931518316268921\n",
      "epoch: 8 step: 24 loss: 0.6931518912315369\n",
      "epoch: 8 step: 25 loss: 0.6931518316268921\n",
      "epoch: 8 step: 26 loss: 0.6931518912315369\n",
      "epoch: 8 step: 27 loss: 0.6931518316268921\n",
      "epoch: 8 step: 28 loss: 0.6931518316268921\n",
      "epoch: 8 step: 29 loss: 0.6931518316268921\n",
      "epoch: 8 step: 30 loss: 0.6931518316268921\n",
      "epoch: 8 step: 31 loss: 0.6931518316268921\n",
      "epoch: 8 step: 32 loss: 0.6931518316268921\n",
      "epoch: 8 step: 33 loss: 0.6931518912315369\n",
      "epoch: 8 step: 34 loss: 0.6931518316268921\n",
      "epoch: 8 step: 35 loss: 0.6931518316268921\n",
      "epoch: 8 step: 36 loss: 0.6931518316268921\n",
      "epoch: 8 step: 37 loss: 0.6931518316268921\n",
      "epoch: 8 step: 38 loss: 0.6931518316268921\n",
      "epoch: 8 step: 39 loss: 0.6931518316268921\n",
      "epoch: 8 step: 40 loss: 0.6931518316268921\n",
      "epoch: 8 step: 41 loss: 0.6931518316268921\n",
      "epoch: 8 step: 42 loss: 0.6931518316268921\n",
      "epoch: 8 step: 43 loss: 0.6931518316268921\n",
      "epoch: 8 step: 44 loss: 0.6931518316268921\n",
      "epoch: 8 step: 45 loss: 0.6931518316268921\n",
      "epoch: 8 step: 46 loss: 0.6931518316268921\n",
      "epoch: 8 step: 47 loss: 0.6931518316268921\n",
      "epoch: 8 step: 48 loss: 0.6931518316268921\n",
      "epoch: 8 step: 49 loss: 0.6931518316268921\n",
      "epoch: 8 step: 50 loss: 0.6931518316268921\n",
      "epoch: 8 step: 51 loss: 0.6931518316268921\n",
      "epoch: 8 step: 52 loss: 0.6931518316268921\n",
      "epoch: 8 step: 53 loss: 0.6931518316268921\n",
      "epoch: 8 step: 54 loss: 0.6931518316268921\n",
      "epoch: 8 step: 55 loss: 0.6931518316268921\n",
      "epoch: 8 step: 56 loss: 0.6931518316268921\n",
      "epoch: 8 step: 57 loss: 0.6931518316268921\n",
      "epoch: 8 step: 58 loss: 0.6931518316268921\n",
      "epoch: 8 step: 59 loss: 0.6931518316268921\n",
      "epoch: 8 step: 60 loss: 0.6931518316268921\n",
      "epoch: 8 step: 61 loss: 0.6931517720222473\n",
      "epoch: 8 step: 62 loss: 0.6931518316268921\n",
      "epoch: 8 step: 63 loss: 0.6931517720222473\n",
      "epoch: 8 step: 64 loss: 0.6931518316268921\n",
      "epoch: 8 step: 65 loss: 0.6931518316268921\n",
      "epoch: 8 step: 66 loss: 0.6931517720222473\n",
      "epoch: 8 step: 67 loss: 0.6931517720222473\n",
      "epoch: 8 step: 68 loss: 0.6931518316268921\n",
      "epoch: 8 step: 69 loss: 0.6931517720222473\n",
      "epoch: 8 step: 70 loss: 0.6931517124176025\n",
      "epoch: 8 step: 71 loss: 0.6931518316268921\n",
      "epoch: 8 step: 72 loss: 0.6931517720222473\n",
      "epoch: 8 step: 73 loss: 0.6931517124176025\n",
      "epoch: 8 step: 74 loss: 0.6931517124176025\n",
      "epoch: 8 step: 75 loss: 0.6931517720222473\n",
      "epoch: 8 step: 76 loss: 0.6931517124176025\n",
      "epoch: 8 step: 77 loss: 0.6931517124176025\n",
      "epoch: 8 step: 78 loss: 0.6931517124176025\n",
      "epoch: 8 step: 79 loss: 0.6931517124176025\n",
      "epoch: 8 step: 80 loss: 0.6931517124176025\n",
      "epoch: 8 step: 81 loss: 0.6931517124176025\n",
      "epoch: 8 step: 82 loss: 0.6931517124176025\n",
      "epoch: 8 step: 83 loss: 0.6931517124176025\n",
      "epoch: 8 step: 84 loss: 0.6931517124176025\n",
      "epoch: 8 step: 85 loss: 0.6931517124176025\n",
      "epoch: 8 step: 86 loss: 0.6931517124176025\n",
      "epoch: 8 step: 87 loss: 0.6931517124176025\n",
      "epoch: 8 step: 88 loss: 0.6931517124176025\n",
      "epoch: 8 step: 89 loss: 0.6931517124176025\n",
      "epoch: 8 step: 90 loss: 0.6931517124176025\n",
      "epoch: 8 step: 91 loss: 0.6931517124176025\n",
      "epoch: 8 step: 92 loss: 0.6931517124176025\n",
      "epoch: 8 step: 93 loss: 0.6931517124176025\n",
      "epoch: 8 step: 94 loss: 0.6931517124176025\n",
      "epoch: 8 step: 95 loss: 0.6931517124176025\n",
      "epoch: 8 step: 96 loss: 0.6931517124176025\n",
      "epoch: 8 step: 97 loss: 0.6931517124176025\n",
      "epoch: 8 step: 98 loss: 0.6931517124176025\n",
      "epoch: 8 step: 99 loss: 0.6931517124176025\n",
      "epoch: 8 step: 100 loss: 0.6931517124176025\n",
      "epoch: 8 step: 101 loss: 0.6931517124176025\n",
      "epoch: 8 step: 102 loss: 0.6931517124176025\n",
      "epoch: 8 step: 103 loss: 0.6931517124176025\n",
      "epoch: 8 step: 104 loss: 0.6931517124176025\n",
      "epoch: 8 step: 105 loss: 0.6931517124176025\n",
      "epoch: 8 step: 106 loss: 0.6931517124176025\n",
      "epoch: 8 step: 107 loss: 0.6931517124176025\n",
      "epoch: 8 step: 108 loss: 0.6931517124176025\n",
      "epoch: 8 step: 109 loss: 0.693151593208313\n",
      "epoch: 8 step: 110 loss: 0.6931516528129578\n",
      "epoch: 8 step: 111 loss: 0.6931517124176025\n",
      "epoch: 8 step: 112 loss: 0.6931516528129578\n",
      "epoch: 8 step: 113 loss: 0.693151593208313\n",
      "epoch: 8 step: 114 loss: 0.693151593208313\n",
      "epoch: 8 step: 115 loss: 0.693151593208313\n",
      "epoch: 8 step: 116 loss: 0.693151593208313\n",
      "epoch: 8 step: 117 loss: 0.693151593208313\n",
      "epoch: 8 step: 118 loss: 0.693151593208313\n",
      "epoch: 8 step: 119 loss: 0.6931516528129578\n",
      "epoch: 8 step: 120 loss: 0.693151593208313\n",
      "epoch: 8 step: 121 loss: 0.693151593208313\n",
      "epoch: 8 step: 122 loss: 0.693151593208313\n",
      "epoch: 8 step: 123 loss: 0.693151593208313\n",
      "epoch: 8 step: 124 loss: 0.693151593208313\n",
      "epoch: 8 step: 125 loss: 0.693151593208313\n",
      "epoch: 8 step: 126 loss: 0.693151593208313\n",
      "epoch: 8 step: 127 loss: 0.693151593208313\n",
      "epoch: 8 step: 128 loss: 0.693151593208313\n",
      "epoch: 8 step: 129 loss: 0.693151593208313\n",
      "epoch: 8 step: 130 loss: 0.693151593208313\n",
      "epoch: 8 step: 131 loss: 0.693151593208313\n",
      "epoch: 8 step: 132 loss: 0.693151593208313\n",
      "epoch: 8 step: 133 loss: 0.693151593208313\n",
      "epoch: 8 step: 134 loss: 0.693151593208313\n",
      "epoch: 8 step: 135 loss: 0.693151593208313\n",
      "epoch: 8 step: 136 loss: 0.693151593208313\n",
      "epoch: 8 step: 137 loss: 0.693151593208313\n",
      "epoch: 8 step: 138 loss: 0.693151593208313\n",
      "epoch: 8 step: 139 loss: 0.693151593208313\n",
      "epoch: 8 step: 140 loss: 0.693151593208313\n",
      "epoch: 8 step: 141 loss: 0.693151593208313\n",
      "epoch: 8 step: 142 loss: 0.693151593208313\n",
      "epoch: 8 step: 143 loss: 0.693151593208313\n",
      "epoch: 8 step: 144 loss: 0.693151593208313\n",
      "epoch: 8 step: 145 loss: 0.693151593208313\n",
      "epoch: 8 step: 146 loss: 0.693151593208313\n",
      "epoch: 8 step: 147 loss: 0.693151593208313\n",
      "epoch: 8 step: 148 loss: 0.693151593208313\n",
      "epoch: 8 step: 149 loss: 0.693151593208313\n",
      "epoch: 8 step: 150 loss: 0.693151593208313\n",
      "epoch: 8 step: 151 loss: 0.693151593208313\n",
      "epoch: 8 step: 152 loss: 0.693151593208313\n",
      "epoch: 8 step: 153 loss: 0.693151593208313\n",
      "epoch: 8 step: 154 loss: 0.6931515336036682\n",
      "epoch: 8 step: 155 loss: 0.693151593208313\n",
      "epoch: 8 step: 156 loss: 0.6931515336036682\n",
      "epoch: 8 step: 157 loss: 0.693151593208313\n",
      "epoch: 8 step: 158 loss: 0.6931515336036682\n",
      "epoch: 8 step: 159 loss: 0.6931515336036682\n",
      "epoch: 8 step: 160 loss: 0.6931514739990234\n",
      "epoch: 8 step: 161 loss: 0.6931515336036682\n",
      "epoch: 8 step: 162 loss: 0.6931514739990234\n",
      "epoch: 8 step: 163 loss: 0.6931514739990234\n",
      "epoch: 8 step: 164 loss: 0.6931514739990234\n",
      "epoch: 8 step: 165 loss: 0.6931514739990234\n",
      "epoch: 8 step: 166 loss: 0.6931515336036682\n",
      "epoch: 8 step: 167 loss: 0.6931514739990234\n",
      "epoch: 8 step: 168 loss: 0.6931515336036682\n",
      "epoch: 8 step: 169 loss: 0.6931514739990234\n",
      "epoch: 8 step: 170 loss: 0.6931514739990234\n",
      "epoch: 8 step: 171 loss: 0.6931514739990234\n",
      "epoch: 8 step: 172 loss: 0.6931514739990234\n",
      "epoch: 8 step: 173 loss: 0.6931514739990234\n",
      "epoch: 8 step: 174 loss: 0.6931514739990234\n",
      "epoch: 8 step: 175 loss: 0.6931514739990234\n",
      "epoch: 8 step: 176 loss: 0.6931514739990234\n",
      "epoch: 8 step: 177 loss: 0.6931514739990234\n",
      "epoch: 8 step: 178 loss: 0.6931514739990234\n",
      "epoch: 8 step: 179 loss: 0.6931514739990234\n",
      "epoch: 8 step: 180 loss: 0.6931514739990234\n",
      "epoch: 8 step: 181 loss: 0.6931514739990234\n",
      "epoch: 8 step: 182 loss: 0.6931514739990234\n",
      "epoch: 8 step: 183 loss: 0.6931514739990234\n",
      "epoch: 8 step: 184 loss: 0.6931514739990234\n",
      "epoch: 8 step: 185 loss: 0.6931514739990234\n",
      "epoch: 8 step: 186 loss: 0.6931514739990234\n",
      "epoch: 8 step: 187 loss: 0.6931514739990234\n",
      "epoch: 8 step: 188 loss: 0.6931514739990234\n",
      "epoch: 8 step: 189 loss: 0.6931514739990234\n",
      "epoch: 8 step: 190 loss: 0.6931514739990234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 191 loss: 0.6931514739990234\n",
      "epoch: 8 step: 192 loss: 0.6931514739990234\n",
      "epoch: 8 step: 193 loss: 0.6931514739990234\n",
      "epoch: 8 step: 194 loss: 0.6931514739990234\n",
      "epoch: 8 step: 195 loss: 0.6931514739990234\n",
      "epoch: 8 step: 196 loss: 0.6931514739990234\n",
      "epoch: 8 step: 197 loss: 0.6931514739990234\n",
      "epoch: 8 step: 198 loss: 0.6931514739990234\n",
      "epoch: 8 step: 199 loss: 0.6931514739990234\n",
      "epoch: 8 step: 200 loss: 0.6931514739990234\n",
      "epoch: 8 step: 201 loss: 0.6931514739990234\n",
      "epoch: 8 step: 202 loss: 0.6931514739990234\n",
      "epoch: 8 step: 203 loss: 0.6931514143943787\n",
      "epoch: 8 step: 204 loss: 0.6931514739990234\n",
      "epoch: 8 step: 205 loss: 0.6931514143943787\n",
      "epoch: 8 step: 206 loss: 0.6931514143943787\n",
      "epoch: 8 step: 207 loss: 0.6931514143943787\n",
      "epoch: 8 step: 208 loss: 0.6931514739990234\n",
      "epoch: 8 step: 209 loss: 0.6931514739990234\n",
      "epoch: 8 step: 210 loss: 0.6931513547897339\n",
      "epoch: 8 step: 211 loss: 0.6931514143943787\n",
      "epoch: 8 step: 212 loss: 0.6931513547897339\n",
      "epoch: 8 step: 213 loss: 0.6931513547897339\n",
      "epoch: 8 step: 214 loss: 0.6931513547897339\n",
      "epoch: 8 step: 215 loss: 0.6931513547897339\n",
      "epoch: 8 step: 216 loss: 0.6931513547897339\n",
      "epoch: 8 step: 217 loss: 0.6931513547897339\n",
      "epoch: 8 step: 218 loss: 0.6931513547897339\n",
      "epoch: 8 step: 219 loss: 0.6931513547897339\n",
      "epoch: 8 step: 220 loss: 0.6931513547897339\n",
      "epoch: 8 step: 221 loss: 0.6931513547897339\n",
      "epoch: 8 step: 222 loss: 0.6931513547897339\n",
      "epoch: 8 step: 223 loss: 0.6931513547897339\n",
      "epoch: 8 step: 224 loss: 0.6931513547897339\n",
      "epoch: 8 step: 225 loss: 0.6931513547897339\n",
      "epoch: 8 step: 226 loss: 0.6931513547897339\n",
      "epoch: 8 step: 227 loss: 0.6931513547897339\n",
      "epoch: 8 step: 228 loss: 0.6931513547897339\n",
      "epoch: 8 step: 229 loss: 0.6931513547897339\n",
      "epoch: 8 step: 230 loss: 0.6931513547897339\n",
      "epoch: 8 step: 231 loss: 0.6931513547897339\n",
      "epoch: 8 step: 232 loss: 0.6931513547897339\n",
      "epoch: 8 step: 233 loss: 0.6931513547897339\n",
      "epoch: 8 step: 234 loss: 0.6931513547897339\n",
      "epoch: 8 step: 235 loss: 0.6931513547897339\n",
      "epoch: 8 step: 236 loss: 0.6931513547897339\n",
      "epoch: 8 step: 237 loss: 0.6931513547897339\n",
      "epoch: 8 step: 238 loss: 0.6931513547897339\n",
      "epoch: 8 step: 239 loss: 0.6931513547897339\n",
      "epoch: 8 step: 240 loss: 0.6931513547897339\n",
      "epoch: 8 step: 241 loss: 0.6931513547897339\n",
      "epoch: 8 step: 242 loss: 0.6931513547897339\n",
      "epoch: 8 step: 243 loss: 0.6931513547897339\n",
      "epoch: 8 step: 244 loss: 0.6931513547897339\n",
      "epoch: 8 step: 245 loss: 0.6931513547897339\n",
      "epoch: 8 step: 246 loss: 0.6931513547897339\n",
      "epoch: 8 step: 247 loss: 0.6931513547897339\n",
      "epoch: 8 step: 248 loss: 0.6931513547897339\n",
      "epoch: 8 step: 249 loss: 0.6931513547897339\n",
      "epoch: 8 step: 250 loss: 0.6931512951850891\n",
      "epoch: 8 step: 251 loss: 0.6931512951850891\n",
      "epoch: 8 step: 252 loss: 0.6931512951850891\n",
      "epoch: 8 step: 253 loss: 0.6931513547897339\n",
      "epoch: 8 step: 254 loss: 0.6931513547897339\n",
      "epoch: 8 step: 255 loss: 0.6931513547897339\n",
      "epoch: 8 step: 256 loss: 0.6931512951850891\n",
      "epoch: 8 step: 257 loss: 0.6931513547897339\n",
      "epoch: 8 step: 258 loss: 0.6931512951850891\n",
      "epoch: 8 step: 259 loss: 0.6931513547897339\n",
      "epoch: 8 step: 260 loss: 0.6931512355804443\n",
      "epoch: 8 step: 261 loss: 0.6931512355804443\n",
      "epoch: 8 step: 262 loss: 0.6931512355804443\n",
      "epoch: 8 step: 263 loss: 0.6931512355804443\n",
      "epoch: 8 step: 264 loss: 0.6931512355804443\n",
      "epoch: 8 step: 265 loss: 0.6931512355804443\n",
      "epoch: 8 step: 266 loss: 0.6931512355804443\n",
      "epoch: 8 step: 267 loss: 0.6931512951850891\n",
      "epoch: 8 step: 268 loss: 0.6931512355804443\n",
      "epoch: 8 step: 269 loss: 0.6931512951850891\n",
      "epoch: 8 step: 270 loss: 0.6931512355804443\n",
      "epoch: 8 step: 271 loss: 0.6931512355804443\n",
      "epoch: 8 step: 272 loss: 0.6931512355804443\n",
      "epoch: 8 step: 273 loss: 0.6931512355804443\n",
      "epoch: 8 step: 274 loss: 0.6931512355804443\n",
      "epoch: 8 step: 275 loss: 0.6931512355804443\n",
      "epoch: 8 step: 276 loss: 0.6931512355804443\n",
      "epoch: 8 step: 277 loss: 0.6931512355804443\n",
      "epoch: 8 step: 278 loss: 0.6931512355804443\n",
      "epoch: 8 step: 279 loss: 0.6931512355804443\n",
      "epoch: 8 step: 280 loss: 0.6931512355804443\n",
      "epoch: 8 step: 281 loss: 0.6931512355804443\n",
      "epoch: 8 step: 282 loss: 0.6931512355804443\n",
      "epoch: 8 step: 283 loss: 0.6931512355804443\n",
      "epoch: 8 step: 284 loss: 0.6931512355804443\n",
      "epoch: 8 step: 285 loss: 0.6931512355804443\n",
      "epoch: 8 step: 286 loss: 0.6931512355804443\n",
      "epoch: 8 step: 287 loss: 0.6931512355804443\n",
      "epoch: 8 step: 288 loss: 0.6931512355804443\n",
      "epoch: 8 step: 289 loss: 0.6931512355804443\n",
      "epoch: 8 step: 290 loss: 0.6931512355804443\n",
      "epoch: 8 step: 291 loss: 0.6931512355804443\n",
      "epoch: 8 step: 292 loss: 0.6931512355804443\n",
      "epoch: 8 step: 293 loss: 0.6931512355804443\n",
      "epoch: 8 step: 294 loss: 0.6931512355804443\n",
      "epoch: 8 step: 295 loss: 0.6931512355804443\n",
      "epoch: 8 step: 296 loss: 0.6931512355804443\n",
      "epoch: 8 step: 297 loss: 0.6931512355804443\n",
      "epoch: 8 step: 298 loss: 0.6931512355804443\n",
      "epoch: 8 step: 299 loss: 0.6931512355804443\n",
      "epoch: 8 step: 300 loss: 0.6931512355804443\n",
      "epoch: 8 step: 301 loss: 0.6931512355804443\n",
      "epoch: 8 step: 302 loss: 0.6931512355804443\n",
      "epoch: 8 step: 303 loss: 0.6931512355804443\n",
      "epoch: 8 step: 304 loss: 0.6931512355804443\n",
      "epoch: 8 step: 305 loss: 0.6931512355804443\n",
      "epoch: 8 step: 306 loss: 0.6931511759757996\n",
      "epoch: 8 step: 307 loss: 0.6931511163711548\n",
      "epoch: 8 step: 308 loss: 0.6931512355804443\n",
      "epoch: 8 step: 309 loss: 0.6931512355804443\n",
      "epoch: 8 step: 310 loss: 0.6931512355804443\n",
      "epoch: 8 step: 311 loss: 0.6931511759757996\n",
      "epoch: 8 step: 312 loss: 0.6931512355804443\n",
      "epoch: 8 step: 313 loss: 0.6931511759757996\n",
      "epoch: 8 step: 314 loss: 0.6931511163711548\n",
      "epoch: 8 step: 315 loss: 0.6931511163711548\n",
      "epoch: 8 step: 316 loss: 0.6931511759757996\n",
      "epoch: 8 step: 317 loss: 0.6931511163711548\n",
      "epoch: 8 step: 318 loss: 0.6931511163711548\n",
      "epoch: 8 step: 319 loss: 0.6931511163711548\n",
      "epoch: 8 step: 320 loss: 0.6931511163711548\n",
      "epoch: 8 step: 321 loss: 0.6931511163711548\n",
      "epoch: 8 step: 322 loss: 0.6931511163711548\n",
      "epoch: 8 step: 323 loss: 0.6931511163711548\n",
      "epoch: 8 step: 324 loss: 0.6931511163711548\n",
      "epoch: 8 step: 325 loss: 0.6931511163711548\n",
      "epoch: 8 step: 326 loss: 0.6931511163711548\n",
      "epoch: 8 step: 327 loss: 0.6931511163711548\n",
      "epoch: 8 step: 328 loss: 0.6931511163711548\n",
      "epoch: 8 step: 329 loss: 0.6931511163711548\n",
      "epoch: 8 step: 330 loss: 0.6931511163711548\n",
      "epoch: 8 step: 331 loss: 0.6931511163711548\n",
      "epoch: 8 step: 332 loss: 0.6931511163711548\n",
      "epoch: 8 step: 333 loss: 0.6931511163711548\n",
      "epoch: 8 step: 334 loss: 0.6931511163711548\n",
      "epoch: 8 step: 335 loss: 0.6931511163711548\n",
      "epoch: 8 step: 336 loss: 0.6931511163711548\n",
      "epoch: 8 step: 337 loss: 0.6931511163711548\n",
      "epoch: 8 step: 338 loss: 0.6931511163711548\n",
      "epoch: 8 step: 339 loss: 0.6931511163711548\n",
      "epoch: 8 step: 340 loss: 0.6931511163711548\n",
      "epoch: 8 step: 341 loss: 0.6931511163711548\n",
      "epoch: 8 step: 342 loss: 0.6931511163711548\n",
      "epoch: 8 step: 343 loss: 0.6931511163711548\n",
      "epoch: 8 step: 344 loss: 0.6931511163711548\n",
      "epoch: 8 step: 345 loss: 0.6931511163711548\n",
      "epoch: 8 step: 346 loss: 0.6931511163711548\n",
      "epoch: 8 step: 347 loss: 0.6931511163711548\n",
      "epoch: 8 step: 348 loss: 0.6931511163711548\n",
      "epoch: 8 step: 349 loss: 0.6931511163711548\n",
      "epoch: 8 step: 350 loss: 0.6931511163711548\n",
      "epoch: 8 step: 351 loss: 0.6931511163711548\n",
      "epoch: 8 step: 352 loss: 0.6931511163711548\n",
      "epoch: 8 step: 353 loss: 0.6931511163711548\n",
      "epoch: 8 step: 354 loss: 0.6931511163711548\n",
      "epoch: 8 step: 355 loss: 0.6931511163711548\n",
      "epoch: 8 step: 356 loss: 0.6931511163711548\n",
      "epoch: 8 step: 357 loss: 0.69315105676651\n",
      "epoch: 8 step: 358 loss: 0.69315105676651\n",
      "epoch: 8 step: 359 loss: 0.69315105676651\n",
      "epoch: 8 step: 360 loss: 0.6931511163711548\n",
      "epoch: 8 step: 361 loss: 0.69315105676651\n",
      "epoch: 8 step: 362 loss: 0.6931511163711548\n",
      "epoch: 8 step: 363 loss: 0.69315105676651\n",
      "epoch: 8 step: 364 loss: 0.69315105676651\n",
      "epoch: 8 step: 365 loss: 0.6931509971618652\n",
      "epoch: 8 step: 366 loss: 0.6931511163711548\n",
      "epoch: 8 step: 367 loss: 0.69315105676651\n",
      "epoch: 8 step: 368 loss: 0.6931509971618652\n",
      "epoch: 8 step: 369 loss: 0.6931509971618652\n",
      "epoch: 8 step: 370 loss: 0.6931509971618652\n",
      "epoch: 8 step: 371 loss: 0.6931509971618652\n",
      "epoch: 8 step: 372 loss: 0.6931509971618652\n",
      "epoch: 8 step: 373 loss: 0.6931509971618652\n",
      "epoch: 8 step: 374 loss: 0.6931509971618652\n",
      "epoch: 8 step: 375 loss: 0.6931509971618652\n",
      "epoch: 8 step: 376 loss: 0.6931509971618652\n",
      "epoch: 8 step: 377 loss: 0.6931509971618652\n",
      "epoch: 8 step: 378 loss: 0.6931509971618652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 379 loss: 0.6931509971618652\n",
      "epoch: 8 step: 380 loss: 0.6931509971618652\n",
      "epoch: 8 step: 381 loss: 0.6931509971618652\n",
      "epoch: 8 step: 382 loss: 0.6931509971618652\n",
      "epoch: 8 step: 383 loss: 0.6931509971618652\n",
      "epoch: 8 step: 384 loss: 0.6931509971618652\n",
      "epoch: 8 step: 385 loss: 0.6931509971618652\n",
      "epoch: 8 step: 386 loss: 0.6931509971618652\n",
      "epoch: 8 step: 387 loss: 0.6931509971618652\n",
      "epoch: 8 step: 388 loss: 0.6931509971618652\n",
      "epoch: 8 step: 389 loss: 0.6931509971618652\n",
      "epoch: 8 step: 390 loss: 0.6931509971618652\n",
      "epoch: 8 step: 391 loss: 0.6931509971618652\n",
      "epoch: 8 step: 392 loss: 0.6931509971618652\n",
      "epoch: 8 step: 393 loss: 0.6931509971618652\n",
      "epoch: 8 step: 394 loss: 0.6931509971618652\n",
      "epoch: 8 step: 395 loss: 0.6931509971618652\n",
      "epoch: 8 step: 396 loss: 0.6931509971618652\n",
      "epoch: 8 step: 397 loss: 0.6931509971618652\n",
      "epoch: 8 step: 398 loss: 0.6931509971618652\n",
      "epoch: 8 step: 399 loss: 0.6931509971618652\n",
      "epoch: 8 step: 400 loss: 0.6931509971618652\n",
      "epoch: 8 step: 401 loss: 0.6931509971618652\n",
      "epoch: 8 step: 402 loss: 0.6931509971618652\n",
      "epoch: 8 step: 403 loss: 0.6931509971618652\n",
      "epoch: 8 step: 404 loss: 0.6931509971618652\n",
      "epoch: 8 step: 405 loss: 0.6931509971618652\n",
      "epoch: 8 step: 406 loss: 0.6931509971618652\n",
      "epoch: 8 step: 407 loss: 0.6931509971618652\n",
      "epoch: 8 step: 408 loss: 0.6931509971618652\n",
      "epoch: 8 step: 409 loss: 0.6931509971618652\n",
      "epoch: 8 step: 410 loss: 0.6931509971618652\n",
      "epoch: 8 step: 411 loss: 0.6931509971618652\n",
      "epoch: 8 step: 412 loss: 0.6931509971618652\n",
      "epoch: 8 step: 413 loss: 0.6931509375572205\n",
      "epoch: 8 step: 414 loss: 0.6931509375572205\n",
      "epoch: 8 step: 415 loss: 0.6931509971618652\n",
      "epoch: 8 step: 416 loss: 0.6931509971618652\n",
      "epoch: 8 step: 417 loss: 0.6931509375572205\n",
      "epoch: 8 step: 418 loss: 0.6931509971618652\n",
      "epoch: 8 step: 419 loss: 0.6931508779525757\n",
      "epoch: 8 step: 420 loss: 0.6931508779525757\n",
      "epoch: 8 step: 421 loss: 0.6931508779525757\n",
      "epoch: 8 step: 422 loss: 0.6931508779525757\n",
      "epoch: 8 step: 423 loss: 0.6931509375572205\n",
      "epoch: 8 step: 424 loss: 0.6931509375572205\n",
      "epoch: 8 step: 425 loss: 0.6931508779525757\n",
      "epoch: 8 step: 426 loss: 0.6931508779525757\n",
      "epoch: 8 step: 427 loss: 0.6931508779525757\n",
      "epoch: 8 step: 428 loss: 0.6931508779525757\n",
      "epoch: 8 step: 429 loss: 0.6931508779525757\n",
      "epoch: 8 step: 430 loss: 0.6931508779525757\n",
      "epoch: 8 step: 431 loss: 0.6931508779525757\n",
      "epoch: 8 step: 432 loss: 0.6931508779525757\n",
      "epoch: 8 step: 433 loss: 0.6931508779525757\n",
      "epoch: 8 step: 434 loss: 0.6931508779525757\n",
      "epoch: 8 step: 435 loss: 0.6931508779525757\n",
      "epoch: 8 step: 436 loss: 0.6931508779525757\n",
      "epoch: 8 step: 437 loss: 0.6931508779525757\n",
      "epoch: 8 step: 438 loss: 0.6931508779525757\n",
      "epoch: 8 step: 439 loss: 0.6931508779525757\n",
      "epoch: 8 step: 440 loss: 0.6931508779525757\n",
      "epoch: 8 step: 441 loss: 0.6931508779525757\n",
      "epoch: 8 step: 442 loss: 0.6931508779525757\n",
      "epoch: 8 step: 443 loss: 0.6931508779525757\n",
      "epoch: 8 step: 444 loss: 0.6931508779525757\n",
      "epoch: 8 step: 445 loss: 0.6931508779525757\n",
      "epoch: 8 step: 446 loss: 0.6931508779525757\n",
      "epoch: 8 step: 447 loss: 0.6931508779525757\n",
      "epoch: 8 step: 448 loss: 0.6931508779525757\n",
      "epoch: 8 step: 449 loss: 0.6931508779525757\n",
      "epoch: 8 step: 450 loss: 0.6931508779525757\n",
      "epoch: 8 step: 451 loss: 0.6931508779525757\n",
      "epoch: 8 step: 452 loss: 0.6931508779525757\n",
      "epoch: 8 step: 453 loss: 0.6931508779525757\n",
      "epoch: 8 step: 454 loss: 0.6931508779525757\n",
      "epoch: 8 step: 455 loss: 0.6931508779525757\n",
      "epoch: 8 step: 456 loss: 0.6931508779525757\n",
      "epoch: 8 step: 457 loss: 0.6931508779525757\n",
      "epoch: 8 step: 458 loss: 0.6931508779525757\n",
      "epoch: 8 step: 459 loss: 0.6931508779525757\n",
      "epoch: 8 step: 460 loss: 0.6931508779525757\n",
      "epoch: 8 step: 461 loss: 0.6931508779525757\n",
      "epoch: 8 step: 462 loss: 0.6931508779525757\n",
      "epoch: 8 step: 463 loss: 0.6931508779525757\n",
      "epoch: 8 step: 464 loss: 0.6931508779525757\n",
      "epoch: 8 step: 465 loss: 0.6931508183479309\n",
      "epoch: 8 step: 466 loss: 0.6931508779525757\n",
      "epoch: 8 step: 467 loss: 0.6931508779525757\n",
      "epoch: 8 step: 468 loss: 0.6931508779525757\n",
      "epoch: 8 step: 469 loss: 0.6931508779525757\n",
      "epoch: 8 step: 470 loss: 0.6931508779525757\n",
      "epoch: 8 step: 471 loss: 0.6931508779525757\n",
      "epoch: 8 step: 472 loss: 0.6931508779525757\n",
      "epoch: 8 step: 473 loss: 0.6931508779525757\n",
      "epoch: 8 step: 474 loss: 0.6931507587432861\n",
      "epoch: 8 step: 475 loss: 0.6931508779525757\n",
      "epoch: 8 step: 476 loss: 0.6931508183479309\n",
      "epoch: 8 step: 477 loss: 0.6931507587432861\n",
      "epoch: 8 step: 478 loss: 0.6931508183479309\n",
      "epoch: 8 step: 479 loss: 0.6931508183479309\n",
      "epoch: 8 step: 480 loss: 0.6931508183479309\n",
      "epoch: 8 step: 481 loss: 0.6931508183479309\n",
      "epoch: 8 step: 482 loss: 0.6931507587432861\n",
      "epoch: 8 step: 483 loss: 0.6931507587432861\n",
      "epoch: 8 step: 484 loss: 0.6931507587432861\n",
      "epoch: 8 step: 485 loss: 0.6931507587432861\n",
      "epoch: 8 step: 486 loss: 0.6931507587432861\n",
      "epoch: 8 step: 487 loss: 0.6931507587432861\n",
      "epoch: 8 step: 488 loss: 0.6931507587432861\n",
      "epoch: 8 step: 489 loss: 0.6931507587432861\n",
      "epoch: 8 step: 490 loss: 0.6931507587432861\n",
      "epoch: 8 step: 491 loss: 0.6931507587432861\n",
      "epoch: 8 step: 492 loss: 0.6931507587432861\n",
      "epoch: 8 step: 493 loss: 0.6931507587432861\n",
      "epoch: 8 step: 494 loss: 0.6931507587432861\n",
      "epoch: 8 step: 495 loss: 0.6931507587432861\n",
      "epoch: 8 step: 496 loss: 0.6931507587432861\n",
      "epoch: 8 step: 497 loss: 0.6931507587432861\n",
      "epoch: 8 step: 498 loss: 0.6931507587432861\n",
      "epoch: 8 step: 499 loss: 0.6931507587432861\n",
      "epoch: 8 step: 500 loss: 0.6931507587432861\n",
      "epoch: 8 step: 501 loss: 0.6931507587432861\n",
      "epoch: 8 step: 502 loss: 0.6931507587432861\n",
      "epoch: 8 step: 503 loss: 0.6931507587432861\n",
      "epoch: 8 step: 504 loss: 0.6931507587432861\n",
      "epoch: 8 step: 505 loss: 0.6931507587432861\n",
      "epoch: 8 step: 506 loss: 0.6931507587432861\n",
      "epoch: 8 step: 507 loss: 0.6931507587432861\n",
      "epoch: 8 step: 508 loss: 0.6931507587432861\n",
      "epoch: 8 step: 509 loss: 0.6931507587432861\n",
      "epoch: 8 step: 510 loss: 0.6931507587432861\n",
      "epoch: 8 step: 511 loss: 0.6931507587432861\n",
      "epoch: 8 step: 512 loss: 0.6931507587432861\n",
      "epoch: 8 step: 513 loss: 0.6931507587432861\n",
      "epoch: 8 step: 514 loss: 0.6931507587432861\n",
      "epoch: 8 step: 515 loss: 0.6931507587432861\n",
      "epoch: 8 step: 516 loss: 0.6931507587432861\n",
      "epoch: 8 step: 517 loss: 0.6931507587432861\n",
      "epoch: 8 step: 518 loss: 0.6931507587432861\n",
      "epoch: 8 step: 519 loss: 0.6931507587432861\n",
      "epoch: 8 step: 520 loss: 0.6931507587432861\n",
      "epoch: 8 step: 521 loss: 0.6931507587432861\n",
      "epoch: 8 step: 522 loss: 0.6931507587432861\n",
      "epoch: 8 step: 523 loss: 0.6931507587432861\n",
      "epoch: 8 step: 524 loss: 0.6931507587432861\n",
      "epoch: 8 step: 525 loss: 0.6931507587432861\n",
      "epoch: 8 step: 526 loss: 0.6931507587432861\n",
      "epoch: 8 step: 527 loss: 0.6931507587432861\n",
      "epoch: 8 step: 528 loss: 0.6931507587432861\n",
      "epoch: 8 step: 529 loss: 0.6931507587432861\n",
      "epoch: 8 step: 530 loss: 0.6931507587432861\n",
      "epoch: 8 step: 531 loss: 0.6931506991386414\n",
      "epoch: 8 step: 532 loss: 0.6931507587432861\n",
      "epoch: 8 step: 533 loss: 0.6931506991386414\n",
      "epoch: 8 step: 534 loss: 0.6931507587432861\n",
      "epoch: 8 step: 535 loss: 0.6931507587432861\n",
      "epoch: 8 step: 536 loss: 0.6931507587432861\n",
      "epoch: 8 step: 537 loss: 0.6931507587432861\n",
      "epoch: 8 step: 538 loss: 0.6931506991386414\n",
      "epoch: 8 step: 539 loss: 0.6931506991386414\n",
      "epoch: 8 step: 540 loss: 0.6931506395339966\n",
      "epoch: 8 step: 541 loss: 0.6931506991386414\n",
      "epoch: 8 step: 542 loss: 0.6931506991386414\n",
      "epoch: 8 step: 543 loss: 0.6931506395339966\n",
      "epoch: 8 step: 544 loss: 0.6931506395339966\n",
      "epoch: 8 step: 545 loss: 0.6931506395339966\n",
      "epoch: 8 step: 546 loss: 0.6931506395339966\n",
      "epoch: 8 step: 547 loss: 0.6931506395339966\n",
      "epoch: 8 step: 548 loss: 0.6931506395339966\n",
      "epoch: 8 step: 549 loss: 0.6931506395339966\n",
      "epoch: 8 step: 550 loss: 0.6931506395339966\n",
      "epoch: 8 step: 551 loss: 0.6931506395339966\n",
      "epoch: 8 step: 552 loss: 0.6931506395339966\n",
      "epoch: 8 step: 553 loss: 0.6931506395339966\n",
      "epoch: 8 step: 554 loss: 0.6931506395339966\n",
      "epoch: 8 step: 555 loss: 0.6931506395339966\n",
      "epoch: 8 step: 556 loss: 0.6931506395339966\n",
      "epoch: 8 step: 557 loss: 0.6931506395339966\n",
      "epoch: 8 step: 558 loss: 0.6931506395339966\n",
      "epoch: 8 step: 559 loss: 0.6931506395339966\n",
      "epoch: 8 step: 560 loss: 0.6931506395339966\n",
      "epoch: 8 step: 561 loss: 0.6931506395339966\n",
      "epoch: 8 step: 562 loss: 0.6931506395339966\n",
      "epoch: 8 step: 563 loss: 0.6931506395339966\n",
      "epoch: 8 step: 564 loss: 0.6931506395339966\n",
      "epoch: 8 step: 565 loss: 0.6931506395339966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 566 loss: 0.6931506395339966\n",
      "epoch: 8 step: 567 loss: 0.6931506395339966\n",
      "epoch: 8 step: 568 loss: 0.6931506395339966\n",
      "epoch: 8 step: 569 loss: 0.6931506395339966\n",
      "epoch: 8 step: 570 loss: 0.6931506395339966\n",
      "epoch: 8 step: 571 loss: 0.6931506395339966\n",
      "epoch: 8 step: 572 loss: 0.6931506395339966\n",
      "epoch: 8 step: 573 loss: 0.6931506395339966\n",
      "epoch: 8 step: 574 loss: 0.6931506395339966\n",
      "epoch: 8 step: 575 loss: 0.6931506395339966\n",
      "epoch: 8 step: 576 loss: 0.6931506395339966\n",
      "epoch: 8 step: 577 loss: 0.6931506395339966\n",
      "epoch: 8 step: 578 loss: 0.6931506395339966\n",
      "epoch: 8 step: 579 loss: 0.6931506395339966\n",
      "epoch: 8 step: 580 loss: 0.6931506395339966\n",
      "epoch: 8 step: 581 loss: 0.6931506395339966\n",
      "epoch: 8 step: 582 loss: 0.6931506395339966\n",
      "epoch: 8 step: 583 loss: 0.6931506395339966\n",
      "epoch: 8 step: 584 loss: 0.6931506395339966\n",
      "epoch: 8 step: 585 loss: 0.6931506395339966\n",
      "epoch: 8 step: 586 loss: 0.6931506395339966\n",
      "epoch: 8 step: 587 loss: 0.6931506395339966\n",
      "epoch: 8 step: 588 loss: 0.6931506395339966\n",
      "epoch: 8 step: 589 loss: 0.693150520324707\n",
      "epoch: 8 step: 590 loss: 0.6931506395339966\n",
      "epoch: 8 step: 591 loss: 0.6931506395339966\n",
      "epoch: 8 step: 592 loss: 0.693150520324707\n",
      "epoch: 8 step: 593 loss: 0.6931506395339966\n",
      "epoch: 8 step: 594 loss: 0.6931506395339966\n",
      "epoch: 8 step: 595 loss: 0.6931505799293518\n",
      "epoch: 8 step: 596 loss: 0.6931505799293518\n",
      "epoch: 8 step: 597 loss: 0.693150520324707\n",
      "epoch: 8 step: 598 loss: 0.693150520324707\n",
      "epoch: 8 step: 599 loss: 0.6931505799293518\n",
      "epoch: 8 step: 600 loss: 0.693150520324707\n",
      "epoch: 8 step: 601 loss: 0.693150520324707\n",
      "epoch: 8 step: 602 loss: 0.693150520324707\n",
      "epoch: 8 step: 603 loss: 0.693150520324707\n",
      "epoch: 8 step: 604 loss: 0.693150520324707\n",
      "epoch: 8 step: 605 loss: 0.693150520324707\n",
      "epoch: 8 step: 606 loss: 0.693150520324707\n",
      "epoch: 8 step: 607 loss: 0.693150520324707\n",
      "epoch: 8 step: 608 loss: 0.693150520324707\n",
      "epoch: 8 step: 609 loss: 0.693150520324707\n",
      "epoch: 8 step: 610 loss: 0.693150520324707\n",
      "epoch: 8 step: 611 loss: 0.693150520324707\n",
      "epoch: 8 step: 612 loss: 0.693150520324707\n",
      "epoch: 8 step: 613 loss: 0.693150520324707\n",
      "epoch: 8 step: 614 loss: 0.693150520324707\n",
      "epoch: 8 step: 615 loss: 0.693150520324707\n",
      "epoch: 8 step: 616 loss: 0.693150520324707\n",
      "epoch: 8 step: 617 loss: 0.693150520324707\n",
      "epoch: 8 step: 618 loss: 0.693150520324707\n",
      "epoch: 8 step: 619 loss: 0.693150520324707\n",
      "epoch: 8 step: 620 loss: 0.693150520324707\n",
      "epoch: 8 step: 621 loss: 0.693150520324707\n",
      "epoch: 8 step: 622 loss: 0.693150520324707\n",
      "epoch: 8 step: 623 loss: 0.693150520324707\n",
      "epoch: 8 step: 624 loss: 0.693150520324707\n",
      "epoch: 8 step: 625 loss: 0.693150520324707\n",
      "epoch: 8 step: 626 loss: 0.693150520324707\n",
      "epoch: 8 step: 627 loss: 0.693150520324707\n",
      "epoch: 8 step: 628 loss: 0.693150520324707\n",
      "epoch: 8 step: 629 loss: 0.693150520324707\n",
      "epoch: 8 step: 630 loss: 0.693150520324707\n",
      "epoch: 8 step: 631 loss: 0.693150520324707\n",
      "epoch: 8 step: 632 loss: 0.693150520324707\n",
      "epoch: 8 step: 633 loss: 0.693150520324707\n",
      "epoch: 8 step: 634 loss: 0.693150520324707\n",
      "epoch: 8 step: 635 loss: 0.693150520324707\n",
      "epoch: 8 step: 636 loss: 0.693150520324707\n",
      "epoch: 8 step: 637 loss: 0.693150520324707\n",
      "epoch: 8 step: 638 loss: 0.693150520324707\n",
      "epoch: 8 step: 639 loss: 0.693150520324707\n",
      "epoch: 8 step: 640 loss: 0.693150520324707\n",
      "epoch: 8 step: 641 loss: 0.693150520324707\n",
      "epoch: 8 step: 642 loss: 0.693150520324707\n",
      "epoch: 8 step: 643 loss: 0.693150520324707\n",
      "epoch: 8 step: 644 loss: 0.693150520324707\n",
      "epoch: 8 step: 645 loss: 0.693150520324707\n",
      "epoch: 8 step: 646 loss: 0.693150520324707\n",
      "epoch: 8 step: 647 loss: 0.693150520324707\n",
      "epoch: 8 step: 648 loss: 0.693150520324707\n",
      "epoch: 8 step: 649 loss: 0.693150520324707\n",
      "epoch: 8 step: 650 loss: 0.6931504607200623\n",
      "epoch: 8 step: 651 loss: 0.693150520324707\n",
      "epoch: 8 step: 652 loss: 0.693150520324707\n",
      "epoch: 8 step: 653 loss: 0.693150520324707\n",
      "epoch: 8 step: 654 loss: 0.693150520324707\n",
      "epoch: 8 step: 655 loss: 0.693150520324707\n",
      "epoch: 8 step: 656 loss: 0.693150520324707\n",
      "epoch: 8 step: 657 loss: 0.693150520324707\n",
      "epoch: 8 step: 658 loss: 0.693150520324707\n",
      "epoch: 8 step: 659 loss: 0.693150520324707\n",
      "epoch: 8 step: 660 loss: 0.693150520324707\n",
      "epoch: 8 step: 661 loss: 0.693150520324707\n",
      "epoch: 8 step: 662 loss: 0.6931504607200623\n",
      "epoch: 8 step: 663 loss: 0.6931504607200623\n",
      "epoch: 8 step: 664 loss: 0.693150520324707\n",
      "epoch: 8 step: 665 loss: 0.6931504607200623\n",
      "epoch: 8 step: 666 loss: 0.6931504607200623\n",
      "epoch: 8 step: 667 loss: 0.6931504607200623\n",
      "epoch: 8 step: 668 loss: 0.6931504011154175\n",
      "epoch: 8 step: 669 loss: 0.6931504607200623\n",
      "epoch: 8 step: 670 loss: 0.6931504011154175\n",
      "epoch: 8 step: 671 loss: 0.6931504011154175\n",
      "epoch: 8 step: 672 loss: 0.6931504607200623\n",
      "epoch: 8 step: 673 loss: 0.6931504011154175\n",
      "epoch: 8 step: 674 loss: 0.6931504011154175\n",
      "epoch: 8 step: 675 loss: 0.6931504011154175\n",
      "epoch: 8 step: 676 loss: 0.6931504011154175\n",
      "epoch: 8 step: 677 loss: 0.6931504011154175\n",
      "epoch: 8 step: 678 loss: 0.6931504011154175\n",
      "epoch: 8 step: 679 loss: 0.6931504011154175\n",
      "epoch: 8 step: 680 loss: 0.6931504011154175\n",
      "epoch: 8 step: 681 loss: 0.6931504011154175\n",
      "epoch: 8 step: 682 loss: 0.6931504011154175\n",
      "epoch: 8 step: 683 loss: 0.6931504011154175\n",
      "epoch: 8 step: 684 loss: 0.6931504011154175\n",
      "epoch: 8 step: 685 loss: 0.6931504011154175\n",
      "epoch: 8 step: 686 loss: 0.6931504011154175\n",
      "epoch: 8 step: 687 loss: 0.6931504011154175\n",
      "epoch: 8 step: 688 loss: 0.6931504011154175\n",
      "epoch: 8 step: 689 loss: 0.6931504011154175\n",
      "epoch: 8 step: 690 loss: 0.6931504011154175\n",
      "epoch: 8 step: 691 loss: 0.6931504011154175\n",
      "epoch: 8 step: 692 loss: 0.6931504011154175\n",
      "epoch: 8 step: 693 loss: 0.6931504011154175\n",
      "epoch: 8 step: 694 loss: 0.6931504011154175\n",
      "epoch: 8 step: 695 loss: 0.6931504011154175\n",
      "epoch: 8 step: 696 loss: 0.6931504011154175\n",
      "epoch: 8 step: 697 loss: 0.6931504011154175\n",
      "epoch: 8 step: 698 loss: 0.6931504011154175\n",
      "epoch: 8 step: 699 loss: 0.6931504011154175\n",
      "epoch: 8 step: 700 loss: 0.6931504011154175\n",
      "epoch: 8 step: 701 loss: 0.6931504011154175\n",
      "epoch: 8 step: 702 loss: 0.6931504011154175\n",
      "epoch: 8 step: 703 loss: 0.6931504011154175\n",
      "epoch: 8 step: 704 loss: 0.6931504011154175\n",
      "epoch: 8 step: 705 loss: 0.6931504011154175\n",
      "epoch: 8 step: 706 loss: 0.6931504011154175\n",
      "epoch: 8 step: 707 loss: 0.6931504011154175\n",
      "epoch: 8 step: 708 loss: 0.6931504011154175\n",
      "epoch: 8 step: 709 loss: 0.6931504011154175\n",
      "epoch: 8 step: 710 loss: 0.6931504011154175\n",
      "epoch: 8 step: 711 loss: 0.6931504011154175\n",
      "epoch: 8 step: 712 loss: 0.6931504011154175\n",
      "epoch: 8 step: 713 loss: 0.6931504011154175\n",
      "epoch: 8 step: 714 loss: 0.6931504011154175\n",
      "epoch: 8 step: 715 loss: 0.6931504011154175\n",
      "epoch: 8 step: 716 loss: 0.6931504011154175\n",
      "epoch: 8 step: 717 loss: 0.6931504011154175\n",
      "epoch: 8 step: 718 loss: 0.6931504011154175\n",
      "epoch: 8 step: 719 loss: 0.6931504011154175\n",
      "epoch: 8 step: 720 loss: 0.6931504011154175\n",
      "epoch: 8 step: 721 loss: 0.6931504011154175\n",
      "epoch: 8 step: 722 loss: 0.6931504011154175\n",
      "epoch: 8 step: 723 loss: 0.6931504011154175\n",
      "epoch: 8 step: 724 loss: 0.6931504011154175\n",
      "epoch: 8 step: 725 loss: 0.6931504011154175\n",
      "epoch: 8 step: 726 loss: 0.6931503415107727\n",
      "epoch: 8 step: 727 loss: 0.6931503415107727\n",
      "epoch: 8 step: 728 loss: 0.6931504011154175\n",
      "epoch: 8 step: 729 loss: 0.6931502819061279\n",
      "epoch: 8 step: 730 loss: 0.6931503415107727\n",
      "epoch: 8 step: 731 loss: 0.6931502819061279\n",
      "epoch: 8 step: 732 loss: 0.6931502819061279\n",
      "epoch: 8 step: 733 loss: 0.6931503415107727\n",
      "epoch: 8 step: 734 loss: 0.6931503415107727\n",
      "epoch: 8 step: 735 loss: 0.6931503415107727\n",
      "epoch: 8 step: 736 loss: 0.6931503415107727\n",
      "epoch: 8 step: 737 loss: 0.6931502819061279\n",
      "epoch: 8 step: 738 loss: 0.6931502819061279\n",
      "epoch: 8 step: 739 loss: 0.6931502819061279\n",
      "epoch: 8 step: 740 loss: 0.6931502819061279\n",
      "epoch: 8 step: 741 loss: 0.6931502819061279\n",
      "epoch: 8 step: 742 loss: 0.6931502819061279\n",
      "epoch: 8 step: 743 loss: 0.6931502819061279\n",
      "epoch: 8 step: 744 loss: 0.6931502819061279\n",
      "epoch: 8 step: 745 loss: 0.6931502819061279\n",
      "epoch: 8 step: 746 loss: 0.6931502819061279\n",
      "epoch: 8 step: 747 loss: 0.6931502819061279\n",
      "epoch: 8 step: 748 loss: 0.6931502819061279\n",
      "epoch: 8 step: 749 loss: 0.6931502819061279\n",
      "epoch: 8 step: 750 loss: 0.6931502819061279\n",
      "epoch: 8 step: 751 loss: 0.6931502819061279\n",
      "epoch: 8 step: 752 loss: 0.6931502819061279\n",
      "epoch: 8 step: 753 loss: 0.6931502819061279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 754 loss: 0.6931502819061279\n",
      "epoch: 8 step: 755 loss: 0.6931502819061279\n",
      "epoch: 8 step: 756 loss: 0.6931502819061279\n",
      "epoch: 8 step: 757 loss: 0.6931502819061279\n",
      "epoch: 8 step: 758 loss: 0.6931502819061279\n",
      "epoch: 8 step: 759 loss: 0.6931502819061279\n",
      "epoch: 8 step: 760 loss: 0.6931502819061279\n",
      "epoch: 8 step: 761 loss: 0.6931502819061279\n",
      "epoch: 8 step: 762 loss: 0.6931502819061279\n",
      "epoch: 8 step: 763 loss: 0.6931502819061279\n",
      "epoch: 8 step: 764 loss: 0.6931502819061279\n",
      "epoch: 8 step: 765 loss: 0.6931502819061279\n",
      "epoch: 8 step: 766 loss: 0.6931502819061279\n",
      "epoch: 8 step: 767 loss: 0.6931502819061279\n",
      "epoch: 8 step: 768 loss: 0.6931502819061279\n",
      "epoch: 8 step: 769 loss: 0.6931502819061279\n",
      "epoch: 8 step: 770 loss: 0.6931502819061279\n",
      "epoch: 8 step: 771 loss: 0.6931502819061279\n",
      "epoch: 8 step: 772 loss: 0.6931502819061279\n",
      "epoch: 8 step: 773 loss: 0.6931502819061279\n",
      "epoch: 8 step: 774 loss: 0.6931502819061279\n",
      "epoch: 8 step: 775 loss: 0.6931502819061279\n",
      "epoch: 8 step: 776 loss: 0.6931502819061279\n",
      "epoch: 8 step: 777 loss: 0.6931502819061279\n",
      "epoch: 8 step: 778 loss: 0.6931502819061279\n",
      "epoch: 8 step: 779 loss: 0.6931502819061279\n",
      "epoch: 8 step: 780 loss: 0.6931502819061279\n",
      "epoch: 8 step: 781 loss: 0.6931502819061279\n",
      "epoch: 9 step: 1 loss: 0.6931502819061279\n",
      "epoch: 9 step: 2 loss: 0.6931502819061279\n",
      "epoch: 9 step: 3 loss: 0.6931502819061279\n",
      "epoch: 9 step: 4 loss: 0.6931502819061279\n",
      "epoch: 9 step: 5 loss: 0.6931502819061279\n",
      "epoch: 9 step: 6 loss: 0.6931502819061279\n",
      "epoch: 9 step: 7 loss: 0.6931502819061279\n",
      "epoch: 9 step: 8 loss: 0.6931502819061279\n",
      "epoch: 9 step: 9 loss: 0.6931502819061279\n",
      "epoch: 9 step: 10 loss: 0.6931502819061279\n",
      "epoch: 9 step: 11 loss: 0.6931502819061279\n",
      "epoch: 9 step: 12 loss: 0.6931502819061279\n",
      "epoch: 9 step: 13 loss: 0.6931502819061279\n",
      "epoch: 9 step: 14 loss: 0.6931502819061279\n",
      "epoch: 9 step: 15 loss: 0.6931502819061279\n",
      "epoch: 9 step: 16 loss: 0.6931502223014832\n",
      "epoch: 9 step: 17 loss: 0.6931502819061279\n",
      "epoch: 9 step: 18 loss: 0.6931501626968384\n",
      "epoch: 9 step: 19 loss: 0.6931502223014832\n",
      "epoch: 9 step: 20 loss: 0.6931502223014832\n",
      "epoch: 9 step: 21 loss: 0.6931502819061279\n",
      "epoch: 9 step: 22 loss: 0.6931501626968384\n",
      "epoch: 9 step: 23 loss: 0.6931501626968384\n",
      "epoch: 9 step: 24 loss: 0.6931501626968384\n",
      "epoch: 9 step: 25 loss: 0.6931502819061279\n",
      "epoch: 9 step: 26 loss: 0.6931502223014832\n",
      "epoch: 9 step: 27 loss: 0.6931501626968384\n",
      "epoch: 9 step: 28 loss: 0.6931501626968384\n",
      "epoch: 9 step: 29 loss: 0.6931501626968384\n",
      "epoch: 9 step: 30 loss: 0.6931501626968384\n",
      "epoch: 9 step: 31 loss: 0.6931501626968384\n",
      "epoch: 9 step: 32 loss: 0.6931501626968384\n",
      "epoch: 9 step: 33 loss: 0.6931501626968384\n",
      "epoch: 9 step: 34 loss: 0.6931501626968384\n",
      "epoch: 9 step: 35 loss: 0.6931501626968384\n",
      "epoch: 9 step: 36 loss: 0.6931501626968384\n",
      "epoch: 9 step: 37 loss: 0.6931501626968384\n",
      "epoch: 9 step: 38 loss: 0.6931501626968384\n",
      "epoch: 9 step: 39 loss: 0.6931501626968384\n",
      "epoch: 9 step: 40 loss: 0.6931501626968384\n",
      "epoch: 9 step: 41 loss: 0.6931501626968384\n",
      "epoch: 9 step: 42 loss: 0.6931501626968384\n",
      "epoch: 9 step: 43 loss: 0.6931501626968384\n",
      "epoch: 9 step: 44 loss: 0.6931501626968384\n",
      "epoch: 9 step: 45 loss: 0.6931501626968384\n",
      "epoch: 9 step: 46 loss: 0.6931501626968384\n",
      "epoch: 9 step: 47 loss: 0.6931501626968384\n",
      "epoch: 9 step: 48 loss: 0.6931501626968384\n",
      "epoch: 9 step: 49 loss: 0.6931501626968384\n",
      "epoch: 9 step: 50 loss: 0.6931501626968384\n",
      "epoch: 9 step: 51 loss: 0.6931501626968384\n",
      "epoch: 9 step: 52 loss: 0.6931501626968384\n",
      "epoch: 9 step: 53 loss: 0.6931501626968384\n",
      "epoch: 9 step: 54 loss: 0.6931501626968384\n",
      "epoch: 9 step: 55 loss: 0.6931501626968384\n",
      "epoch: 9 step: 56 loss: 0.6931501626968384\n",
      "epoch: 9 step: 57 loss: 0.6931501626968384\n",
      "epoch: 9 step: 58 loss: 0.6931501626968384\n",
      "epoch: 9 step: 59 loss: 0.6931501626968384\n",
      "epoch: 9 step: 60 loss: 0.6931501626968384\n",
      "epoch: 9 step: 61 loss: 0.6931501626968384\n",
      "epoch: 9 step: 62 loss: 0.6931501626968384\n",
      "epoch: 9 step: 63 loss: 0.6931501626968384\n",
      "epoch: 9 step: 64 loss: 0.6931501626968384\n",
      "epoch: 9 step: 65 loss: 0.6931501626968384\n",
      "epoch: 9 step: 66 loss: 0.6931501626968384\n",
      "epoch: 9 step: 67 loss: 0.6931501626968384\n",
      "epoch: 9 step: 68 loss: 0.6931501626968384\n",
      "epoch: 9 step: 69 loss: 0.6931501626968384\n",
      "epoch: 9 step: 70 loss: 0.6931501626968384\n",
      "epoch: 9 step: 71 loss: 0.6931501626968384\n",
      "epoch: 9 step: 72 loss: 0.6931501626968384\n",
      "epoch: 9 step: 73 loss: 0.6931501626968384\n",
      "epoch: 9 step: 74 loss: 0.6931501626968384\n",
      "epoch: 9 step: 75 loss: 0.6931501030921936\n",
      "epoch: 9 step: 76 loss: 0.6931501626968384\n",
      "epoch: 9 step: 77 loss: 0.6931501626968384\n",
      "epoch: 9 step: 78 loss: 0.6931501626968384\n",
      "epoch: 9 step: 79 loss: 0.6931501626968384\n",
      "epoch: 9 step: 80 loss: 0.6931501626968384\n",
      "epoch: 9 step: 81 loss: 0.6931501626968384\n",
      "epoch: 9 step: 82 loss: 0.6931501626968384\n",
      "epoch: 9 step: 83 loss: 0.6931500434875488\n",
      "epoch: 9 step: 84 loss: 0.6931501030921936\n",
      "epoch: 9 step: 85 loss: 0.6931501626968384\n",
      "epoch: 9 step: 86 loss: 0.6931501626968384\n",
      "epoch: 9 step: 87 loss: 0.6931501030921936\n",
      "epoch: 9 step: 88 loss: 0.6931501030921936\n",
      "epoch: 9 step: 89 loss: 0.6931500434875488\n",
      "epoch: 9 step: 90 loss: 0.6931500434875488\n",
      "epoch: 9 step: 91 loss: 0.6931500434875488\n",
      "epoch: 9 step: 92 loss: 0.6931500434875488\n",
      "epoch: 9 step: 93 loss: 0.6931500434875488\n",
      "epoch: 9 step: 94 loss: 0.6931501030921936\n",
      "epoch: 9 step: 95 loss: 0.6931500434875488\n",
      "epoch: 9 step: 96 loss: 0.6931500434875488\n",
      "epoch: 9 step: 97 loss: 0.6931500434875488\n",
      "epoch: 9 step: 98 loss: 0.6931500434875488\n",
      "epoch: 9 step: 99 loss: 0.6931500434875488\n",
      "epoch: 9 step: 100 loss: 0.6931500434875488\n",
      "epoch: 9 step: 101 loss: 0.6931500434875488\n",
      "epoch: 9 step: 102 loss: 0.6931500434875488\n",
      "epoch: 9 step: 103 loss: 0.6931500434875488\n",
      "epoch: 9 step: 104 loss: 0.6931500434875488\n",
      "epoch: 9 step: 105 loss: 0.6931500434875488\n",
      "epoch: 9 step: 106 loss: 0.6931500434875488\n",
      "epoch: 9 step: 107 loss: 0.6931500434875488\n",
      "epoch: 9 step: 108 loss: 0.6931500434875488\n",
      "epoch: 9 step: 109 loss: 0.6931500434875488\n",
      "epoch: 9 step: 110 loss: 0.6931500434875488\n",
      "epoch: 9 step: 111 loss: 0.6931500434875488\n",
      "epoch: 9 step: 112 loss: 0.6931500434875488\n",
      "epoch: 9 step: 113 loss: 0.6931500434875488\n",
      "epoch: 9 step: 114 loss: 0.6931500434875488\n",
      "epoch: 9 step: 115 loss: 0.6931500434875488\n",
      "epoch: 9 step: 116 loss: 0.6931500434875488\n",
      "epoch: 9 step: 117 loss: 0.6931500434875488\n",
      "epoch: 9 step: 118 loss: 0.6931500434875488\n",
      "epoch: 9 step: 119 loss: 0.6931500434875488\n",
      "epoch: 9 step: 120 loss: 0.6931500434875488\n",
      "epoch: 9 step: 121 loss: 0.6931500434875488\n",
      "epoch: 9 step: 122 loss: 0.6931500434875488\n",
      "epoch: 9 step: 123 loss: 0.6931500434875488\n",
      "epoch: 9 step: 124 loss: 0.6931500434875488\n",
      "epoch: 9 step: 125 loss: 0.6931500434875488\n",
      "epoch: 9 step: 126 loss: 0.6931500434875488\n",
      "epoch: 9 step: 127 loss: 0.6931500434875488\n",
      "epoch: 9 step: 128 loss: 0.6931500434875488\n",
      "epoch: 9 step: 129 loss: 0.6931500434875488\n",
      "epoch: 9 step: 130 loss: 0.6931500434875488\n",
      "epoch: 9 step: 131 loss: 0.6931500434875488\n",
      "epoch: 9 step: 132 loss: 0.6931500434875488\n",
      "epoch: 9 step: 133 loss: 0.6931500434875488\n",
      "epoch: 9 step: 134 loss: 0.6931500434875488\n",
      "epoch: 9 step: 135 loss: 0.6931500434875488\n",
      "epoch: 9 step: 136 loss: 0.6931500434875488\n",
      "epoch: 9 step: 137 loss: 0.6931500434875488\n",
      "epoch: 9 step: 138 loss: 0.6931500434875488\n",
      "epoch: 9 step: 139 loss: 0.6931500434875488\n",
      "epoch: 9 step: 140 loss: 0.6931500434875488\n",
      "epoch: 9 step: 141 loss: 0.6931500434875488\n",
      "epoch: 9 step: 142 loss: 0.6931500434875488\n",
      "epoch: 9 step: 143 loss: 0.6931500434875488\n",
      "epoch: 9 step: 144 loss: 0.6931500434875488\n",
      "epoch: 9 step: 145 loss: 0.6931500434875488\n",
      "epoch: 9 step: 146 loss: 0.6931500434875488\n",
      "epoch: 9 step: 147 loss: 0.6931500434875488\n",
      "epoch: 9 step: 148 loss: 0.6931500434875488\n",
      "epoch: 9 step: 149 loss: 0.6931500434875488\n",
      "epoch: 9 step: 150 loss: 0.6931500434875488\n",
      "epoch: 9 step: 151 loss: 0.6931500434875488\n",
      "epoch: 9 step: 152 loss: 0.6931500434875488\n",
      "epoch: 9 step: 153 loss: 0.6931500434875488\n",
      "epoch: 9 step: 154 loss: 0.693149983882904\n",
      "epoch: 9 step: 155 loss: 0.6931500434875488\n",
      "epoch: 9 step: 156 loss: 0.693149983882904\n",
      "epoch: 9 step: 157 loss: 0.693149983882904\n",
      "epoch: 9 step: 158 loss: 0.6931500434875488\n",
      "epoch: 9 step: 159 loss: 0.693149983882904\n",
      "epoch: 9 step: 160 loss: 0.693149983882904\n",
      "epoch: 9 step: 161 loss: 0.6931499242782593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 162 loss: 0.693149983882904\n",
      "epoch: 9 step: 163 loss: 0.6931499242782593\n",
      "epoch: 9 step: 164 loss: 0.6931499242782593\n",
      "epoch: 9 step: 165 loss: 0.6931499242782593\n",
      "epoch: 9 step: 166 loss: 0.6931499242782593\n",
      "epoch: 9 step: 167 loss: 0.693149983882904\n",
      "epoch: 9 step: 168 loss: 0.6931499242782593\n",
      "epoch: 9 step: 169 loss: 0.6931499242782593\n",
      "epoch: 9 step: 170 loss: 0.6931499242782593\n",
      "epoch: 9 step: 171 loss: 0.6931499242782593\n",
      "epoch: 9 step: 172 loss: 0.6931499242782593\n",
      "epoch: 9 step: 173 loss: 0.6931499242782593\n",
      "epoch: 9 step: 174 loss: 0.6931499242782593\n",
      "epoch: 9 step: 175 loss: 0.6931499242782593\n",
      "epoch: 9 step: 176 loss: 0.6931499242782593\n",
      "epoch: 9 step: 177 loss: 0.6931499242782593\n",
      "epoch: 9 step: 178 loss: 0.6931499242782593\n",
      "epoch: 9 step: 179 loss: 0.6931499242782593\n",
      "epoch: 9 step: 180 loss: 0.6931499242782593\n",
      "epoch: 9 step: 181 loss: 0.6931499242782593\n",
      "epoch: 9 step: 182 loss: 0.6931499242782593\n",
      "epoch: 9 step: 183 loss: 0.6931499242782593\n",
      "epoch: 9 step: 184 loss: 0.6931499242782593\n",
      "epoch: 9 step: 185 loss: 0.6931499242782593\n",
      "epoch: 9 step: 186 loss: 0.6931499242782593\n",
      "epoch: 9 step: 187 loss: 0.6931499242782593\n",
      "epoch: 9 step: 188 loss: 0.6931499242782593\n",
      "epoch: 9 step: 189 loss: 0.6931499242782593\n",
      "epoch: 9 step: 190 loss: 0.6931499242782593\n",
      "epoch: 9 step: 191 loss: 0.6931499242782593\n",
      "epoch: 9 step: 192 loss: 0.6931499242782593\n",
      "epoch: 9 step: 193 loss: 0.6931499242782593\n",
      "epoch: 9 step: 194 loss: 0.6931499242782593\n",
      "epoch: 9 step: 195 loss: 0.6931499242782593\n",
      "epoch: 9 step: 196 loss: 0.6931499242782593\n",
      "epoch: 9 step: 197 loss: 0.6931499242782593\n",
      "epoch: 9 step: 198 loss: 0.6931499242782593\n",
      "epoch: 9 step: 199 loss: 0.6931499242782593\n",
      "epoch: 9 step: 200 loss: 0.6931499242782593\n",
      "epoch: 9 step: 201 loss: 0.6931499242782593\n",
      "epoch: 9 step: 202 loss: 0.6931499242782593\n",
      "epoch: 9 step: 203 loss: 0.6931499242782593\n",
      "epoch: 9 step: 204 loss: 0.6931499242782593\n",
      "epoch: 9 step: 205 loss: 0.6931499242782593\n",
      "epoch: 9 step: 206 loss: 0.6931499242782593\n",
      "epoch: 9 step: 207 loss: 0.6931499242782593\n",
      "epoch: 9 step: 208 loss: 0.6931499242782593\n",
      "epoch: 9 step: 209 loss: 0.6931499242782593\n",
      "epoch: 9 step: 210 loss: 0.6931499242782593\n",
      "epoch: 9 step: 211 loss: 0.6931499242782593\n",
      "epoch: 9 step: 212 loss: 0.6931499242782593\n",
      "epoch: 9 step: 213 loss: 0.6931499242782593\n",
      "epoch: 9 step: 214 loss: 0.6931499242782593\n",
      "epoch: 9 step: 215 loss: 0.6931499242782593\n",
      "epoch: 9 step: 216 loss: 0.6931499242782593\n",
      "epoch: 9 step: 217 loss: 0.6931499242782593\n",
      "epoch: 9 step: 218 loss: 0.6931499242782593\n",
      "epoch: 9 step: 219 loss: 0.6931499242782593\n",
      "epoch: 9 step: 220 loss: 0.6931499242782593\n",
      "epoch: 9 step: 221 loss: 0.6931499242782593\n",
      "epoch: 9 step: 222 loss: 0.6931499242782593\n",
      "epoch: 9 step: 223 loss: 0.6931499242782593\n",
      "epoch: 9 step: 224 loss: 0.6931499242782593\n",
      "epoch: 9 step: 225 loss: 0.6931499242782593\n",
      "epoch: 9 step: 226 loss: 0.6931499242782593\n",
      "epoch: 9 step: 227 loss: 0.6931499242782593\n",
      "epoch: 9 step: 228 loss: 0.6931499242782593\n",
      "epoch: 9 step: 229 loss: 0.6931499242782593\n",
      "epoch: 9 step: 230 loss: 0.6931499242782593\n",
      "epoch: 9 step: 231 loss: 0.6931499242782593\n",
      "epoch: 9 step: 232 loss: 0.6931499242782593\n",
      "epoch: 9 step: 233 loss: 0.6931499242782593\n",
      "epoch: 9 step: 234 loss: 0.6931499242782593\n",
      "epoch: 9 step: 235 loss: 0.6931499242782593\n",
      "epoch: 9 step: 236 loss: 0.6931499242782593\n",
      "epoch: 9 step: 237 loss: 0.6931499242782593\n",
      "epoch: 9 step: 238 loss: 0.6931499242782593\n",
      "epoch: 9 step: 239 loss: 0.6931499242782593\n",
      "epoch: 9 step: 240 loss: 0.6931499242782593\n",
      "epoch: 9 step: 241 loss: 0.6931498646736145\n",
      "epoch: 9 step: 242 loss: 0.6931499242782593\n",
      "epoch: 9 step: 243 loss: 0.6931498646736145\n",
      "epoch: 9 step: 244 loss: 0.6931499242782593\n",
      "epoch: 9 step: 245 loss: 0.6931498646736145\n",
      "epoch: 9 step: 246 loss: 0.6931498646736145\n",
      "epoch: 9 step: 247 loss: 0.6931499242782593\n",
      "epoch: 9 step: 248 loss: 0.6931499242782593\n",
      "epoch: 9 step: 249 loss: 0.6931498646736145\n",
      "epoch: 9 step: 250 loss: 0.6931498050689697\n",
      "epoch: 9 step: 251 loss: 0.6931499242782593\n",
      "epoch: 9 step: 252 loss: 0.6931498050689697\n",
      "epoch: 9 step: 253 loss: 0.6931498050689697\n",
      "epoch: 9 step: 254 loss: 0.6931498050689697\n",
      "epoch: 9 step: 255 loss: 0.6931498050689697\n",
      "epoch: 9 step: 256 loss: 0.6931498050689697\n",
      "epoch: 9 step: 257 loss: 0.6931498050689697\n",
      "epoch: 9 step: 258 loss: 0.6931498050689697\n",
      "epoch: 9 step: 259 loss: 0.6931498050689697\n",
      "epoch: 9 step: 260 loss: 0.6931498050689697\n",
      "epoch: 9 step: 261 loss: 0.6931498050689697\n",
      "epoch: 9 step: 262 loss: 0.6931498646736145\n",
      "epoch: 9 step: 263 loss: 0.6931498050689697\n",
      "epoch: 9 step: 264 loss: 0.6931498050689697\n",
      "epoch: 9 step: 265 loss: 0.6931498050689697\n",
      "epoch: 9 step: 266 loss: 0.6931498050689697\n",
      "epoch: 9 step: 267 loss: 0.6931498050689697\n",
      "epoch: 9 step: 268 loss: 0.6931498050689697\n",
      "epoch: 9 step: 269 loss: 0.6931498050689697\n",
      "epoch: 9 step: 270 loss: 0.6931498050689697\n",
      "epoch: 9 step: 271 loss: 0.6931498050689697\n",
      "epoch: 9 step: 272 loss: 0.6931498050689697\n",
      "epoch: 9 step: 273 loss: 0.6931498050689697\n",
      "epoch: 9 step: 274 loss: 0.6931498050689697\n",
      "epoch: 9 step: 275 loss: 0.6931498050689697\n",
      "epoch: 9 step: 276 loss: 0.6931498050689697\n",
      "epoch: 9 step: 277 loss: 0.6931498050689697\n",
      "epoch: 9 step: 278 loss: 0.6931498050689697\n",
      "epoch: 9 step: 279 loss: 0.6931498050689697\n",
      "epoch: 9 step: 280 loss: 0.6931498050689697\n",
      "epoch: 9 step: 281 loss: 0.6931498050689697\n",
      "epoch: 9 step: 282 loss: 0.6931498050689697\n",
      "epoch: 9 step: 283 loss: 0.6931498050689697\n",
      "epoch: 9 step: 284 loss: 0.6931498050689697\n",
      "epoch: 9 step: 285 loss: 0.6931498050689697\n",
      "epoch: 9 step: 286 loss: 0.6931498050689697\n",
      "epoch: 9 step: 287 loss: 0.6931498050689697\n",
      "epoch: 9 step: 288 loss: 0.6931498050689697\n",
      "epoch: 9 step: 289 loss: 0.6931498050689697\n",
      "epoch: 9 step: 290 loss: 0.6931498050689697\n",
      "epoch: 9 step: 291 loss: 0.6931498050689697\n",
      "epoch: 9 step: 292 loss: 0.6931498050689697\n",
      "epoch: 9 step: 293 loss: 0.6931498050689697\n",
      "epoch: 9 step: 294 loss: 0.6931498050689697\n",
      "epoch: 9 step: 295 loss: 0.6931498050689697\n",
      "epoch: 9 step: 296 loss: 0.6931498050689697\n",
      "epoch: 9 step: 297 loss: 0.6931498050689697\n",
      "epoch: 9 step: 298 loss: 0.6931498050689697\n",
      "epoch: 9 step: 299 loss: 0.6931498050689697\n",
      "epoch: 9 step: 300 loss: 0.6931498050689697\n",
      "epoch: 9 step: 301 loss: 0.6931498050689697\n",
      "epoch: 9 step: 302 loss: 0.6931498050689697\n",
      "epoch: 9 step: 303 loss: 0.6931498050689697\n",
      "epoch: 9 step: 304 loss: 0.6931498050689697\n",
      "epoch: 9 step: 305 loss: 0.6931498050689697\n",
      "epoch: 9 step: 306 loss: 0.6931498050689697\n",
      "epoch: 9 step: 307 loss: 0.6931498050689697\n",
      "epoch: 9 step: 308 loss: 0.6931498050689697\n",
      "epoch: 9 step: 309 loss: 0.6931498050689697\n",
      "epoch: 9 step: 310 loss: 0.6931498050689697\n",
      "epoch: 9 step: 311 loss: 0.6931498050689697\n",
      "epoch: 9 step: 312 loss: 0.6931498050689697\n",
      "epoch: 9 step: 313 loss: 0.6931498050689697\n",
      "epoch: 9 step: 314 loss: 0.6931498050689697\n",
      "epoch: 9 step: 315 loss: 0.6931498050689697\n",
      "epoch: 9 step: 316 loss: 0.693149745464325\n",
      "epoch: 9 step: 317 loss: 0.6931498050689697\n",
      "epoch: 9 step: 318 loss: 0.6931498050689697\n",
      "epoch: 9 step: 319 loss: 0.6931498050689697\n",
      "epoch: 9 step: 320 loss: 0.6931496858596802\n",
      "epoch: 9 step: 321 loss: 0.6931498050689697\n",
      "epoch: 9 step: 322 loss: 0.6931498050689697\n",
      "epoch: 9 step: 323 loss: 0.693149745464325\n",
      "epoch: 9 step: 324 loss: 0.6931496858596802\n",
      "epoch: 9 step: 325 loss: 0.693149745464325\n",
      "epoch: 9 step: 326 loss: 0.6931496858596802\n",
      "epoch: 9 step: 327 loss: 0.693149745464325\n",
      "epoch: 9 step: 328 loss: 0.693149745464325\n",
      "epoch: 9 step: 329 loss: 0.6931496858596802\n",
      "epoch: 9 step: 330 loss: 0.6931496858596802\n",
      "epoch: 9 step: 331 loss: 0.6931496858596802\n",
      "epoch: 9 step: 332 loss: 0.6931498050689697\n",
      "epoch: 9 step: 333 loss: 0.693149745464325\n",
      "epoch: 9 step: 334 loss: 0.693149745464325\n",
      "epoch: 9 step: 335 loss: 0.6931496858596802\n",
      "epoch: 9 step: 336 loss: 0.6931496858596802\n",
      "epoch: 9 step: 337 loss: 0.6931496858596802\n",
      "epoch: 9 step: 338 loss: 0.6931496858596802\n",
      "epoch: 9 step: 339 loss: 0.6931496858596802\n",
      "epoch: 9 step: 340 loss: 0.6931496858596802\n",
      "epoch: 9 step: 341 loss: 0.6931496858596802\n",
      "epoch: 9 step: 342 loss: 0.6931496858596802\n",
      "epoch: 9 step: 343 loss: 0.6931496858596802\n",
      "epoch: 9 step: 344 loss: 0.6931496858596802\n",
      "epoch: 9 step: 345 loss: 0.6931496858596802\n",
      "epoch: 9 step: 346 loss: 0.6931496858596802\n",
      "epoch: 9 step: 347 loss: 0.6931496858596802\n",
      "epoch: 9 step: 348 loss: 0.6931496858596802\n",
      "epoch: 9 step: 349 loss: 0.6931496858596802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 350 loss: 0.6931496858596802\n",
      "epoch: 9 step: 351 loss: 0.6931496858596802\n",
      "epoch: 9 step: 352 loss: 0.6931496858596802\n",
      "epoch: 9 step: 353 loss: 0.6931496858596802\n",
      "epoch: 9 step: 354 loss: 0.6931496858596802\n",
      "epoch: 9 step: 355 loss: 0.6931496858596802\n",
      "epoch: 9 step: 356 loss: 0.6931496858596802\n",
      "epoch: 9 step: 357 loss: 0.6931496858596802\n",
      "epoch: 9 step: 358 loss: 0.6931496858596802\n",
      "epoch: 9 step: 359 loss: 0.6931496858596802\n",
      "epoch: 9 step: 360 loss: 0.6931496858596802\n",
      "epoch: 9 step: 361 loss: 0.6931496858596802\n",
      "epoch: 9 step: 362 loss: 0.6931496858596802\n",
      "epoch: 9 step: 363 loss: 0.6931496858596802\n",
      "epoch: 9 step: 364 loss: 0.6931496858596802\n",
      "epoch: 9 step: 365 loss: 0.6931496858596802\n",
      "epoch: 9 step: 366 loss: 0.6931496858596802\n",
      "epoch: 9 step: 367 loss: 0.6931496858596802\n",
      "epoch: 9 step: 368 loss: 0.6931496858596802\n",
      "epoch: 9 step: 369 loss: 0.6931496858596802\n",
      "epoch: 9 step: 370 loss: 0.6931496858596802\n",
      "epoch: 9 step: 371 loss: 0.6931496858596802\n",
      "epoch: 9 step: 372 loss: 0.6931496858596802\n",
      "epoch: 9 step: 373 loss: 0.6931496858596802\n",
      "epoch: 9 step: 374 loss: 0.6931496858596802\n",
      "epoch: 9 step: 375 loss: 0.6931496858596802\n",
      "epoch: 9 step: 376 loss: 0.6931496858596802\n",
      "epoch: 9 step: 377 loss: 0.6931496858596802\n",
      "epoch: 9 step: 378 loss: 0.6931496858596802\n",
      "epoch: 9 step: 379 loss: 0.6931496858596802\n",
      "epoch: 9 step: 380 loss: 0.6931496858596802\n",
      "epoch: 9 step: 381 loss: 0.6931496858596802\n",
      "epoch: 9 step: 382 loss: 0.6931496858596802\n",
      "epoch: 9 step: 383 loss: 0.6931496858596802\n",
      "epoch: 9 step: 384 loss: 0.6931496858596802\n",
      "epoch: 9 step: 385 loss: 0.6931496858596802\n",
      "epoch: 9 step: 386 loss: 0.6931496858596802\n",
      "epoch: 9 step: 387 loss: 0.6931496858596802\n",
      "epoch: 9 step: 388 loss: 0.6931496858596802\n",
      "epoch: 9 step: 389 loss: 0.6931496858596802\n",
      "epoch: 9 step: 390 loss: 0.6931496858596802\n",
      "epoch: 9 step: 391 loss: 0.6931496858596802\n",
      "epoch: 9 step: 392 loss: 0.6931496858596802\n",
      "epoch: 9 step: 393 loss: 0.6931496858596802\n",
      "epoch: 9 step: 394 loss: 0.6931496858596802\n",
      "epoch: 9 step: 395 loss: 0.6931496858596802\n",
      "epoch: 9 step: 396 loss: 0.6931496858596802\n",
      "epoch: 9 step: 397 loss: 0.6931496858596802\n",
      "epoch: 9 step: 398 loss: 0.6931496858596802\n",
      "epoch: 9 step: 399 loss: 0.6931496262550354\n",
      "epoch: 9 step: 400 loss: 0.6931496858596802\n",
      "epoch: 9 step: 401 loss: 0.6931496858596802\n",
      "epoch: 9 step: 402 loss: 0.6931496262550354\n",
      "epoch: 9 step: 403 loss: 0.6931496858596802\n",
      "epoch: 9 step: 404 loss: 0.6931496858596802\n",
      "epoch: 9 step: 405 loss: 0.6931496858596802\n",
      "epoch: 9 step: 406 loss: 0.6931496858596802\n",
      "epoch: 9 step: 407 loss: 0.6931496858596802\n",
      "epoch: 9 step: 408 loss: 0.6931496262550354\n",
      "epoch: 9 step: 409 loss: 0.6931496858596802\n",
      "epoch: 9 step: 410 loss: 0.6931496262550354\n",
      "epoch: 9 step: 411 loss: 0.6931496262550354\n",
      "epoch: 9 step: 412 loss: 0.6931495666503906\n",
      "epoch: 9 step: 413 loss: 0.6931496858596802\n",
      "epoch: 9 step: 414 loss: 0.6931496262550354\n",
      "epoch: 9 step: 415 loss: 0.6931495666503906\n",
      "epoch: 9 step: 416 loss: 0.6931496262550354\n",
      "epoch: 9 step: 417 loss: 0.6931495666503906\n",
      "epoch: 9 step: 418 loss: 0.6931495666503906\n",
      "epoch: 9 step: 419 loss: 0.6931496262550354\n",
      "epoch: 9 step: 420 loss: 0.6931495666503906\n",
      "epoch: 9 step: 421 loss: 0.6931495666503906\n",
      "epoch: 9 step: 422 loss: 0.6931495666503906\n",
      "epoch: 9 step: 423 loss: 0.6931495666503906\n",
      "epoch: 9 step: 424 loss: 0.6931495666503906\n",
      "epoch: 9 step: 425 loss: 0.6931495666503906\n",
      "epoch: 9 step: 426 loss: 0.6931495666503906\n",
      "epoch: 9 step: 427 loss: 0.6931495666503906\n",
      "epoch: 9 step: 428 loss: 0.6931495666503906\n",
      "epoch: 9 step: 429 loss: 0.6931495666503906\n",
      "epoch: 9 step: 430 loss: 0.6931495666503906\n",
      "epoch: 9 step: 431 loss: 0.6931495666503906\n",
      "epoch: 9 step: 432 loss: 0.6931495666503906\n",
      "epoch: 9 step: 433 loss: 0.6931495666503906\n",
      "epoch: 9 step: 434 loss: 0.6931495666503906\n",
      "epoch: 9 step: 435 loss: 0.6931495666503906\n",
      "epoch: 9 step: 436 loss: 0.6931495666503906\n",
      "epoch: 9 step: 437 loss: 0.6931495666503906\n",
      "epoch: 9 step: 438 loss: 0.6931495666503906\n",
      "epoch: 9 step: 439 loss: 0.6931495666503906\n",
      "epoch: 9 step: 440 loss: 0.6931495666503906\n",
      "epoch: 9 step: 441 loss: 0.6931495666503906\n",
      "epoch: 9 step: 442 loss: 0.6931495666503906\n",
      "epoch: 9 step: 443 loss: 0.6931495666503906\n",
      "epoch: 9 step: 444 loss: 0.6931495666503906\n",
      "epoch: 9 step: 445 loss: 0.6931495666503906\n",
      "epoch: 9 step: 446 loss: 0.6931495666503906\n",
      "epoch: 9 step: 447 loss: 0.6931495666503906\n",
      "epoch: 9 step: 448 loss: 0.6931495666503906\n",
      "epoch: 9 step: 449 loss: 0.6931495666503906\n",
      "epoch: 9 step: 450 loss: 0.6931495666503906\n",
      "epoch: 9 step: 451 loss: 0.6931495666503906\n",
      "epoch: 9 step: 452 loss: 0.6931495666503906\n",
      "epoch: 9 step: 453 loss: 0.6931495666503906\n",
      "epoch: 9 step: 454 loss: 0.6931495666503906\n",
      "epoch: 9 step: 455 loss: 0.6931495666503906\n",
      "epoch: 9 step: 456 loss: 0.6931495666503906\n",
      "epoch: 9 step: 457 loss: 0.6931495666503906\n",
      "epoch: 9 step: 458 loss: 0.6931495666503906\n",
      "epoch: 9 step: 459 loss: 0.6931495666503906\n",
      "epoch: 9 step: 460 loss: 0.6931495666503906\n",
      "epoch: 9 step: 461 loss: 0.6931495666503906\n",
      "epoch: 9 step: 462 loss: 0.6931495666503906\n",
      "epoch: 9 step: 463 loss: 0.6931495666503906\n",
      "epoch: 9 step: 464 loss: 0.6931495666503906\n",
      "epoch: 9 step: 465 loss: 0.6931495666503906\n",
      "epoch: 9 step: 466 loss: 0.6931495666503906\n",
      "epoch: 9 step: 467 loss: 0.6931495666503906\n",
      "epoch: 9 step: 468 loss: 0.6931495666503906\n",
      "epoch: 9 step: 469 loss: 0.6931495666503906\n",
      "epoch: 9 step: 470 loss: 0.6931495666503906\n",
      "epoch: 9 step: 471 loss: 0.6931495666503906\n",
      "epoch: 9 step: 472 loss: 0.6931495666503906\n",
      "epoch: 9 step: 473 loss: 0.6931495666503906\n",
      "epoch: 9 step: 474 loss: 0.6931495666503906\n",
      "epoch: 9 step: 475 loss: 0.6931495666503906\n",
      "epoch: 9 step: 476 loss: 0.6931495666503906\n",
      "epoch: 9 step: 477 loss: 0.6931495666503906\n",
      "epoch: 9 step: 478 loss: 0.6931495666503906\n",
      "epoch: 9 step: 479 loss: 0.6931495666503906\n",
      "epoch: 9 step: 480 loss: 0.6931495666503906\n",
      "epoch: 9 step: 481 loss: 0.6931495666503906\n",
      "epoch: 9 step: 482 loss: 0.6931495666503906\n",
      "epoch: 9 step: 483 loss: 0.6931495666503906\n",
      "epoch: 9 step: 484 loss: 0.6931495666503906\n",
      "epoch: 9 step: 485 loss: 0.6931495666503906\n",
      "epoch: 9 step: 486 loss: 0.6931495666503906\n",
      "epoch: 9 step: 487 loss: 0.6931495666503906\n",
      "epoch: 9 step: 488 loss: 0.6931495666503906\n",
      "epoch: 9 step: 489 loss: 0.6931495666503906\n",
      "epoch: 9 step: 490 loss: 0.6931495666503906\n",
      "epoch: 9 step: 491 loss: 0.6931495666503906\n",
      "epoch: 9 step: 492 loss: 0.6931495666503906\n",
      "epoch: 9 step: 493 loss: 0.6931495666503906\n",
      "epoch: 9 step: 494 loss: 0.6931495666503906\n",
      "epoch: 9 step: 495 loss: 0.6931495666503906\n",
      "epoch: 9 step: 496 loss: 0.6931495666503906\n",
      "epoch: 9 step: 497 loss: 0.6931495666503906\n",
      "epoch: 9 step: 498 loss: 0.6931495666503906\n",
      "epoch: 9 step: 499 loss: 0.6931495666503906\n",
      "epoch: 9 step: 500 loss: 0.6931495666503906\n",
      "epoch: 9 step: 501 loss: 0.6931495666503906\n",
      "epoch: 9 step: 502 loss: 0.6931495666503906\n",
      "epoch: 9 step: 503 loss: 0.6931495666503906\n",
      "epoch: 9 step: 504 loss: 0.6931495666503906\n",
      "epoch: 9 step: 505 loss: 0.6931495666503906\n",
      "epoch: 9 step: 506 loss: 0.6931495666503906\n",
      "epoch: 9 step: 507 loss: 0.6931495070457458\n",
      "epoch: 9 step: 508 loss: 0.6931495666503906\n",
      "epoch: 9 step: 509 loss: 0.6931495666503906\n",
      "epoch: 9 step: 510 loss: 0.6931494474411011\n",
      "epoch: 9 step: 511 loss: 0.6931494474411011\n",
      "epoch: 9 step: 512 loss: 0.6931495666503906\n",
      "epoch: 9 step: 513 loss: 0.6931494474411011\n",
      "epoch: 9 step: 514 loss: 0.6931494474411011\n",
      "epoch: 9 step: 515 loss: 0.6931494474411011\n",
      "epoch: 9 step: 516 loss: 0.6931494474411011\n",
      "epoch: 9 step: 517 loss: 0.6931494474411011\n",
      "epoch: 9 step: 518 loss: 0.6931494474411011\n",
      "epoch: 9 step: 519 loss: 0.6931494474411011\n",
      "epoch: 9 step: 520 loss: 0.6931495070457458\n",
      "epoch: 9 step: 521 loss: 0.6931494474411011\n",
      "epoch: 9 step: 522 loss: 0.6931494474411011\n",
      "epoch: 9 step: 523 loss: 0.6931494474411011\n",
      "epoch: 9 step: 524 loss: 0.6931494474411011\n",
      "epoch: 9 step: 525 loss: 0.6931495070457458\n",
      "epoch: 9 step: 526 loss: 0.6931494474411011\n",
      "epoch: 9 step: 527 loss: 0.6931494474411011\n",
      "epoch: 9 step: 528 loss: 0.6931494474411011\n",
      "epoch: 9 step: 529 loss: 0.6931494474411011\n",
      "epoch: 9 step: 530 loss: 0.6931494474411011\n",
      "epoch: 9 step: 531 loss: 0.6931494474411011\n",
      "epoch: 9 step: 532 loss: 0.6931494474411011\n",
      "epoch: 9 step: 533 loss: 0.6931494474411011\n",
      "epoch: 9 step: 534 loss: 0.6931494474411011\n",
      "epoch: 9 step: 535 loss: 0.6931494474411011\n",
      "epoch: 9 step: 536 loss: 0.6931494474411011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 537 loss: 0.6931494474411011\n",
      "epoch: 9 step: 538 loss: 0.6931494474411011\n",
      "epoch: 9 step: 539 loss: 0.6931494474411011\n",
      "epoch: 9 step: 540 loss: 0.6931494474411011\n",
      "epoch: 9 step: 541 loss: 0.6931494474411011\n",
      "epoch: 9 step: 542 loss: 0.6931494474411011\n",
      "epoch: 9 step: 543 loss: 0.6931494474411011\n",
      "epoch: 9 step: 544 loss: 0.6931494474411011\n",
      "epoch: 9 step: 545 loss: 0.6931494474411011\n",
      "epoch: 9 step: 546 loss: 0.6931494474411011\n",
      "epoch: 9 step: 547 loss: 0.6931494474411011\n",
      "epoch: 9 step: 548 loss: 0.6931494474411011\n",
      "epoch: 9 step: 549 loss: 0.6931494474411011\n",
      "epoch: 9 step: 550 loss: 0.6931494474411011\n",
      "epoch: 9 step: 551 loss: 0.6931494474411011\n",
      "epoch: 9 step: 552 loss: 0.6931494474411011\n",
      "epoch: 9 step: 553 loss: 0.6931494474411011\n",
      "epoch: 9 step: 554 loss: 0.6931494474411011\n",
      "epoch: 9 step: 555 loss: 0.6931494474411011\n",
      "epoch: 9 step: 556 loss: 0.6931494474411011\n",
      "epoch: 9 step: 557 loss: 0.6931494474411011\n",
      "epoch: 9 step: 558 loss: 0.6931494474411011\n",
      "epoch: 9 step: 559 loss: 0.6931494474411011\n",
      "epoch: 9 step: 560 loss: 0.6931494474411011\n",
      "epoch: 9 step: 561 loss: 0.6931494474411011\n",
      "epoch: 9 step: 562 loss: 0.6931494474411011\n",
      "epoch: 9 step: 563 loss: 0.6931494474411011\n",
      "epoch: 9 step: 564 loss: 0.6931494474411011\n",
      "epoch: 9 step: 565 loss: 0.6931494474411011\n",
      "epoch: 9 step: 566 loss: 0.6931494474411011\n",
      "epoch: 9 step: 567 loss: 0.6931494474411011\n",
      "epoch: 9 step: 568 loss: 0.6931494474411011\n",
      "epoch: 9 step: 569 loss: 0.6931494474411011\n",
      "epoch: 9 step: 570 loss: 0.6931494474411011\n",
      "epoch: 9 step: 571 loss: 0.6931494474411011\n",
      "epoch: 9 step: 572 loss: 0.6931494474411011\n",
      "epoch: 9 step: 573 loss: 0.6931494474411011\n",
      "epoch: 9 step: 574 loss: 0.6931494474411011\n",
      "epoch: 9 step: 575 loss: 0.6931494474411011\n",
      "epoch: 9 step: 576 loss: 0.6931494474411011\n",
      "epoch: 9 step: 577 loss: 0.6931494474411011\n",
      "epoch: 9 step: 578 loss: 0.6931494474411011\n",
      "epoch: 9 step: 579 loss: 0.6931494474411011\n",
      "epoch: 9 step: 580 loss: 0.6931494474411011\n",
      "epoch: 9 step: 581 loss: 0.6931494474411011\n",
      "epoch: 9 step: 582 loss: 0.6931494474411011\n",
      "epoch: 9 step: 583 loss: 0.6931493878364563\n",
      "epoch: 9 step: 584 loss: 0.6931494474411011\n",
      "epoch: 9 step: 585 loss: 0.6931494474411011\n",
      "epoch: 9 step: 586 loss: 0.6931494474411011\n",
      "epoch: 9 step: 587 loss: 0.6931494474411011\n",
      "epoch: 9 step: 588 loss: 0.6931494474411011\n",
      "epoch: 9 step: 589 loss: 0.6931493878364563\n",
      "epoch: 9 step: 590 loss: 0.6931494474411011\n",
      "epoch: 9 step: 591 loss: 0.6931494474411011\n",
      "epoch: 9 step: 592 loss: 0.6931493282318115\n",
      "epoch: 9 step: 593 loss: 0.6931494474411011\n",
      "epoch: 9 step: 594 loss: 0.6931494474411011\n",
      "epoch: 9 step: 595 loss: 0.6931493282318115\n",
      "epoch: 9 step: 596 loss: 0.6931493878364563\n",
      "epoch: 9 step: 597 loss: 0.6931493282318115\n",
      "epoch: 9 step: 598 loss: 0.6931493282318115\n",
      "epoch: 9 step: 599 loss: 0.6931493282318115\n",
      "epoch: 9 step: 600 loss: 0.6931493282318115\n",
      "epoch: 9 step: 601 loss: 0.6931493282318115\n",
      "epoch: 9 step: 602 loss: 0.6931493282318115\n",
      "epoch: 9 step: 603 loss: 0.6931493878364563\n",
      "epoch: 9 step: 604 loss: 0.6931493282318115\n",
      "epoch: 9 step: 605 loss: 0.6931493282318115\n",
      "epoch: 9 step: 606 loss: 0.6931493282318115\n",
      "epoch: 9 step: 607 loss: 0.6931493282318115\n",
      "epoch: 9 step: 608 loss: 0.6931493282318115\n",
      "epoch: 9 step: 609 loss: 0.6931493282318115\n",
      "epoch: 9 step: 610 loss: 0.6931493282318115\n",
      "epoch: 9 step: 611 loss: 0.6931493282318115\n",
      "epoch: 9 step: 612 loss: 0.6931493282318115\n",
      "epoch: 9 step: 613 loss: 0.6931493282318115\n",
      "epoch: 9 step: 614 loss: 0.6931493282318115\n",
      "epoch: 9 step: 615 loss: 0.6931493282318115\n",
      "epoch: 9 step: 616 loss: 0.6931493282318115\n",
      "epoch: 9 step: 617 loss: 0.6931493282318115\n",
      "epoch: 9 step: 618 loss: 0.6931493282318115\n",
      "epoch: 9 step: 619 loss: 0.6931493282318115\n",
      "epoch: 9 step: 620 loss: 0.6931493282318115\n",
      "epoch: 9 step: 621 loss: 0.6931493282318115\n",
      "epoch: 9 step: 622 loss: 0.6931493282318115\n",
      "epoch: 9 step: 623 loss: 0.6931493282318115\n",
      "epoch: 9 step: 624 loss: 0.6931493282318115\n",
      "epoch: 9 step: 625 loss: 0.6931493282318115\n",
      "epoch: 9 step: 626 loss: 0.6931493282318115\n",
      "epoch: 9 step: 627 loss: 0.6931493282318115\n",
      "epoch: 9 step: 628 loss: 0.6931493282318115\n",
      "epoch: 9 step: 629 loss: 0.6931493282318115\n",
      "epoch: 9 step: 630 loss: 0.6931493282318115\n",
      "epoch: 9 step: 631 loss: 0.6931493282318115\n",
      "epoch: 9 step: 632 loss: 0.6931493282318115\n",
      "epoch: 9 step: 633 loss: 0.6931493282318115\n",
      "epoch: 9 step: 634 loss: 0.6931493282318115\n",
      "epoch: 9 step: 635 loss: 0.6931493282318115\n",
      "epoch: 9 step: 636 loss: 0.6931493282318115\n",
      "epoch: 9 step: 637 loss: 0.6931493282318115\n",
      "epoch: 9 step: 638 loss: 0.6931493282318115\n",
      "epoch: 9 step: 639 loss: 0.6931493282318115\n",
      "epoch: 9 step: 640 loss: 0.6931493282318115\n",
      "epoch: 9 step: 641 loss: 0.6931493282318115\n",
      "epoch: 9 step: 642 loss: 0.6931493282318115\n",
      "epoch: 9 step: 643 loss: 0.6931493282318115\n",
      "epoch: 9 step: 644 loss: 0.6931493282318115\n",
      "epoch: 9 step: 645 loss: 0.6931493282318115\n",
      "epoch: 9 step: 646 loss: 0.6931493282318115\n",
      "epoch: 9 step: 647 loss: 0.6931493282318115\n",
      "epoch: 9 step: 648 loss: 0.6931493282318115\n",
      "epoch: 9 step: 649 loss: 0.6931493282318115\n",
      "epoch: 9 step: 650 loss: 0.6931493282318115\n",
      "epoch: 9 step: 651 loss: 0.6931493282318115\n",
      "epoch: 9 step: 652 loss: 0.6931493282318115\n",
      "epoch: 9 step: 653 loss: 0.6931493282318115\n",
      "epoch: 9 step: 654 loss: 0.6931493282318115\n",
      "epoch: 9 step: 655 loss: 0.6931493282318115\n",
      "epoch: 9 step: 656 loss: 0.6931493282318115\n",
      "epoch: 9 step: 657 loss: 0.6931493282318115\n",
      "epoch: 9 step: 658 loss: 0.6931493282318115\n",
      "epoch: 9 step: 659 loss: 0.6931493282318115\n",
      "epoch: 9 step: 660 loss: 0.6931493282318115\n",
      "epoch: 9 step: 661 loss: 0.6931493282318115\n",
      "epoch: 9 step: 662 loss: 0.6931493282318115\n",
      "epoch: 9 step: 663 loss: 0.6931493282318115\n",
      "epoch: 9 step: 664 loss: 0.6931493282318115\n",
      "epoch: 9 step: 665 loss: 0.6931493282318115\n",
      "epoch: 9 step: 666 loss: 0.6931493282318115\n",
      "epoch: 9 step: 667 loss: 0.6931493282318115\n",
      "epoch: 9 step: 668 loss: 0.6931493282318115\n",
      "epoch: 9 step: 669 loss: 0.6931493282318115\n",
      "epoch: 9 step: 670 loss: 0.6931493282318115\n",
      "epoch: 9 step: 671 loss: 0.6931493282318115\n",
      "epoch: 9 step: 672 loss: 0.6931493282318115\n",
      "epoch: 9 step: 673 loss: 0.6931493282318115\n",
      "epoch: 9 step: 674 loss: 0.6931493282318115\n",
      "epoch: 9 step: 675 loss: 0.6931493282318115\n",
      "epoch: 9 step: 676 loss: 0.6931493282318115\n",
      "epoch: 9 step: 677 loss: 0.6931493282318115\n",
      "epoch: 9 step: 678 loss: 0.6931493282318115\n",
      "epoch: 9 step: 679 loss: 0.6931493282318115\n",
      "epoch: 9 step: 680 loss: 0.6931493282318115\n",
      "epoch: 9 step: 681 loss: 0.6931493282318115\n",
      "epoch: 9 step: 682 loss: 0.6931493282318115\n",
      "epoch: 9 step: 683 loss: 0.6931493282318115\n",
      "epoch: 9 step: 684 loss: 0.6931493282318115\n",
      "epoch: 9 step: 685 loss: 0.6931493282318115\n",
      "epoch: 9 step: 686 loss: 0.6931493282318115\n",
      "epoch: 9 step: 687 loss: 0.6931493282318115\n",
      "epoch: 9 step: 688 loss: 0.6931493282318115\n",
      "epoch: 9 step: 689 loss: 0.6931493282318115\n",
      "epoch: 9 step: 690 loss: 0.6931493282318115\n",
      "epoch: 9 step: 691 loss: 0.6931493282318115\n",
      "epoch: 9 step: 692 loss: 0.6931493282318115\n",
      "epoch: 9 step: 693 loss: 0.6931493282318115\n",
      "epoch: 9 step: 694 loss: 0.6931493282318115\n",
      "epoch: 9 step: 695 loss: 0.6931493282318115\n",
      "epoch: 9 step: 696 loss: 0.6931493282318115\n",
      "epoch: 9 step: 697 loss: 0.6931493282318115\n",
      "epoch: 9 step: 698 loss: 0.6931493282318115\n",
      "epoch: 9 step: 699 loss: 0.6931493282318115\n",
      "epoch: 9 step: 700 loss: 0.6931493282318115\n",
      "epoch: 9 step: 701 loss: 0.6931492686271667\n",
      "epoch: 9 step: 702 loss: 0.6931493282318115\n",
      "epoch: 9 step: 703 loss: 0.6931493282318115\n",
      "epoch: 9 step: 704 loss: 0.6931493282318115\n",
      "epoch: 9 step: 705 loss: 0.6931492686271667\n",
      "epoch: 9 step: 706 loss: 0.693149209022522\n",
      "epoch: 9 step: 707 loss: 0.693149209022522\n",
      "epoch: 9 step: 708 loss: 0.693149209022522\n",
      "epoch: 9 step: 709 loss: 0.6931493282318115\n",
      "epoch: 9 step: 710 loss: 0.6931492686271667\n",
      "epoch: 9 step: 711 loss: 0.693149209022522\n",
      "epoch: 9 step: 712 loss: 0.693149209022522\n",
      "epoch: 9 step: 713 loss: 0.6931492686271667\n",
      "epoch: 9 step: 714 loss: 0.6931493282318115\n",
      "epoch: 9 step: 715 loss: 0.693149209022522\n",
      "epoch: 9 step: 716 loss: 0.693149209022522\n",
      "epoch: 9 step: 717 loss: 0.693149209022522\n",
      "epoch: 9 step: 718 loss: 0.693149209022522\n",
      "epoch: 9 step: 719 loss: 0.693149209022522\n",
      "epoch: 9 step: 720 loss: 0.693149209022522\n",
      "epoch: 9 step: 721 loss: 0.693149209022522\n",
      "epoch: 9 step: 722 loss: 0.693149209022522\n",
      "epoch: 9 step: 723 loss: 0.6931493282318115\n",
      "epoch: 9 step: 724 loss: 0.693149209022522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 725 loss: 0.693149209022522\n",
      "epoch: 9 step: 726 loss: 0.693149209022522\n",
      "epoch: 9 step: 727 loss: 0.693149209022522\n",
      "epoch: 9 step: 728 loss: 0.693149209022522\n",
      "epoch: 9 step: 729 loss: 0.693149209022522\n",
      "epoch: 9 step: 730 loss: 0.693149209022522\n",
      "epoch: 9 step: 731 loss: 0.693149209022522\n",
      "epoch: 9 step: 732 loss: 0.693149209022522\n",
      "epoch: 9 step: 733 loss: 0.693149209022522\n",
      "epoch: 9 step: 734 loss: 0.693149209022522\n",
      "epoch: 9 step: 735 loss: 0.693149209022522\n",
      "epoch: 9 step: 736 loss: 0.693149209022522\n",
      "epoch: 9 step: 737 loss: 0.693149209022522\n",
      "epoch: 9 step: 738 loss: 0.693149209022522\n",
      "epoch: 9 step: 739 loss: 0.693149209022522\n",
      "epoch: 9 step: 740 loss: 0.693149209022522\n",
      "epoch: 9 step: 741 loss: 0.693149209022522\n",
      "epoch: 9 step: 742 loss: 0.693149209022522\n",
      "epoch: 9 step: 743 loss: 0.693149209022522\n",
      "epoch: 9 step: 744 loss: 0.693149209022522\n",
      "epoch: 9 step: 745 loss: 0.693149209022522\n",
      "epoch: 9 step: 746 loss: 0.693149209022522\n",
      "epoch: 9 step: 747 loss: 0.693149209022522\n",
      "epoch: 9 step: 748 loss: 0.693149209022522\n",
      "epoch: 9 step: 749 loss: 0.693149209022522\n",
      "epoch: 9 step: 750 loss: 0.693149209022522\n",
      "epoch: 9 step: 751 loss: 0.693149209022522\n",
      "epoch: 9 step: 752 loss: 0.693149209022522\n",
      "epoch: 9 step: 753 loss: 0.693149209022522\n",
      "epoch: 9 step: 754 loss: 0.693149209022522\n",
      "epoch: 9 step: 755 loss: 0.693149209022522\n",
      "epoch: 9 step: 756 loss: 0.693149209022522\n",
      "epoch: 9 step: 757 loss: 0.693149209022522\n",
      "epoch: 9 step: 758 loss: 0.693149209022522\n",
      "epoch: 9 step: 759 loss: 0.693149209022522\n",
      "epoch: 9 step: 760 loss: 0.693149209022522\n",
      "epoch: 9 step: 761 loss: 0.693149209022522\n",
      "epoch: 9 step: 762 loss: 0.693149209022522\n",
      "epoch: 9 step: 763 loss: 0.693149209022522\n",
      "epoch: 9 step: 764 loss: 0.693149209022522\n",
      "epoch: 9 step: 765 loss: 0.693149209022522\n",
      "epoch: 9 step: 766 loss: 0.693149209022522\n",
      "epoch: 9 step: 767 loss: 0.693149209022522\n",
      "epoch: 9 step: 768 loss: 0.693149209022522\n",
      "epoch: 9 step: 769 loss: 0.693149209022522\n",
      "epoch: 9 step: 770 loss: 0.693149209022522\n",
      "epoch: 9 step: 771 loss: 0.693149209022522\n",
      "epoch: 9 step: 772 loss: 0.693149209022522\n",
      "epoch: 9 step: 773 loss: 0.693149209022522\n",
      "epoch: 9 step: 774 loss: 0.693149209022522\n",
      "epoch: 9 step: 775 loss: 0.693149209022522\n",
      "epoch: 9 step: 776 loss: 0.693149209022522\n",
      "epoch: 9 step: 777 loss: 0.693149209022522\n",
      "epoch: 9 step: 778 loss: 0.693149209022522\n",
      "epoch: 9 step: 779 loss: 0.6931491494178772\n",
      "epoch: 9 step: 780 loss: 0.693149209022522\n",
      "epoch: 9 step: 781 loss: 0.6931492686271667\n",
      "epoch: 10 step: 1 loss: 0.693149209022522\n",
      "epoch: 10 step: 2 loss: 0.693149209022522\n",
      "epoch: 10 step: 3 loss: 0.693149209022522\n",
      "epoch: 10 step: 4 loss: 0.693149209022522\n",
      "epoch: 10 step: 5 loss: 0.693149209022522\n",
      "epoch: 10 step: 6 loss: 0.693149209022522\n",
      "epoch: 10 step: 7 loss: 0.693149209022522\n",
      "epoch: 10 step: 8 loss: 0.693149209022522\n",
      "epoch: 10 step: 9 loss: 0.693149209022522\n",
      "epoch: 10 step: 10 loss: 0.693149209022522\n",
      "epoch: 10 step: 11 loss: 0.693149209022522\n",
      "epoch: 10 step: 12 loss: 0.693149209022522\n",
      "epoch: 10 step: 13 loss: 0.6931491494178772\n",
      "epoch: 10 step: 14 loss: 0.693149209022522\n",
      "epoch: 10 step: 15 loss: 0.693149209022522\n",
      "epoch: 10 step: 16 loss: 0.693149209022522\n",
      "epoch: 10 step: 17 loss: 0.693149209022522\n",
      "epoch: 10 step: 18 loss: 0.6931490898132324\n",
      "epoch: 10 step: 19 loss: 0.693149209022522\n",
      "epoch: 10 step: 20 loss: 0.6931491494178772\n",
      "epoch: 10 step: 21 loss: 0.693149209022522\n",
      "epoch: 10 step: 22 loss: 0.6931490898132324\n",
      "epoch: 10 step: 23 loss: 0.6931490898132324\n",
      "epoch: 10 step: 24 loss: 0.6931490898132324\n",
      "epoch: 10 step: 25 loss: 0.6931491494178772\n",
      "epoch: 10 step: 26 loss: 0.6931490898132324\n",
      "epoch: 10 step: 27 loss: 0.6931490898132324\n",
      "epoch: 10 step: 28 loss: 0.6931491494178772\n",
      "epoch: 10 step: 29 loss: 0.693149209022522\n",
      "epoch: 10 step: 30 loss: 0.6931490898132324\n",
      "epoch: 10 step: 31 loss: 0.6931490898132324\n",
      "epoch: 10 step: 32 loss: 0.6931490898132324\n",
      "epoch: 10 step: 33 loss: 0.6931490898132324\n",
      "epoch: 10 step: 34 loss: 0.6931491494178772\n",
      "epoch: 10 step: 35 loss: 0.6931490898132324\n",
      "epoch: 10 step: 36 loss: 0.6931490898132324\n",
      "epoch: 10 step: 37 loss: 0.6931490898132324\n",
      "epoch: 10 step: 38 loss: 0.6931490898132324\n",
      "epoch: 10 step: 39 loss: 0.6931490898132324\n",
      "epoch: 10 step: 40 loss: 0.6931490898132324\n",
      "epoch: 10 step: 41 loss: 0.6931490898132324\n",
      "epoch: 10 step: 42 loss: 0.6931490898132324\n",
      "epoch: 10 step: 43 loss: 0.6931490898132324\n",
      "epoch: 10 step: 44 loss: 0.6931490898132324\n",
      "epoch: 10 step: 45 loss: 0.6931490898132324\n",
      "epoch: 10 step: 46 loss: 0.6931490898132324\n",
      "epoch: 10 step: 47 loss: 0.6931490898132324\n",
      "epoch: 10 step: 48 loss: 0.6931490898132324\n",
      "epoch: 10 step: 49 loss: 0.6931490898132324\n",
      "epoch: 10 step: 50 loss: 0.6931490898132324\n",
      "epoch: 10 step: 51 loss: 0.6931490898132324\n",
      "epoch: 10 step: 52 loss: 0.6931490898132324\n",
      "epoch: 10 step: 53 loss: 0.6931490898132324\n",
      "epoch: 10 step: 54 loss: 0.6931490898132324\n",
      "epoch: 10 step: 55 loss: 0.6931490898132324\n",
      "epoch: 10 step: 56 loss: 0.6931490898132324\n",
      "epoch: 10 step: 57 loss: 0.6931490898132324\n",
      "epoch: 10 step: 58 loss: 0.6931490898132324\n",
      "epoch: 10 step: 59 loss: 0.6931490898132324\n",
      "epoch: 10 step: 60 loss: 0.6931490898132324\n",
      "epoch: 10 step: 61 loss: 0.6931490898132324\n",
      "epoch: 10 step: 62 loss: 0.6931490898132324\n",
      "epoch: 10 step: 63 loss: 0.6931490898132324\n",
      "epoch: 10 step: 64 loss: 0.6931490898132324\n",
      "epoch: 10 step: 65 loss: 0.6931490898132324\n",
      "epoch: 10 step: 66 loss: 0.6931490898132324\n",
      "epoch: 10 step: 67 loss: 0.6931490898132324\n",
      "epoch: 10 step: 68 loss: 0.6931490898132324\n",
      "epoch: 10 step: 69 loss: 0.6931490898132324\n",
      "epoch: 10 step: 70 loss: 0.6931490898132324\n",
      "epoch: 10 step: 71 loss: 0.6931490898132324\n",
      "epoch: 10 step: 72 loss: 0.6931490898132324\n",
      "epoch: 10 step: 73 loss: 0.6931490898132324\n",
      "epoch: 10 step: 74 loss: 0.6931490898132324\n",
      "epoch: 10 step: 75 loss: 0.6931490898132324\n",
      "epoch: 10 step: 76 loss: 0.6931490898132324\n",
      "epoch: 10 step: 77 loss: 0.6931490898132324\n",
      "epoch: 10 step: 78 loss: 0.6931490898132324\n",
      "epoch: 10 step: 79 loss: 0.6931490898132324\n",
      "epoch: 10 step: 80 loss: 0.6931490898132324\n",
      "epoch: 10 step: 81 loss: 0.6931490898132324\n",
      "epoch: 10 step: 82 loss: 0.6931490898132324\n",
      "epoch: 10 step: 83 loss: 0.6931490898132324\n",
      "epoch: 10 step: 84 loss: 0.6931490898132324\n",
      "epoch: 10 step: 85 loss: 0.6931490898132324\n",
      "epoch: 10 step: 86 loss: 0.6931490898132324\n",
      "epoch: 10 step: 87 loss: 0.6931490898132324\n",
      "epoch: 10 step: 88 loss: 0.6931490898132324\n",
      "epoch: 10 step: 89 loss: 0.6931490898132324\n",
      "epoch: 10 step: 90 loss: 0.6931490898132324\n",
      "epoch: 10 step: 91 loss: 0.6931490898132324\n",
      "epoch: 10 step: 92 loss: 0.6931490898132324\n",
      "epoch: 10 step: 93 loss: 0.6931490898132324\n",
      "epoch: 10 step: 94 loss: 0.6931490898132324\n",
      "epoch: 10 step: 95 loss: 0.6931490898132324\n",
      "epoch: 10 step: 96 loss: 0.6931490898132324\n",
      "epoch: 10 step: 97 loss: 0.6931490898132324\n",
      "epoch: 10 step: 98 loss: 0.6931490898132324\n",
      "epoch: 10 step: 99 loss: 0.6931490898132324\n",
      "epoch: 10 step: 100 loss: 0.6931490898132324\n",
      "epoch: 10 step: 101 loss: 0.6931490898132324\n",
      "epoch: 10 step: 102 loss: 0.6931490898132324\n",
      "epoch: 10 step: 103 loss: 0.6931490898132324\n",
      "epoch: 10 step: 104 loss: 0.6931490898132324\n",
      "epoch: 10 step: 105 loss: 0.6931490898132324\n",
      "epoch: 10 step: 106 loss: 0.6931490898132324\n",
      "epoch: 10 step: 107 loss: 0.6931490898132324\n",
      "epoch: 10 step: 108 loss: 0.6931490898132324\n",
      "epoch: 10 step: 109 loss: 0.6931490898132324\n",
      "epoch: 10 step: 110 loss: 0.6931490898132324\n",
      "epoch: 10 step: 111 loss: 0.6931490898132324\n",
      "epoch: 10 step: 112 loss: 0.6931490898132324\n",
      "epoch: 10 step: 113 loss: 0.6931490898132324\n",
      "epoch: 10 step: 114 loss: 0.6931490898132324\n",
      "epoch: 10 step: 115 loss: 0.6931490898132324\n",
      "epoch: 10 step: 116 loss: 0.6931490898132324\n",
      "epoch: 10 step: 117 loss: 0.6931490898132324\n",
      "epoch: 10 step: 118 loss: 0.6931490898132324\n",
      "epoch: 10 step: 119 loss: 0.6931490898132324\n",
      "epoch: 10 step: 120 loss: 0.6931490898132324\n",
      "epoch: 10 step: 121 loss: 0.6931490898132324\n",
      "epoch: 10 step: 122 loss: 0.6931490898132324\n",
      "epoch: 10 step: 123 loss: 0.6931490898132324\n",
      "epoch: 10 step: 124 loss: 0.6931490898132324\n",
      "epoch: 10 step: 125 loss: 0.6931490898132324\n",
      "epoch: 10 step: 126 loss: 0.6931490898132324\n",
      "epoch: 10 step: 127 loss: 0.6931490898132324\n",
      "epoch: 10 step: 128 loss: 0.6931490898132324\n",
      "epoch: 10 step: 129 loss: 0.6931490898132324\n",
      "epoch: 10 step: 130 loss: 0.6931490898132324\n",
      "epoch: 10 step: 131 loss: 0.6931490898132324\n",
      "epoch: 10 step: 132 loss: 0.6931490302085876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 133 loss: 0.6931490898132324\n",
      "epoch: 10 step: 134 loss: 0.6931490898132324\n",
      "epoch: 10 step: 135 loss: 0.6931490898132324\n",
      "epoch: 10 step: 136 loss: 0.6931490898132324\n",
      "epoch: 10 step: 137 loss: 0.6931490302085876\n",
      "epoch: 10 step: 138 loss: 0.6931490898132324\n",
      "epoch: 10 step: 139 loss: 0.6931490302085876\n",
      "epoch: 10 step: 140 loss: 0.6931490898132324\n",
      "epoch: 10 step: 141 loss: 0.6931490898132324\n",
      "epoch: 10 step: 142 loss: 0.6931489706039429\n",
      "epoch: 10 step: 143 loss: 0.6931490302085876\n",
      "epoch: 10 step: 144 loss: 0.6931490898132324\n",
      "epoch: 10 step: 145 loss: 0.6931490898132324\n",
      "epoch: 10 step: 146 loss: 0.6931490898132324\n",
      "epoch: 10 step: 147 loss: 0.6931489706039429\n",
      "epoch: 10 step: 148 loss: 0.6931489706039429\n",
      "epoch: 10 step: 149 loss: 0.6931490302085876\n",
      "epoch: 10 step: 150 loss: 0.6931489706039429\n",
      "epoch: 10 step: 151 loss: 0.6931489706039429\n",
      "epoch: 10 step: 152 loss: 0.6931489706039429\n",
      "epoch: 10 step: 153 loss: 0.6931489706039429\n",
      "epoch: 10 step: 154 loss: 0.6931489706039429\n",
      "epoch: 10 step: 155 loss: 0.6931489706039429\n",
      "epoch: 10 step: 156 loss: 0.6931489706039429\n",
      "epoch: 10 step: 157 loss: 0.6931489706039429\n",
      "epoch: 10 step: 158 loss: 0.6931489706039429\n",
      "epoch: 10 step: 159 loss: 0.6931489706039429\n",
      "epoch: 10 step: 160 loss: 0.6931489706039429\n",
      "epoch: 10 step: 161 loss: 0.6931489706039429\n",
      "epoch: 10 step: 162 loss: 0.6931489706039429\n",
      "epoch: 10 step: 163 loss: 0.6931489706039429\n",
      "epoch: 10 step: 164 loss: 0.6931489706039429\n",
      "epoch: 10 step: 165 loss: 0.6931489706039429\n",
      "epoch: 10 step: 166 loss: 0.6931489706039429\n",
      "epoch: 10 step: 167 loss: 0.6931489706039429\n",
      "epoch: 10 step: 168 loss: 0.6931489706039429\n",
      "epoch: 10 step: 169 loss: 0.6931489706039429\n",
      "epoch: 10 step: 170 loss: 0.6931489706039429\n",
      "epoch: 10 step: 171 loss: 0.6931489706039429\n",
      "epoch: 10 step: 172 loss: 0.6931489706039429\n",
      "epoch: 10 step: 173 loss: 0.6931489706039429\n",
      "epoch: 10 step: 174 loss: 0.6931489706039429\n",
      "epoch: 10 step: 175 loss: 0.6931489706039429\n",
      "epoch: 10 step: 176 loss: 0.6931489706039429\n",
      "epoch: 10 step: 177 loss: 0.6931489706039429\n",
      "epoch: 10 step: 178 loss: 0.6931489706039429\n",
      "epoch: 10 step: 179 loss: 0.6931489706039429\n",
      "epoch: 10 step: 180 loss: 0.6931489706039429\n",
      "epoch: 10 step: 181 loss: 0.6931489706039429\n",
      "epoch: 10 step: 182 loss: 0.6931489706039429\n",
      "epoch: 10 step: 183 loss: 0.6931489706039429\n",
      "epoch: 10 step: 184 loss: 0.6931489706039429\n",
      "epoch: 10 step: 185 loss: 0.6931489706039429\n",
      "epoch: 10 step: 186 loss: 0.6931489706039429\n",
      "epoch: 10 step: 187 loss: 0.6931489706039429\n",
      "epoch: 10 step: 188 loss: 0.6931489706039429\n",
      "epoch: 10 step: 189 loss: 0.6931489706039429\n",
      "epoch: 10 step: 190 loss: 0.6931489706039429\n",
      "epoch: 10 step: 191 loss: 0.6931489706039429\n",
      "epoch: 10 step: 192 loss: 0.6931489706039429\n",
      "epoch: 10 step: 193 loss: 0.6931489706039429\n",
      "epoch: 10 step: 194 loss: 0.6931489706039429\n",
      "epoch: 10 step: 195 loss: 0.6931489706039429\n",
      "epoch: 10 step: 196 loss: 0.6931489706039429\n",
      "epoch: 10 step: 197 loss: 0.6931489706039429\n",
      "epoch: 10 step: 198 loss: 0.6931489706039429\n",
      "epoch: 10 step: 199 loss: 0.6931489706039429\n",
      "epoch: 10 step: 200 loss: 0.6931489706039429\n",
      "epoch: 10 step: 201 loss: 0.6931489706039429\n",
      "epoch: 10 step: 202 loss: 0.6931489706039429\n",
      "epoch: 10 step: 203 loss: 0.6931489706039429\n",
      "epoch: 10 step: 204 loss: 0.6931489706039429\n",
      "epoch: 10 step: 205 loss: 0.6931489706039429\n",
      "epoch: 10 step: 206 loss: 0.6931489706039429\n",
      "epoch: 10 step: 207 loss: 0.6931489706039429\n",
      "epoch: 10 step: 208 loss: 0.6931489706039429\n",
      "epoch: 10 step: 209 loss: 0.6931489706039429\n",
      "epoch: 10 step: 210 loss: 0.6931489706039429\n",
      "epoch: 10 step: 211 loss: 0.6931489706039429\n",
      "epoch: 10 step: 212 loss: 0.6931489706039429\n",
      "epoch: 10 step: 213 loss: 0.6931489706039429\n",
      "epoch: 10 step: 214 loss: 0.6931489706039429\n",
      "epoch: 10 step: 215 loss: 0.6931489706039429\n",
      "epoch: 10 step: 216 loss: 0.6931489706039429\n",
      "epoch: 10 step: 217 loss: 0.6931489706039429\n",
      "epoch: 10 step: 218 loss: 0.6931489706039429\n",
      "epoch: 10 step: 219 loss: 0.6931489706039429\n",
      "epoch: 10 step: 220 loss: 0.6931489706039429\n",
      "epoch: 10 step: 221 loss: 0.6931489706039429\n",
      "epoch: 10 step: 222 loss: 0.6931489706039429\n",
      "epoch: 10 step: 223 loss: 0.6931489706039429\n",
      "epoch: 10 step: 224 loss: 0.6931489706039429\n",
      "epoch: 10 step: 225 loss: 0.6931489706039429\n",
      "epoch: 10 step: 226 loss: 0.6931489706039429\n",
      "epoch: 10 step: 227 loss: 0.6931489706039429\n",
      "epoch: 10 step: 228 loss: 0.6931489706039429\n",
      "epoch: 10 step: 229 loss: 0.6931489706039429\n",
      "epoch: 10 step: 230 loss: 0.6931489706039429\n",
      "epoch: 10 step: 231 loss: 0.6931489706039429\n",
      "epoch: 10 step: 232 loss: 0.6931489706039429\n",
      "epoch: 10 step: 233 loss: 0.6931489706039429\n",
      "epoch: 10 step: 234 loss: 0.6931489706039429\n",
      "epoch: 10 step: 235 loss: 0.6931489706039429\n",
      "epoch: 10 step: 236 loss: 0.6931489706039429\n",
      "epoch: 10 step: 237 loss: 0.6931489706039429\n",
      "epoch: 10 step: 238 loss: 0.6931489706039429\n",
      "epoch: 10 step: 239 loss: 0.6931489706039429\n",
      "epoch: 10 step: 240 loss: 0.6931489706039429\n",
      "epoch: 10 step: 241 loss: 0.6931489706039429\n",
      "epoch: 10 step: 242 loss: 0.6931489706039429\n",
      "epoch: 10 step: 243 loss: 0.6931489706039429\n",
      "epoch: 10 step: 244 loss: 0.6931489706039429\n",
      "epoch: 10 step: 245 loss: 0.6931489706039429\n",
      "epoch: 10 step: 246 loss: 0.6931489706039429\n",
      "epoch: 10 step: 247 loss: 0.6931489706039429\n",
      "epoch: 10 step: 248 loss: 0.6931489706039429\n",
      "epoch: 10 step: 249 loss: 0.6931489706039429\n",
      "epoch: 10 step: 250 loss: 0.6931489706039429\n",
      "epoch: 10 step: 251 loss: 0.6931489706039429\n",
      "epoch: 10 step: 252 loss: 0.6931489706039429\n",
      "epoch: 10 step: 253 loss: 0.6931489706039429\n",
      "epoch: 10 step: 254 loss: 0.6931489706039429\n",
      "epoch: 10 step: 255 loss: 0.6931489706039429\n",
      "epoch: 10 step: 256 loss: 0.6931489706039429\n",
      "epoch: 10 step: 257 loss: 0.6931489706039429\n",
      "epoch: 10 step: 258 loss: 0.6931489706039429\n",
      "epoch: 10 step: 259 loss: 0.6931489706039429\n",
      "epoch: 10 step: 260 loss: 0.6931489706039429\n",
      "epoch: 10 step: 261 loss: 0.6931489706039429\n",
      "epoch: 10 step: 262 loss: 0.6931489706039429\n",
      "epoch: 10 step: 263 loss: 0.6931489706039429\n",
      "epoch: 10 step: 264 loss: 0.6931489706039429\n",
      "epoch: 10 step: 265 loss: 0.6931489706039429\n",
      "epoch: 10 step: 266 loss: 0.6931489706039429\n",
      "epoch: 10 step: 267 loss: 0.6931489706039429\n",
      "epoch: 10 step: 268 loss: 0.6931489706039429\n",
      "epoch: 10 step: 269 loss: 0.6931489706039429\n",
      "epoch: 10 step: 270 loss: 0.6931489706039429\n",
      "epoch: 10 step: 271 loss: 0.6931489706039429\n",
      "epoch: 10 step: 272 loss: 0.6931489706039429\n",
      "epoch: 10 step: 273 loss: 0.6931489109992981\n",
      "epoch: 10 step: 274 loss: 0.6931489706039429\n",
      "epoch: 10 step: 275 loss: 0.6931488513946533\n",
      "epoch: 10 step: 276 loss: 0.6931489706039429\n",
      "epoch: 10 step: 277 loss: 0.6931488513946533\n",
      "epoch: 10 step: 278 loss: 0.6931488513946533\n",
      "epoch: 10 step: 279 loss: 0.6931489706039429\n",
      "epoch: 10 step: 280 loss: 0.6931488513946533\n",
      "epoch: 10 step: 281 loss: 0.6931488513946533\n",
      "epoch: 10 step: 282 loss: 0.6931488513946533\n",
      "epoch: 10 step: 283 loss: 0.6931488513946533\n",
      "epoch: 10 step: 284 loss: 0.6931489109992981\n",
      "epoch: 10 step: 285 loss: 0.6931488513946533\n",
      "epoch: 10 step: 286 loss: 0.6931488513946533\n",
      "epoch: 10 step: 287 loss: 0.6931488513946533\n",
      "epoch: 10 step: 288 loss: 0.6931489109992981\n",
      "epoch: 10 step: 289 loss: 0.6931488513946533\n",
      "epoch: 10 step: 290 loss: 0.6931488513946533\n",
      "epoch: 10 step: 291 loss: 0.6931488513946533\n",
      "epoch: 10 step: 292 loss: 0.6931488513946533\n",
      "epoch: 10 step: 293 loss: 0.6931488513946533\n",
      "epoch: 10 step: 294 loss: 0.6931488513946533\n",
      "epoch: 10 step: 295 loss: 0.6931488513946533\n",
      "epoch: 10 step: 296 loss: 0.6931488513946533\n",
      "epoch: 10 step: 297 loss: 0.6931488513946533\n",
      "epoch: 10 step: 298 loss: 0.6931488513946533\n",
      "epoch: 10 step: 299 loss: 0.6931488513946533\n",
      "epoch: 10 step: 300 loss: 0.6931488513946533\n",
      "epoch: 10 step: 301 loss: 0.6931488513946533\n",
      "epoch: 10 step: 302 loss: 0.6931488513946533\n",
      "epoch: 10 step: 303 loss: 0.6931488513946533\n",
      "epoch: 10 step: 304 loss: 0.6931488513946533\n",
      "epoch: 10 step: 305 loss: 0.6931488513946533\n",
      "epoch: 10 step: 306 loss: 0.6931488513946533\n",
      "epoch: 10 step: 307 loss: 0.6931488513946533\n",
      "epoch: 10 step: 308 loss: 0.6931488513946533\n",
      "epoch: 10 step: 309 loss: 0.6931488513946533\n",
      "epoch: 10 step: 310 loss: 0.6931488513946533\n",
      "epoch: 10 step: 311 loss: 0.6931488513946533\n",
      "epoch: 10 step: 312 loss: 0.6931488513946533\n",
      "epoch: 10 step: 313 loss: 0.6931488513946533\n",
      "epoch: 10 step: 314 loss: 0.6931488513946533\n",
      "epoch: 10 step: 315 loss: 0.6931488513946533\n",
      "epoch: 10 step: 316 loss: 0.6931488513946533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 317 loss: 0.6931488513946533\n",
      "epoch: 10 step: 318 loss: 0.6931488513946533\n",
      "epoch: 10 step: 319 loss: 0.6931488513946533\n",
      "epoch: 10 step: 320 loss: 0.6931488513946533\n",
      "epoch: 10 step: 321 loss: 0.6931488513946533\n",
      "epoch: 10 step: 322 loss: 0.6931488513946533\n",
      "epoch: 10 step: 323 loss: 0.6931488513946533\n",
      "epoch: 10 step: 324 loss: 0.6931488513946533\n",
      "epoch: 10 step: 325 loss: 0.6931488513946533\n",
      "epoch: 10 step: 326 loss: 0.6931488513946533\n",
      "epoch: 10 step: 327 loss: 0.6931488513946533\n",
      "epoch: 10 step: 328 loss: 0.6931488513946533\n",
      "epoch: 10 step: 329 loss: 0.6931488513946533\n",
      "epoch: 10 step: 330 loss: 0.6931488513946533\n",
      "epoch: 10 step: 331 loss: 0.6931488513946533\n",
      "epoch: 10 step: 332 loss: 0.6931488513946533\n",
      "epoch: 10 step: 333 loss: 0.6931488513946533\n",
      "epoch: 10 step: 334 loss: 0.6931488513946533\n",
      "epoch: 10 step: 335 loss: 0.6931488513946533\n",
      "epoch: 10 step: 336 loss: 0.6931488513946533\n",
      "epoch: 10 step: 337 loss: 0.6931488513946533\n",
      "epoch: 10 step: 338 loss: 0.6931488513946533\n",
      "epoch: 10 step: 339 loss: 0.6931488513946533\n",
      "epoch: 10 step: 340 loss: 0.6931488513946533\n",
      "epoch: 10 step: 341 loss: 0.6931488513946533\n",
      "epoch: 10 step: 342 loss: 0.6931488513946533\n",
      "epoch: 10 step: 343 loss: 0.6931488513946533\n",
      "epoch: 10 step: 344 loss: 0.6931488513946533\n",
      "epoch: 10 step: 345 loss: 0.6931488513946533\n",
      "epoch: 10 step: 346 loss: 0.6931488513946533\n",
      "epoch: 10 step: 347 loss: 0.6931488513946533\n",
      "epoch: 10 step: 348 loss: 0.6931488513946533\n",
      "epoch: 10 step: 349 loss: 0.6931488513946533\n",
      "epoch: 10 step: 350 loss: 0.6931488513946533\n",
      "epoch: 10 step: 351 loss: 0.6931488513946533\n",
      "epoch: 10 step: 352 loss: 0.6931488513946533\n",
      "epoch: 10 step: 353 loss: 0.6931488513946533\n",
      "epoch: 10 step: 354 loss: 0.6931488513946533\n",
      "epoch: 10 step: 355 loss: 0.6931488513946533\n",
      "epoch: 10 step: 356 loss: 0.6931488513946533\n",
      "epoch: 10 step: 357 loss: 0.6931488513946533\n",
      "epoch: 10 step: 358 loss: 0.6931488513946533\n",
      "epoch: 10 step: 359 loss: 0.6931488513946533\n",
      "epoch: 10 step: 360 loss: 0.6931488513946533\n",
      "epoch: 10 step: 361 loss: 0.6931488513946533\n",
      "epoch: 10 step: 362 loss: 0.6931488513946533\n",
      "epoch: 10 step: 363 loss: 0.6931488513946533\n",
      "epoch: 10 step: 364 loss: 0.6931488513946533\n",
      "epoch: 10 step: 365 loss: 0.6931488513946533\n",
      "epoch: 10 step: 366 loss: 0.6931488513946533\n",
      "epoch: 10 step: 367 loss: 0.6931488513946533\n",
      "epoch: 10 step: 368 loss: 0.6931488513946533\n",
      "epoch: 10 step: 369 loss: 0.6931487917900085\n",
      "epoch: 10 step: 370 loss: 0.6931488513946533\n",
      "epoch: 10 step: 371 loss: 0.6931488513946533\n",
      "epoch: 10 step: 372 loss: 0.6931488513946533\n",
      "epoch: 10 step: 373 loss: 0.6931488513946533\n",
      "epoch: 10 step: 374 loss: 0.6931488513946533\n",
      "epoch: 10 step: 375 loss: 0.6931488513946533\n",
      "epoch: 10 step: 376 loss: 0.6931488513946533\n",
      "epoch: 10 step: 377 loss: 0.6931488513946533\n",
      "epoch: 10 step: 378 loss: 0.6931487917900085\n",
      "epoch: 10 step: 379 loss: 0.6931488513946533\n",
      "epoch: 10 step: 380 loss: 0.6931488513946533\n",
      "epoch: 10 step: 381 loss: 0.6931488513946533\n",
      "epoch: 10 step: 382 loss: 0.6931487917900085\n",
      "epoch: 10 step: 383 loss: 0.6931488513946533\n",
      "epoch: 10 step: 384 loss: 0.6931488513946533\n",
      "epoch: 10 step: 385 loss: 0.6931488513946533\n",
      "epoch: 10 step: 386 loss: 0.6931488513946533\n",
      "epoch: 10 step: 387 loss: 0.6931487321853638\n",
      "epoch: 10 step: 388 loss: 0.6931487917900085\n",
      "epoch: 10 step: 389 loss: 0.6931487917900085\n",
      "epoch: 10 step: 390 loss: 0.6931487917900085\n",
      "epoch: 10 step: 391 loss: 0.6931488513946533\n",
      "epoch: 10 step: 392 loss: 0.6931488513946533\n",
      "epoch: 10 step: 393 loss: 0.6931488513946533\n",
      "epoch: 10 step: 394 loss: 0.6931487321853638\n",
      "epoch: 10 step: 395 loss: 0.6931488513946533\n",
      "epoch: 10 step: 396 loss: 0.6931487321853638\n",
      "epoch: 10 step: 397 loss: 0.6931487917900085\n",
      "epoch: 10 step: 398 loss: 0.6931488513946533\n",
      "epoch: 10 step: 399 loss: 0.6931487321853638\n",
      "epoch: 10 step: 400 loss: 0.6931487321853638\n",
      "epoch: 10 step: 401 loss: 0.6931487917900085\n",
      "epoch: 10 step: 402 loss: 0.6931487321853638\n",
      "epoch: 10 step: 403 loss: 0.6931487321853638\n",
      "epoch: 10 step: 404 loss: 0.6931487321853638\n",
      "epoch: 10 step: 405 loss: 0.6931487321853638\n",
      "epoch: 10 step: 406 loss: 0.6931487321853638\n",
      "epoch: 10 step: 407 loss: 0.6931487321853638\n",
      "epoch: 10 step: 408 loss: 0.6931487321853638\n",
      "epoch: 10 step: 409 loss: 0.6931487321853638\n",
      "epoch: 10 step: 410 loss: 0.6931487321853638\n",
      "epoch: 10 step: 411 loss: 0.6931487321853638\n",
      "epoch: 10 step: 412 loss: 0.6931487321853638\n",
      "epoch: 10 step: 413 loss: 0.6931487321853638\n",
      "epoch: 10 step: 414 loss: 0.6931487321853638\n",
      "epoch: 10 step: 415 loss: 0.6931487321853638\n",
      "epoch: 10 step: 416 loss: 0.6931487321853638\n",
      "epoch: 10 step: 417 loss: 0.6931487321853638\n",
      "epoch: 10 step: 418 loss: 0.6931487321853638\n",
      "epoch: 10 step: 419 loss: 0.6931487321853638\n",
      "epoch: 10 step: 420 loss: 0.6931487321853638\n",
      "epoch: 10 step: 421 loss: 0.6931487321853638\n",
      "epoch: 10 step: 422 loss: 0.6931487321853638\n",
      "epoch: 10 step: 423 loss: 0.6931487321853638\n",
      "epoch: 10 step: 424 loss: 0.6931487321853638\n",
      "epoch: 10 step: 425 loss: 0.6931487321853638\n",
      "epoch: 10 step: 426 loss: 0.6931487321853638\n",
      "epoch: 10 step: 427 loss: 0.6931487321853638\n",
      "epoch: 10 step: 428 loss: 0.6931487321853638\n",
      "epoch: 10 step: 429 loss: 0.6931487321853638\n",
      "epoch: 10 step: 430 loss: 0.6931487321853638\n",
      "epoch: 10 step: 431 loss: 0.6931487321853638\n",
      "epoch: 10 step: 432 loss: 0.6931487321853638\n",
      "epoch: 10 step: 433 loss: 0.6931487321853638\n",
      "epoch: 10 step: 434 loss: 0.6931487321853638\n",
      "epoch: 10 step: 435 loss: 0.6931487321853638\n",
      "epoch: 10 step: 436 loss: 0.6931487321853638\n",
      "epoch: 10 step: 437 loss: 0.6931487321853638\n",
      "epoch: 10 step: 438 loss: 0.6931487321853638\n",
      "epoch: 10 step: 439 loss: 0.6931487321853638\n",
      "epoch: 10 step: 440 loss: 0.6931487321853638\n",
      "epoch: 10 step: 441 loss: 0.6931487321853638\n",
      "epoch: 10 step: 442 loss: 0.6931487321853638\n",
      "epoch: 10 step: 443 loss: 0.6931487321853638\n",
      "epoch: 10 step: 444 loss: 0.6931487321853638\n",
      "epoch: 10 step: 445 loss: 0.6931487321853638\n",
      "epoch: 10 step: 446 loss: 0.6931487321853638\n",
      "epoch: 10 step: 447 loss: 0.6931487321853638\n",
      "epoch: 10 step: 448 loss: 0.6931487321853638\n",
      "epoch: 10 step: 449 loss: 0.6931487321853638\n",
      "epoch: 10 step: 450 loss: 0.6931487321853638\n",
      "epoch: 10 step: 451 loss: 0.6931487321853638\n",
      "epoch: 10 step: 452 loss: 0.6931487321853638\n",
      "epoch: 10 step: 453 loss: 0.6931487321853638\n",
      "epoch: 10 step: 454 loss: 0.6931487321853638\n",
      "epoch: 10 step: 455 loss: 0.6931487321853638\n",
      "epoch: 10 step: 456 loss: 0.6931487321853638\n",
      "epoch: 10 step: 457 loss: 0.6931487321853638\n",
      "epoch: 10 step: 458 loss: 0.6931487321853638\n",
      "epoch: 10 step: 459 loss: 0.6931487321853638\n",
      "epoch: 10 step: 460 loss: 0.6931487321853638\n",
      "epoch: 10 step: 461 loss: 0.6931487321853638\n",
      "epoch: 10 step: 462 loss: 0.6931487321853638\n",
      "epoch: 10 step: 463 loss: 0.6931487321853638\n",
      "epoch: 10 step: 464 loss: 0.6931487321853638\n",
      "epoch: 10 step: 465 loss: 0.6931487321853638\n",
      "epoch: 10 step: 466 loss: 0.6931487321853638\n",
      "epoch: 10 step: 467 loss: 0.6931487321853638\n",
      "epoch: 10 step: 468 loss: 0.6931487321853638\n",
      "epoch: 10 step: 469 loss: 0.6931487321853638\n",
      "epoch: 10 step: 470 loss: 0.6931487321853638\n",
      "epoch: 10 step: 471 loss: 0.6931487321853638\n",
      "epoch: 10 step: 472 loss: 0.6931487321853638\n",
      "epoch: 10 step: 473 loss: 0.6931487321853638\n",
      "epoch: 10 step: 474 loss: 0.6931487321853638\n",
      "epoch: 10 step: 475 loss: 0.6931487321853638\n",
      "epoch: 10 step: 476 loss: 0.6931487321853638\n",
      "epoch: 10 step: 477 loss: 0.6931487321853638\n",
      "epoch: 10 step: 478 loss: 0.6931487321853638\n",
      "epoch: 10 step: 479 loss: 0.6931487321853638\n",
      "epoch: 10 step: 480 loss: 0.6931487321853638\n",
      "epoch: 10 step: 481 loss: 0.6931487321853638\n",
      "epoch: 10 step: 482 loss: 0.6931487321853638\n",
      "epoch: 10 step: 483 loss: 0.6931487321853638\n",
      "epoch: 10 step: 484 loss: 0.6931487321853638\n",
      "epoch: 10 step: 485 loss: 0.6931487321853638\n",
      "epoch: 10 step: 486 loss: 0.6931487321853638\n",
      "epoch: 10 step: 487 loss: 0.6931487321853638\n",
      "epoch: 10 step: 488 loss: 0.6931487321853638\n",
      "epoch: 10 step: 489 loss: 0.6931487321853638\n",
      "epoch: 10 step: 490 loss: 0.6931487321853638\n",
      "epoch: 10 step: 491 loss: 0.6931487321853638\n",
      "epoch: 10 step: 492 loss: 0.6931487321853638\n",
      "epoch: 10 step: 493 loss: 0.6931487321853638\n",
      "epoch: 10 step: 494 loss: 0.6931487321853638\n",
      "epoch: 10 step: 495 loss: 0.6931487321853638\n",
      "epoch: 10 step: 496 loss: 0.6931487321853638\n",
      "epoch: 10 step: 497 loss: 0.6931487321853638\n",
      "epoch: 10 step: 498 loss: 0.6931487321853638\n",
      "epoch: 10 step: 499 loss: 0.6931487321853638\n",
      "epoch: 10 step: 500 loss: 0.6931487321853638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 501 loss: 0.6931487321853638\n",
      "epoch: 10 step: 502 loss: 0.6931487321853638\n",
      "epoch: 10 step: 503 loss: 0.6931487321853638\n",
      "epoch: 10 step: 504 loss: 0.6931487321853638\n",
      "epoch: 10 step: 505 loss: 0.6931487321853638\n",
      "epoch: 10 step: 506 loss: 0.6931487321853638\n",
      "epoch: 10 step: 507 loss: 0.6931487321853638\n",
      "epoch: 10 step: 508 loss: 0.6931487321853638\n",
      "epoch: 10 step: 509 loss: 0.6931487321853638\n",
      "epoch: 10 step: 510 loss: 0.6931487321853638\n",
      "epoch: 10 step: 511 loss: 0.6931487321853638\n",
      "epoch: 10 step: 512 loss: 0.6931487321853638\n",
      "epoch: 10 step: 513 loss: 0.6931487321853638\n",
      "epoch: 10 step: 514 loss: 0.6931487321853638\n",
      "epoch: 10 step: 515 loss: 0.6931487321853638\n",
      "epoch: 10 step: 516 loss: 0.6931487321853638\n",
      "epoch: 10 step: 517 loss: 0.6931487321853638\n",
      "epoch: 10 step: 518 loss: 0.6931487321853638\n",
      "epoch: 10 step: 519 loss: 0.6931487321853638\n",
      "epoch: 10 step: 520 loss: 0.6931487321853638\n",
      "epoch: 10 step: 521 loss: 0.6931487321853638\n",
      "epoch: 10 step: 522 loss: 0.6931487321853638\n",
      "epoch: 10 step: 523 loss: 0.6931487321853638\n",
      "epoch: 10 step: 524 loss: 0.6931487321853638\n",
      "epoch: 10 step: 525 loss: 0.6931487321853638\n",
      "epoch: 10 step: 526 loss: 0.6931487321853638\n",
      "epoch: 10 step: 527 loss: 0.6931487321853638\n",
      "epoch: 10 step: 528 loss: 0.6931487321853638\n",
      "epoch: 10 step: 529 loss: 0.6931487321853638\n",
      "epoch: 10 step: 530 loss: 0.6931487321853638\n",
      "epoch: 10 step: 531 loss: 0.6931487321853638\n",
      "epoch: 10 step: 532 loss: 0.6931487321853638\n",
      "epoch: 10 step: 533 loss: 0.6931487321853638\n",
      "epoch: 10 step: 534 loss: 0.6931487321853638\n",
      "epoch: 10 step: 535 loss: 0.6931487321853638\n",
      "epoch: 10 step: 536 loss: 0.6931487321853638\n",
      "epoch: 10 step: 537 loss: 0.6931487321853638\n",
      "epoch: 10 step: 538 loss: 0.6931487321853638\n",
      "epoch: 10 step: 539 loss: 0.6931487321853638\n",
      "epoch: 10 step: 540 loss: 0.6931487321853638\n",
      "epoch: 10 step: 541 loss: 0.6931487321853638\n",
      "epoch: 10 step: 542 loss: 0.6931487321853638\n",
      "epoch: 10 step: 543 loss: 0.6931487321853638\n",
      "epoch: 10 step: 544 loss: 0.6931487321853638\n",
      "epoch: 10 step: 545 loss: 0.6931487321853638\n",
      "epoch: 10 step: 546 loss: 0.693148672580719\n",
      "epoch: 10 step: 547 loss: 0.6931487321853638\n",
      "epoch: 10 step: 548 loss: 0.6931487321853638\n",
      "epoch: 10 step: 549 loss: 0.6931487321853638\n",
      "epoch: 10 step: 550 loss: 0.6931487321853638\n",
      "epoch: 10 step: 551 loss: 0.6931487321853638\n",
      "epoch: 10 step: 552 loss: 0.6931486129760742\n",
      "epoch: 10 step: 553 loss: 0.693148672580719\n",
      "epoch: 10 step: 554 loss: 0.6931487321853638\n",
      "epoch: 10 step: 555 loss: 0.6931486129760742\n",
      "epoch: 10 step: 556 loss: 0.693148672580719\n",
      "epoch: 10 step: 557 loss: 0.693148672580719\n",
      "epoch: 10 step: 558 loss: 0.693148672580719\n",
      "epoch: 10 step: 559 loss: 0.6931486129760742\n",
      "epoch: 10 step: 560 loss: 0.6931486129760742\n",
      "epoch: 10 step: 561 loss: 0.693148672580719\n",
      "epoch: 10 step: 562 loss: 0.6931486129760742\n",
      "epoch: 10 step: 563 loss: 0.6931487321853638\n",
      "epoch: 10 step: 564 loss: 0.6931486129760742\n",
      "epoch: 10 step: 565 loss: 0.6931486129760742\n",
      "epoch: 10 step: 566 loss: 0.693148672580719\n",
      "epoch: 10 step: 567 loss: 0.6931486129760742\n",
      "epoch: 10 step: 568 loss: 0.6931486129760742\n",
      "epoch: 10 step: 569 loss: 0.6931486129760742\n",
      "epoch: 10 step: 570 loss: 0.6931486129760742\n",
      "epoch: 10 step: 571 loss: 0.693148672580719\n",
      "epoch: 10 step: 572 loss: 0.6931486129760742\n",
      "epoch: 10 step: 573 loss: 0.6931486129760742\n",
      "epoch: 10 step: 574 loss: 0.6931486129760742\n",
      "epoch: 10 step: 575 loss: 0.6931486129760742\n",
      "epoch: 10 step: 576 loss: 0.6931486129760742\n",
      "epoch: 10 step: 577 loss: 0.6931486129760742\n",
      "epoch: 10 step: 578 loss: 0.6931486129760742\n",
      "epoch: 10 step: 579 loss: 0.6931486129760742\n",
      "epoch: 10 step: 580 loss: 0.6931486129760742\n",
      "epoch: 10 step: 581 loss: 0.6931486129760742\n",
      "epoch: 10 step: 582 loss: 0.6931486129760742\n",
      "epoch: 10 step: 583 loss: 0.6931486129760742\n",
      "epoch: 10 step: 584 loss: 0.6931486129760742\n",
      "epoch: 10 step: 585 loss: 0.6931486129760742\n",
      "epoch: 10 step: 586 loss: 0.6931486129760742\n",
      "epoch: 10 step: 587 loss: 0.6931486129760742\n",
      "epoch: 10 step: 588 loss: 0.6931486129760742\n",
      "epoch: 10 step: 589 loss: 0.6931486129760742\n",
      "epoch: 10 step: 590 loss: 0.6931486129760742\n",
      "epoch: 10 step: 591 loss: 0.6931486129760742\n",
      "epoch: 10 step: 592 loss: 0.6931486129760742\n",
      "epoch: 10 step: 593 loss: 0.6931486129760742\n",
      "epoch: 10 step: 594 loss: 0.6931486129760742\n",
      "epoch: 10 step: 595 loss: 0.6931486129760742\n",
      "epoch: 10 step: 596 loss: 0.6931486129760742\n",
      "epoch: 10 step: 597 loss: 0.6931486129760742\n",
      "epoch: 10 step: 598 loss: 0.6931486129760742\n",
      "epoch: 10 step: 599 loss: 0.6931486129760742\n",
      "epoch: 10 step: 600 loss: 0.6931486129760742\n",
      "epoch: 10 step: 601 loss: 0.6931486129760742\n",
      "epoch: 10 step: 602 loss: 0.6931486129760742\n",
      "epoch: 10 step: 603 loss: 0.6931486129760742\n",
      "epoch: 10 step: 604 loss: 0.6931486129760742\n",
      "epoch: 10 step: 605 loss: 0.6931486129760742\n",
      "epoch: 10 step: 606 loss: 0.6931486129760742\n",
      "epoch: 10 step: 607 loss: 0.6931486129760742\n",
      "epoch: 10 step: 608 loss: 0.6931486129760742\n",
      "epoch: 10 step: 609 loss: 0.6931486129760742\n",
      "epoch: 10 step: 610 loss: 0.6931486129760742\n",
      "epoch: 10 step: 611 loss: 0.6931486129760742\n",
      "epoch: 10 step: 612 loss: 0.6931486129760742\n",
      "epoch: 10 step: 613 loss: 0.6931486129760742\n",
      "epoch: 10 step: 614 loss: 0.6931486129760742\n",
      "epoch: 10 step: 615 loss: 0.6931486129760742\n",
      "epoch: 10 step: 616 loss: 0.6931486129760742\n",
      "epoch: 10 step: 617 loss: 0.6931486129760742\n",
      "epoch: 10 step: 618 loss: 0.6931486129760742\n",
      "epoch: 10 step: 619 loss: 0.6931486129760742\n",
      "epoch: 10 step: 620 loss: 0.6931486129760742\n",
      "epoch: 10 step: 621 loss: 0.6931486129760742\n",
      "epoch: 10 step: 622 loss: 0.6931486129760742\n",
      "epoch: 10 step: 623 loss: 0.6931486129760742\n",
      "epoch: 10 step: 624 loss: 0.6931486129760742\n",
      "epoch: 10 step: 625 loss: 0.6931486129760742\n",
      "epoch: 10 step: 626 loss: 0.6931486129760742\n",
      "epoch: 10 step: 627 loss: 0.6931486129760742\n",
      "epoch: 10 step: 628 loss: 0.6931486129760742\n",
      "epoch: 10 step: 629 loss: 0.6931486129760742\n",
      "epoch: 10 step: 630 loss: 0.6931486129760742\n",
      "epoch: 10 step: 631 loss: 0.6931486129760742\n",
      "epoch: 10 step: 632 loss: 0.6931486129760742\n",
      "epoch: 10 step: 633 loss: 0.6931486129760742\n",
      "epoch: 10 step: 634 loss: 0.6931486129760742\n",
      "epoch: 10 step: 635 loss: 0.6931486129760742\n",
      "epoch: 10 step: 636 loss: 0.6931486129760742\n",
      "epoch: 10 step: 637 loss: 0.6931486129760742\n",
      "epoch: 10 step: 638 loss: 0.6931486129760742\n",
      "epoch: 10 step: 639 loss: 0.6931486129760742\n",
      "epoch: 10 step: 640 loss: 0.6931486129760742\n",
      "epoch: 10 step: 641 loss: 0.6931486129760742\n",
      "epoch: 10 step: 642 loss: 0.6931486129760742\n",
      "epoch: 10 step: 643 loss: 0.6931486129760742\n",
      "epoch: 10 step: 644 loss: 0.6931486129760742\n",
      "epoch: 10 step: 645 loss: 0.6931486129760742\n",
      "epoch: 10 step: 646 loss: 0.6931486129760742\n",
      "epoch: 10 step: 647 loss: 0.6931486129760742\n",
      "epoch: 10 step: 648 loss: 0.6931486129760742\n",
      "epoch: 10 step: 649 loss: 0.6931486129760742\n",
      "epoch: 10 step: 650 loss: 0.6931486129760742\n",
      "epoch: 10 step: 651 loss: 0.6931486129760742\n",
      "epoch: 10 step: 652 loss: 0.6931486129760742\n",
      "epoch: 10 step: 653 loss: 0.6931486129760742\n",
      "epoch: 10 step: 654 loss: 0.6931486129760742\n",
      "epoch: 10 step: 655 loss: 0.6931486129760742\n",
      "epoch: 10 step: 656 loss: 0.6931486129760742\n",
      "epoch: 10 step: 657 loss: 0.6931486129760742\n",
      "epoch: 10 step: 658 loss: 0.6931486129760742\n",
      "epoch: 10 step: 659 loss: 0.6931486129760742\n",
      "epoch: 10 step: 660 loss: 0.6931486129760742\n",
      "epoch: 10 step: 661 loss: 0.6931486129760742\n",
      "epoch: 10 step: 662 loss: 0.6931486129760742\n",
      "epoch: 10 step: 663 loss: 0.6931486129760742\n",
      "epoch: 10 step: 664 loss: 0.6931486129760742\n",
      "epoch: 10 step: 665 loss: 0.6931486129760742\n",
      "epoch: 10 step: 666 loss: 0.6931486129760742\n",
      "epoch: 10 step: 667 loss: 0.6931486129760742\n",
      "epoch: 10 step: 668 loss: 0.6931486129760742\n",
      "epoch: 10 step: 669 loss: 0.6931486129760742\n",
      "epoch: 10 step: 670 loss: 0.6931486129760742\n",
      "epoch: 10 step: 671 loss: 0.6931486129760742\n",
      "epoch: 10 step: 672 loss: 0.6931486129760742\n",
      "epoch: 10 step: 673 loss: 0.6931486129760742\n",
      "epoch: 10 step: 674 loss: 0.6931486129760742\n",
      "epoch: 10 step: 675 loss: 0.6931486129760742\n",
      "epoch: 10 step: 676 loss: 0.6931486129760742\n",
      "epoch: 10 step: 677 loss: 0.6931486129760742\n",
      "epoch: 10 step: 678 loss: 0.6931486129760742\n",
      "epoch: 10 step: 679 loss: 0.6931486129760742\n",
      "epoch: 10 step: 680 loss: 0.6931486129760742\n",
      "epoch: 10 step: 681 loss: 0.6931486129760742\n",
      "epoch: 10 step: 682 loss: 0.6931486129760742\n",
      "epoch: 10 step: 683 loss: 0.6931486129760742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 684 loss: 0.6931486129760742\n",
      "epoch: 10 step: 685 loss: 0.6931486129760742\n",
      "epoch: 10 step: 686 loss: 0.6931486129760742\n",
      "epoch: 10 step: 687 loss: 0.6931486129760742\n",
      "epoch: 10 step: 688 loss: 0.6931486129760742\n",
      "epoch: 10 step: 689 loss: 0.6931486129760742\n",
      "epoch: 10 step: 690 loss: 0.6931486129760742\n",
      "epoch: 10 step: 691 loss: 0.6931486129760742\n",
      "epoch: 10 step: 692 loss: 0.6931486129760742\n",
      "epoch: 10 step: 693 loss: 0.6931486129760742\n",
      "epoch: 10 step: 694 loss: 0.6931486129760742\n",
      "epoch: 10 step: 695 loss: 0.6931486129760742\n",
      "epoch: 10 step: 696 loss: 0.6931485533714294\n",
      "epoch: 10 step: 697 loss: 0.6931486129760742\n",
      "epoch: 10 step: 698 loss: 0.6931486129760742\n",
      "epoch: 10 step: 699 loss: 0.6931486129760742\n",
      "epoch: 10 step: 700 loss: 0.6931486129760742\n",
      "epoch: 10 step: 701 loss: 0.6931486129760742\n",
      "epoch: 10 step: 702 loss: 0.6931486129760742\n",
      "epoch: 10 step: 703 loss: 0.6931485533714294\n",
      "epoch: 10 step: 704 loss: 0.6931486129760742\n",
      "epoch: 10 step: 705 loss: 0.6931486129760742\n",
      "epoch: 10 step: 706 loss: 0.6931484937667847\n",
      "epoch: 10 step: 707 loss: 0.6931484937667847\n",
      "epoch: 10 step: 708 loss: 0.6931484937667847\n",
      "epoch: 10 step: 709 loss: 0.6931486129760742\n",
      "epoch: 10 step: 710 loss: 0.6931486129760742\n",
      "epoch: 10 step: 711 loss: 0.6931485533714294\n",
      "epoch: 10 step: 712 loss: 0.6931486129760742\n",
      "epoch: 10 step: 713 loss: 0.6931484937667847\n",
      "epoch: 10 step: 714 loss: 0.6931484937667847\n",
      "epoch: 10 step: 715 loss: 0.6931486129760742\n",
      "epoch: 10 step: 716 loss: 0.6931484937667847\n",
      "epoch: 10 step: 717 loss: 0.6931484937667847\n",
      "epoch: 10 step: 718 loss: 0.6931486129760742\n",
      "epoch: 10 step: 719 loss: 0.6931485533714294\n",
      "epoch: 10 step: 720 loss: 0.6931484937667847\n",
      "epoch: 10 step: 721 loss: 0.6931485533714294\n",
      "epoch: 10 step: 722 loss: 0.6931484937667847\n",
      "epoch: 10 step: 723 loss: 0.6931484937667847\n",
      "epoch: 10 step: 724 loss: 0.6931484937667847\n",
      "epoch: 10 step: 725 loss: 0.6931484937667847\n",
      "epoch: 10 step: 726 loss: 0.6931484937667847\n",
      "epoch: 10 step: 727 loss: 0.6931484937667847\n",
      "epoch: 10 step: 728 loss: 0.6931484937667847\n",
      "epoch: 10 step: 729 loss: 0.6931484937667847\n",
      "epoch: 10 step: 730 loss: 0.6931484937667847\n",
      "epoch: 10 step: 731 loss: 0.6931485533714294\n",
      "epoch: 10 step: 732 loss: 0.6931484937667847\n",
      "epoch: 10 step: 733 loss: 0.6931484937667847\n",
      "epoch: 10 step: 734 loss: 0.6931484937667847\n",
      "epoch: 10 step: 735 loss: 0.6931484937667847\n",
      "epoch: 10 step: 736 loss: 0.6931484937667847\n",
      "epoch: 10 step: 737 loss: 0.6931484937667847\n",
      "epoch: 10 step: 738 loss: 0.6931484937667847\n",
      "epoch: 10 step: 739 loss: 0.6931484937667847\n",
      "epoch: 10 step: 740 loss: 0.6931484937667847\n",
      "epoch: 10 step: 741 loss: 0.6931484937667847\n",
      "epoch: 10 step: 742 loss: 0.6931484937667847\n",
      "epoch: 10 step: 743 loss: 0.6931484937667847\n",
      "epoch: 10 step: 744 loss: 0.6931484937667847\n",
      "epoch: 10 step: 745 loss: 0.6931484937667847\n",
      "epoch: 10 step: 746 loss: 0.6931484937667847\n",
      "epoch: 10 step: 747 loss: 0.6931484937667847\n",
      "epoch: 10 step: 748 loss: 0.6931484937667847\n",
      "epoch: 10 step: 749 loss: 0.6931484937667847\n",
      "epoch: 10 step: 750 loss: 0.6931484937667847\n",
      "epoch: 10 step: 751 loss: 0.6931484937667847\n",
      "epoch: 10 step: 752 loss: 0.6931484937667847\n",
      "epoch: 10 step: 753 loss: 0.6931484937667847\n",
      "epoch: 10 step: 754 loss: 0.6931484937667847\n",
      "epoch: 10 step: 755 loss: 0.6931484937667847\n",
      "epoch: 10 step: 756 loss: 0.6931484937667847\n",
      "epoch: 10 step: 757 loss: 0.6931484937667847\n",
      "epoch: 10 step: 758 loss: 0.6931484937667847\n",
      "epoch: 10 step: 759 loss: 0.6931484937667847\n",
      "epoch: 10 step: 760 loss: 0.6931484937667847\n",
      "epoch: 10 step: 761 loss: 0.6931484937667847\n",
      "epoch: 10 step: 762 loss: 0.6931484937667847\n",
      "epoch: 10 step: 763 loss: 0.6931484937667847\n",
      "epoch: 10 step: 764 loss: 0.6931484937667847\n",
      "epoch: 10 step: 765 loss: 0.6931484937667847\n",
      "epoch: 10 step: 766 loss: 0.6931484937667847\n",
      "epoch: 10 step: 767 loss: 0.6931484937667847\n",
      "epoch: 10 step: 768 loss: 0.6931484937667847\n",
      "epoch: 10 step: 769 loss: 0.6931484937667847\n",
      "epoch: 10 step: 770 loss: 0.6931484937667847\n",
      "epoch: 10 step: 771 loss: 0.6931484937667847\n",
      "epoch: 10 step: 772 loss: 0.6931484937667847\n",
      "epoch: 10 step: 773 loss: 0.6931484937667847\n",
      "epoch: 10 step: 774 loss: 0.6931484937667847\n",
      "epoch: 10 step: 775 loss: 0.6931484937667847\n",
      "epoch: 10 step: 776 loss: 0.6931484937667847\n",
      "epoch: 10 step: 777 loss: 0.6931484937667847\n",
      "epoch: 10 step: 778 loss: 0.6931484937667847\n",
      "epoch: 10 step: 779 loss: 0.6931484937667847\n",
      "epoch: 10 step: 780 loss: 0.6931484937667847\n",
      "epoch: 10 step: 781 loss: 0.6931484937667847\n",
      "epoch: 11 step: 1 loss: 0.6931484937667847\n",
      "epoch: 11 step: 2 loss: 0.6931484937667847\n",
      "epoch: 11 step: 3 loss: 0.6931484937667847\n",
      "epoch: 11 step: 4 loss: 0.6931484937667847\n",
      "epoch: 11 step: 5 loss: 0.6931484937667847\n",
      "epoch: 11 step: 6 loss: 0.6931484937667847\n",
      "epoch: 11 step: 7 loss: 0.6931484937667847\n",
      "epoch: 11 step: 8 loss: 0.6931484937667847\n",
      "epoch: 11 step: 9 loss: 0.6931484937667847\n",
      "epoch: 11 step: 10 loss: 0.6931484937667847\n",
      "epoch: 11 step: 11 loss: 0.6931484937667847\n",
      "epoch: 11 step: 12 loss: 0.6931484937667847\n",
      "epoch: 11 step: 13 loss: 0.6931484937667847\n",
      "epoch: 11 step: 14 loss: 0.6931484937667847\n",
      "epoch: 11 step: 15 loss: 0.6931484937667847\n",
      "epoch: 11 step: 16 loss: 0.6931484937667847\n",
      "epoch: 11 step: 17 loss: 0.6931484937667847\n",
      "epoch: 11 step: 18 loss: 0.6931484937667847\n",
      "epoch: 11 step: 19 loss: 0.6931484937667847\n",
      "epoch: 11 step: 20 loss: 0.6931484937667847\n",
      "epoch: 11 step: 21 loss: 0.6931484937667847\n",
      "epoch: 11 step: 22 loss: 0.6931484937667847\n",
      "epoch: 11 step: 23 loss: 0.6931484937667847\n",
      "epoch: 11 step: 24 loss: 0.6931484937667847\n",
      "epoch: 11 step: 25 loss: 0.6931484937667847\n",
      "epoch: 11 step: 26 loss: 0.6931484937667847\n",
      "epoch: 11 step: 27 loss: 0.6931484937667847\n",
      "epoch: 11 step: 28 loss: 0.6931484937667847\n",
      "epoch: 11 step: 29 loss: 0.6931484937667847\n",
      "epoch: 11 step: 30 loss: 0.6931484937667847\n",
      "epoch: 11 step: 31 loss: 0.6931484937667847\n",
      "epoch: 11 step: 32 loss: 0.6931484937667847\n",
      "epoch: 11 step: 33 loss: 0.6931484937667847\n",
      "epoch: 11 step: 34 loss: 0.6931484937667847\n",
      "epoch: 11 step: 35 loss: 0.6931484937667847\n",
      "epoch: 11 step: 36 loss: 0.6931484937667847\n",
      "epoch: 11 step: 37 loss: 0.6931484937667847\n",
      "epoch: 11 step: 38 loss: 0.6931484937667847\n",
      "epoch: 11 step: 39 loss: 0.6931484937667847\n",
      "epoch: 11 step: 40 loss: 0.6931484937667847\n",
      "epoch: 11 step: 41 loss: 0.6931484937667847\n",
      "epoch: 11 step: 42 loss: 0.6931484937667847\n",
      "epoch: 11 step: 43 loss: 0.6931484937667847\n",
      "epoch: 11 step: 44 loss: 0.6931484937667847\n",
      "epoch: 11 step: 45 loss: 0.6931484937667847\n",
      "epoch: 11 step: 46 loss: 0.6931484937667847\n",
      "epoch: 11 step: 47 loss: 0.6931484937667847\n",
      "epoch: 11 step: 48 loss: 0.6931484937667847\n",
      "epoch: 11 step: 49 loss: 0.6931484937667847\n",
      "epoch: 11 step: 50 loss: 0.6931484937667847\n",
      "epoch: 11 step: 51 loss: 0.6931484937667847\n",
      "epoch: 11 step: 52 loss: 0.6931484937667847\n",
      "epoch: 11 step: 53 loss: 0.6931484937667847\n",
      "epoch: 11 step: 54 loss: 0.6931484937667847\n",
      "epoch: 11 step: 55 loss: 0.6931484937667847\n",
      "epoch: 11 step: 56 loss: 0.6931484937667847\n",
      "epoch: 11 step: 57 loss: 0.6931484937667847\n",
      "epoch: 11 step: 58 loss: 0.6931484937667847\n",
      "epoch: 11 step: 59 loss: 0.6931484937667847\n",
      "epoch: 11 step: 60 loss: 0.6931484937667847\n",
      "epoch: 11 step: 61 loss: 0.6931484937667847\n",
      "epoch: 11 step: 62 loss: 0.6931484937667847\n",
      "epoch: 11 step: 63 loss: 0.6931484937667847\n",
      "epoch: 11 step: 64 loss: 0.6931484937667847\n",
      "epoch: 11 step: 65 loss: 0.6931484937667847\n",
      "epoch: 11 step: 66 loss: 0.6931484937667847\n",
      "epoch: 11 step: 67 loss: 0.6931484937667847\n",
      "epoch: 11 step: 68 loss: 0.6931484937667847\n",
      "epoch: 11 step: 69 loss: 0.6931484937667847\n",
      "epoch: 11 step: 70 loss: 0.6931484937667847\n",
      "epoch: 11 step: 71 loss: 0.6931484937667847\n",
      "epoch: 11 step: 72 loss: 0.6931484937667847\n",
      "epoch: 11 step: 73 loss: 0.6931484937667847\n",
      "epoch: 11 step: 74 loss: 0.6931484937667847\n",
      "epoch: 11 step: 75 loss: 0.6931484937667847\n",
      "epoch: 11 step: 76 loss: 0.6931484937667847\n",
      "epoch: 11 step: 77 loss: 0.6931484937667847\n",
      "epoch: 11 step: 78 loss: 0.6931484937667847\n",
      "epoch: 11 step: 79 loss: 0.6931484937667847\n",
      "epoch: 11 step: 80 loss: 0.6931484937667847\n",
      "epoch: 11 step: 81 loss: 0.6931484937667847\n",
      "epoch: 11 step: 82 loss: 0.6931484937667847\n",
      "epoch: 11 step: 83 loss: 0.6931483745574951\n",
      "epoch: 11 step: 84 loss: 0.6931484937667847\n",
      "epoch: 11 step: 85 loss: 0.6931484937667847\n",
      "epoch: 11 step: 86 loss: 0.6931484341621399\n",
      "epoch: 11 step: 87 loss: 0.6931484937667847\n",
      "epoch: 11 step: 88 loss: 0.6931483745574951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 89 loss: 0.6931484341621399\n",
      "epoch: 11 step: 90 loss: 0.6931483745574951\n",
      "epoch: 11 step: 91 loss: 0.6931484341621399\n",
      "epoch: 11 step: 92 loss: 0.6931483745574951\n",
      "epoch: 11 step: 93 loss: 0.6931483745574951\n",
      "epoch: 11 step: 94 loss: 0.6931484341621399\n",
      "epoch: 11 step: 95 loss: 0.6931484937667847\n",
      "epoch: 11 step: 96 loss: 0.6931484341621399\n",
      "epoch: 11 step: 97 loss: 0.6931483745574951\n",
      "epoch: 11 step: 98 loss: 0.6931483745574951\n",
      "epoch: 11 step: 99 loss: 0.6931484341621399\n",
      "epoch: 11 step: 100 loss: 0.6931483745574951\n",
      "epoch: 11 step: 101 loss: 0.6931484341621399\n",
      "epoch: 11 step: 102 loss: 0.6931483745574951\n",
      "epoch: 11 step: 103 loss: 0.6931483745574951\n",
      "epoch: 11 step: 104 loss: 0.6931483745574951\n",
      "epoch: 11 step: 105 loss: 0.6931483745574951\n",
      "epoch: 11 step: 106 loss: 0.6931483745574951\n",
      "epoch: 11 step: 107 loss: 0.6931483745574951\n",
      "epoch: 11 step: 108 loss: 0.6931483745574951\n",
      "epoch: 11 step: 109 loss: 0.6931483745574951\n",
      "epoch: 11 step: 110 loss: 0.6931483745574951\n",
      "epoch: 11 step: 111 loss: 0.6931483745574951\n",
      "epoch: 11 step: 112 loss: 0.6931483745574951\n",
      "epoch: 11 step: 113 loss: 0.6931483745574951\n",
      "epoch: 11 step: 114 loss: 0.6931483745574951\n",
      "epoch: 11 step: 115 loss: 0.6931483745574951\n",
      "epoch: 11 step: 116 loss: 0.6931483745574951\n",
      "epoch: 11 step: 117 loss: 0.6931483745574951\n",
      "epoch: 11 step: 118 loss: 0.6931483745574951\n",
      "epoch: 11 step: 119 loss: 0.6931483745574951\n",
      "epoch: 11 step: 120 loss: 0.6931483745574951\n",
      "epoch: 11 step: 121 loss: 0.6931483745574951\n",
      "epoch: 11 step: 122 loss: 0.6931483745574951\n",
      "epoch: 11 step: 123 loss: 0.6931483745574951\n",
      "epoch: 11 step: 124 loss: 0.6931483745574951\n",
      "epoch: 11 step: 125 loss: 0.6931483745574951\n",
      "epoch: 11 step: 126 loss: 0.6931483745574951\n",
      "epoch: 11 step: 127 loss: 0.6931483745574951\n",
      "epoch: 11 step: 128 loss: 0.6931483745574951\n",
      "epoch: 11 step: 129 loss: 0.6931483745574951\n",
      "epoch: 11 step: 130 loss: 0.6931483745574951\n",
      "epoch: 11 step: 131 loss: 0.6931483745574951\n",
      "epoch: 11 step: 132 loss: 0.6931483745574951\n",
      "epoch: 11 step: 133 loss: 0.6931483745574951\n",
      "epoch: 11 step: 134 loss: 0.6931483745574951\n",
      "epoch: 11 step: 135 loss: 0.6931483745574951\n",
      "epoch: 11 step: 136 loss: 0.6931483745574951\n",
      "epoch: 11 step: 137 loss: 0.6931483745574951\n",
      "epoch: 11 step: 138 loss: 0.6931483745574951\n",
      "epoch: 11 step: 139 loss: 0.6931483745574951\n",
      "epoch: 11 step: 140 loss: 0.6931483745574951\n",
      "epoch: 11 step: 141 loss: 0.6931483745574951\n",
      "epoch: 11 step: 142 loss: 0.6931483745574951\n",
      "epoch: 11 step: 143 loss: 0.6931483745574951\n",
      "epoch: 11 step: 144 loss: 0.6931483745574951\n",
      "epoch: 11 step: 145 loss: 0.6931483745574951\n",
      "epoch: 11 step: 146 loss: 0.6931483745574951\n",
      "epoch: 11 step: 147 loss: 0.6931483745574951\n",
      "epoch: 11 step: 148 loss: 0.6931483745574951\n",
      "epoch: 11 step: 149 loss: 0.6931483745574951\n",
      "epoch: 11 step: 150 loss: 0.6931483745574951\n",
      "epoch: 11 step: 151 loss: 0.6931483745574951\n",
      "epoch: 11 step: 152 loss: 0.6931483745574951\n",
      "epoch: 11 step: 153 loss: 0.6931483745574951\n",
      "epoch: 11 step: 154 loss: 0.6931483745574951\n",
      "epoch: 11 step: 155 loss: 0.6931483745574951\n",
      "epoch: 11 step: 156 loss: 0.6931483745574951\n",
      "epoch: 11 step: 157 loss: 0.6931483745574951\n",
      "epoch: 11 step: 158 loss: 0.6931483745574951\n",
      "epoch: 11 step: 159 loss: 0.6931483745574951\n",
      "epoch: 11 step: 160 loss: 0.6931483745574951\n",
      "epoch: 11 step: 161 loss: 0.6931483745574951\n",
      "epoch: 11 step: 162 loss: 0.6931483745574951\n",
      "epoch: 11 step: 163 loss: 0.6931483745574951\n",
      "epoch: 11 step: 164 loss: 0.6931483745574951\n",
      "epoch: 11 step: 165 loss: 0.6931483745574951\n",
      "epoch: 11 step: 166 loss: 0.6931483745574951\n",
      "epoch: 11 step: 167 loss: 0.6931483745574951\n",
      "epoch: 11 step: 168 loss: 0.6931483745574951\n",
      "epoch: 11 step: 169 loss: 0.6931483745574951\n",
      "epoch: 11 step: 170 loss: 0.6931483745574951\n",
      "epoch: 11 step: 171 loss: 0.6931483745574951\n",
      "epoch: 11 step: 172 loss: 0.6931483745574951\n",
      "epoch: 11 step: 173 loss: 0.6931483745574951\n",
      "epoch: 11 step: 174 loss: 0.6931483745574951\n",
      "epoch: 11 step: 175 loss: 0.6931483745574951\n",
      "epoch: 11 step: 176 loss: 0.6931483745574951\n",
      "epoch: 11 step: 177 loss: 0.6931483745574951\n",
      "epoch: 11 step: 178 loss: 0.6931483745574951\n",
      "epoch: 11 step: 179 loss: 0.6931483745574951\n",
      "epoch: 11 step: 180 loss: 0.6931483745574951\n",
      "epoch: 11 step: 181 loss: 0.6931483745574951\n",
      "epoch: 11 step: 182 loss: 0.6931483745574951\n",
      "epoch: 11 step: 183 loss: 0.6931483745574951\n",
      "epoch: 11 step: 184 loss: 0.6931483745574951\n",
      "epoch: 11 step: 185 loss: 0.6931483745574951\n",
      "epoch: 11 step: 186 loss: 0.6931483745574951\n",
      "epoch: 11 step: 187 loss: 0.6931483745574951\n",
      "epoch: 11 step: 188 loss: 0.6931483745574951\n",
      "epoch: 11 step: 189 loss: 0.6931483745574951\n",
      "epoch: 11 step: 190 loss: 0.6931483745574951\n",
      "epoch: 11 step: 191 loss: 0.6931483745574951\n",
      "epoch: 11 step: 192 loss: 0.6931483745574951\n",
      "epoch: 11 step: 193 loss: 0.6931483745574951\n",
      "epoch: 11 step: 194 loss: 0.6931483745574951\n",
      "epoch: 11 step: 195 loss: 0.6931483745574951\n",
      "epoch: 11 step: 196 loss: 0.6931483745574951\n",
      "epoch: 11 step: 197 loss: 0.6931483745574951\n",
      "epoch: 11 step: 198 loss: 0.6931483745574951\n",
      "epoch: 11 step: 199 loss: 0.6931483745574951\n",
      "epoch: 11 step: 200 loss: 0.6931483745574951\n",
      "epoch: 11 step: 201 loss: 0.6931483745574951\n",
      "epoch: 11 step: 202 loss: 0.6931483745574951\n",
      "epoch: 11 step: 203 loss: 0.6931483745574951\n",
      "epoch: 11 step: 204 loss: 0.6931483745574951\n",
      "epoch: 11 step: 205 loss: 0.6931483745574951\n",
      "epoch: 11 step: 206 loss: 0.6931483745574951\n",
      "epoch: 11 step: 207 loss: 0.6931483745574951\n",
      "epoch: 11 step: 208 loss: 0.6931483745574951\n",
      "epoch: 11 step: 209 loss: 0.6931483745574951\n",
      "epoch: 11 step: 210 loss: 0.6931483745574951\n",
      "epoch: 11 step: 211 loss: 0.6931483745574951\n",
      "epoch: 11 step: 212 loss: 0.6931483745574951\n",
      "epoch: 11 step: 213 loss: 0.6931483745574951\n",
      "epoch: 11 step: 214 loss: 0.6931483745574951\n",
      "epoch: 11 step: 215 loss: 0.6931483745574951\n",
      "epoch: 11 step: 216 loss: 0.6931483745574951\n",
      "epoch: 11 step: 217 loss: 0.6931483745574951\n",
      "epoch: 11 step: 218 loss: 0.6931483745574951\n",
      "epoch: 11 step: 219 loss: 0.6931483745574951\n",
      "epoch: 11 step: 220 loss: 0.6931483745574951\n",
      "epoch: 11 step: 221 loss: 0.6931483745574951\n",
      "epoch: 11 step: 222 loss: 0.6931483745574951\n",
      "epoch: 11 step: 223 loss: 0.6931483745574951\n",
      "epoch: 11 step: 224 loss: 0.6931483745574951\n",
      "epoch: 11 step: 225 loss: 0.6931483745574951\n",
      "epoch: 11 step: 226 loss: 0.6931483745574951\n",
      "epoch: 11 step: 227 loss: 0.6931483745574951\n",
      "epoch: 11 step: 228 loss: 0.6931483745574951\n",
      "epoch: 11 step: 229 loss: 0.6931483745574951\n",
      "epoch: 11 step: 230 loss: 0.6931483745574951\n",
      "epoch: 11 step: 231 loss: 0.6931483745574951\n",
      "epoch: 11 step: 232 loss: 0.6931483745574951\n",
      "epoch: 11 step: 233 loss: 0.6931483745574951\n",
      "epoch: 11 step: 234 loss: 0.6931483745574951\n",
      "epoch: 11 step: 235 loss: 0.6931483745574951\n",
      "epoch: 11 step: 236 loss: 0.6931483745574951\n",
      "epoch: 11 step: 237 loss: 0.6931483745574951\n",
      "epoch: 11 step: 238 loss: 0.6931483745574951\n",
      "epoch: 11 step: 239 loss: 0.6931483745574951\n",
      "epoch: 11 step: 240 loss: 0.6931483745574951\n",
      "epoch: 11 step: 241 loss: 0.6931483745574951\n",
      "epoch: 11 step: 242 loss: 0.6931483745574951\n",
      "epoch: 11 step: 243 loss: 0.6931483745574951\n",
      "epoch: 11 step: 244 loss: 0.6931483745574951\n",
      "epoch: 11 step: 245 loss: 0.6931483745574951\n",
      "epoch: 11 step: 246 loss: 0.6931483745574951\n",
      "epoch: 11 step: 247 loss: 0.6931483745574951\n",
      "epoch: 11 step: 248 loss: 0.6931483745574951\n",
      "epoch: 11 step: 249 loss: 0.6931483745574951\n",
      "epoch: 11 step: 250 loss: 0.6931483745574951\n",
      "epoch: 11 step: 251 loss: 0.6931483745574951\n",
      "epoch: 11 step: 252 loss: 0.6931483745574951\n",
      "epoch: 11 step: 253 loss: 0.6931483745574951\n",
      "epoch: 11 step: 254 loss: 0.6931483745574951\n",
      "epoch: 11 step: 255 loss: 0.6931483745574951\n",
      "epoch: 11 step: 256 loss: 0.6931483745574951\n",
      "epoch: 11 step: 257 loss: 0.6931483745574951\n",
      "epoch: 11 step: 258 loss: 0.6931483745574951\n",
      "epoch: 11 step: 259 loss: 0.6931483745574951\n",
      "epoch: 11 step: 260 loss: 0.6931483745574951\n",
      "epoch: 11 step: 261 loss: 0.6931483745574951\n",
      "epoch: 11 step: 262 loss: 0.6931483745574951\n",
      "epoch: 11 step: 263 loss: 0.6931483745574951\n",
      "epoch: 11 step: 264 loss: 0.6931483745574951\n",
      "epoch: 11 step: 265 loss: 0.6931483745574951\n",
      "epoch: 11 step: 266 loss: 0.6931483745574951\n",
      "epoch: 11 step: 267 loss: 0.6931483745574951\n",
      "epoch: 11 step: 268 loss: 0.6931483745574951\n",
      "epoch: 11 step: 269 loss: 0.6931483745574951\n",
      "epoch: 11 step: 270 loss: 0.6931483745574951\n",
      "epoch: 11 step: 271 loss: 0.6931483745574951\n",
      "epoch: 11 step: 272 loss: 0.6931483745574951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 273 loss: 0.6931483745574951\n",
      "epoch: 11 step: 274 loss: 0.6931483745574951\n",
      "epoch: 11 step: 275 loss: 0.6931483745574951\n",
      "epoch: 11 step: 276 loss: 0.6931483745574951\n",
      "epoch: 11 step: 277 loss: 0.6931483745574951\n",
      "epoch: 11 step: 278 loss: 0.6931483745574951\n",
      "epoch: 11 step: 279 loss: 0.6931483745574951\n",
      "epoch: 11 step: 280 loss: 0.6931483745574951\n",
      "epoch: 11 step: 281 loss: 0.6931483745574951\n",
      "epoch: 11 step: 282 loss: 0.6931483745574951\n",
      "epoch: 11 step: 283 loss: 0.6931483149528503\n",
      "epoch: 11 step: 284 loss: 0.6931483745574951\n",
      "epoch: 11 step: 285 loss: 0.6931483745574951\n",
      "epoch: 11 step: 286 loss: 0.6931483745574951\n",
      "epoch: 11 step: 287 loss: 0.6931483149528503\n",
      "epoch: 11 step: 288 loss: 0.6931483745574951\n",
      "epoch: 11 step: 289 loss: 0.6931483149528503\n",
      "epoch: 11 step: 290 loss: 0.6931483745574951\n",
      "epoch: 11 step: 291 loss: 0.6931483745574951\n",
      "epoch: 11 step: 292 loss: 0.6931482553482056\n",
      "epoch: 11 step: 293 loss: 0.6931482553482056\n",
      "epoch: 11 step: 294 loss: 0.6931483149528503\n",
      "epoch: 11 step: 295 loss: 0.6931482553482056\n",
      "epoch: 11 step: 296 loss: 0.6931483149528503\n",
      "epoch: 11 step: 297 loss: 0.6931483149528503\n",
      "epoch: 11 step: 298 loss: 0.6931483745574951\n",
      "epoch: 11 step: 299 loss: 0.6931483149528503\n",
      "epoch: 11 step: 300 loss: 0.6931482553482056\n",
      "epoch: 11 step: 301 loss: 0.6931482553482056\n",
      "epoch: 11 step: 302 loss: 0.6931482553482056\n",
      "epoch: 11 step: 303 loss: 0.6931482553482056\n",
      "epoch: 11 step: 304 loss: 0.6931482553482056\n",
      "epoch: 11 step: 305 loss: 0.6931482553482056\n",
      "epoch: 11 step: 306 loss: 0.6931482553482056\n",
      "epoch: 11 step: 307 loss: 0.6931482553482056\n",
      "epoch: 11 step: 308 loss: 0.6931482553482056\n",
      "epoch: 11 step: 309 loss: 0.6931482553482056\n",
      "epoch: 11 step: 310 loss: 0.6931483149528503\n",
      "epoch: 11 step: 311 loss: 0.6931482553482056\n",
      "epoch: 11 step: 312 loss: 0.6931483149528503\n",
      "epoch: 11 step: 313 loss: 0.6931482553482056\n",
      "epoch: 11 step: 314 loss: 0.6931482553482056\n",
      "epoch: 11 step: 315 loss: 0.6931482553482056\n",
      "epoch: 11 step: 316 loss: 0.6931482553482056\n",
      "epoch: 11 step: 317 loss: 0.6931482553482056\n",
      "epoch: 11 step: 318 loss: 0.6931482553482056\n",
      "epoch: 11 step: 319 loss: 0.6931482553482056\n",
      "epoch: 11 step: 320 loss: 0.6931482553482056\n",
      "epoch: 11 step: 321 loss: 0.6931482553482056\n",
      "epoch: 11 step: 322 loss: 0.6931482553482056\n",
      "epoch: 11 step: 323 loss: 0.6931482553482056\n",
      "epoch: 11 step: 324 loss: 0.6931482553482056\n",
      "epoch: 11 step: 325 loss: 0.6931482553482056\n",
      "epoch: 11 step: 326 loss: 0.6931482553482056\n",
      "epoch: 11 step: 327 loss: 0.6931482553482056\n",
      "epoch: 11 step: 328 loss: 0.6931482553482056\n",
      "epoch: 11 step: 329 loss: 0.6931482553482056\n",
      "epoch: 11 step: 330 loss: 0.6931482553482056\n",
      "epoch: 11 step: 331 loss: 0.6931482553482056\n",
      "epoch: 11 step: 332 loss: 0.6931482553482056\n",
      "epoch: 11 step: 333 loss: 0.6931482553482056\n",
      "epoch: 11 step: 334 loss: 0.6931482553482056\n",
      "epoch: 11 step: 335 loss: 0.6931482553482056\n",
      "epoch: 11 step: 336 loss: 0.6931482553482056\n",
      "epoch: 11 step: 337 loss: 0.6931482553482056\n",
      "epoch: 11 step: 338 loss: 0.6931482553482056\n",
      "epoch: 11 step: 339 loss: 0.6931482553482056\n",
      "epoch: 11 step: 340 loss: 0.6931482553482056\n",
      "epoch: 11 step: 341 loss: 0.6931482553482056\n",
      "epoch: 11 step: 342 loss: 0.6931482553482056\n",
      "epoch: 11 step: 343 loss: 0.6931482553482056\n",
      "epoch: 11 step: 344 loss: 0.6931482553482056\n",
      "epoch: 11 step: 345 loss: 0.6931482553482056\n",
      "epoch: 11 step: 346 loss: 0.6931482553482056\n",
      "epoch: 11 step: 347 loss: 0.6931482553482056\n",
      "epoch: 11 step: 348 loss: 0.6931482553482056\n",
      "epoch: 11 step: 349 loss: 0.6931482553482056\n",
      "epoch: 11 step: 350 loss: 0.6931482553482056\n",
      "epoch: 11 step: 351 loss: 0.6931482553482056\n",
      "epoch: 11 step: 352 loss: 0.6931482553482056\n",
      "epoch: 11 step: 353 loss: 0.6931482553482056\n",
      "epoch: 11 step: 354 loss: 0.6931482553482056\n",
      "epoch: 11 step: 355 loss: 0.6931482553482056\n",
      "epoch: 11 step: 356 loss: 0.6931482553482056\n",
      "epoch: 11 step: 357 loss: 0.6931482553482056\n",
      "epoch: 11 step: 358 loss: 0.6931482553482056\n",
      "epoch: 11 step: 359 loss: 0.6931482553482056\n",
      "epoch: 11 step: 360 loss: 0.6931482553482056\n",
      "epoch: 11 step: 361 loss: 0.6931482553482056\n",
      "epoch: 11 step: 362 loss: 0.6931482553482056\n",
      "epoch: 11 step: 363 loss: 0.6931482553482056\n",
      "epoch: 11 step: 364 loss: 0.6931482553482056\n",
      "epoch: 11 step: 365 loss: 0.6931482553482056\n",
      "epoch: 11 step: 366 loss: 0.6931482553482056\n",
      "epoch: 11 step: 367 loss: 0.6931482553482056\n",
      "epoch: 11 step: 368 loss: 0.6931482553482056\n",
      "epoch: 11 step: 369 loss: 0.6931482553482056\n",
      "epoch: 11 step: 370 loss: 0.6931482553482056\n",
      "epoch: 11 step: 371 loss: 0.6931482553482056\n",
      "epoch: 11 step: 372 loss: 0.6931482553482056\n",
      "epoch: 11 step: 373 loss: 0.6931482553482056\n",
      "epoch: 11 step: 374 loss: 0.6931482553482056\n",
      "epoch: 11 step: 375 loss: 0.6931482553482056\n",
      "epoch: 11 step: 376 loss: 0.6931482553482056\n",
      "epoch: 11 step: 377 loss: 0.6931482553482056\n",
      "epoch: 11 step: 378 loss: 0.6931482553482056\n",
      "epoch: 11 step: 379 loss: 0.6931482553482056\n",
      "epoch: 11 step: 380 loss: 0.6931482553482056\n",
      "epoch: 11 step: 381 loss: 0.6931482553482056\n",
      "epoch: 11 step: 382 loss: 0.6931482553482056\n",
      "epoch: 11 step: 383 loss: 0.6931482553482056\n",
      "epoch: 11 step: 384 loss: 0.6931482553482056\n",
      "epoch: 11 step: 385 loss: 0.6931482553482056\n",
      "epoch: 11 step: 386 loss: 0.6931482553482056\n",
      "epoch: 11 step: 387 loss: 0.6931482553482056\n",
      "epoch: 11 step: 388 loss: 0.6931482553482056\n",
      "epoch: 11 step: 389 loss: 0.6931482553482056\n",
      "epoch: 11 step: 390 loss: 0.6931482553482056\n",
      "epoch: 11 step: 391 loss: 0.6931482553482056\n",
      "epoch: 11 step: 392 loss: 0.6931482553482056\n",
      "epoch: 11 step: 393 loss: 0.6931482553482056\n",
      "epoch: 11 step: 394 loss: 0.6931482553482056\n",
      "epoch: 11 step: 395 loss: 0.6931482553482056\n",
      "epoch: 11 step: 396 loss: 0.6931482553482056\n",
      "epoch: 11 step: 397 loss: 0.6931482553482056\n",
      "epoch: 11 step: 398 loss: 0.6931482553482056\n",
      "epoch: 11 step: 399 loss: 0.6931482553482056\n",
      "epoch: 11 step: 400 loss: 0.6931482553482056\n",
      "epoch: 11 step: 401 loss: 0.6931482553482056\n",
      "epoch: 11 step: 402 loss: 0.6931482553482056\n",
      "epoch: 11 step: 403 loss: 0.6931482553482056\n",
      "epoch: 11 step: 404 loss: 0.6931482553482056\n",
      "epoch: 11 step: 405 loss: 0.6931482553482056\n",
      "epoch: 11 step: 406 loss: 0.6931482553482056\n",
      "epoch: 11 step: 407 loss: 0.6931482553482056\n",
      "epoch: 11 step: 408 loss: 0.6931482553482056\n",
      "epoch: 11 step: 409 loss: 0.6931482553482056\n",
      "epoch: 11 step: 410 loss: 0.6931482553482056\n",
      "epoch: 11 step: 411 loss: 0.6931482553482056\n",
      "epoch: 11 step: 412 loss: 0.6931482553482056\n",
      "epoch: 11 step: 413 loss: 0.6931482553482056\n",
      "epoch: 11 step: 414 loss: 0.6931482553482056\n",
      "epoch: 11 step: 415 loss: 0.6931482553482056\n",
      "epoch: 11 step: 416 loss: 0.6931482553482056\n",
      "epoch: 11 step: 417 loss: 0.6931482553482056\n",
      "epoch: 11 step: 418 loss: 0.6931482553482056\n",
      "epoch: 11 step: 419 loss: 0.6931482553482056\n",
      "epoch: 11 step: 420 loss: 0.6931482553482056\n",
      "epoch: 11 step: 421 loss: 0.6931482553482056\n",
      "epoch: 11 step: 422 loss: 0.6931482553482056\n",
      "epoch: 11 step: 423 loss: 0.6931482553482056\n",
      "epoch: 11 step: 424 loss: 0.6931482553482056\n",
      "epoch: 11 step: 425 loss: 0.6931482553482056\n",
      "epoch: 11 step: 426 loss: 0.6931482553482056\n",
      "epoch: 11 step: 427 loss: 0.6931482553482056\n",
      "epoch: 11 step: 428 loss: 0.6931482553482056\n",
      "epoch: 11 step: 429 loss: 0.6931482553482056\n",
      "epoch: 11 step: 430 loss: 0.6931482553482056\n",
      "epoch: 11 step: 431 loss: 0.6931482553482056\n",
      "epoch: 11 step: 432 loss: 0.6931482553482056\n",
      "epoch: 11 step: 433 loss: 0.6931482553482056\n",
      "epoch: 11 step: 434 loss: 0.6931482553482056\n",
      "epoch: 11 step: 435 loss: 0.6931482553482056\n",
      "epoch: 11 step: 436 loss: 0.6931482553482056\n",
      "epoch: 11 step: 437 loss: 0.6931482553482056\n",
      "epoch: 11 step: 438 loss: 0.6931482553482056\n",
      "epoch: 11 step: 439 loss: 0.6931482553482056\n",
      "epoch: 11 step: 440 loss: 0.6931482553482056\n",
      "epoch: 11 step: 441 loss: 0.6931482553482056\n",
      "epoch: 11 step: 442 loss: 0.6931482553482056\n",
      "epoch: 11 step: 443 loss: 0.6931482553482056\n",
      "epoch: 11 step: 444 loss: 0.6931482553482056\n",
      "epoch: 11 step: 445 loss: 0.6931482553482056\n",
      "epoch: 11 step: 446 loss: 0.6931482553482056\n",
      "epoch: 11 step: 447 loss: 0.6931482553482056\n",
      "epoch: 11 step: 448 loss: 0.6931482553482056\n",
      "epoch: 11 step: 449 loss: 0.6931482553482056\n",
      "epoch: 11 step: 450 loss: 0.6931482553482056\n",
      "epoch: 11 step: 451 loss: 0.6931482553482056\n",
      "epoch: 11 step: 452 loss: 0.6931482553482056\n",
      "epoch: 11 step: 453 loss: 0.6931482553482056\n",
      "epoch: 11 step: 454 loss: 0.6931482553482056\n",
      "epoch: 11 step: 455 loss: 0.6931482553482056\n",
      "epoch: 11 step: 456 loss: 0.6931482553482056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 457 loss: 0.6931482553482056\n",
      "epoch: 11 step: 458 loss: 0.6931482553482056\n",
      "epoch: 11 step: 459 loss: 0.6931482553482056\n",
      "epoch: 11 step: 460 loss: 0.6931482553482056\n",
      "epoch: 11 step: 461 loss: 0.6931482553482056\n",
      "epoch: 11 step: 462 loss: 0.6931482553482056\n",
      "epoch: 11 step: 463 loss: 0.6931482553482056\n",
      "epoch: 11 step: 464 loss: 0.6931482553482056\n",
      "epoch: 11 step: 465 loss: 0.6931482553482056\n",
      "epoch: 11 step: 466 loss: 0.6931482553482056\n",
      "epoch: 11 step: 467 loss: 0.6931482553482056\n",
      "epoch: 11 step: 468 loss: 0.6931482553482056\n",
      "epoch: 11 step: 469 loss: 0.6931482553482056\n",
      "epoch: 11 step: 470 loss: 0.6931482553482056\n",
      "epoch: 11 step: 471 loss: 0.6931482553482056\n",
      "epoch: 11 step: 472 loss: 0.6931482553482056\n",
      "epoch: 11 step: 473 loss: 0.6931482553482056\n",
      "epoch: 11 step: 474 loss: 0.6931482553482056\n",
      "epoch: 11 step: 475 loss: 0.6931482553482056\n",
      "epoch: 11 step: 476 loss: 0.6931482553482056\n",
      "epoch: 11 step: 477 loss: 0.6931482553482056\n",
      "epoch: 11 step: 478 loss: 0.6931482553482056\n",
      "epoch: 11 step: 479 loss: 0.6931482553482056\n",
      "epoch: 11 step: 480 loss: 0.6931482553482056\n",
      "epoch: 11 step: 481 loss: 0.6931482553482056\n",
      "epoch: 11 step: 482 loss: 0.6931482553482056\n",
      "epoch: 11 step: 483 loss: 0.6931482553482056\n",
      "epoch: 11 step: 484 loss: 0.6931482553482056\n",
      "epoch: 11 step: 485 loss: 0.6931482553482056\n",
      "epoch: 11 step: 486 loss: 0.6931482553482056\n",
      "epoch: 11 step: 487 loss: 0.6931482553482056\n",
      "epoch: 11 step: 488 loss: 0.6931482553482056\n",
      "epoch: 11 step: 489 loss: 0.6931482553482056\n",
      "epoch: 11 step: 490 loss: 0.6931482553482056\n",
      "epoch: 11 step: 491 loss: 0.6931482553482056\n",
      "epoch: 11 step: 492 loss: 0.6931482553482056\n",
      "epoch: 11 step: 493 loss: 0.6931482553482056\n",
      "epoch: 11 step: 494 loss: 0.6931482553482056\n",
      "epoch: 11 step: 495 loss: 0.6931482553482056\n",
      "epoch: 11 step: 496 loss: 0.6931482553482056\n",
      "epoch: 11 step: 497 loss: 0.6931482553482056\n",
      "epoch: 11 step: 498 loss: 0.6931482553482056\n",
      "epoch: 11 step: 499 loss: 0.6931482553482056\n",
      "epoch: 11 step: 500 loss: 0.6931482553482056\n",
      "epoch: 11 step: 501 loss: 0.6931482553482056\n",
      "epoch: 11 step: 502 loss: 0.6931482553482056\n",
      "epoch: 11 step: 503 loss: 0.6931482553482056\n",
      "epoch: 11 step: 504 loss: 0.6931482553482056\n",
      "epoch: 11 step: 505 loss: 0.6931482553482056\n",
      "epoch: 11 step: 506 loss: 0.6931482553482056\n",
      "epoch: 11 step: 507 loss: 0.6931482553482056\n",
      "epoch: 11 step: 508 loss: 0.6931482553482056\n",
      "epoch: 11 step: 509 loss: 0.6931482553482056\n",
      "epoch: 11 step: 510 loss: 0.6931482553482056\n",
      "epoch: 11 step: 511 loss: 0.6931482553482056\n",
      "epoch: 11 step: 512 loss: 0.6931481957435608\n",
      "epoch: 11 step: 513 loss: 0.693148136138916\n",
      "epoch: 11 step: 514 loss: 0.6931482553482056\n",
      "epoch: 11 step: 515 loss: 0.6931482553482056\n",
      "epoch: 11 step: 516 loss: 0.6931482553482056\n",
      "epoch: 11 step: 517 loss: 0.693148136138916\n",
      "epoch: 11 step: 518 loss: 0.693148136138916\n",
      "epoch: 11 step: 519 loss: 0.6931482553482056\n",
      "epoch: 11 step: 520 loss: 0.6931482553482056\n",
      "epoch: 11 step: 521 loss: 0.693148136138916\n",
      "epoch: 11 step: 522 loss: 0.6931481957435608\n",
      "epoch: 11 step: 523 loss: 0.6931481957435608\n",
      "epoch: 11 step: 524 loss: 0.6931481957435608\n",
      "epoch: 11 step: 525 loss: 0.693148136138916\n",
      "epoch: 11 step: 526 loss: 0.6931481957435608\n",
      "epoch: 11 step: 527 loss: 0.693148136138916\n",
      "epoch: 11 step: 528 loss: 0.693148136138916\n",
      "epoch: 11 step: 529 loss: 0.693148136138916\n",
      "epoch: 11 step: 530 loss: 0.6931481957435608\n",
      "epoch: 11 step: 531 loss: 0.693148136138916\n",
      "epoch: 11 step: 532 loss: 0.693148136138916\n",
      "epoch: 11 step: 533 loss: 0.693148136138916\n",
      "epoch: 11 step: 534 loss: 0.693148136138916\n",
      "epoch: 11 step: 535 loss: 0.693148136138916\n",
      "epoch: 11 step: 536 loss: 0.693148136138916\n",
      "epoch: 11 step: 537 loss: 0.693148136138916\n",
      "epoch: 11 step: 538 loss: 0.693148136138916\n",
      "epoch: 11 step: 539 loss: 0.693148136138916\n",
      "epoch: 11 step: 540 loss: 0.693148136138916\n",
      "epoch: 11 step: 541 loss: 0.693148136138916\n",
      "epoch: 11 step: 542 loss: 0.693148136138916\n",
      "epoch: 11 step: 543 loss: 0.693148136138916\n",
      "epoch: 11 step: 544 loss: 0.693148136138916\n",
      "epoch: 11 step: 545 loss: 0.693148136138916\n",
      "epoch: 11 step: 546 loss: 0.693148136138916\n",
      "epoch: 11 step: 547 loss: 0.693148136138916\n",
      "epoch: 11 step: 548 loss: 0.693148136138916\n",
      "epoch: 11 step: 549 loss: 0.693148136138916\n",
      "epoch: 11 step: 550 loss: 0.693148136138916\n",
      "epoch: 11 step: 551 loss: 0.693148136138916\n",
      "epoch: 11 step: 552 loss: 0.693148136138916\n",
      "epoch: 11 step: 553 loss: 0.693148136138916\n",
      "epoch: 11 step: 554 loss: 0.693148136138916\n",
      "epoch: 11 step: 555 loss: 0.693148136138916\n",
      "epoch: 11 step: 556 loss: 0.693148136138916\n",
      "epoch: 11 step: 557 loss: 0.693148136138916\n",
      "epoch: 11 step: 558 loss: 0.693148136138916\n",
      "epoch: 11 step: 559 loss: 0.693148136138916\n",
      "epoch: 11 step: 560 loss: 0.693148136138916\n",
      "epoch: 11 step: 561 loss: 0.693148136138916\n",
      "epoch: 11 step: 562 loss: 0.693148136138916\n",
      "epoch: 11 step: 563 loss: 0.693148136138916\n",
      "epoch: 11 step: 564 loss: 0.693148136138916\n",
      "epoch: 11 step: 565 loss: 0.693148136138916\n",
      "epoch: 11 step: 566 loss: 0.693148136138916\n",
      "epoch: 11 step: 567 loss: 0.693148136138916\n",
      "epoch: 11 step: 568 loss: 0.693148136138916\n",
      "epoch: 11 step: 569 loss: 0.693148136138916\n",
      "epoch: 11 step: 570 loss: 0.693148136138916\n",
      "epoch: 11 step: 571 loss: 0.693148136138916\n",
      "epoch: 11 step: 572 loss: 0.693148136138916\n",
      "epoch: 11 step: 573 loss: 0.693148136138916\n",
      "epoch: 11 step: 574 loss: 0.693148136138916\n",
      "epoch: 11 step: 575 loss: 0.693148136138916\n",
      "epoch: 11 step: 576 loss: 0.693148136138916\n",
      "epoch: 11 step: 577 loss: 0.693148136138916\n",
      "epoch: 11 step: 578 loss: 0.693148136138916\n",
      "epoch: 11 step: 579 loss: 0.693148136138916\n",
      "epoch: 11 step: 580 loss: 0.693148136138916\n",
      "epoch: 11 step: 581 loss: 0.693148136138916\n",
      "epoch: 11 step: 582 loss: 0.693148136138916\n",
      "epoch: 11 step: 583 loss: 0.693148136138916\n",
      "epoch: 11 step: 584 loss: 0.693148136138916\n",
      "epoch: 11 step: 585 loss: 0.693148136138916\n",
      "epoch: 11 step: 586 loss: 0.693148136138916\n",
      "epoch: 11 step: 587 loss: 0.693148136138916\n",
      "epoch: 11 step: 588 loss: 0.693148136138916\n",
      "epoch: 11 step: 589 loss: 0.693148136138916\n",
      "epoch: 11 step: 590 loss: 0.693148136138916\n",
      "epoch: 11 step: 591 loss: 0.693148136138916\n",
      "epoch: 11 step: 592 loss: 0.693148136138916\n",
      "epoch: 11 step: 593 loss: 0.693148136138916\n",
      "epoch: 11 step: 594 loss: 0.693148136138916\n",
      "epoch: 11 step: 595 loss: 0.693148136138916\n",
      "epoch: 11 step: 596 loss: 0.693148136138916\n",
      "epoch: 11 step: 597 loss: 0.693148136138916\n",
      "epoch: 11 step: 598 loss: 0.693148136138916\n",
      "epoch: 11 step: 599 loss: 0.693148136138916\n",
      "epoch: 11 step: 600 loss: 0.693148136138916\n",
      "epoch: 11 step: 601 loss: 0.693148136138916\n",
      "epoch: 11 step: 602 loss: 0.693148136138916\n",
      "epoch: 11 step: 603 loss: 0.693148136138916\n",
      "epoch: 11 step: 604 loss: 0.693148136138916\n",
      "epoch: 11 step: 605 loss: 0.693148136138916\n",
      "epoch: 11 step: 606 loss: 0.693148136138916\n",
      "epoch: 11 step: 607 loss: 0.693148136138916\n",
      "epoch: 11 step: 608 loss: 0.693148136138916\n",
      "epoch: 11 step: 609 loss: 0.693148136138916\n",
      "epoch: 11 step: 610 loss: 0.693148136138916\n",
      "epoch: 11 step: 611 loss: 0.693148136138916\n",
      "epoch: 11 step: 612 loss: 0.693148136138916\n",
      "epoch: 11 step: 613 loss: 0.693148136138916\n",
      "epoch: 11 step: 614 loss: 0.693148136138916\n",
      "epoch: 11 step: 615 loss: 0.693148136138916\n",
      "epoch: 11 step: 616 loss: 0.693148136138916\n",
      "epoch: 11 step: 617 loss: 0.693148136138916\n",
      "epoch: 11 step: 618 loss: 0.693148136138916\n",
      "epoch: 11 step: 619 loss: 0.693148136138916\n",
      "epoch: 11 step: 620 loss: 0.693148136138916\n",
      "epoch: 11 step: 621 loss: 0.693148136138916\n",
      "epoch: 11 step: 622 loss: 0.693148136138916\n",
      "epoch: 11 step: 623 loss: 0.693148136138916\n",
      "epoch: 11 step: 624 loss: 0.693148136138916\n",
      "epoch: 11 step: 625 loss: 0.693148136138916\n",
      "epoch: 11 step: 626 loss: 0.693148136138916\n",
      "epoch: 11 step: 627 loss: 0.693148136138916\n",
      "epoch: 11 step: 628 loss: 0.693148136138916\n",
      "epoch: 11 step: 629 loss: 0.693148136138916\n",
      "epoch: 11 step: 630 loss: 0.693148136138916\n",
      "epoch: 11 step: 631 loss: 0.693148136138916\n",
      "epoch: 11 step: 632 loss: 0.693148136138916\n",
      "epoch: 11 step: 633 loss: 0.693148136138916\n",
      "epoch: 11 step: 634 loss: 0.693148136138916\n",
      "epoch: 11 step: 635 loss: 0.693148136138916\n",
      "epoch: 11 step: 636 loss: 0.693148136138916\n",
      "epoch: 11 step: 637 loss: 0.693148136138916\n",
      "epoch: 11 step: 638 loss: 0.693148136138916\n",
      "epoch: 11 step: 639 loss: 0.693148136138916\n",
      "epoch: 11 step: 640 loss: 0.693148136138916\n",
      "epoch: 11 step: 641 loss: 0.693148136138916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 642 loss: 0.693148136138916\n",
      "epoch: 11 step: 643 loss: 0.693148136138916\n",
      "epoch: 11 step: 644 loss: 0.693148136138916\n",
      "epoch: 11 step: 645 loss: 0.693148136138916\n",
      "epoch: 11 step: 646 loss: 0.693148136138916\n",
      "epoch: 11 step: 647 loss: 0.693148136138916\n",
      "epoch: 11 step: 648 loss: 0.693148136138916\n",
      "epoch: 11 step: 649 loss: 0.693148136138916\n",
      "epoch: 11 step: 650 loss: 0.693148136138916\n",
      "epoch: 11 step: 651 loss: 0.693148136138916\n",
      "epoch: 11 step: 652 loss: 0.693148136138916\n",
      "epoch: 11 step: 653 loss: 0.693148136138916\n",
      "epoch: 11 step: 654 loss: 0.693148136138916\n",
      "epoch: 11 step: 655 loss: 0.693148136138916\n",
      "epoch: 11 step: 656 loss: 0.693148136138916\n",
      "epoch: 11 step: 657 loss: 0.693148136138916\n",
      "epoch: 11 step: 658 loss: 0.693148136138916\n",
      "epoch: 11 step: 659 loss: 0.693148136138916\n",
      "epoch: 11 step: 660 loss: 0.693148136138916\n",
      "epoch: 11 step: 661 loss: 0.693148136138916\n",
      "epoch: 11 step: 662 loss: 0.693148136138916\n",
      "epoch: 11 step: 663 loss: 0.693148136138916\n",
      "epoch: 11 step: 664 loss: 0.693148136138916\n",
      "epoch: 11 step: 665 loss: 0.693148136138916\n",
      "epoch: 11 step: 666 loss: 0.693148136138916\n",
      "epoch: 11 step: 667 loss: 0.693148136138916\n",
      "epoch: 11 step: 668 loss: 0.693148136138916\n",
      "epoch: 11 step: 669 loss: 0.693148136138916\n",
      "epoch: 11 step: 670 loss: 0.693148136138916\n",
      "epoch: 11 step: 671 loss: 0.693148136138916\n",
      "epoch: 11 step: 672 loss: 0.693148136138916\n",
      "epoch: 11 step: 673 loss: 0.693148136138916\n",
      "epoch: 11 step: 674 loss: 0.693148136138916\n",
      "epoch: 11 step: 675 loss: 0.693148136138916\n",
      "epoch: 11 step: 676 loss: 0.693148136138916\n",
      "epoch: 11 step: 677 loss: 0.693148136138916\n",
      "epoch: 11 step: 678 loss: 0.693148136138916\n",
      "epoch: 11 step: 679 loss: 0.693148136138916\n",
      "epoch: 11 step: 680 loss: 0.693148136138916\n",
      "epoch: 11 step: 681 loss: 0.693148136138916\n",
      "epoch: 11 step: 682 loss: 0.693148136138916\n",
      "epoch: 11 step: 683 loss: 0.693148136138916\n",
      "epoch: 11 step: 684 loss: 0.693148136138916\n",
      "epoch: 11 step: 685 loss: 0.693148136138916\n",
      "epoch: 11 step: 686 loss: 0.693148136138916\n",
      "epoch: 11 step: 687 loss: 0.693148136138916\n",
      "epoch: 11 step: 688 loss: 0.693148136138916\n",
      "epoch: 11 step: 689 loss: 0.693148136138916\n",
      "epoch: 11 step: 690 loss: 0.693148136138916\n",
      "epoch: 11 step: 691 loss: 0.693148136138916\n",
      "epoch: 11 step: 692 loss: 0.693148136138916\n",
      "epoch: 11 step: 693 loss: 0.693148136138916\n",
      "epoch: 11 step: 694 loss: 0.693148136138916\n",
      "epoch: 11 step: 695 loss: 0.693148136138916\n",
      "epoch: 11 step: 696 loss: 0.693148136138916\n",
      "epoch: 11 step: 697 loss: 0.693148136138916\n",
      "epoch: 11 step: 698 loss: 0.693148136138916\n",
      "epoch: 11 step: 699 loss: 0.693148136138916\n",
      "epoch: 11 step: 700 loss: 0.693148136138916\n",
      "epoch: 11 step: 701 loss: 0.693148136138916\n",
      "epoch: 11 step: 702 loss: 0.693148136138916\n",
      "epoch: 11 step: 703 loss: 0.693148136138916\n",
      "epoch: 11 step: 704 loss: 0.693148136138916\n",
      "epoch: 11 step: 705 loss: 0.693148136138916\n",
      "epoch: 11 step: 706 loss: 0.693148136138916\n",
      "epoch: 11 step: 707 loss: 0.693148136138916\n",
      "epoch: 11 step: 708 loss: 0.693148136138916\n",
      "epoch: 11 step: 709 loss: 0.693148136138916\n",
      "epoch: 11 step: 710 loss: 0.693148136138916\n",
      "epoch: 11 step: 711 loss: 0.693148136138916\n",
      "epoch: 11 step: 712 loss: 0.693148136138916\n",
      "epoch: 11 step: 713 loss: 0.693148136138916\n",
      "epoch: 11 step: 714 loss: 0.693148136138916\n",
      "epoch: 11 step: 715 loss: 0.693148136138916\n",
      "epoch: 11 step: 716 loss: 0.693148136138916\n",
      "epoch: 11 step: 717 loss: 0.693148136138916\n",
      "epoch: 11 step: 718 loss: 0.693148136138916\n",
      "epoch: 11 step: 719 loss: 0.693148136138916\n",
      "epoch: 11 step: 720 loss: 0.693148136138916\n",
      "epoch: 11 step: 721 loss: 0.693148136138916\n",
      "epoch: 11 step: 722 loss: 0.693148136138916\n",
      "epoch: 11 step: 723 loss: 0.693148136138916\n",
      "epoch: 11 step: 724 loss: 0.693148136138916\n",
      "epoch: 11 step: 725 loss: 0.693148136138916\n",
      "epoch: 11 step: 726 loss: 0.693148136138916\n",
      "epoch: 11 step: 727 loss: 0.693148136138916\n",
      "epoch: 11 step: 728 loss: 0.693148136138916\n",
      "epoch: 11 step: 729 loss: 0.693148136138916\n",
      "epoch: 11 step: 730 loss: 0.693148136138916\n",
      "epoch: 11 step: 731 loss: 0.693148136138916\n",
      "epoch: 11 step: 732 loss: 0.693148136138916\n",
      "epoch: 11 step: 733 loss: 0.693148136138916\n",
      "epoch: 11 step: 734 loss: 0.693148136138916\n",
      "epoch: 11 step: 735 loss: 0.693148136138916\n",
      "epoch: 11 step: 736 loss: 0.693148136138916\n",
      "epoch: 11 step: 737 loss: 0.693148136138916\n",
      "epoch: 11 step: 738 loss: 0.693148136138916\n",
      "epoch: 11 step: 739 loss: 0.693148136138916\n",
      "epoch: 11 step: 740 loss: 0.693148136138916\n",
      "epoch: 11 step: 741 loss: 0.693148136138916\n",
      "epoch: 11 step: 742 loss: 0.693148136138916\n",
      "epoch: 11 step: 743 loss: 0.6931480765342712\n",
      "epoch: 11 step: 744 loss: 0.693148136138916\n",
      "epoch: 11 step: 745 loss: 0.693148136138916\n",
      "epoch: 11 step: 746 loss: 0.693148136138916\n",
      "epoch: 11 step: 747 loss: 0.693148136138916\n",
      "epoch: 11 step: 748 loss: 0.693148136138916\n",
      "epoch: 11 step: 749 loss: 0.693148136138916\n",
      "epoch: 11 step: 750 loss: 0.693148136138916\n",
      "epoch: 11 step: 751 loss: 0.693148136138916\n",
      "epoch: 11 step: 752 loss: 0.693148136138916\n",
      "epoch: 11 step: 753 loss: 0.6931480765342712\n",
      "epoch: 11 step: 754 loss: 0.6931480765342712\n",
      "epoch: 11 step: 755 loss: 0.693148136138916\n",
      "epoch: 11 step: 756 loss: 0.693148136138916\n",
      "epoch: 11 step: 757 loss: 0.6931480765342712\n",
      "epoch: 11 step: 758 loss: 0.693148136138916\n",
      "epoch: 11 step: 759 loss: 0.693148136138916\n",
      "epoch: 11 step: 760 loss: 0.6931480765342712\n",
      "epoch: 11 step: 761 loss: 0.6931480169296265\n",
      "epoch: 11 step: 762 loss: 0.6931480169296265\n",
      "epoch: 11 step: 763 loss: 0.6931480765342712\n",
      "epoch: 11 step: 764 loss: 0.693148136138916\n",
      "epoch: 11 step: 765 loss: 0.6931480169296265\n",
      "epoch: 11 step: 766 loss: 0.6931480169296265\n",
      "epoch: 11 step: 767 loss: 0.6931480765342712\n",
      "epoch: 11 step: 768 loss: 0.6931480169296265\n",
      "epoch: 11 step: 769 loss: 0.6931480169296265\n",
      "epoch: 11 step: 770 loss: 0.6931480765342712\n",
      "epoch: 11 step: 771 loss: 0.6931480169296265\n",
      "epoch: 11 step: 772 loss: 0.6931480169296265\n",
      "epoch: 11 step: 773 loss: 0.6931480169296265\n",
      "epoch: 11 step: 774 loss: 0.693148136138916\n",
      "epoch: 11 step: 775 loss: 0.6931480169296265\n",
      "epoch: 11 step: 776 loss: 0.6931480169296265\n",
      "epoch: 11 step: 777 loss: 0.6931480765342712\n",
      "epoch: 11 step: 778 loss: 0.6931480169296265\n",
      "epoch: 11 step: 779 loss: 0.6931480169296265\n",
      "epoch: 11 step: 780 loss: 0.6931480169296265\n",
      "epoch: 11 step: 781 loss: 0.6931480169296265\n",
      "epoch: 12 step: 1 loss: 0.6931480169296265\n",
      "epoch: 12 step: 2 loss: 0.6931480169296265\n",
      "epoch: 12 step: 3 loss: 0.6931480169296265\n",
      "epoch: 12 step: 4 loss: 0.6931480169296265\n",
      "epoch: 12 step: 5 loss: 0.6931480169296265\n",
      "epoch: 12 step: 6 loss: 0.6931480169296265\n",
      "epoch: 12 step: 7 loss: 0.6931480169296265\n",
      "epoch: 12 step: 8 loss: 0.6931480169296265\n",
      "epoch: 12 step: 9 loss: 0.6931480169296265\n",
      "epoch: 12 step: 10 loss: 0.6931480169296265\n",
      "epoch: 12 step: 11 loss: 0.6931480169296265\n",
      "epoch: 12 step: 12 loss: 0.6931480169296265\n",
      "epoch: 12 step: 13 loss: 0.6931480169296265\n",
      "epoch: 12 step: 14 loss: 0.6931480169296265\n",
      "epoch: 12 step: 15 loss: 0.6931480169296265\n",
      "epoch: 12 step: 16 loss: 0.6931480169296265\n",
      "epoch: 12 step: 17 loss: 0.6931480169296265\n",
      "epoch: 12 step: 18 loss: 0.6931480169296265\n",
      "epoch: 12 step: 19 loss: 0.6931480169296265\n",
      "epoch: 12 step: 20 loss: 0.6931480169296265\n",
      "epoch: 12 step: 21 loss: 0.6931480169296265\n",
      "epoch: 12 step: 22 loss: 0.6931480169296265\n",
      "epoch: 12 step: 23 loss: 0.6931480169296265\n",
      "epoch: 12 step: 24 loss: 0.6931480169296265\n",
      "epoch: 12 step: 25 loss: 0.6931480169296265\n",
      "epoch: 12 step: 26 loss: 0.6931480169296265\n",
      "epoch: 12 step: 27 loss: 0.6931480169296265\n",
      "epoch: 12 step: 28 loss: 0.6931480169296265\n",
      "epoch: 12 step: 29 loss: 0.6931480169296265\n",
      "epoch: 12 step: 30 loss: 0.6931480169296265\n",
      "epoch: 12 step: 31 loss: 0.6931480169296265\n",
      "epoch: 12 step: 32 loss: 0.6931480169296265\n",
      "epoch: 12 step: 33 loss: 0.6931480169296265\n",
      "epoch: 12 step: 34 loss: 0.6931480169296265\n",
      "epoch: 12 step: 35 loss: 0.6931480169296265\n",
      "epoch: 12 step: 36 loss: 0.6931480169296265\n",
      "epoch: 12 step: 37 loss: 0.6931480169296265\n",
      "epoch: 12 step: 38 loss: 0.6931480169296265\n",
      "epoch: 12 step: 39 loss: 0.6931480169296265\n",
      "epoch: 12 step: 40 loss: 0.6931480169296265\n",
      "epoch: 12 step: 41 loss: 0.6931480169296265\n",
      "epoch: 12 step: 42 loss: 0.6931480169296265\n",
      "epoch: 12 step: 43 loss: 0.6931480169296265\n",
      "epoch: 12 step: 44 loss: 0.6931480169296265\n",
      "epoch: 12 step: 45 loss: 0.6931480169296265\n",
      "epoch: 12 step: 46 loss: 0.6931480169296265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 47 loss: 0.6931480169296265\n",
      "epoch: 12 step: 48 loss: 0.6931480169296265\n",
      "epoch: 12 step: 49 loss: 0.6931480169296265\n",
      "epoch: 12 step: 50 loss: 0.6931480169296265\n",
      "epoch: 12 step: 51 loss: 0.6931480169296265\n",
      "epoch: 12 step: 52 loss: 0.6931480169296265\n",
      "epoch: 12 step: 53 loss: 0.6931480169296265\n",
      "epoch: 12 step: 54 loss: 0.6931480169296265\n",
      "epoch: 12 step: 55 loss: 0.6931480169296265\n",
      "epoch: 12 step: 56 loss: 0.6931480169296265\n",
      "epoch: 12 step: 57 loss: 0.6931480169296265\n",
      "epoch: 12 step: 58 loss: 0.6931480169296265\n",
      "epoch: 12 step: 59 loss: 0.6931480169296265\n",
      "epoch: 12 step: 60 loss: 0.6931480169296265\n",
      "epoch: 12 step: 61 loss: 0.6931480169296265\n",
      "epoch: 12 step: 62 loss: 0.6931480169296265\n",
      "epoch: 12 step: 63 loss: 0.6931480169296265\n",
      "epoch: 12 step: 64 loss: 0.6931480169296265\n",
      "epoch: 12 step: 65 loss: 0.6931480169296265\n",
      "epoch: 12 step: 66 loss: 0.6931480169296265\n",
      "epoch: 12 step: 67 loss: 0.6931480169296265\n",
      "epoch: 12 step: 68 loss: 0.6931480169296265\n",
      "epoch: 12 step: 69 loss: 0.6931480169296265\n",
      "epoch: 12 step: 70 loss: 0.6931480169296265\n",
      "epoch: 12 step: 71 loss: 0.6931480169296265\n",
      "epoch: 12 step: 72 loss: 0.6931480169296265\n",
      "epoch: 12 step: 73 loss: 0.6931480169296265\n",
      "epoch: 12 step: 74 loss: 0.6931480169296265\n",
      "epoch: 12 step: 75 loss: 0.6931480169296265\n",
      "epoch: 12 step: 76 loss: 0.6931480169296265\n",
      "epoch: 12 step: 77 loss: 0.6931480169296265\n",
      "epoch: 12 step: 78 loss: 0.6931480169296265\n",
      "epoch: 12 step: 79 loss: 0.6931480169296265\n",
      "epoch: 12 step: 80 loss: 0.6931480169296265\n",
      "epoch: 12 step: 81 loss: 0.6931480169296265\n",
      "epoch: 12 step: 82 loss: 0.6931480169296265\n",
      "epoch: 12 step: 83 loss: 0.6931480169296265\n",
      "epoch: 12 step: 84 loss: 0.6931480169296265\n",
      "epoch: 12 step: 85 loss: 0.6931480169296265\n",
      "epoch: 12 step: 86 loss: 0.6931480169296265\n",
      "epoch: 12 step: 87 loss: 0.6931480169296265\n",
      "epoch: 12 step: 88 loss: 0.6931480169296265\n",
      "epoch: 12 step: 89 loss: 0.6931480169296265\n",
      "epoch: 12 step: 90 loss: 0.6931480169296265\n",
      "epoch: 12 step: 91 loss: 0.6931480169296265\n",
      "epoch: 12 step: 92 loss: 0.6931480169296265\n",
      "epoch: 12 step: 93 loss: 0.6931480169296265\n",
      "epoch: 12 step: 94 loss: 0.6931480169296265\n",
      "epoch: 12 step: 95 loss: 0.6931480169296265\n",
      "epoch: 12 step: 96 loss: 0.6931480169296265\n",
      "epoch: 12 step: 97 loss: 0.6931480169296265\n",
      "epoch: 12 step: 98 loss: 0.6931480169296265\n",
      "epoch: 12 step: 99 loss: 0.6931480169296265\n",
      "epoch: 12 step: 100 loss: 0.6931480169296265\n",
      "epoch: 12 step: 101 loss: 0.6931480169296265\n",
      "epoch: 12 step: 102 loss: 0.6931480169296265\n",
      "epoch: 12 step: 103 loss: 0.6931480169296265\n",
      "epoch: 12 step: 104 loss: 0.6931480169296265\n",
      "epoch: 12 step: 105 loss: 0.6931480169296265\n",
      "epoch: 12 step: 106 loss: 0.6931480169296265\n",
      "epoch: 12 step: 107 loss: 0.6931480169296265\n",
      "epoch: 12 step: 108 loss: 0.6931480169296265\n",
      "epoch: 12 step: 109 loss: 0.6931480169296265\n",
      "epoch: 12 step: 110 loss: 0.6931480169296265\n",
      "epoch: 12 step: 111 loss: 0.6931480169296265\n",
      "epoch: 12 step: 112 loss: 0.6931480169296265\n",
      "epoch: 12 step: 113 loss: 0.6931480169296265\n",
      "epoch: 12 step: 114 loss: 0.6931480169296265\n",
      "epoch: 12 step: 115 loss: 0.6931480169296265\n",
      "epoch: 12 step: 116 loss: 0.6931480169296265\n",
      "epoch: 12 step: 117 loss: 0.6931480169296265\n",
      "epoch: 12 step: 118 loss: 0.6931480169296265\n",
      "epoch: 12 step: 119 loss: 0.6931480169296265\n",
      "epoch: 12 step: 120 loss: 0.6931480169296265\n",
      "epoch: 12 step: 121 loss: 0.6931480169296265\n",
      "epoch: 12 step: 122 loss: 0.6931480169296265\n",
      "epoch: 12 step: 123 loss: 0.6931480169296265\n",
      "epoch: 12 step: 124 loss: 0.6931480169296265\n",
      "epoch: 12 step: 125 loss: 0.6931480169296265\n",
      "epoch: 12 step: 126 loss: 0.6931480169296265\n",
      "epoch: 12 step: 127 loss: 0.6931480169296265\n",
      "epoch: 12 step: 128 loss: 0.6931480169296265\n",
      "epoch: 12 step: 129 loss: 0.6931480169296265\n",
      "epoch: 12 step: 130 loss: 0.6931480169296265\n",
      "epoch: 12 step: 131 loss: 0.6931480169296265\n",
      "epoch: 12 step: 132 loss: 0.6931480169296265\n",
      "epoch: 12 step: 133 loss: 0.6931480169296265\n",
      "epoch: 12 step: 134 loss: 0.6931480169296265\n",
      "epoch: 12 step: 135 loss: 0.6931480169296265\n",
      "epoch: 12 step: 136 loss: 0.6931480169296265\n",
      "epoch: 12 step: 137 loss: 0.6931480169296265\n",
      "epoch: 12 step: 138 loss: 0.6931480169296265\n",
      "epoch: 12 step: 139 loss: 0.6931480169296265\n",
      "epoch: 12 step: 140 loss: 0.6931480169296265\n",
      "epoch: 12 step: 141 loss: 0.6931480169296265\n",
      "epoch: 12 step: 142 loss: 0.6931480169296265\n",
      "epoch: 12 step: 143 loss: 0.6931480169296265\n",
      "epoch: 12 step: 144 loss: 0.6931480169296265\n",
      "epoch: 12 step: 145 loss: 0.6931480169296265\n",
      "epoch: 12 step: 146 loss: 0.6931480169296265\n",
      "epoch: 12 step: 147 loss: 0.6931480169296265\n",
      "epoch: 12 step: 148 loss: 0.6931480169296265\n",
      "epoch: 12 step: 149 loss: 0.6931480169296265\n",
      "epoch: 12 step: 150 loss: 0.6931480169296265\n",
      "epoch: 12 step: 151 loss: 0.6931480169296265\n",
      "epoch: 12 step: 152 loss: 0.6931480169296265\n",
      "epoch: 12 step: 153 loss: 0.6931480169296265\n",
      "epoch: 12 step: 154 loss: 0.6931480169296265\n",
      "epoch: 12 step: 155 loss: 0.6931480169296265\n",
      "epoch: 12 step: 156 loss: 0.6931480169296265\n",
      "epoch: 12 step: 157 loss: 0.6931480169296265\n",
      "epoch: 12 step: 158 loss: 0.6931480169296265\n",
      "epoch: 12 step: 159 loss: 0.6931480169296265\n",
      "epoch: 12 step: 160 loss: 0.6931480169296265\n",
      "epoch: 12 step: 161 loss: 0.6931480169296265\n",
      "epoch: 12 step: 162 loss: 0.6931480169296265\n",
      "epoch: 12 step: 163 loss: 0.6931480169296265\n",
      "epoch: 12 step: 164 loss: 0.6931480169296265\n",
      "epoch: 12 step: 165 loss: 0.6931480169296265\n",
      "epoch: 12 step: 166 loss: 0.6931480169296265\n",
      "epoch: 12 step: 167 loss: 0.6931480169296265\n",
      "epoch: 12 step: 168 loss: 0.6931480169296265\n",
      "epoch: 12 step: 169 loss: 0.6931480169296265\n",
      "epoch: 12 step: 170 loss: 0.6931480169296265\n",
      "epoch: 12 step: 171 loss: 0.6931480169296265\n",
      "epoch: 12 step: 172 loss: 0.6931480169296265\n",
      "epoch: 12 step: 173 loss: 0.6931480169296265\n",
      "epoch: 12 step: 174 loss: 0.6931480169296265\n",
      "epoch: 12 step: 175 loss: 0.6931480169296265\n",
      "epoch: 12 step: 176 loss: 0.6931480169296265\n",
      "epoch: 12 step: 177 loss: 0.6931480169296265\n",
      "epoch: 12 step: 178 loss: 0.6931480169296265\n",
      "epoch: 12 step: 179 loss: 0.6931480169296265\n",
      "epoch: 12 step: 180 loss: 0.6931480169296265\n",
      "epoch: 12 step: 181 loss: 0.6931480169296265\n",
      "epoch: 12 step: 182 loss: 0.6931480169296265\n",
      "epoch: 12 step: 183 loss: 0.6931480169296265\n",
      "epoch: 12 step: 184 loss: 0.6931479573249817\n",
      "epoch: 12 step: 185 loss: 0.6931480169296265\n",
      "epoch: 12 step: 186 loss: 0.6931480169296265\n",
      "epoch: 12 step: 187 loss: 0.6931480169296265\n",
      "epoch: 12 step: 188 loss: 0.6931480169296265\n",
      "epoch: 12 step: 189 loss: 0.6931480169296265\n",
      "epoch: 12 step: 190 loss: 0.6931480169296265\n",
      "epoch: 12 step: 191 loss: 0.6931480169296265\n",
      "epoch: 12 step: 192 loss: 0.6931480169296265\n",
      "epoch: 12 step: 193 loss: 0.6931480169296265\n",
      "epoch: 12 step: 194 loss: 0.6931480169296265\n",
      "epoch: 12 step: 195 loss: 0.6931480169296265\n",
      "epoch: 12 step: 196 loss: 0.6931480169296265\n",
      "epoch: 12 step: 197 loss: 0.6931480169296265\n",
      "epoch: 12 step: 198 loss: 0.6931480169296265\n",
      "epoch: 12 step: 199 loss: 0.6931480169296265\n",
      "epoch: 12 step: 200 loss: 0.6931480169296265\n",
      "epoch: 12 step: 201 loss: 0.6931480169296265\n",
      "epoch: 12 step: 202 loss: 0.6931480169296265\n",
      "epoch: 12 step: 203 loss: 0.6931480169296265\n",
      "epoch: 12 step: 204 loss: 0.6931480169296265\n",
      "epoch: 12 step: 205 loss: 0.6931480169296265\n",
      "epoch: 12 step: 206 loss: 0.6931480169296265\n",
      "epoch: 12 step: 207 loss: 0.6931480169296265\n",
      "epoch: 12 step: 208 loss: 0.6931479573249817\n",
      "epoch: 12 step: 209 loss: 0.6931480169296265\n",
      "epoch: 12 step: 210 loss: 0.6931480169296265\n",
      "epoch: 12 step: 211 loss: 0.6931480169296265\n",
      "epoch: 12 step: 212 loss: 0.6931480169296265\n",
      "epoch: 12 step: 213 loss: 0.6931480169296265\n",
      "epoch: 12 step: 214 loss: 0.6931480169296265\n",
      "epoch: 12 step: 215 loss: 0.6931480169296265\n",
      "epoch: 12 step: 216 loss: 0.6931479573249817\n",
      "epoch: 12 step: 217 loss: 0.6931478977203369\n",
      "epoch: 12 step: 218 loss: 0.6931479573249817\n",
      "epoch: 12 step: 219 loss: 0.6931480169296265\n",
      "epoch: 12 step: 220 loss: 0.6931479573249817\n",
      "epoch: 12 step: 221 loss: 0.6931479573249817\n",
      "epoch: 12 step: 222 loss: 0.6931478977203369\n",
      "epoch: 12 step: 223 loss: 0.6931479573249817\n",
      "epoch: 12 step: 224 loss: 0.6931479573249817\n",
      "epoch: 12 step: 225 loss: 0.6931478977203369\n",
      "epoch: 12 step: 226 loss: 0.6931479573249817\n",
      "epoch: 12 step: 227 loss: 0.6931480169296265\n",
      "epoch: 12 step: 228 loss: 0.6931480169296265\n",
      "epoch: 12 step: 229 loss: 0.6931479573249817\n",
      "epoch: 12 step: 230 loss: 0.6931479573249817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 231 loss: 0.6931478977203369\n",
      "epoch: 12 step: 232 loss: 0.6931480169296265\n",
      "epoch: 12 step: 233 loss: 0.6931478977203369\n",
      "epoch: 12 step: 234 loss: 0.6931478977203369\n",
      "epoch: 12 step: 235 loss: 0.6931480169296265\n",
      "epoch: 12 step: 236 loss: 0.6931478977203369\n",
      "epoch: 12 step: 237 loss: 0.6931478977203369\n",
      "epoch: 12 step: 238 loss: 0.6931478977203369\n",
      "epoch: 12 step: 239 loss: 0.6931478977203369\n",
      "epoch: 12 step: 240 loss: 0.6931478977203369\n",
      "epoch: 12 step: 241 loss: 0.6931480169296265\n",
      "epoch: 12 step: 242 loss: 0.6931478977203369\n",
      "epoch: 12 step: 243 loss: 0.6931479573249817\n",
      "epoch: 12 step: 244 loss: 0.6931478977203369\n",
      "epoch: 12 step: 245 loss: 0.6931478977203369\n",
      "epoch: 12 step: 246 loss: 0.6931478977203369\n",
      "epoch: 12 step: 247 loss: 0.6931478977203369\n",
      "epoch: 12 step: 248 loss: 0.6931478977203369\n",
      "epoch: 12 step: 249 loss: 0.6931479573249817\n",
      "epoch: 12 step: 250 loss: 0.6931478977203369\n",
      "epoch: 12 step: 251 loss: 0.6931478977203369\n",
      "epoch: 12 step: 252 loss: 0.6931478977203369\n",
      "epoch: 12 step: 253 loss: 0.6931478977203369\n",
      "epoch: 12 step: 254 loss: 0.6931478977203369\n",
      "epoch: 12 step: 255 loss: 0.6931478977203369\n",
      "epoch: 12 step: 256 loss: 0.6931478977203369\n",
      "epoch: 12 step: 257 loss: 0.6931478977203369\n",
      "epoch: 12 step: 258 loss: 0.6931478977203369\n",
      "epoch: 12 step: 259 loss: 0.6931479573249817\n",
      "epoch: 12 step: 260 loss: 0.6931478977203369\n",
      "epoch: 12 step: 261 loss: 0.6931478977203369\n",
      "epoch: 12 step: 262 loss: 0.6931478977203369\n",
      "epoch: 12 step: 263 loss: 0.6931478977203369\n",
      "epoch: 12 step: 264 loss: 0.6931478977203369\n",
      "epoch: 12 step: 265 loss: 0.6931478977203369\n",
      "epoch: 12 step: 266 loss: 0.6931478977203369\n",
      "epoch: 12 step: 267 loss: 0.6931478977203369\n",
      "epoch: 12 step: 268 loss: 0.6931478977203369\n",
      "epoch: 12 step: 269 loss: 0.6931478977203369\n",
      "epoch: 12 step: 270 loss: 0.6931478977203369\n",
      "epoch: 12 step: 271 loss: 0.6931478977203369\n",
      "epoch: 12 step: 272 loss: 0.6931478977203369\n",
      "epoch: 12 step: 273 loss: 0.6931478977203369\n",
      "epoch: 12 step: 274 loss: 0.6931478977203369\n",
      "epoch: 12 step: 275 loss: 0.6931478977203369\n",
      "epoch: 12 step: 276 loss: 0.6931479573249817\n",
      "epoch: 12 step: 277 loss: 0.6931478977203369\n",
      "epoch: 12 step: 278 loss: 0.6931478977203369\n",
      "epoch: 12 step: 279 loss: 0.6931478977203369\n",
      "epoch: 12 step: 280 loss: 0.6931478977203369\n",
      "epoch: 12 step: 281 loss: 0.6931478977203369\n",
      "epoch: 12 step: 282 loss: 0.6931478977203369\n",
      "epoch: 12 step: 283 loss: 0.6931478977203369\n",
      "epoch: 12 step: 284 loss: 0.6931478977203369\n",
      "epoch: 12 step: 285 loss: 0.6931478977203369\n",
      "epoch: 12 step: 286 loss: 0.6931478977203369\n",
      "epoch: 12 step: 287 loss: 0.6931478977203369\n",
      "epoch: 12 step: 288 loss: 0.6931478977203369\n",
      "epoch: 12 step: 289 loss: 0.6931478977203369\n",
      "epoch: 12 step: 290 loss: 0.6931478977203369\n",
      "epoch: 12 step: 291 loss: 0.6931478977203369\n",
      "epoch: 12 step: 292 loss: 0.6931478977203369\n",
      "epoch: 12 step: 293 loss: 0.6931478977203369\n",
      "epoch: 12 step: 294 loss: 0.6931478977203369\n",
      "epoch: 12 step: 295 loss: 0.6931478977203369\n",
      "epoch: 12 step: 296 loss: 0.6931478977203369\n",
      "epoch: 12 step: 297 loss: 0.6931478977203369\n",
      "epoch: 12 step: 298 loss: 0.6931478977203369\n",
      "epoch: 12 step: 299 loss: 0.6931478977203369\n",
      "epoch: 12 step: 300 loss: 0.6931478977203369\n",
      "epoch: 12 step: 301 loss: 0.6931478977203369\n",
      "epoch: 12 step: 302 loss: 0.6931478977203369\n",
      "epoch: 12 step: 303 loss: 0.6931478977203369\n",
      "epoch: 12 step: 304 loss: 0.6931478977203369\n",
      "epoch: 12 step: 305 loss: 0.6931478977203369\n",
      "epoch: 12 step: 306 loss: 0.6931478977203369\n",
      "epoch: 12 step: 307 loss: 0.6931478977203369\n",
      "epoch: 12 step: 308 loss: 0.6931478977203369\n",
      "epoch: 12 step: 309 loss: 0.6931478977203369\n",
      "epoch: 12 step: 310 loss: 0.6931478977203369\n",
      "epoch: 12 step: 311 loss: 0.6931478977203369\n",
      "epoch: 12 step: 312 loss: 0.6931478977203369\n",
      "epoch: 12 step: 313 loss: 0.6931478977203369\n",
      "epoch: 12 step: 314 loss: 0.6931478977203369\n",
      "epoch: 12 step: 315 loss: 0.6931478977203369\n",
      "epoch: 12 step: 316 loss: 0.6931478977203369\n",
      "epoch: 12 step: 317 loss: 0.6931478977203369\n",
      "epoch: 12 step: 318 loss: 0.6931478977203369\n",
      "epoch: 12 step: 319 loss: 0.6931478977203369\n",
      "epoch: 12 step: 320 loss: 0.6931478977203369\n",
      "epoch: 12 step: 321 loss: 0.6931478977203369\n",
      "epoch: 12 step: 322 loss: 0.6931478977203369\n",
      "epoch: 12 step: 323 loss: 0.6931478977203369\n",
      "epoch: 12 step: 324 loss: 0.6931478977203369\n",
      "epoch: 12 step: 325 loss: 0.6931478977203369\n",
      "epoch: 12 step: 326 loss: 0.6931478977203369\n",
      "epoch: 12 step: 327 loss: 0.6931478977203369\n",
      "epoch: 12 step: 328 loss: 0.6931478977203369\n",
      "epoch: 12 step: 329 loss: 0.6931478977203369\n",
      "epoch: 12 step: 330 loss: 0.6931478977203369\n",
      "epoch: 12 step: 331 loss: 0.6931478977203369\n",
      "epoch: 12 step: 332 loss: 0.6931478977203369\n",
      "epoch: 12 step: 333 loss: 0.6931478977203369\n",
      "epoch: 12 step: 334 loss: 0.6931478977203369\n",
      "epoch: 12 step: 335 loss: 0.6931478977203369\n",
      "epoch: 12 step: 336 loss: 0.6931478977203369\n",
      "epoch: 12 step: 337 loss: 0.6931478977203369\n",
      "epoch: 12 step: 338 loss: 0.6931478977203369\n",
      "epoch: 12 step: 339 loss: 0.6931478977203369\n",
      "epoch: 12 step: 340 loss: 0.6931478977203369\n",
      "epoch: 12 step: 341 loss: 0.6931478977203369\n",
      "epoch: 12 step: 342 loss: 0.6931478977203369\n",
      "epoch: 12 step: 343 loss: 0.6931478977203369\n",
      "epoch: 12 step: 344 loss: 0.6931478977203369\n",
      "epoch: 12 step: 345 loss: 0.6931478977203369\n",
      "epoch: 12 step: 346 loss: 0.6931478977203369\n",
      "epoch: 12 step: 347 loss: 0.6931478977203369\n",
      "epoch: 12 step: 348 loss: 0.6931478977203369\n",
      "epoch: 12 step: 349 loss: 0.6931478977203369\n",
      "epoch: 12 step: 350 loss: 0.6931478977203369\n",
      "epoch: 12 step: 351 loss: 0.6931478977203369\n",
      "epoch: 12 step: 352 loss: 0.6931478977203369\n",
      "epoch: 12 step: 353 loss: 0.6931478977203369\n",
      "epoch: 12 step: 354 loss: 0.6931478977203369\n",
      "epoch: 12 step: 355 loss: 0.6931478977203369\n",
      "epoch: 12 step: 356 loss: 0.6931478977203369\n",
      "epoch: 12 step: 357 loss: 0.6931478977203369\n",
      "epoch: 12 step: 358 loss: 0.6931478977203369\n",
      "epoch: 12 step: 359 loss: 0.6931478977203369\n",
      "epoch: 12 step: 360 loss: 0.6931478977203369\n",
      "epoch: 12 step: 361 loss: 0.6931478977203369\n",
      "epoch: 12 step: 362 loss: 0.6931478977203369\n",
      "epoch: 12 step: 363 loss: 0.6931478977203369\n",
      "epoch: 12 step: 364 loss: 0.6931478977203369\n",
      "epoch: 12 step: 365 loss: 0.6931478977203369\n",
      "epoch: 12 step: 366 loss: 0.6931478977203369\n",
      "epoch: 12 step: 367 loss: 0.6931478977203369\n",
      "epoch: 12 step: 368 loss: 0.6931478977203369\n",
      "epoch: 12 step: 369 loss: 0.6931478977203369\n",
      "epoch: 12 step: 370 loss: 0.6931478977203369\n",
      "epoch: 12 step: 371 loss: 0.6931478977203369\n",
      "epoch: 12 step: 372 loss: 0.6931478977203369\n",
      "epoch: 12 step: 373 loss: 0.6931478977203369\n",
      "epoch: 12 step: 374 loss: 0.6931478977203369\n",
      "epoch: 12 step: 375 loss: 0.6931478977203369\n",
      "epoch: 12 step: 376 loss: 0.6931478977203369\n",
      "epoch: 12 step: 377 loss: 0.6931478977203369\n",
      "epoch: 12 step: 378 loss: 0.6931478977203369\n",
      "epoch: 12 step: 379 loss: 0.6931478977203369\n",
      "epoch: 12 step: 380 loss: 0.6931478977203369\n",
      "epoch: 12 step: 381 loss: 0.6931478977203369\n",
      "epoch: 12 step: 382 loss: 0.6931478977203369\n",
      "epoch: 12 step: 383 loss: 0.6931478977203369\n",
      "epoch: 12 step: 384 loss: 0.6931478977203369\n",
      "epoch: 12 step: 385 loss: 0.6931478977203369\n",
      "epoch: 12 step: 386 loss: 0.6931478977203369\n",
      "epoch: 12 step: 387 loss: 0.6931478977203369\n",
      "epoch: 12 step: 388 loss: 0.6931478977203369\n",
      "epoch: 12 step: 389 loss: 0.6931478977203369\n",
      "epoch: 12 step: 390 loss: 0.6931478977203369\n",
      "epoch: 12 step: 391 loss: 0.6931478977203369\n",
      "epoch: 12 step: 392 loss: 0.6931478977203369\n",
      "epoch: 12 step: 393 loss: 0.6931478977203369\n",
      "epoch: 12 step: 394 loss: 0.6931478977203369\n",
      "epoch: 12 step: 395 loss: 0.6931478977203369\n",
      "epoch: 12 step: 396 loss: 0.6931478977203369\n",
      "epoch: 12 step: 397 loss: 0.6931478977203369\n",
      "epoch: 12 step: 398 loss: 0.6931478977203369\n",
      "epoch: 12 step: 399 loss: 0.6931478977203369\n",
      "epoch: 12 step: 400 loss: 0.6931478977203369\n",
      "epoch: 12 step: 401 loss: 0.6931478977203369\n",
      "epoch: 12 step: 402 loss: 0.6931478977203369\n",
      "epoch: 12 step: 403 loss: 0.6931478977203369\n",
      "epoch: 12 step: 404 loss: 0.6931478977203369\n",
      "epoch: 12 step: 405 loss: 0.6931478977203369\n",
      "epoch: 12 step: 406 loss: 0.6931478977203369\n",
      "epoch: 12 step: 407 loss: 0.6931478977203369\n",
      "epoch: 12 step: 408 loss: 0.6931478977203369\n",
      "epoch: 12 step: 409 loss: 0.6931478977203369\n",
      "epoch: 12 step: 410 loss: 0.6931478977203369\n",
      "epoch: 12 step: 411 loss: 0.6931478977203369\n",
      "epoch: 12 step: 412 loss: 0.6931478977203369\n",
      "epoch: 12 step: 413 loss: 0.6931478977203369\n",
      "epoch: 12 step: 414 loss: 0.6931478977203369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 415 loss: 0.6931478977203369\n",
      "epoch: 12 step: 416 loss: 0.6931478977203369\n",
      "epoch: 12 step: 417 loss: 0.6931478977203369\n",
      "epoch: 12 step: 418 loss: 0.6931478977203369\n",
      "epoch: 12 step: 419 loss: 0.6931478977203369\n",
      "epoch: 12 step: 420 loss: 0.6931478977203369\n",
      "epoch: 12 step: 421 loss: 0.6931478977203369\n",
      "epoch: 12 step: 422 loss: 0.6931478977203369\n",
      "epoch: 12 step: 423 loss: 0.6931478977203369\n",
      "epoch: 12 step: 424 loss: 0.6931478977203369\n",
      "epoch: 12 step: 425 loss: 0.6931478977203369\n",
      "epoch: 12 step: 426 loss: 0.6931478977203369\n",
      "epoch: 12 step: 427 loss: 0.6931478977203369\n",
      "epoch: 12 step: 428 loss: 0.6931478977203369\n",
      "epoch: 12 step: 429 loss: 0.6931478977203369\n",
      "epoch: 12 step: 430 loss: 0.6931478977203369\n",
      "epoch: 12 step: 431 loss: 0.6931478977203369\n",
      "epoch: 12 step: 432 loss: 0.6931478977203369\n",
      "epoch: 12 step: 433 loss: 0.6931478977203369\n",
      "epoch: 12 step: 434 loss: 0.6931478977203369\n",
      "epoch: 12 step: 435 loss: 0.6931478977203369\n",
      "epoch: 12 step: 436 loss: 0.6931478977203369\n",
      "epoch: 12 step: 437 loss: 0.6931478977203369\n",
      "epoch: 12 step: 438 loss: 0.6931478977203369\n",
      "epoch: 12 step: 439 loss: 0.6931478977203369\n",
      "epoch: 12 step: 440 loss: 0.6931478977203369\n",
      "epoch: 12 step: 441 loss: 0.6931478977203369\n",
      "epoch: 12 step: 442 loss: 0.6931478977203369\n",
      "epoch: 12 step: 443 loss: 0.6931478977203369\n",
      "epoch: 12 step: 444 loss: 0.6931478977203369\n",
      "epoch: 12 step: 445 loss: 0.6931478977203369\n",
      "epoch: 12 step: 446 loss: 0.6931478977203369\n",
      "epoch: 12 step: 447 loss: 0.6931478977203369\n",
      "epoch: 12 step: 448 loss: 0.6931478977203369\n",
      "epoch: 12 step: 449 loss: 0.6931478977203369\n",
      "epoch: 12 step: 450 loss: 0.6931478977203369\n",
      "epoch: 12 step: 451 loss: 0.6931478977203369\n",
      "epoch: 12 step: 452 loss: 0.6931478977203369\n",
      "epoch: 12 step: 453 loss: 0.6931478977203369\n",
      "epoch: 12 step: 454 loss: 0.6931478977203369\n",
      "epoch: 12 step: 455 loss: 0.6931478977203369\n",
      "epoch: 12 step: 456 loss: 0.6931478977203369\n",
      "epoch: 12 step: 457 loss: 0.6931478977203369\n",
      "epoch: 12 step: 458 loss: 0.6931478977203369\n",
      "epoch: 12 step: 459 loss: 0.6931478977203369\n",
      "epoch: 12 step: 460 loss: 0.6931478977203369\n",
      "epoch: 12 step: 461 loss: 0.6931478977203369\n",
      "epoch: 12 step: 462 loss: 0.6931478977203369\n",
      "epoch: 12 step: 463 loss: 0.6931478977203369\n",
      "epoch: 12 step: 464 loss: 0.6931478381156921\n",
      "epoch: 12 step: 465 loss: 0.6931478977203369\n",
      "epoch: 12 step: 466 loss: 0.6931478977203369\n",
      "epoch: 12 step: 467 loss: 0.6931478977203369\n",
      "epoch: 12 step: 468 loss: 0.6931478977203369\n",
      "epoch: 12 step: 469 loss: 0.6931478977203369\n",
      "epoch: 12 step: 470 loss: 0.6931478977203369\n",
      "epoch: 12 step: 471 loss: 0.6931478977203369\n",
      "epoch: 12 step: 472 loss: 0.6931478977203369\n",
      "epoch: 12 step: 473 loss: 0.6931478977203369\n",
      "epoch: 12 step: 474 loss: 0.6931478977203369\n",
      "epoch: 12 step: 475 loss: 0.6931478977203369\n",
      "epoch: 12 step: 476 loss: 0.6931478381156921\n",
      "epoch: 12 step: 477 loss: 0.6931477785110474\n",
      "epoch: 12 step: 478 loss: 0.6931478977203369\n",
      "epoch: 12 step: 479 loss: 0.6931478977203369\n",
      "epoch: 12 step: 480 loss: 0.6931477785110474\n",
      "epoch: 12 step: 481 loss: 0.6931478977203369\n",
      "epoch: 12 step: 482 loss: 0.6931478977203369\n",
      "epoch: 12 step: 483 loss: 0.6931478381156921\n",
      "epoch: 12 step: 484 loss: 0.6931477785110474\n",
      "epoch: 12 step: 485 loss: 0.6931477785110474\n",
      "epoch: 12 step: 486 loss: 0.6931477785110474\n",
      "epoch: 12 step: 487 loss: 0.6931478977203369\n",
      "epoch: 12 step: 488 loss: 0.6931477785110474\n",
      "epoch: 12 step: 489 loss: 0.6931477785110474\n",
      "epoch: 12 step: 490 loss: 0.6931478381156921\n",
      "epoch: 12 step: 491 loss: 0.6931477785110474\n",
      "epoch: 12 step: 492 loss: 0.6931478381156921\n",
      "epoch: 12 step: 493 loss: 0.6931478977203369\n",
      "epoch: 12 step: 494 loss: 0.6931478977203369\n",
      "epoch: 12 step: 495 loss: 0.6931477785110474\n",
      "epoch: 12 step: 496 loss: 0.6931477785110474\n",
      "epoch: 12 step: 497 loss: 0.6931478977203369\n",
      "epoch: 12 step: 498 loss: 0.6931477785110474\n",
      "epoch: 12 step: 499 loss: 0.6931477785110474\n",
      "epoch: 12 step: 500 loss: 0.6931478381156921\n",
      "epoch: 12 step: 501 loss: 0.6931478381156921\n",
      "epoch: 12 step: 502 loss: 0.6931478381156921\n",
      "epoch: 12 step: 503 loss: 0.6931478381156921\n",
      "epoch: 12 step: 504 loss: 0.6931478381156921\n",
      "epoch: 12 step: 505 loss: 0.6931478977203369\n",
      "epoch: 12 step: 506 loss: 0.6931477785110474\n",
      "epoch: 12 step: 507 loss: 0.6931477785110474\n",
      "epoch: 12 step: 508 loss: 0.6931477785110474\n",
      "epoch: 12 step: 509 loss: 0.6931477785110474\n",
      "epoch: 12 step: 510 loss: 0.6931477785110474\n",
      "epoch: 12 step: 511 loss: 0.6931477785110474\n",
      "epoch: 12 step: 512 loss: 0.6931477785110474\n",
      "epoch: 12 step: 513 loss: 0.6931477785110474\n",
      "epoch: 12 step: 514 loss: 0.6931477785110474\n",
      "epoch: 12 step: 515 loss: 0.6931477785110474\n",
      "epoch: 12 step: 516 loss: 0.6931477785110474\n",
      "epoch: 12 step: 517 loss: 0.6931477785110474\n",
      "epoch: 12 step: 518 loss: 0.6931477785110474\n",
      "epoch: 12 step: 519 loss: 0.6931477785110474\n",
      "epoch: 12 step: 520 loss: 0.6931477785110474\n",
      "epoch: 12 step: 521 loss: 0.6931477785110474\n",
      "epoch: 12 step: 522 loss: 0.6931477785110474\n",
      "epoch: 12 step: 523 loss: 0.6931477785110474\n",
      "epoch: 12 step: 524 loss: 0.6931477785110474\n",
      "epoch: 12 step: 525 loss: 0.6931477785110474\n",
      "epoch: 12 step: 526 loss: 0.6931477785110474\n",
      "epoch: 12 step: 527 loss: 0.6931477785110474\n",
      "epoch: 12 step: 528 loss: 0.6931477785110474\n",
      "epoch: 12 step: 529 loss: 0.6931477785110474\n",
      "epoch: 12 step: 530 loss: 0.6931477785110474\n",
      "epoch: 12 step: 531 loss: 0.6931477785110474\n",
      "epoch: 12 step: 532 loss: 0.6931477785110474\n",
      "epoch: 12 step: 533 loss: 0.6931477785110474\n",
      "epoch: 12 step: 534 loss: 0.6931477785110474\n",
      "epoch: 12 step: 535 loss: 0.6931477785110474\n",
      "epoch: 12 step: 536 loss: 0.6931477785110474\n",
      "epoch: 12 step: 537 loss: 0.6931477785110474\n",
      "epoch: 12 step: 538 loss: 0.6931477785110474\n",
      "epoch: 12 step: 539 loss: 0.6931477785110474\n",
      "epoch: 12 step: 540 loss: 0.6931477785110474\n",
      "epoch: 12 step: 541 loss: 0.6931477785110474\n",
      "epoch: 12 step: 542 loss: 0.6931477785110474\n",
      "epoch: 12 step: 543 loss: 0.6931477785110474\n",
      "epoch: 12 step: 544 loss: 0.6931477785110474\n",
      "epoch: 12 step: 545 loss: 0.6931477785110474\n",
      "epoch: 12 step: 546 loss: 0.6931477785110474\n",
      "epoch: 12 step: 547 loss: 0.6931477785110474\n",
      "epoch: 12 step: 548 loss: 0.6931477785110474\n",
      "epoch: 12 step: 549 loss: 0.6931477785110474\n",
      "epoch: 12 step: 550 loss: 0.6931477785110474\n",
      "epoch: 12 step: 551 loss: 0.6931477785110474\n",
      "epoch: 12 step: 552 loss: 0.6931477785110474\n",
      "epoch: 12 step: 553 loss: 0.6931477785110474\n",
      "epoch: 12 step: 554 loss: 0.6931477785110474\n",
      "epoch: 12 step: 555 loss: 0.6931477785110474\n",
      "epoch: 12 step: 556 loss: 0.6931477785110474\n",
      "epoch: 12 step: 557 loss: 0.6931477785110474\n",
      "epoch: 12 step: 558 loss: 0.6931477785110474\n",
      "epoch: 12 step: 559 loss: 0.6931477785110474\n",
      "epoch: 12 step: 560 loss: 0.6931477785110474\n",
      "epoch: 12 step: 561 loss: 0.6931477785110474\n",
      "epoch: 12 step: 562 loss: 0.6931477785110474\n",
      "epoch: 12 step: 563 loss: 0.6931477785110474\n",
      "epoch: 12 step: 564 loss: 0.6931477785110474\n",
      "epoch: 12 step: 565 loss: 0.6931477785110474\n",
      "epoch: 12 step: 566 loss: 0.6931477785110474\n",
      "epoch: 12 step: 567 loss: 0.6931477785110474\n",
      "epoch: 12 step: 568 loss: 0.6931477785110474\n",
      "epoch: 12 step: 569 loss: 0.6931477785110474\n",
      "epoch: 12 step: 570 loss: 0.6931477785110474\n",
      "epoch: 12 step: 571 loss: 0.6931477785110474\n",
      "epoch: 12 step: 572 loss: 0.6931477785110474\n",
      "epoch: 12 step: 573 loss: 0.6931477785110474\n",
      "epoch: 12 step: 574 loss: 0.6931477785110474\n",
      "epoch: 12 step: 575 loss: 0.6931477785110474\n",
      "epoch: 12 step: 576 loss: 0.6931477785110474\n",
      "epoch: 12 step: 577 loss: 0.6931477785110474\n",
      "epoch: 12 step: 578 loss: 0.6931477785110474\n",
      "epoch: 12 step: 579 loss: 0.6931477785110474\n",
      "epoch: 12 step: 580 loss: 0.6931477785110474\n",
      "epoch: 12 step: 581 loss: 0.6931477785110474\n",
      "epoch: 12 step: 582 loss: 0.6931477785110474\n",
      "epoch: 12 step: 583 loss: 0.6931477785110474\n",
      "epoch: 12 step: 584 loss: 0.6931477785110474\n",
      "epoch: 12 step: 585 loss: 0.6931477785110474\n",
      "epoch: 12 step: 586 loss: 0.6931477785110474\n",
      "epoch: 12 step: 587 loss: 0.6931477785110474\n",
      "epoch: 12 step: 588 loss: 0.6931477785110474\n",
      "epoch: 12 step: 589 loss: 0.6931477785110474\n",
      "epoch: 12 step: 590 loss: 0.6931477785110474\n",
      "epoch: 12 step: 591 loss: 0.6931477785110474\n",
      "epoch: 12 step: 592 loss: 0.6931477785110474\n",
      "epoch: 12 step: 593 loss: 0.6931477785110474\n",
      "epoch: 12 step: 594 loss: 0.6931477785110474\n",
      "epoch: 12 step: 595 loss: 0.6931477785110474\n",
      "epoch: 12 step: 596 loss: 0.6931477785110474\n",
      "epoch: 12 step: 597 loss: 0.6931477785110474\n",
      "epoch: 12 step: 598 loss: 0.6931477785110474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 599 loss: 0.6931477785110474\n",
      "epoch: 12 step: 600 loss: 0.6931477785110474\n",
      "epoch: 12 step: 601 loss: 0.6931477785110474\n",
      "epoch: 12 step: 602 loss: 0.6931477785110474\n",
      "epoch: 12 step: 603 loss: 0.6931477785110474\n",
      "epoch: 12 step: 604 loss: 0.6931477785110474\n",
      "epoch: 12 step: 605 loss: 0.6931477785110474\n",
      "epoch: 12 step: 606 loss: 0.6931477785110474\n",
      "epoch: 12 step: 607 loss: 0.6931477785110474\n",
      "epoch: 12 step: 608 loss: 0.6931477785110474\n",
      "epoch: 12 step: 609 loss: 0.6931477785110474\n",
      "epoch: 12 step: 610 loss: 0.6931477785110474\n",
      "epoch: 12 step: 611 loss: 0.6931477785110474\n",
      "epoch: 12 step: 612 loss: 0.6931477785110474\n",
      "epoch: 12 step: 613 loss: 0.6931477785110474\n",
      "epoch: 12 step: 614 loss: 0.6931477785110474\n",
      "epoch: 12 step: 615 loss: 0.6931477785110474\n",
      "epoch: 12 step: 616 loss: 0.6931477785110474\n",
      "epoch: 12 step: 617 loss: 0.6931477785110474\n",
      "epoch: 12 step: 618 loss: 0.6931477785110474\n",
      "epoch: 12 step: 619 loss: 0.6931477785110474\n",
      "epoch: 12 step: 620 loss: 0.6931477785110474\n",
      "epoch: 12 step: 621 loss: 0.6931477785110474\n",
      "epoch: 12 step: 622 loss: 0.6931477785110474\n",
      "epoch: 12 step: 623 loss: 0.6931477785110474\n",
      "epoch: 12 step: 624 loss: 0.6931477785110474\n",
      "epoch: 12 step: 625 loss: 0.6931477785110474\n",
      "epoch: 12 step: 626 loss: 0.6931477785110474\n",
      "epoch: 12 step: 627 loss: 0.6931477785110474\n",
      "epoch: 12 step: 628 loss: 0.6931477785110474\n",
      "epoch: 12 step: 629 loss: 0.6931477785110474\n",
      "epoch: 12 step: 630 loss: 0.6931477785110474\n",
      "epoch: 12 step: 631 loss: 0.6931477785110474\n",
      "epoch: 12 step: 632 loss: 0.6931477785110474\n",
      "epoch: 12 step: 633 loss: 0.6931477785110474\n",
      "epoch: 12 step: 634 loss: 0.6931477785110474\n",
      "epoch: 12 step: 635 loss: 0.6931477785110474\n",
      "epoch: 12 step: 636 loss: 0.6931477785110474\n",
      "epoch: 12 step: 637 loss: 0.6931477785110474\n",
      "epoch: 12 step: 638 loss: 0.6931477785110474\n",
      "epoch: 12 step: 639 loss: 0.6931477785110474\n",
      "epoch: 12 step: 640 loss: 0.6931477785110474\n",
      "epoch: 12 step: 641 loss: 0.6931477785110474\n",
      "epoch: 12 step: 642 loss: 0.6931477785110474\n",
      "epoch: 12 step: 643 loss: 0.6931477785110474\n",
      "epoch: 12 step: 644 loss: 0.6931477785110474\n",
      "epoch: 12 step: 645 loss: 0.6931477785110474\n",
      "epoch: 12 step: 646 loss: 0.6931477785110474\n",
      "epoch: 12 step: 647 loss: 0.6931477785110474\n",
      "epoch: 12 step: 648 loss: 0.6931477785110474\n",
      "epoch: 12 step: 649 loss: 0.6931477785110474\n",
      "epoch: 12 step: 650 loss: 0.6931477785110474\n",
      "epoch: 12 step: 651 loss: 0.6931477785110474\n",
      "epoch: 12 step: 652 loss: 0.6931477785110474\n",
      "epoch: 12 step: 653 loss: 0.6931477785110474\n",
      "epoch: 12 step: 654 loss: 0.6931477785110474\n",
      "epoch: 12 step: 655 loss: 0.6931477785110474\n",
      "epoch: 12 step: 656 loss: 0.6931477785110474\n",
      "epoch: 12 step: 657 loss: 0.6931477785110474\n",
      "epoch: 12 step: 658 loss: 0.6931477785110474\n",
      "epoch: 12 step: 659 loss: 0.6931477785110474\n",
      "epoch: 12 step: 660 loss: 0.6931477785110474\n",
      "epoch: 12 step: 661 loss: 0.6931477785110474\n",
      "epoch: 12 step: 662 loss: 0.6931477785110474\n",
      "epoch: 12 step: 663 loss: 0.6931477785110474\n",
      "epoch: 12 step: 664 loss: 0.6931477785110474\n",
      "epoch: 12 step: 665 loss: 0.6931477785110474\n",
      "epoch: 12 step: 666 loss: 0.6931477785110474\n",
      "epoch: 12 step: 667 loss: 0.6931477785110474\n",
      "epoch: 12 step: 668 loss: 0.6931477785110474\n",
      "epoch: 12 step: 669 loss: 0.6931477785110474\n",
      "epoch: 12 step: 670 loss: 0.6931477785110474\n",
      "epoch: 12 step: 671 loss: 0.6931477785110474\n",
      "epoch: 12 step: 672 loss: 0.6931477785110474\n",
      "epoch: 12 step: 673 loss: 0.6931477785110474\n",
      "epoch: 12 step: 674 loss: 0.6931477785110474\n",
      "epoch: 12 step: 675 loss: 0.6931477785110474\n",
      "epoch: 12 step: 676 loss: 0.6931477785110474\n",
      "epoch: 12 step: 677 loss: 0.6931477785110474\n",
      "epoch: 12 step: 678 loss: 0.6931477785110474\n",
      "epoch: 12 step: 679 loss: 0.6931477785110474\n",
      "epoch: 12 step: 680 loss: 0.6931477785110474\n",
      "epoch: 12 step: 681 loss: 0.6931477785110474\n",
      "epoch: 12 step: 682 loss: 0.6931477785110474\n",
      "epoch: 12 step: 683 loss: 0.6931477785110474\n",
      "epoch: 12 step: 684 loss: 0.6931477785110474\n",
      "epoch: 12 step: 685 loss: 0.6931477785110474\n",
      "epoch: 12 step: 686 loss: 0.6931477785110474\n",
      "epoch: 12 step: 687 loss: 0.6931477785110474\n",
      "epoch: 12 step: 688 loss: 0.6931477785110474\n",
      "epoch: 12 step: 689 loss: 0.6931477785110474\n",
      "epoch: 12 step: 690 loss: 0.6931477785110474\n",
      "epoch: 12 step: 691 loss: 0.6931477785110474\n",
      "epoch: 12 step: 692 loss: 0.6931477785110474\n",
      "epoch: 12 step: 693 loss: 0.6931477785110474\n",
      "epoch: 12 step: 694 loss: 0.6931477785110474\n",
      "epoch: 12 step: 695 loss: 0.6931477785110474\n",
      "epoch: 12 step: 696 loss: 0.6931477785110474\n",
      "epoch: 12 step: 697 loss: 0.6931477785110474\n",
      "epoch: 12 step: 698 loss: 0.6931477785110474\n",
      "epoch: 12 step: 699 loss: 0.6931477785110474\n",
      "epoch: 12 step: 700 loss: 0.6931477785110474\n",
      "epoch: 12 step: 701 loss: 0.6931477785110474\n",
      "epoch: 12 step: 702 loss: 0.6931477785110474\n",
      "epoch: 12 step: 703 loss: 0.6931477785110474\n",
      "epoch: 12 step: 704 loss: 0.6931477785110474\n",
      "epoch: 12 step: 705 loss: 0.6931477785110474\n",
      "epoch: 12 step: 706 loss: 0.6931477785110474\n",
      "epoch: 12 step: 707 loss: 0.6931477785110474\n",
      "epoch: 12 step: 708 loss: 0.6931477785110474\n",
      "epoch: 12 step: 709 loss: 0.6931477785110474\n",
      "epoch: 12 step: 710 loss: 0.6931477785110474\n",
      "epoch: 12 step: 711 loss: 0.6931477785110474\n",
      "epoch: 12 step: 712 loss: 0.6931477785110474\n",
      "epoch: 12 step: 713 loss: 0.6931477785110474\n",
      "epoch: 12 step: 714 loss: 0.6931477785110474\n",
      "epoch: 12 step: 715 loss: 0.6931477785110474\n",
      "epoch: 12 step: 716 loss: 0.6931477785110474\n",
      "epoch: 12 step: 717 loss: 0.6931477785110474\n",
      "epoch: 12 step: 718 loss: 0.6931477785110474\n",
      "epoch: 12 step: 719 loss: 0.6931477785110474\n",
      "epoch: 12 step: 720 loss: 0.6931477785110474\n",
      "epoch: 12 step: 721 loss: 0.6931477785110474\n",
      "epoch: 12 step: 722 loss: 0.6931477785110474\n",
      "epoch: 12 step: 723 loss: 0.6931477785110474\n",
      "epoch: 12 step: 724 loss: 0.6931477785110474\n",
      "epoch: 12 step: 725 loss: 0.6931477785110474\n",
      "epoch: 12 step: 726 loss: 0.6931477785110474\n",
      "epoch: 12 step: 727 loss: 0.6931477785110474\n",
      "epoch: 12 step: 728 loss: 0.6931477785110474\n",
      "epoch: 12 step: 729 loss: 0.6931477785110474\n",
      "epoch: 12 step: 730 loss: 0.6931477785110474\n",
      "epoch: 12 step: 731 loss: 0.6931477785110474\n",
      "epoch: 12 step: 732 loss: 0.6931477785110474\n",
      "epoch: 12 step: 733 loss: 0.6931477785110474\n",
      "epoch: 12 step: 734 loss: 0.6931477785110474\n",
      "epoch: 12 step: 735 loss: 0.6931477785110474\n",
      "epoch: 12 step: 736 loss: 0.6931477785110474\n",
      "epoch: 12 step: 737 loss: 0.6931477785110474\n",
      "epoch: 12 step: 738 loss: 0.6931477785110474\n",
      "epoch: 12 step: 739 loss: 0.6931477785110474\n",
      "epoch: 12 step: 740 loss: 0.6931477785110474\n",
      "epoch: 12 step: 741 loss: 0.6931477785110474\n",
      "epoch: 12 step: 742 loss: 0.6931477785110474\n",
      "epoch: 12 step: 743 loss: 0.6931477785110474\n",
      "epoch: 12 step: 744 loss: 0.6931477785110474\n",
      "epoch: 12 step: 745 loss: 0.6931477785110474\n",
      "epoch: 12 step: 746 loss: 0.6931477785110474\n",
      "epoch: 12 step: 747 loss: 0.6931477785110474\n",
      "epoch: 12 step: 748 loss: 0.6931477785110474\n",
      "epoch: 12 step: 749 loss: 0.6931477785110474\n",
      "epoch: 12 step: 750 loss: 0.6931477785110474\n",
      "epoch: 12 step: 751 loss: 0.6931477785110474\n",
      "epoch: 12 step: 752 loss: 0.6931477785110474\n",
      "epoch: 12 step: 753 loss: 0.6931477785110474\n",
      "epoch: 12 step: 754 loss: 0.6931477785110474\n",
      "epoch: 12 step: 755 loss: 0.6931477785110474\n",
      "epoch: 12 step: 756 loss: 0.6931477785110474\n",
      "epoch: 12 step: 757 loss: 0.6931477785110474\n",
      "epoch: 12 step: 758 loss: 0.6931477785110474\n",
      "epoch: 12 step: 759 loss: 0.6931477785110474\n",
      "epoch: 12 step: 760 loss: 0.6931477785110474\n",
      "epoch: 12 step: 761 loss: 0.6931477785110474\n",
      "epoch: 12 step: 762 loss: 0.6931477785110474\n",
      "epoch: 12 step: 763 loss: 0.6931477785110474\n",
      "epoch: 12 step: 764 loss: 0.6931477785110474\n",
      "epoch: 12 step: 765 loss: 0.6931477785110474\n",
      "epoch: 12 step: 766 loss: 0.6931477785110474\n",
      "epoch: 12 step: 767 loss: 0.6931477785110474\n",
      "epoch: 12 step: 768 loss: 0.6931477785110474\n",
      "epoch: 12 step: 769 loss: 0.6931477785110474\n",
      "epoch: 12 step: 770 loss: 0.6931477785110474\n",
      "epoch: 12 step: 771 loss: 0.6931477785110474\n",
      "epoch: 12 step: 772 loss: 0.6931477785110474\n",
      "epoch: 12 step: 773 loss: 0.6931477785110474\n",
      "epoch: 12 step: 774 loss: 0.6931477785110474\n",
      "epoch: 12 step: 775 loss: 0.6931477785110474\n",
      "epoch: 12 step: 776 loss: 0.6931477785110474\n",
      "epoch: 12 step: 777 loss: 0.6931477785110474\n",
      "epoch: 12 step: 778 loss: 0.6931477785110474\n",
      "epoch: 12 step: 779 loss: 0.6931477785110474\n",
      "epoch: 12 step: 780 loss: 0.6931477785110474\n",
      "epoch: 12 step: 781 loss: 0.6931478381156921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 1 loss: 0.6931477785110474\n",
      "epoch: 13 step: 2 loss: 0.6931477785110474\n",
      "epoch: 13 step: 3 loss: 0.6931477785110474\n",
      "epoch: 13 step: 4 loss: 0.6931477785110474\n",
      "epoch: 13 step: 5 loss: 0.6931477785110474\n",
      "epoch: 13 step: 6 loss: 0.6931477785110474\n",
      "epoch: 13 step: 7 loss: 0.6931477785110474\n",
      "epoch: 13 step: 8 loss: 0.6931477785110474\n",
      "epoch: 13 step: 9 loss: 0.6931477785110474\n",
      "epoch: 13 step: 10 loss: 0.6931477785110474\n",
      "epoch: 13 step: 11 loss: 0.6931477785110474\n",
      "epoch: 13 step: 12 loss: 0.6931477785110474\n",
      "epoch: 13 step: 13 loss: 0.6931477785110474\n",
      "epoch: 13 step: 14 loss: 0.6931477785110474\n",
      "epoch: 13 step: 15 loss: 0.6931477785110474\n",
      "epoch: 13 step: 16 loss: 0.6931477785110474\n",
      "epoch: 13 step: 17 loss: 0.6931477785110474\n",
      "epoch: 13 step: 18 loss: 0.6931477785110474\n",
      "epoch: 13 step: 19 loss: 0.6931477785110474\n",
      "epoch: 13 step: 20 loss: 0.6931477785110474\n",
      "epoch: 13 step: 21 loss: 0.6931477785110474\n",
      "epoch: 13 step: 22 loss: 0.6931477785110474\n",
      "epoch: 13 step: 23 loss: 0.6931477785110474\n",
      "epoch: 13 step: 24 loss: 0.6931477785110474\n",
      "epoch: 13 step: 25 loss: 0.6931477785110474\n",
      "epoch: 13 step: 26 loss: 0.6931477785110474\n",
      "epoch: 13 step: 27 loss: 0.6931477785110474\n",
      "epoch: 13 step: 28 loss: 0.6931477785110474\n",
      "epoch: 13 step: 29 loss: 0.6931477785110474\n",
      "epoch: 13 step: 30 loss: 0.6931477785110474\n",
      "epoch: 13 step: 31 loss: 0.6931477785110474\n",
      "epoch: 13 step: 32 loss: 0.6931477785110474\n",
      "epoch: 13 step: 33 loss: 0.6931477785110474\n",
      "epoch: 13 step: 34 loss: 0.6931477785110474\n",
      "epoch: 13 step: 35 loss: 0.6931477785110474\n",
      "epoch: 13 step: 36 loss: 0.6931477785110474\n",
      "epoch: 13 step: 37 loss: 0.6931477785110474\n",
      "epoch: 13 step: 38 loss: 0.6931477785110474\n",
      "epoch: 13 step: 39 loss: 0.6931477785110474\n",
      "epoch: 13 step: 40 loss: 0.6931477785110474\n",
      "epoch: 13 step: 41 loss: 0.6931477785110474\n",
      "epoch: 13 step: 42 loss: 0.6931477785110474\n",
      "epoch: 13 step: 43 loss: 0.6931477785110474\n",
      "epoch: 13 step: 44 loss: 0.6931477785110474\n",
      "epoch: 13 step: 45 loss: 0.6931477785110474\n",
      "epoch: 13 step: 46 loss: 0.6931477785110474\n",
      "epoch: 13 step: 47 loss: 0.6931477785110474\n",
      "epoch: 13 step: 48 loss: 0.6931477785110474\n",
      "epoch: 13 step: 49 loss: 0.6931477785110474\n",
      "epoch: 13 step: 50 loss: 0.6931477785110474\n",
      "epoch: 13 step: 51 loss: 0.6931477785110474\n",
      "epoch: 13 step: 52 loss: 0.6931477785110474\n",
      "epoch: 13 step: 53 loss: 0.6931477785110474\n",
      "epoch: 13 step: 54 loss: 0.6931477785110474\n",
      "epoch: 13 step: 55 loss: 0.6931477785110474\n",
      "epoch: 13 step: 56 loss: 0.6931477785110474\n",
      "epoch: 13 step: 57 loss: 0.6931477785110474\n",
      "epoch: 13 step: 58 loss: 0.6931477785110474\n",
      "epoch: 13 step: 59 loss: 0.6931477785110474\n",
      "epoch: 13 step: 60 loss: 0.6931477785110474\n",
      "epoch: 13 step: 61 loss: 0.6931477785110474\n",
      "epoch: 13 step: 62 loss: 0.6931477785110474\n",
      "epoch: 13 step: 63 loss: 0.6931477785110474\n",
      "epoch: 13 step: 64 loss: 0.6931477785110474\n",
      "epoch: 13 step: 65 loss: 0.6931477785110474\n",
      "epoch: 13 step: 66 loss: 0.6931477785110474\n",
      "epoch: 13 step: 67 loss: 0.6931477785110474\n",
      "epoch: 13 step: 68 loss: 0.6931477785110474\n",
      "epoch: 13 step: 69 loss: 0.6931477785110474\n",
      "epoch: 13 step: 70 loss: 0.6931477785110474\n",
      "epoch: 13 step: 71 loss: 0.6931477785110474\n",
      "epoch: 13 step: 72 loss: 0.6931477785110474\n",
      "epoch: 13 step: 73 loss: 0.6931477785110474\n",
      "epoch: 13 step: 74 loss: 0.6931477785110474\n",
      "epoch: 13 step: 75 loss: 0.6931477785110474\n",
      "epoch: 13 step: 76 loss: 0.6931477785110474\n",
      "epoch: 13 step: 77 loss: 0.6931477785110474\n",
      "epoch: 13 step: 78 loss: 0.6931477785110474\n",
      "epoch: 13 step: 79 loss: 0.6931477785110474\n",
      "epoch: 13 step: 80 loss: 0.6931477785110474\n",
      "epoch: 13 step: 81 loss: 0.6931477785110474\n",
      "epoch: 13 step: 82 loss: 0.6931477785110474\n",
      "epoch: 13 step: 83 loss: 0.6931477785110474\n",
      "epoch: 13 step: 84 loss: 0.6931477785110474\n",
      "epoch: 13 step: 85 loss: 0.6931477189064026\n",
      "epoch: 13 step: 86 loss: 0.6931477785110474\n",
      "epoch: 13 step: 87 loss: 0.6931477785110474\n",
      "epoch: 13 step: 88 loss: 0.6931476593017578\n",
      "epoch: 13 step: 89 loss: 0.6931477785110474\n",
      "epoch: 13 step: 90 loss: 0.6931477189064026\n",
      "epoch: 13 step: 91 loss: 0.6931476593017578\n",
      "epoch: 13 step: 92 loss: 0.6931477785110474\n",
      "epoch: 13 step: 93 loss: 0.6931477785110474\n",
      "epoch: 13 step: 94 loss: 0.6931477189064026\n",
      "epoch: 13 step: 95 loss: 0.6931477785110474\n",
      "epoch: 13 step: 96 loss: 0.6931477785110474\n",
      "epoch: 13 step: 97 loss: 0.6931477785110474\n",
      "epoch: 13 step: 98 loss: 0.6931477189064026\n",
      "epoch: 13 step: 99 loss: 0.6931476593017578\n",
      "epoch: 13 step: 100 loss: 0.6931476593017578\n",
      "epoch: 13 step: 101 loss: 0.6931477785110474\n",
      "epoch: 13 step: 102 loss: 0.6931477785110474\n",
      "epoch: 13 step: 103 loss: 0.6931476593017578\n",
      "epoch: 13 step: 104 loss: 0.6931477785110474\n",
      "epoch: 13 step: 105 loss: 0.6931477189064026\n",
      "epoch: 13 step: 106 loss: 0.6931476593017578\n",
      "epoch: 13 step: 107 loss: 0.6931477785110474\n",
      "epoch: 13 step: 108 loss: 0.6931476593017578\n",
      "epoch: 13 step: 109 loss: 0.6931477189064026\n",
      "epoch: 13 step: 110 loss: 0.6931477189064026\n",
      "epoch: 13 step: 111 loss: 0.6931477189064026\n",
      "epoch: 13 step: 112 loss: 0.6931476593017578\n",
      "epoch: 13 step: 113 loss: 0.6931476593017578\n",
      "epoch: 13 step: 114 loss: 0.6931476593017578\n",
      "epoch: 13 step: 115 loss: 0.6931476593017578\n",
      "epoch: 13 step: 116 loss: 0.6931476593017578\n",
      "epoch: 13 step: 117 loss: 0.6931476593017578\n",
      "epoch: 13 step: 118 loss: 0.6931476593017578\n",
      "epoch: 13 step: 119 loss: 0.6931477189064026\n",
      "epoch: 13 step: 120 loss: 0.6931476593017578\n",
      "epoch: 13 step: 121 loss: 0.6931476593017578\n",
      "epoch: 13 step: 122 loss: 0.6931476593017578\n",
      "epoch: 13 step: 123 loss: 0.6931476593017578\n",
      "epoch: 13 step: 124 loss: 0.6931476593017578\n",
      "epoch: 13 step: 125 loss: 0.6931476593017578\n",
      "epoch: 13 step: 126 loss: 0.6931476593017578\n",
      "epoch: 13 step: 127 loss: 0.6931476593017578\n",
      "epoch: 13 step: 128 loss: 0.6931476593017578\n",
      "epoch: 13 step: 129 loss: 0.6931476593017578\n",
      "epoch: 13 step: 130 loss: 0.6931476593017578\n",
      "epoch: 13 step: 131 loss: 0.6931476593017578\n",
      "epoch: 13 step: 132 loss: 0.6931476593017578\n",
      "epoch: 13 step: 133 loss: 0.6931476593017578\n",
      "epoch: 13 step: 134 loss: 0.6931476593017578\n",
      "epoch: 13 step: 135 loss: 0.6931476593017578\n",
      "epoch: 13 step: 136 loss: 0.6931476593017578\n",
      "epoch: 13 step: 137 loss: 0.6931476593017578\n",
      "epoch: 13 step: 138 loss: 0.6931476593017578\n",
      "epoch: 13 step: 139 loss: 0.6931477189064026\n",
      "epoch: 13 step: 140 loss: 0.6931476593017578\n",
      "epoch: 13 step: 141 loss: 0.6931476593017578\n",
      "epoch: 13 step: 142 loss: 0.6931476593017578\n",
      "epoch: 13 step: 143 loss: 0.6931476593017578\n",
      "epoch: 13 step: 144 loss: 0.6931476593017578\n",
      "epoch: 13 step: 145 loss: 0.6931476593017578\n",
      "epoch: 13 step: 146 loss: 0.6931476593017578\n",
      "epoch: 13 step: 147 loss: 0.6931476593017578\n",
      "epoch: 13 step: 148 loss: 0.6931476593017578\n",
      "epoch: 13 step: 149 loss: 0.6931476593017578\n",
      "epoch: 13 step: 150 loss: 0.6931476593017578\n",
      "epoch: 13 step: 151 loss: 0.6931476593017578\n",
      "epoch: 13 step: 152 loss: 0.6931476593017578\n",
      "epoch: 13 step: 153 loss: 0.6931476593017578\n",
      "epoch: 13 step: 154 loss: 0.6931476593017578\n",
      "epoch: 13 step: 155 loss: 0.6931476593017578\n",
      "epoch: 13 step: 156 loss: 0.6931476593017578\n",
      "epoch: 13 step: 157 loss: 0.6931476593017578\n",
      "epoch: 13 step: 158 loss: 0.6931476593017578\n",
      "epoch: 13 step: 159 loss: 0.6931476593017578\n",
      "epoch: 13 step: 160 loss: 0.6931476593017578\n",
      "epoch: 13 step: 161 loss: 0.6931476593017578\n",
      "epoch: 13 step: 162 loss: 0.6931476593017578\n",
      "epoch: 13 step: 163 loss: 0.6931476593017578\n",
      "epoch: 13 step: 164 loss: 0.6931476593017578\n",
      "epoch: 13 step: 165 loss: 0.6931476593017578\n",
      "epoch: 13 step: 166 loss: 0.6931476593017578\n",
      "epoch: 13 step: 167 loss: 0.6931476593017578\n",
      "epoch: 13 step: 168 loss: 0.6931476593017578\n",
      "epoch: 13 step: 169 loss: 0.6931476593017578\n",
      "epoch: 13 step: 170 loss: 0.6931476593017578\n",
      "epoch: 13 step: 171 loss: 0.6931476593017578\n",
      "epoch: 13 step: 172 loss: 0.6931476593017578\n",
      "epoch: 13 step: 173 loss: 0.6931476593017578\n",
      "epoch: 13 step: 174 loss: 0.6931476593017578\n",
      "epoch: 13 step: 175 loss: 0.6931476593017578\n",
      "epoch: 13 step: 176 loss: 0.6931476593017578\n",
      "epoch: 13 step: 177 loss: 0.6931476593017578\n",
      "epoch: 13 step: 178 loss: 0.6931476593017578\n",
      "epoch: 13 step: 179 loss: 0.6931476593017578\n",
      "epoch: 13 step: 180 loss: 0.6931476593017578\n",
      "epoch: 13 step: 181 loss: 0.6931476593017578\n",
      "epoch: 13 step: 182 loss: 0.6931476593017578\n",
      "epoch: 13 step: 183 loss: 0.6931476593017578\n",
      "epoch: 13 step: 184 loss: 0.6931476593017578\n",
      "epoch: 13 step: 185 loss: 0.6931476593017578\n",
      "epoch: 13 step: 186 loss: 0.6931476593017578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 187 loss: 0.6931476593017578\n",
      "epoch: 13 step: 188 loss: 0.6931476593017578\n",
      "epoch: 13 step: 189 loss: 0.6931476593017578\n",
      "epoch: 13 step: 190 loss: 0.6931476593017578\n",
      "epoch: 13 step: 191 loss: 0.6931476593017578\n",
      "epoch: 13 step: 192 loss: 0.6931476593017578\n",
      "epoch: 13 step: 193 loss: 0.6931476593017578\n",
      "epoch: 13 step: 194 loss: 0.6931476593017578\n",
      "epoch: 13 step: 195 loss: 0.6931476593017578\n",
      "epoch: 13 step: 196 loss: 0.6931476593017578\n",
      "epoch: 13 step: 197 loss: 0.6931476593017578\n",
      "epoch: 13 step: 198 loss: 0.6931476593017578\n",
      "epoch: 13 step: 199 loss: 0.6931476593017578\n",
      "epoch: 13 step: 200 loss: 0.6931476593017578\n",
      "epoch: 13 step: 201 loss: 0.6931476593017578\n",
      "epoch: 13 step: 202 loss: 0.6931476593017578\n",
      "epoch: 13 step: 203 loss: 0.6931476593017578\n",
      "epoch: 13 step: 204 loss: 0.6931476593017578\n",
      "epoch: 13 step: 205 loss: 0.6931476593017578\n",
      "epoch: 13 step: 206 loss: 0.6931476593017578\n",
      "epoch: 13 step: 207 loss: 0.6931476593017578\n",
      "epoch: 13 step: 208 loss: 0.6931476593017578\n",
      "epoch: 13 step: 209 loss: 0.6931476593017578\n",
      "epoch: 13 step: 210 loss: 0.6931476593017578\n",
      "epoch: 13 step: 211 loss: 0.6931476593017578\n",
      "epoch: 13 step: 212 loss: 0.6931476593017578\n",
      "epoch: 13 step: 213 loss: 0.6931476593017578\n",
      "epoch: 13 step: 214 loss: 0.6931476593017578\n",
      "epoch: 13 step: 215 loss: 0.6931476593017578\n",
      "epoch: 13 step: 216 loss: 0.6931476593017578\n",
      "epoch: 13 step: 217 loss: 0.6931476593017578\n",
      "epoch: 13 step: 218 loss: 0.6931476593017578\n",
      "epoch: 13 step: 219 loss: 0.6931476593017578\n",
      "epoch: 13 step: 220 loss: 0.6931476593017578\n",
      "epoch: 13 step: 221 loss: 0.6931476593017578\n",
      "epoch: 13 step: 222 loss: 0.6931476593017578\n",
      "epoch: 13 step: 223 loss: 0.6931476593017578\n",
      "epoch: 13 step: 224 loss: 0.6931476593017578\n",
      "epoch: 13 step: 225 loss: 0.6931476593017578\n",
      "epoch: 13 step: 226 loss: 0.6931476593017578\n",
      "epoch: 13 step: 227 loss: 0.6931476593017578\n",
      "epoch: 13 step: 228 loss: 0.6931476593017578\n",
      "epoch: 13 step: 229 loss: 0.6931476593017578\n",
      "epoch: 13 step: 230 loss: 0.6931476593017578\n",
      "epoch: 13 step: 231 loss: 0.6931476593017578\n",
      "epoch: 13 step: 232 loss: 0.6931476593017578\n",
      "epoch: 13 step: 233 loss: 0.6931476593017578\n",
      "epoch: 13 step: 234 loss: 0.6931476593017578\n",
      "epoch: 13 step: 235 loss: 0.6931476593017578\n",
      "epoch: 13 step: 236 loss: 0.6931476593017578\n",
      "epoch: 13 step: 237 loss: 0.6931476593017578\n",
      "epoch: 13 step: 238 loss: 0.6931476593017578\n",
      "epoch: 13 step: 239 loss: 0.6931476593017578\n",
      "epoch: 13 step: 240 loss: 0.6931476593017578\n",
      "epoch: 13 step: 241 loss: 0.6931476593017578\n",
      "epoch: 13 step: 242 loss: 0.6931476593017578\n",
      "epoch: 13 step: 243 loss: 0.6931476593017578\n",
      "epoch: 13 step: 244 loss: 0.6931476593017578\n",
      "epoch: 13 step: 245 loss: 0.6931476593017578\n",
      "epoch: 13 step: 246 loss: 0.6931476593017578\n",
      "epoch: 13 step: 247 loss: 0.6931476593017578\n",
      "epoch: 13 step: 248 loss: 0.6931476593017578\n",
      "epoch: 13 step: 249 loss: 0.6931476593017578\n",
      "epoch: 13 step: 250 loss: 0.6931476593017578\n",
      "epoch: 13 step: 251 loss: 0.6931476593017578\n",
      "epoch: 13 step: 252 loss: 0.6931476593017578\n",
      "epoch: 13 step: 253 loss: 0.6931476593017578\n",
      "epoch: 13 step: 254 loss: 0.6931476593017578\n",
      "epoch: 13 step: 255 loss: 0.6931476593017578\n",
      "epoch: 13 step: 256 loss: 0.6931476593017578\n",
      "epoch: 13 step: 257 loss: 0.6931476593017578\n",
      "epoch: 13 step: 258 loss: 0.6931476593017578\n",
      "epoch: 13 step: 259 loss: 0.6931476593017578\n",
      "epoch: 13 step: 260 loss: 0.6931476593017578\n",
      "epoch: 13 step: 261 loss: 0.6931476593017578\n",
      "epoch: 13 step: 262 loss: 0.6931476593017578\n",
      "epoch: 13 step: 263 loss: 0.6931476593017578\n",
      "epoch: 13 step: 264 loss: 0.6931476593017578\n",
      "epoch: 13 step: 265 loss: 0.6931476593017578\n",
      "epoch: 13 step: 266 loss: 0.6931476593017578\n",
      "epoch: 13 step: 267 loss: 0.6931476593017578\n",
      "epoch: 13 step: 268 loss: 0.6931476593017578\n",
      "epoch: 13 step: 269 loss: 0.6931476593017578\n",
      "epoch: 13 step: 270 loss: 0.6931476593017578\n",
      "epoch: 13 step: 271 loss: 0.6931476593017578\n",
      "epoch: 13 step: 272 loss: 0.6931476593017578\n",
      "epoch: 13 step: 273 loss: 0.6931476593017578\n",
      "epoch: 13 step: 274 loss: 0.6931476593017578\n",
      "epoch: 13 step: 275 loss: 0.6931476593017578\n",
      "epoch: 13 step: 276 loss: 0.6931476593017578\n",
      "epoch: 13 step: 277 loss: 0.6931476593017578\n",
      "epoch: 13 step: 278 loss: 0.6931476593017578\n",
      "epoch: 13 step: 279 loss: 0.6931476593017578\n",
      "epoch: 13 step: 280 loss: 0.6931476593017578\n",
      "epoch: 13 step: 281 loss: 0.6931476593017578\n",
      "epoch: 13 step: 282 loss: 0.6931476593017578\n",
      "epoch: 13 step: 283 loss: 0.6931476593017578\n",
      "epoch: 13 step: 284 loss: 0.6931476593017578\n",
      "epoch: 13 step: 285 loss: 0.6931476593017578\n",
      "epoch: 13 step: 286 loss: 0.6931476593017578\n",
      "epoch: 13 step: 287 loss: 0.6931476593017578\n",
      "epoch: 13 step: 288 loss: 0.6931476593017578\n",
      "epoch: 13 step: 289 loss: 0.6931476593017578\n",
      "epoch: 13 step: 290 loss: 0.6931476593017578\n",
      "epoch: 13 step: 291 loss: 0.6931476593017578\n",
      "epoch: 13 step: 292 loss: 0.6931476593017578\n",
      "epoch: 13 step: 293 loss: 0.6931476593017578\n",
      "epoch: 13 step: 294 loss: 0.6931476593017578\n",
      "epoch: 13 step: 295 loss: 0.6931476593017578\n",
      "epoch: 13 step: 296 loss: 0.6931476593017578\n",
      "epoch: 13 step: 297 loss: 0.6931476593017578\n",
      "epoch: 13 step: 298 loss: 0.6931476593017578\n",
      "epoch: 13 step: 299 loss: 0.6931476593017578\n",
      "epoch: 13 step: 300 loss: 0.6931476593017578\n",
      "epoch: 13 step: 301 loss: 0.6931476593017578\n",
      "epoch: 13 step: 302 loss: 0.6931476593017578\n",
      "epoch: 13 step: 303 loss: 0.6931476593017578\n",
      "epoch: 13 step: 304 loss: 0.6931476593017578\n",
      "epoch: 13 step: 305 loss: 0.6931476593017578\n",
      "epoch: 13 step: 306 loss: 0.6931476593017578\n",
      "epoch: 13 step: 307 loss: 0.6931476593017578\n",
      "epoch: 13 step: 308 loss: 0.6931476593017578\n",
      "epoch: 13 step: 309 loss: 0.6931476593017578\n",
      "epoch: 13 step: 310 loss: 0.6931476593017578\n",
      "epoch: 13 step: 311 loss: 0.6931476593017578\n",
      "epoch: 13 step: 312 loss: 0.6931476593017578\n",
      "epoch: 13 step: 313 loss: 0.6931476593017578\n",
      "epoch: 13 step: 314 loss: 0.6931476593017578\n",
      "epoch: 13 step: 315 loss: 0.6931476593017578\n",
      "epoch: 13 step: 316 loss: 0.6931476593017578\n",
      "epoch: 13 step: 317 loss: 0.6931476593017578\n",
      "epoch: 13 step: 318 loss: 0.6931476593017578\n",
      "epoch: 13 step: 319 loss: 0.6931476593017578\n",
      "epoch: 13 step: 320 loss: 0.6931476593017578\n",
      "epoch: 13 step: 321 loss: 0.6931476593017578\n",
      "epoch: 13 step: 322 loss: 0.6931476593017578\n",
      "epoch: 13 step: 323 loss: 0.6931476593017578\n",
      "epoch: 13 step: 324 loss: 0.6931476593017578\n",
      "epoch: 13 step: 325 loss: 0.6931476593017578\n",
      "epoch: 13 step: 326 loss: 0.6931476593017578\n",
      "epoch: 13 step: 327 loss: 0.6931476593017578\n",
      "epoch: 13 step: 328 loss: 0.6931476593017578\n",
      "epoch: 13 step: 329 loss: 0.6931476593017578\n",
      "epoch: 13 step: 330 loss: 0.6931476593017578\n",
      "epoch: 13 step: 331 loss: 0.6931476593017578\n",
      "epoch: 13 step: 332 loss: 0.6931476593017578\n",
      "epoch: 13 step: 333 loss: 0.6931476593017578\n",
      "epoch: 13 step: 334 loss: 0.6931476593017578\n",
      "epoch: 13 step: 335 loss: 0.6931476593017578\n",
      "epoch: 13 step: 336 loss: 0.6931476593017578\n",
      "epoch: 13 step: 337 loss: 0.6931476593017578\n",
      "epoch: 13 step: 338 loss: 0.6931476593017578\n",
      "epoch: 13 step: 339 loss: 0.6931476593017578\n",
      "epoch: 13 step: 340 loss: 0.6931476593017578\n",
      "epoch: 13 step: 341 loss: 0.6931476593017578\n",
      "epoch: 13 step: 342 loss: 0.6931476593017578\n",
      "epoch: 13 step: 343 loss: 0.6931476593017578\n",
      "epoch: 13 step: 344 loss: 0.6931476593017578\n",
      "epoch: 13 step: 345 loss: 0.6931476593017578\n",
      "epoch: 13 step: 346 loss: 0.6931476593017578\n",
      "epoch: 13 step: 347 loss: 0.6931476593017578\n",
      "epoch: 13 step: 348 loss: 0.6931476593017578\n",
      "epoch: 13 step: 349 loss: 0.6931476593017578\n",
      "epoch: 13 step: 350 loss: 0.6931476593017578\n",
      "epoch: 13 step: 351 loss: 0.6931476593017578\n",
      "epoch: 13 step: 352 loss: 0.6931476593017578\n",
      "epoch: 13 step: 353 loss: 0.6931476593017578\n",
      "epoch: 13 step: 354 loss: 0.6931476593017578\n",
      "epoch: 13 step: 355 loss: 0.6931476593017578\n",
      "epoch: 13 step: 356 loss: 0.6931476593017578\n",
      "epoch: 13 step: 357 loss: 0.6931476593017578\n",
      "epoch: 13 step: 358 loss: 0.6931476593017578\n",
      "epoch: 13 step: 359 loss: 0.6931476593017578\n",
      "epoch: 13 step: 360 loss: 0.6931476593017578\n",
      "epoch: 13 step: 361 loss: 0.6931476593017578\n",
      "epoch: 13 step: 362 loss: 0.6931476593017578\n",
      "epoch: 13 step: 363 loss: 0.6931476593017578\n",
      "epoch: 13 step: 364 loss: 0.6931476593017578\n",
      "epoch: 13 step: 365 loss: 0.6931476593017578\n",
      "epoch: 13 step: 366 loss: 0.6931476593017578\n",
      "epoch: 13 step: 367 loss: 0.6931476593017578\n",
      "epoch: 13 step: 368 loss: 0.6931476593017578\n",
      "epoch: 13 step: 369 loss: 0.6931476593017578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 370 loss: 0.6931476593017578\n",
      "epoch: 13 step: 371 loss: 0.6931476593017578\n",
      "epoch: 13 step: 372 loss: 0.6931476593017578\n",
      "epoch: 13 step: 373 loss: 0.6931476593017578\n",
      "epoch: 13 step: 374 loss: 0.6931476593017578\n",
      "epoch: 13 step: 375 loss: 0.6931476593017578\n",
      "epoch: 13 step: 376 loss: 0.6931476593017578\n",
      "epoch: 13 step: 377 loss: 0.6931476593017578\n",
      "epoch: 13 step: 378 loss: 0.6931476593017578\n",
      "epoch: 13 step: 379 loss: 0.6931476593017578\n",
      "epoch: 13 step: 380 loss: 0.6931476593017578\n",
      "epoch: 13 step: 381 loss: 0.6931476593017578\n",
      "epoch: 13 step: 382 loss: 0.6931476593017578\n",
      "epoch: 13 step: 383 loss: 0.6931476593017578\n",
      "epoch: 13 step: 384 loss: 0.6931476593017578\n",
      "epoch: 13 step: 385 loss: 0.6931476593017578\n",
      "epoch: 13 step: 386 loss: 0.6931476593017578\n",
      "epoch: 13 step: 387 loss: 0.6931476593017578\n",
      "epoch: 13 step: 388 loss: 0.6931476593017578\n",
      "epoch: 13 step: 389 loss: 0.6931476593017578\n",
      "epoch: 13 step: 390 loss: 0.6931476593017578\n",
      "epoch: 13 step: 391 loss: 0.6931476593017578\n",
      "epoch: 13 step: 392 loss: 0.6931476593017578\n",
      "epoch: 13 step: 393 loss: 0.6931476593017578\n",
      "epoch: 13 step: 394 loss: 0.6931476593017578\n",
      "epoch: 13 step: 395 loss: 0.6931476593017578\n",
      "epoch: 13 step: 396 loss: 0.6931476593017578\n",
      "epoch: 13 step: 397 loss: 0.6931476593017578\n",
      "epoch: 13 step: 398 loss: 0.6931476593017578\n",
      "epoch: 13 step: 399 loss: 0.6931476593017578\n",
      "epoch: 13 step: 400 loss: 0.6931476593017578\n",
      "epoch: 13 step: 401 loss: 0.6931476593017578\n",
      "epoch: 13 step: 402 loss: 0.6931476593017578\n",
      "epoch: 13 step: 403 loss: 0.6931476593017578\n",
      "epoch: 13 step: 404 loss: 0.6931476593017578\n",
      "epoch: 13 step: 405 loss: 0.6931476593017578\n",
      "epoch: 13 step: 406 loss: 0.6931476593017578\n",
      "epoch: 13 step: 407 loss: 0.6931476593017578\n",
      "epoch: 13 step: 408 loss: 0.6931476593017578\n",
      "epoch: 13 step: 409 loss: 0.6931476593017578\n",
      "epoch: 13 step: 410 loss: 0.6931476593017578\n",
      "epoch: 13 step: 411 loss: 0.6931476593017578\n",
      "epoch: 13 step: 412 loss: 0.6931476593017578\n",
      "epoch: 13 step: 413 loss: 0.6931476593017578\n",
      "epoch: 13 step: 414 loss: 0.6931476593017578\n",
      "epoch: 13 step: 415 loss: 0.6931476593017578\n",
      "epoch: 13 step: 416 loss: 0.6931476593017578\n",
      "epoch: 13 step: 417 loss: 0.6931476593017578\n",
      "epoch: 13 step: 418 loss: 0.6931476593017578\n",
      "epoch: 13 step: 419 loss: 0.6931476593017578\n",
      "epoch: 13 step: 420 loss: 0.6931476593017578\n",
      "epoch: 13 step: 421 loss: 0.6931476593017578\n",
      "epoch: 13 step: 422 loss: 0.6931476593017578\n",
      "epoch: 13 step: 423 loss: 0.6931476593017578\n",
      "epoch: 13 step: 424 loss: 0.6931476593017578\n",
      "epoch: 13 step: 425 loss: 0.6931476593017578\n",
      "epoch: 13 step: 426 loss: 0.6931476593017578\n",
      "epoch: 13 step: 427 loss: 0.6931476593017578\n",
      "epoch: 13 step: 428 loss: 0.6931476593017578\n",
      "epoch: 13 step: 429 loss: 0.6931476593017578\n",
      "epoch: 13 step: 430 loss: 0.6931476593017578\n",
      "epoch: 13 step: 431 loss: 0.6931476593017578\n",
      "epoch: 13 step: 432 loss: 0.6931476593017578\n",
      "epoch: 13 step: 433 loss: 0.6931476593017578\n",
      "epoch: 13 step: 434 loss: 0.6931476593017578\n",
      "epoch: 13 step: 435 loss: 0.6931476593017578\n",
      "epoch: 13 step: 436 loss: 0.6931476593017578\n",
      "epoch: 13 step: 437 loss: 0.6931476593017578\n",
      "epoch: 13 step: 438 loss: 0.6931476593017578\n",
      "epoch: 13 step: 439 loss: 0.6931476593017578\n",
      "epoch: 13 step: 440 loss: 0.6931476593017578\n",
      "epoch: 13 step: 441 loss: 0.6931476593017578\n",
      "epoch: 13 step: 442 loss: 0.6931476593017578\n",
      "epoch: 13 step: 443 loss: 0.6931476593017578\n",
      "epoch: 13 step: 444 loss: 0.6931476593017578\n",
      "epoch: 13 step: 445 loss: 0.6931476593017578\n",
      "epoch: 13 step: 446 loss: 0.6931476593017578\n",
      "epoch: 13 step: 447 loss: 0.6931476593017578\n",
      "epoch: 13 step: 448 loss: 0.6931476593017578\n",
      "epoch: 13 step: 449 loss: 0.6931476593017578\n",
      "epoch: 13 step: 450 loss: 0.6931476593017578\n",
      "epoch: 13 step: 451 loss: 0.6931476593017578\n",
      "epoch: 13 step: 452 loss: 0.6931476593017578\n",
      "epoch: 13 step: 453 loss: 0.6931476593017578\n",
      "epoch: 13 step: 454 loss: 0.6931476593017578\n",
      "epoch: 13 step: 455 loss: 0.6931476593017578\n",
      "epoch: 13 step: 456 loss: 0.6931476593017578\n",
      "epoch: 13 step: 457 loss: 0.6931476593017578\n",
      "epoch: 13 step: 458 loss: 0.6931476593017578\n",
      "epoch: 13 step: 459 loss: 0.6931476593017578\n",
      "epoch: 13 step: 460 loss: 0.6931476593017578\n",
      "epoch: 13 step: 461 loss: 0.6931476593017578\n",
      "epoch: 13 step: 462 loss: 0.6931476593017578\n",
      "epoch: 13 step: 463 loss: 0.6931476593017578\n",
      "epoch: 13 step: 464 loss: 0.6931476593017578\n",
      "epoch: 13 step: 465 loss: 0.6931476593017578\n",
      "epoch: 13 step: 466 loss: 0.6931476593017578\n",
      "epoch: 13 step: 467 loss: 0.6931476593017578\n",
      "epoch: 13 step: 468 loss: 0.6931476593017578\n",
      "epoch: 13 step: 469 loss: 0.6931476593017578\n",
      "epoch: 13 step: 470 loss: 0.6931476593017578\n",
      "epoch: 13 step: 471 loss: 0.6931476593017578\n",
      "epoch: 13 step: 472 loss: 0.6931476593017578\n",
      "epoch: 13 step: 473 loss: 0.6931476593017578\n",
      "epoch: 13 step: 474 loss: 0.6931476593017578\n",
      "epoch: 13 step: 475 loss: 0.6931476593017578\n",
      "epoch: 13 step: 476 loss: 0.6931476593017578\n",
      "epoch: 13 step: 477 loss: 0.6931476593017578\n",
      "epoch: 13 step: 478 loss: 0.6931476593017578\n",
      "epoch: 13 step: 479 loss: 0.6931476593017578\n",
      "epoch: 13 step: 480 loss: 0.6931476593017578\n",
      "epoch: 13 step: 481 loss: 0.6931476593017578\n",
      "epoch: 13 step: 482 loss: 0.6931476593017578\n",
      "epoch: 13 step: 483 loss: 0.6931476593017578\n",
      "epoch: 13 step: 484 loss: 0.6931476593017578\n",
      "epoch: 13 step: 485 loss: 0.6931476593017578\n",
      "epoch: 13 step: 486 loss: 0.6931476593017578\n",
      "epoch: 13 step: 487 loss: 0.6931476593017578\n",
      "epoch: 13 step: 488 loss: 0.6931476593017578\n",
      "epoch: 13 step: 489 loss: 0.6931476593017578\n",
      "epoch: 13 step: 490 loss: 0.6931476593017578\n",
      "epoch: 13 step: 491 loss: 0.6931476593017578\n",
      "epoch: 13 step: 492 loss: 0.6931476593017578\n",
      "epoch: 13 step: 493 loss: 0.6931476593017578\n",
      "epoch: 13 step: 494 loss: 0.6931476593017578\n",
      "epoch: 13 step: 495 loss: 0.6931476593017578\n",
      "epoch: 13 step: 496 loss: 0.6931476593017578\n",
      "epoch: 13 step: 497 loss: 0.6931476593017578\n",
      "epoch: 13 step: 498 loss: 0.6931476593017578\n",
      "epoch: 13 step: 499 loss: 0.6931476593017578\n",
      "epoch: 13 step: 500 loss: 0.6931476593017578\n",
      "epoch: 13 step: 501 loss: 0.6931476593017578\n",
      "epoch: 13 step: 502 loss: 0.6931476593017578\n",
      "epoch: 13 step: 503 loss: 0.6931476593017578\n",
      "epoch: 13 step: 504 loss: 0.6931476593017578\n",
      "epoch: 13 step: 505 loss: 0.6931476593017578\n",
      "epoch: 13 step: 506 loss: 0.6931476593017578\n",
      "epoch: 13 step: 507 loss: 0.6931476593017578\n",
      "epoch: 13 step: 508 loss: 0.6931476593017578\n",
      "epoch: 13 step: 509 loss: 0.6931476593017578\n",
      "epoch: 13 step: 510 loss: 0.6931476593017578\n",
      "epoch: 13 step: 511 loss: 0.6931476593017578\n",
      "epoch: 13 step: 512 loss: 0.6931476593017578\n",
      "epoch: 13 step: 513 loss: 0.6931476593017578\n",
      "epoch: 13 step: 514 loss: 0.6931476593017578\n",
      "epoch: 13 step: 515 loss: 0.6931476593017578\n",
      "epoch: 13 step: 516 loss: 0.6931476593017578\n",
      "epoch: 13 step: 517 loss: 0.6931476593017578\n",
      "epoch: 13 step: 518 loss: 0.6931476593017578\n",
      "epoch: 13 step: 519 loss: 0.6931476593017578\n",
      "epoch: 13 step: 520 loss: 0.6931476593017578\n",
      "epoch: 13 step: 521 loss: 0.6931476593017578\n",
      "epoch: 13 step: 522 loss: 0.6931476593017578\n",
      "epoch: 13 step: 523 loss: 0.6931476593017578\n",
      "epoch: 13 step: 524 loss: 0.6931476593017578\n",
      "epoch: 13 step: 525 loss: 0.6931476593017578\n",
      "epoch: 13 step: 526 loss: 0.6931476593017578\n",
      "epoch: 13 step: 527 loss: 0.6931476593017578\n",
      "epoch: 13 step: 528 loss: 0.6931476593017578\n",
      "epoch: 13 step: 529 loss: 0.6931476593017578\n",
      "epoch: 13 step: 530 loss: 0.6931476593017578\n",
      "epoch: 13 step: 531 loss: 0.6931476593017578\n",
      "epoch: 13 step: 532 loss: 0.6931476593017578\n",
      "epoch: 13 step: 533 loss: 0.6931476593017578\n",
      "epoch: 13 step: 534 loss: 0.6931476593017578\n",
      "epoch: 13 step: 535 loss: 0.6931476593017578\n",
      "epoch: 13 step: 536 loss: 0.6931476593017578\n",
      "epoch: 13 step: 537 loss: 0.6931476593017578\n",
      "epoch: 13 step: 538 loss: 0.6931476593017578\n",
      "epoch: 13 step: 539 loss: 0.6931476593017578\n",
      "epoch: 13 step: 540 loss: 0.6931476593017578\n",
      "epoch: 13 step: 541 loss: 0.6931476593017578\n",
      "epoch: 13 step: 542 loss: 0.6931476593017578\n",
      "epoch: 13 step: 543 loss: 0.6931476593017578\n",
      "epoch: 13 step: 544 loss: 0.6931476593017578\n",
      "epoch: 13 step: 545 loss: 0.6931476593017578\n",
      "epoch: 13 step: 546 loss: 0.6931476593017578\n",
      "epoch: 13 step: 547 loss: 0.6931476593017578\n",
      "epoch: 13 step: 548 loss: 0.6931476593017578\n",
      "epoch: 13 step: 549 loss: 0.6931476593017578\n",
      "epoch: 13 step: 550 loss: 0.6931476593017578\n",
      "epoch: 13 step: 551 loss: 0.6931476593017578\n",
      "epoch: 13 step: 552 loss: 0.6931476593017578\n",
      "epoch: 13 step: 553 loss: 0.6931476593017578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 554 loss: 0.6931476593017578\n",
      "epoch: 13 step: 555 loss: 0.6931476593017578\n",
      "epoch: 13 step: 556 loss: 0.6931476593017578\n",
      "epoch: 13 step: 557 loss: 0.6931476593017578\n",
      "epoch: 13 step: 558 loss: 0.6931476593017578\n",
      "epoch: 13 step: 559 loss: 0.6931476593017578\n",
      "epoch: 13 step: 560 loss: 0.6931476593017578\n",
      "epoch: 13 step: 561 loss: 0.6931476593017578\n",
      "epoch: 13 step: 562 loss: 0.6931476593017578\n",
      "epoch: 13 step: 563 loss: 0.6931476593017578\n",
      "epoch: 13 step: 564 loss: 0.6931476593017578\n",
      "epoch: 13 step: 565 loss: 0.6931476593017578\n",
      "epoch: 13 step: 566 loss: 0.6931476593017578\n",
      "epoch: 13 step: 567 loss: 0.6931476593017578\n",
      "epoch: 13 step: 568 loss: 0.6931476593017578\n",
      "epoch: 13 step: 569 loss: 0.6931476593017578\n",
      "epoch: 13 step: 570 loss: 0.6931476593017578\n",
      "epoch: 13 step: 571 loss: 0.6931476593017578\n",
      "epoch: 13 step: 572 loss: 0.6931476593017578\n",
      "epoch: 13 step: 573 loss: 0.6931476593017578\n",
      "epoch: 13 step: 574 loss: 0.6931476593017578\n",
      "epoch: 13 step: 575 loss: 0.6931476593017578\n",
      "epoch: 13 step: 576 loss: 0.6931476593017578\n",
      "epoch: 13 step: 577 loss: 0.6931476593017578\n",
      "epoch: 13 step: 578 loss: 0.6931476593017578\n",
      "epoch: 13 step: 579 loss: 0.6931476593017578\n",
      "epoch: 13 step: 580 loss: 0.6931476593017578\n",
      "epoch: 13 step: 581 loss: 0.6931476593017578\n",
      "epoch: 13 step: 582 loss: 0.6931476593017578\n",
      "epoch: 13 step: 583 loss: 0.6931476593017578\n",
      "epoch: 13 step: 584 loss: 0.6931476593017578\n",
      "epoch: 13 step: 585 loss: 0.6931476593017578\n",
      "epoch: 13 step: 586 loss: 0.6931476593017578\n",
      "epoch: 13 step: 587 loss: 0.6931476593017578\n",
      "epoch: 13 step: 588 loss: 0.6931476593017578\n",
      "epoch: 13 step: 589 loss: 0.6931476593017578\n",
      "epoch: 13 step: 590 loss: 0.6931476593017578\n",
      "epoch: 13 step: 591 loss: 0.6931476593017578\n",
      "epoch: 13 step: 592 loss: 0.6931476593017578\n",
      "epoch: 13 step: 593 loss: 0.6931476593017578\n",
      "epoch: 13 step: 594 loss: 0.6931476593017578\n",
      "epoch: 13 step: 595 loss: 0.6931476593017578\n",
      "epoch: 13 step: 596 loss: 0.6931476593017578\n",
      "epoch: 13 step: 597 loss: 0.6931476593017578\n",
      "epoch: 13 step: 598 loss: 0.6931476593017578\n",
      "epoch: 13 step: 599 loss: 0.6931476593017578\n",
      "epoch: 13 step: 600 loss: 0.6931476593017578\n",
      "epoch: 13 step: 601 loss: 0.6931476593017578\n",
      "epoch: 13 step: 602 loss: 0.6931476593017578\n",
      "epoch: 13 step: 603 loss: 0.6931476593017578\n",
      "epoch: 13 step: 604 loss: 0.6931476593017578\n",
      "epoch: 13 step: 605 loss: 0.6931476593017578\n",
      "epoch: 13 step: 606 loss: 0.6931476593017578\n",
      "epoch: 13 step: 607 loss: 0.6931476593017578\n",
      "epoch: 13 step: 608 loss: 0.6931476593017578\n",
      "epoch: 13 step: 609 loss: 0.6931476593017578\n",
      "epoch: 13 step: 610 loss: 0.6931476593017578\n",
      "epoch: 13 step: 611 loss: 0.6931476593017578\n",
      "epoch: 13 step: 612 loss: 0.693147599697113\n",
      "epoch: 13 step: 613 loss: 0.6931476593017578\n",
      "epoch: 13 step: 614 loss: 0.6931476593017578\n",
      "epoch: 13 step: 615 loss: 0.6931476593017578\n",
      "epoch: 13 step: 616 loss: 0.6931476593017578\n",
      "epoch: 13 step: 617 loss: 0.6931476593017578\n",
      "epoch: 13 step: 618 loss: 0.6931476593017578\n",
      "epoch: 13 step: 619 loss: 0.6931476593017578\n",
      "epoch: 13 step: 620 loss: 0.6931476593017578\n",
      "epoch: 13 step: 621 loss: 0.6931476593017578\n",
      "epoch: 13 step: 622 loss: 0.6931476593017578\n",
      "epoch: 13 step: 623 loss: 0.6931476593017578\n",
      "epoch: 13 step: 624 loss: 0.693147599697113\n",
      "epoch: 13 step: 625 loss: 0.6931476593017578\n",
      "epoch: 13 step: 626 loss: 0.6931476593017578\n",
      "epoch: 13 step: 627 loss: 0.693147599697113\n",
      "epoch: 13 step: 628 loss: 0.6931476593017578\n",
      "epoch: 13 step: 629 loss: 0.6931476593017578\n",
      "epoch: 13 step: 630 loss: 0.6931476593017578\n",
      "epoch: 13 step: 631 loss: 0.693147599697113\n",
      "epoch: 13 step: 632 loss: 0.693147599697113\n",
      "epoch: 13 step: 633 loss: 0.6931475400924683\n",
      "epoch: 13 step: 634 loss: 0.6931475400924683\n",
      "epoch: 13 step: 635 loss: 0.6931475400924683\n",
      "epoch: 13 step: 636 loss: 0.6931475400924683\n",
      "epoch: 13 step: 637 loss: 0.693147599697113\n",
      "epoch: 13 step: 638 loss: 0.693147599697113\n",
      "epoch: 13 step: 639 loss: 0.6931476593017578\n",
      "epoch: 13 step: 640 loss: 0.6931475400924683\n",
      "epoch: 13 step: 641 loss: 0.6931475400924683\n",
      "epoch: 13 step: 642 loss: 0.6931475400924683\n",
      "epoch: 13 step: 643 loss: 0.6931475400924683\n",
      "epoch: 13 step: 644 loss: 0.6931475400924683\n",
      "epoch: 13 step: 645 loss: 0.6931475400924683\n",
      "epoch: 13 step: 646 loss: 0.693147599697113\n",
      "epoch: 13 step: 647 loss: 0.6931475400924683\n",
      "epoch: 13 step: 648 loss: 0.693147599697113\n",
      "epoch: 13 step: 649 loss: 0.6931475400924683\n",
      "epoch: 13 step: 650 loss: 0.6931475400924683\n",
      "epoch: 13 step: 651 loss: 0.6931475400924683\n",
      "epoch: 13 step: 652 loss: 0.6931475400924683\n",
      "epoch: 13 step: 653 loss: 0.693147599697113\n",
      "epoch: 13 step: 654 loss: 0.6931475400924683\n",
      "epoch: 13 step: 655 loss: 0.6931475400924683\n",
      "epoch: 13 step: 656 loss: 0.693147599697113\n",
      "epoch: 13 step: 657 loss: 0.6931475400924683\n",
      "epoch: 13 step: 658 loss: 0.6931475400924683\n",
      "epoch: 13 step: 659 loss: 0.6931475400924683\n",
      "epoch: 13 step: 660 loss: 0.6931475400924683\n",
      "epoch: 13 step: 661 loss: 0.6931475400924683\n",
      "epoch: 13 step: 662 loss: 0.6931475400924683\n",
      "epoch: 13 step: 663 loss: 0.6931475400924683\n",
      "epoch: 13 step: 664 loss: 0.6931475400924683\n",
      "epoch: 13 step: 665 loss: 0.6931475400924683\n",
      "epoch: 13 step: 666 loss: 0.6931475400924683\n",
      "epoch: 13 step: 667 loss: 0.6931475400924683\n",
      "epoch: 13 step: 668 loss: 0.6931475400924683\n",
      "epoch: 13 step: 669 loss: 0.6931475400924683\n",
      "epoch: 13 step: 670 loss: 0.6931475400924683\n",
      "epoch: 13 step: 671 loss: 0.6931475400924683\n",
      "epoch: 13 step: 672 loss: 0.6931475400924683\n",
      "epoch: 13 step: 673 loss: 0.6931475400924683\n",
      "epoch: 13 step: 674 loss: 0.6931475400924683\n",
      "epoch: 13 step: 675 loss: 0.6931475400924683\n",
      "epoch: 13 step: 676 loss: 0.6931475400924683\n",
      "epoch: 13 step: 677 loss: 0.6931475400924683\n",
      "epoch: 13 step: 678 loss: 0.6931475400924683\n",
      "epoch: 13 step: 679 loss: 0.6931475400924683\n",
      "epoch: 13 step: 680 loss: 0.6931475400924683\n",
      "epoch: 13 step: 681 loss: 0.6931475400924683\n",
      "epoch: 13 step: 682 loss: 0.6931475400924683\n",
      "epoch: 13 step: 683 loss: 0.6931475400924683\n",
      "epoch: 13 step: 684 loss: 0.6931475400924683\n",
      "epoch: 13 step: 685 loss: 0.6931475400924683\n",
      "epoch: 13 step: 686 loss: 0.6931475400924683\n",
      "epoch: 13 step: 687 loss: 0.6931475400924683\n",
      "epoch: 13 step: 688 loss: 0.6931475400924683\n",
      "epoch: 13 step: 689 loss: 0.6931475400924683\n",
      "epoch: 13 step: 690 loss: 0.6931475400924683\n",
      "epoch: 13 step: 691 loss: 0.6931475400924683\n",
      "epoch: 13 step: 692 loss: 0.6931475400924683\n",
      "epoch: 13 step: 693 loss: 0.6931475400924683\n",
      "epoch: 13 step: 694 loss: 0.6931475400924683\n",
      "epoch: 13 step: 695 loss: 0.6931475400924683\n",
      "epoch: 13 step: 696 loss: 0.6931475400924683\n",
      "epoch: 13 step: 697 loss: 0.6931475400924683\n",
      "epoch: 13 step: 698 loss: 0.6931475400924683\n",
      "epoch: 13 step: 699 loss: 0.6931475400924683\n",
      "epoch: 13 step: 700 loss: 0.6931475400924683\n",
      "epoch: 13 step: 701 loss: 0.6931475400924683\n",
      "epoch: 13 step: 702 loss: 0.6931475400924683\n",
      "epoch: 13 step: 703 loss: 0.6931475400924683\n",
      "epoch: 13 step: 704 loss: 0.6931475400924683\n",
      "epoch: 13 step: 705 loss: 0.6931475400924683\n",
      "epoch: 13 step: 706 loss: 0.6931475400924683\n",
      "epoch: 13 step: 707 loss: 0.6931475400924683\n",
      "epoch: 13 step: 708 loss: 0.6931475400924683\n",
      "epoch: 13 step: 709 loss: 0.6931475400924683\n",
      "epoch: 13 step: 710 loss: 0.6931475400924683\n",
      "epoch: 13 step: 711 loss: 0.6931475400924683\n",
      "epoch: 13 step: 712 loss: 0.6931475400924683\n",
      "epoch: 13 step: 713 loss: 0.6931475400924683\n",
      "epoch: 13 step: 714 loss: 0.6931475400924683\n",
      "epoch: 13 step: 715 loss: 0.6931475400924683\n",
      "epoch: 13 step: 716 loss: 0.6931475400924683\n",
      "epoch: 13 step: 717 loss: 0.6931475400924683\n",
      "epoch: 13 step: 718 loss: 0.6931475400924683\n",
      "epoch: 13 step: 719 loss: 0.6931475400924683\n",
      "epoch: 13 step: 720 loss: 0.6931475400924683\n",
      "epoch: 13 step: 721 loss: 0.6931475400924683\n",
      "epoch: 13 step: 722 loss: 0.6931475400924683\n",
      "epoch: 13 step: 723 loss: 0.6931475400924683\n",
      "epoch: 13 step: 724 loss: 0.6931475400924683\n",
      "epoch: 13 step: 725 loss: 0.6931475400924683\n",
      "epoch: 13 step: 726 loss: 0.6931475400924683\n",
      "epoch: 13 step: 727 loss: 0.6931475400924683\n",
      "epoch: 13 step: 728 loss: 0.6931475400924683\n",
      "epoch: 13 step: 729 loss: 0.6931475400924683\n",
      "epoch: 13 step: 730 loss: 0.6931475400924683\n",
      "epoch: 13 step: 731 loss: 0.6931475400924683\n",
      "epoch: 13 step: 732 loss: 0.6931475400924683\n",
      "epoch: 13 step: 733 loss: 0.6931475400924683\n",
      "epoch: 13 step: 734 loss: 0.6931475400924683\n",
      "epoch: 13 step: 735 loss: 0.6931475400924683\n",
      "epoch: 13 step: 736 loss: 0.6931475400924683\n",
      "epoch: 13 step: 737 loss: 0.6931475400924683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 738 loss: 0.6931475400924683\n",
      "epoch: 13 step: 739 loss: 0.6931475400924683\n",
      "epoch: 13 step: 740 loss: 0.6931475400924683\n",
      "epoch: 13 step: 741 loss: 0.6931475400924683\n",
      "epoch: 13 step: 742 loss: 0.6931475400924683\n",
      "epoch: 13 step: 743 loss: 0.6931475400924683\n",
      "epoch: 13 step: 744 loss: 0.6931475400924683\n",
      "epoch: 13 step: 745 loss: 0.6931475400924683\n",
      "epoch: 13 step: 746 loss: 0.6931475400924683\n",
      "epoch: 13 step: 747 loss: 0.6931475400924683\n",
      "epoch: 13 step: 748 loss: 0.6931475400924683\n",
      "epoch: 13 step: 749 loss: 0.6931475400924683\n",
      "epoch: 13 step: 750 loss: 0.6931475400924683\n",
      "epoch: 13 step: 751 loss: 0.6931475400924683\n",
      "epoch: 13 step: 752 loss: 0.6931475400924683\n",
      "epoch: 13 step: 753 loss: 0.6931475400924683\n",
      "epoch: 13 step: 754 loss: 0.6931475400924683\n",
      "epoch: 13 step: 755 loss: 0.6931475400924683\n",
      "epoch: 13 step: 756 loss: 0.6931475400924683\n",
      "epoch: 13 step: 757 loss: 0.6931475400924683\n",
      "epoch: 13 step: 758 loss: 0.6931475400924683\n",
      "epoch: 13 step: 759 loss: 0.6931475400924683\n",
      "epoch: 13 step: 760 loss: 0.6931475400924683\n",
      "epoch: 13 step: 761 loss: 0.6931475400924683\n",
      "epoch: 13 step: 762 loss: 0.6931475400924683\n",
      "epoch: 13 step: 763 loss: 0.6931475400924683\n",
      "epoch: 13 step: 764 loss: 0.6931475400924683\n",
      "epoch: 13 step: 765 loss: 0.6931475400924683\n",
      "epoch: 13 step: 766 loss: 0.6931475400924683\n",
      "epoch: 13 step: 767 loss: 0.6931475400924683\n",
      "epoch: 13 step: 768 loss: 0.6931475400924683\n",
      "epoch: 13 step: 769 loss: 0.6931475400924683\n",
      "epoch: 13 step: 770 loss: 0.6931475400924683\n",
      "epoch: 13 step: 771 loss: 0.6931475400924683\n",
      "epoch: 13 step: 772 loss: 0.6931475400924683\n",
      "epoch: 13 step: 773 loss: 0.6931475400924683\n",
      "epoch: 13 step: 774 loss: 0.6931475400924683\n",
      "epoch: 13 step: 775 loss: 0.6931475400924683\n",
      "epoch: 13 step: 776 loss: 0.6931475400924683\n",
      "epoch: 13 step: 777 loss: 0.6931475400924683\n",
      "epoch: 13 step: 778 loss: 0.6931475400924683\n",
      "epoch: 13 step: 779 loss: 0.6931475400924683\n",
      "epoch: 13 step: 780 loss: 0.6931475400924683\n",
      "epoch: 13 step: 781 loss: 0.6931475400924683\n",
      "epoch: 14 step: 1 loss: 0.6931475400924683\n",
      "epoch: 14 step: 2 loss: 0.6931475400924683\n",
      "epoch: 14 step: 3 loss: 0.6931475400924683\n",
      "epoch: 14 step: 4 loss: 0.6931475400924683\n",
      "epoch: 14 step: 5 loss: 0.6931475400924683\n",
      "epoch: 14 step: 6 loss: 0.6931475400924683\n",
      "epoch: 14 step: 7 loss: 0.6931475400924683\n",
      "epoch: 14 step: 8 loss: 0.6931475400924683\n",
      "epoch: 14 step: 9 loss: 0.6931475400924683\n",
      "epoch: 14 step: 10 loss: 0.6931475400924683\n",
      "epoch: 14 step: 11 loss: 0.6931475400924683\n",
      "epoch: 14 step: 12 loss: 0.6931475400924683\n",
      "epoch: 14 step: 13 loss: 0.6931475400924683\n",
      "epoch: 14 step: 14 loss: 0.6931475400924683\n",
      "epoch: 14 step: 15 loss: 0.6931475400924683\n",
      "epoch: 14 step: 16 loss: 0.6931475400924683\n",
      "epoch: 14 step: 17 loss: 0.6931475400924683\n",
      "epoch: 14 step: 18 loss: 0.6931475400924683\n",
      "epoch: 14 step: 19 loss: 0.6931475400924683\n",
      "epoch: 14 step: 20 loss: 0.6931475400924683\n",
      "epoch: 14 step: 21 loss: 0.6931475400924683\n",
      "epoch: 14 step: 22 loss: 0.6931475400924683\n",
      "epoch: 14 step: 23 loss: 0.6931475400924683\n",
      "epoch: 14 step: 24 loss: 0.6931475400924683\n",
      "epoch: 14 step: 25 loss: 0.6931475400924683\n",
      "epoch: 14 step: 26 loss: 0.6931475400924683\n",
      "epoch: 14 step: 27 loss: 0.6931475400924683\n",
      "epoch: 14 step: 28 loss: 0.6931475400924683\n",
      "epoch: 14 step: 29 loss: 0.6931475400924683\n",
      "epoch: 14 step: 30 loss: 0.6931475400924683\n",
      "epoch: 14 step: 31 loss: 0.6931475400924683\n",
      "epoch: 14 step: 32 loss: 0.6931475400924683\n",
      "epoch: 14 step: 33 loss: 0.6931475400924683\n",
      "epoch: 14 step: 34 loss: 0.6931475400924683\n",
      "epoch: 14 step: 35 loss: 0.6931475400924683\n",
      "epoch: 14 step: 36 loss: 0.6931475400924683\n",
      "epoch: 14 step: 37 loss: 0.6931475400924683\n",
      "epoch: 14 step: 38 loss: 0.6931475400924683\n",
      "epoch: 14 step: 39 loss: 0.6931475400924683\n",
      "epoch: 14 step: 40 loss: 0.6931475400924683\n",
      "epoch: 14 step: 41 loss: 0.6931475400924683\n",
      "epoch: 14 step: 42 loss: 0.6931475400924683\n",
      "epoch: 14 step: 43 loss: 0.6931475400924683\n",
      "epoch: 14 step: 44 loss: 0.6931475400924683\n",
      "epoch: 14 step: 45 loss: 0.6931475400924683\n",
      "epoch: 14 step: 46 loss: 0.6931475400924683\n",
      "epoch: 14 step: 47 loss: 0.6931475400924683\n",
      "epoch: 14 step: 48 loss: 0.6931475400924683\n",
      "epoch: 14 step: 49 loss: 0.6931475400924683\n",
      "epoch: 14 step: 50 loss: 0.6931475400924683\n",
      "epoch: 14 step: 51 loss: 0.6931475400924683\n",
      "epoch: 14 step: 52 loss: 0.6931475400924683\n",
      "epoch: 14 step: 53 loss: 0.6931475400924683\n",
      "epoch: 14 step: 54 loss: 0.6931475400924683\n",
      "epoch: 14 step: 55 loss: 0.6931475400924683\n",
      "epoch: 14 step: 56 loss: 0.6931475400924683\n",
      "epoch: 14 step: 57 loss: 0.6931475400924683\n",
      "epoch: 14 step: 58 loss: 0.6931475400924683\n",
      "epoch: 14 step: 59 loss: 0.6931475400924683\n",
      "epoch: 14 step: 60 loss: 0.6931475400924683\n",
      "epoch: 14 step: 61 loss: 0.6931475400924683\n",
      "epoch: 14 step: 62 loss: 0.6931475400924683\n",
      "epoch: 14 step: 63 loss: 0.6931475400924683\n",
      "epoch: 14 step: 64 loss: 0.6931475400924683\n",
      "epoch: 14 step: 65 loss: 0.6931475400924683\n",
      "epoch: 14 step: 66 loss: 0.6931475400924683\n",
      "epoch: 14 step: 67 loss: 0.6931475400924683\n",
      "epoch: 14 step: 68 loss: 0.6931475400924683\n",
      "epoch: 14 step: 69 loss: 0.6931475400924683\n",
      "epoch: 14 step: 70 loss: 0.6931475400924683\n",
      "epoch: 14 step: 71 loss: 0.6931475400924683\n",
      "epoch: 14 step: 72 loss: 0.6931475400924683\n",
      "epoch: 14 step: 73 loss: 0.6931475400924683\n",
      "epoch: 14 step: 74 loss: 0.6931475400924683\n",
      "epoch: 14 step: 75 loss: 0.6931475400924683\n",
      "epoch: 14 step: 76 loss: 0.6931475400924683\n",
      "epoch: 14 step: 77 loss: 0.6931475400924683\n",
      "epoch: 14 step: 78 loss: 0.6931475400924683\n",
      "epoch: 14 step: 79 loss: 0.6931475400924683\n",
      "epoch: 14 step: 80 loss: 0.6931475400924683\n",
      "epoch: 14 step: 81 loss: 0.6931475400924683\n",
      "epoch: 14 step: 82 loss: 0.6931475400924683\n",
      "epoch: 14 step: 83 loss: 0.6931475400924683\n",
      "epoch: 14 step: 84 loss: 0.6931475400924683\n",
      "epoch: 14 step: 85 loss: 0.6931475400924683\n",
      "epoch: 14 step: 86 loss: 0.6931475400924683\n",
      "epoch: 14 step: 87 loss: 0.6931475400924683\n",
      "epoch: 14 step: 88 loss: 0.6931475400924683\n",
      "epoch: 14 step: 89 loss: 0.6931475400924683\n",
      "epoch: 14 step: 90 loss: 0.6931475400924683\n",
      "epoch: 14 step: 91 loss: 0.6931475400924683\n",
      "epoch: 14 step: 92 loss: 0.6931475400924683\n",
      "epoch: 14 step: 93 loss: 0.6931475400924683\n",
      "epoch: 14 step: 94 loss: 0.6931475400924683\n",
      "epoch: 14 step: 95 loss: 0.6931475400924683\n",
      "epoch: 14 step: 96 loss: 0.6931475400924683\n",
      "epoch: 14 step: 97 loss: 0.6931475400924683\n",
      "epoch: 14 step: 98 loss: 0.6931475400924683\n",
      "epoch: 14 step: 99 loss: 0.6931475400924683\n",
      "epoch: 14 step: 100 loss: 0.6931475400924683\n",
      "epoch: 14 step: 101 loss: 0.6931475400924683\n",
      "epoch: 14 step: 102 loss: 0.6931475400924683\n",
      "epoch: 14 step: 103 loss: 0.6931475400924683\n",
      "epoch: 14 step: 104 loss: 0.6931475400924683\n",
      "epoch: 14 step: 105 loss: 0.6931475400924683\n",
      "epoch: 14 step: 106 loss: 0.6931475400924683\n",
      "epoch: 14 step: 107 loss: 0.6931475400924683\n",
      "epoch: 14 step: 108 loss: 0.6931475400924683\n",
      "epoch: 14 step: 109 loss: 0.6931475400924683\n",
      "epoch: 14 step: 110 loss: 0.6931475400924683\n",
      "epoch: 14 step: 111 loss: 0.6931475400924683\n",
      "epoch: 14 step: 112 loss: 0.6931475400924683\n",
      "epoch: 14 step: 113 loss: 0.6931475400924683\n",
      "epoch: 14 step: 114 loss: 0.6931475400924683\n",
      "epoch: 14 step: 115 loss: 0.6931475400924683\n",
      "epoch: 14 step: 116 loss: 0.6931475400924683\n",
      "epoch: 14 step: 117 loss: 0.6931475400924683\n",
      "epoch: 14 step: 118 loss: 0.6931475400924683\n",
      "epoch: 14 step: 119 loss: 0.6931475400924683\n",
      "epoch: 14 step: 120 loss: 0.6931475400924683\n",
      "epoch: 14 step: 121 loss: 0.6931475400924683\n",
      "epoch: 14 step: 122 loss: 0.6931475400924683\n",
      "epoch: 14 step: 123 loss: 0.6931475400924683\n",
      "epoch: 14 step: 124 loss: 0.6931475400924683\n",
      "epoch: 14 step: 125 loss: 0.6931475400924683\n",
      "epoch: 14 step: 126 loss: 0.6931475400924683\n",
      "epoch: 14 step: 127 loss: 0.6931475400924683\n",
      "epoch: 14 step: 128 loss: 0.6931475400924683\n",
      "epoch: 14 step: 129 loss: 0.6931475400924683\n",
      "epoch: 14 step: 130 loss: 0.6931475400924683\n",
      "epoch: 14 step: 131 loss: 0.6931475400924683\n",
      "epoch: 14 step: 132 loss: 0.6931475400924683\n",
      "epoch: 14 step: 133 loss: 0.6931475400924683\n",
      "epoch: 14 step: 134 loss: 0.6931475400924683\n",
      "epoch: 14 step: 135 loss: 0.6931475400924683\n",
      "epoch: 14 step: 136 loss: 0.6931475400924683\n",
      "epoch: 14 step: 137 loss: 0.6931475400924683\n",
      "epoch: 14 step: 138 loss: 0.6931475400924683\n",
      "epoch: 14 step: 139 loss: 0.6931475400924683\n",
      "epoch: 14 step: 140 loss: 0.6931475400924683\n",
      "epoch: 14 step: 141 loss: 0.6931475400924683\n",
      "epoch: 14 step: 142 loss: 0.6931475400924683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 143 loss: 0.6931475400924683\n",
      "epoch: 14 step: 144 loss: 0.6931475400924683\n",
      "epoch: 14 step: 145 loss: 0.6931475400924683\n",
      "epoch: 14 step: 146 loss: 0.6931475400924683\n",
      "epoch: 14 step: 147 loss: 0.6931475400924683\n",
      "epoch: 14 step: 148 loss: 0.6931475400924683\n",
      "epoch: 14 step: 149 loss: 0.6931475400924683\n",
      "epoch: 14 step: 150 loss: 0.6931475400924683\n",
      "epoch: 14 step: 151 loss: 0.6931475400924683\n",
      "epoch: 14 step: 152 loss: 0.6931475400924683\n",
      "epoch: 14 step: 153 loss: 0.6931475400924683\n",
      "epoch: 14 step: 154 loss: 0.6931475400924683\n",
      "epoch: 14 step: 155 loss: 0.6931475400924683\n",
      "epoch: 14 step: 156 loss: 0.6931475400924683\n",
      "epoch: 14 step: 157 loss: 0.6931475400924683\n",
      "epoch: 14 step: 158 loss: 0.6931475400924683\n",
      "epoch: 14 step: 159 loss: 0.6931475400924683\n",
      "epoch: 14 step: 160 loss: 0.6931475400924683\n",
      "epoch: 14 step: 161 loss: 0.6931475400924683\n",
      "epoch: 14 step: 162 loss: 0.6931475400924683\n",
      "epoch: 14 step: 163 loss: 0.6931475400924683\n",
      "epoch: 14 step: 164 loss: 0.6931475400924683\n",
      "epoch: 14 step: 165 loss: 0.6931475400924683\n",
      "epoch: 14 step: 166 loss: 0.6931475400924683\n",
      "epoch: 14 step: 167 loss: 0.6931475400924683\n",
      "epoch: 14 step: 168 loss: 0.6931475400924683\n",
      "epoch: 14 step: 169 loss: 0.6931475400924683\n",
      "epoch: 14 step: 170 loss: 0.6931475400924683\n",
      "epoch: 14 step: 171 loss: 0.6931475400924683\n",
      "epoch: 14 step: 172 loss: 0.6931475400924683\n",
      "epoch: 14 step: 173 loss: 0.6931475400924683\n",
      "epoch: 14 step: 174 loss: 0.6931475400924683\n",
      "epoch: 14 step: 175 loss: 0.6931475400924683\n",
      "epoch: 14 step: 176 loss: 0.6931475400924683\n",
      "epoch: 14 step: 177 loss: 0.6931475400924683\n",
      "epoch: 14 step: 178 loss: 0.6931475400924683\n",
      "epoch: 14 step: 179 loss: 0.6931475400924683\n",
      "epoch: 14 step: 180 loss: 0.6931475400924683\n",
      "epoch: 14 step: 181 loss: 0.6931475400924683\n",
      "epoch: 14 step: 182 loss: 0.6931475400924683\n",
      "epoch: 14 step: 183 loss: 0.6931475400924683\n",
      "epoch: 14 step: 184 loss: 0.6931475400924683\n",
      "epoch: 14 step: 185 loss: 0.6931475400924683\n",
      "epoch: 14 step: 186 loss: 0.6931475400924683\n",
      "epoch: 14 step: 187 loss: 0.6931475400924683\n",
      "epoch: 14 step: 188 loss: 0.6931475400924683\n",
      "epoch: 14 step: 189 loss: 0.6931475400924683\n",
      "epoch: 14 step: 190 loss: 0.6931475400924683\n",
      "epoch: 14 step: 191 loss: 0.6931475400924683\n",
      "epoch: 14 step: 192 loss: 0.6931475400924683\n",
      "epoch: 14 step: 193 loss: 0.6931475400924683\n",
      "epoch: 14 step: 194 loss: 0.6931475400924683\n",
      "epoch: 14 step: 195 loss: 0.6931475400924683\n",
      "epoch: 14 step: 196 loss: 0.6931475400924683\n",
      "epoch: 14 step: 197 loss: 0.6931475400924683\n",
      "epoch: 14 step: 198 loss: 0.6931475400924683\n",
      "epoch: 14 step: 199 loss: 0.6931475400924683\n",
      "epoch: 14 step: 200 loss: 0.6931475400924683\n",
      "epoch: 14 step: 201 loss: 0.6931475400924683\n",
      "epoch: 14 step: 202 loss: 0.6931475400924683\n",
      "epoch: 14 step: 203 loss: 0.6931475400924683\n",
      "epoch: 14 step: 204 loss: 0.6931475400924683\n",
      "epoch: 14 step: 205 loss: 0.6931475400924683\n",
      "epoch: 14 step: 206 loss: 0.6931475400924683\n",
      "epoch: 14 step: 207 loss: 0.6931475400924683\n",
      "epoch: 14 step: 208 loss: 0.6931475400924683\n",
      "epoch: 14 step: 209 loss: 0.6931475400924683\n",
      "epoch: 14 step: 210 loss: 0.6931475400924683\n",
      "epoch: 14 step: 211 loss: 0.6931475400924683\n",
      "epoch: 14 step: 212 loss: 0.6931475400924683\n",
      "epoch: 14 step: 213 loss: 0.6931475400924683\n",
      "epoch: 14 step: 214 loss: 0.6931475400924683\n",
      "epoch: 14 step: 215 loss: 0.6931475400924683\n",
      "epoch: 14 step: 216 loss: 0.6931475400924683\n",
      "epoch: 14 step: 217 loss: 0.6931475400924683\n",
      "epoch: 14 step: 218 loss: 0.6931475400924683\n",
      "epoch: 14 step: 219 loss: 0.6931475400924683\n",
      "epoch: 14 step: 220 loss: 0.6931475400924683\n",
      "epoch: 14 step: 221 loss: 0.6931475400924683\n",
      "epoch: 14 step: 222 loss: 0.6931475400924683\n",
      "epoch: 14 step: 223 loss: 0.6931475400924683\n",
      "epoch: 14 step: 224 loss: 0.6931475400924683\n",
      "epoch: 14 step: 225 loss: 0.6931475400924683\n",
      "epoch: 14 step: 226 loss: 0.6931475400924683\n",
      "epoch: 14 step: 227 loss: 0.6931475400924683\n",
      "epoch: 14 step: 228 loss: 0.6931475400924683\n",
      "epoch: 14 step: 229 loss: 0.6931475400924683\n",
      "epoch: 14 step: 230 loss: 0.6931475400924683\n",
      "epoch: 14 step: 231 loss: 0.6931475400924683\n",
      "epoch: 14 step: 232 loss: 0.6931475400924683\n",
      "epoch: 14 step: 233 loss: 0.6931475400924683\n",
      "epoch: 14 step: 234 loss: 0.6931475400924683\n",
      "epoch: 14 step: 235 loss: 0.6931475400924683\n",
      "epoch: 14 step: 236 loss: 0.6931475400924683\n",
      "epoch: 14 step: 237 loss: 0.6931475400924683\n",
      "epoch: 14 step: 238 loss: 0.6931475400924683\n",
      "epoch: 14 step: 239 loss: 0.6931475400924683\n",
      "epoch: 14 step: 240 loss: 0.6931475400924683\n",
      "epoch: 14 step: 241 loss: 0.6931475400924683\n",
      "epoch: 14 step: 242 loss: 0.6931475400924683\n",
      "epoch: 14 step: 243 loss: 0.6931475400924683\n",
      "epoch: 14 step: 244 loss: 0.6931475400924683\n",
      "epoch: 14 step: 245 loss: 0.6931475400924683\n",
      "epoch: 14 step: 246 loss: 0.6931475400924683\n",
      "epoch: 14 step: 247 loss: 0.6931475400924683\n",
      "epoch: 14 step: 248 loss: 0.6931475400924683\n",
      "epoch: 14 step: 249 loss: 0.6931475400924683\n",
      "epoch: 14 step: 250 loss: 0.6931475400924683\n",
      "epoch: 14 step: 251 loss: 0.6931475400924683\n",
      "epoch: 14 step: 252 loss: 0.6931475400924683\n",
      "epoch: 14 step: 253 loss: 0.6931475400924683\n",
      "epoch: 14 step: 254 loss: 0.6931475400924683\n",
      "epoch: 14 step: 255 loss: 0.6931475400924683\n",
      "epoch: 14 step: 256 loss: 0.6931475400924683\n",
      "epoch: 14 step: 257 loss: 0.6931475400924683\n",
      "epoch: 14 step: 258 loss: 0.6931475400924683\n",
      "epoch: 14 step: 259 loss: 0.6931475400924683\n",
      "epoch: 14 step: 260 loss: 0.6931475400924683\n",
      "epoch: 14 step: 261 loss: 0.6931475400924683\n",
      "epoch: 14 step: 262 loss: 0.6931475400924683\n",
      "epoch: 14 step: 263 loss: 0.6931475400924683\n",
      "epoch: 14 step: 264 loss: 0.6931475400924683\n",
      "epoch: 14 step: 265 loss: 0.6931475400924683\n",
      "epoch: 14 step: 266 loss: 0.6931475400924683\n",
      "epoch: 14 step: 267 loss: 0.6931475400924683\n",
      "epoch: 14 step: 268 loss: 0.6931475400924683\n",
      "epoch: 14 step: 269 loss: 0.6931475400924683\n",
      "epoch: 14 step: 270 loss: 0.6931475400924683\n",
      "epoch: 14 step: 271 loss: 0.6931475400924683\n",
      "epoch: 14 step: 272 loss: 0.6931475400924683\n",
      "epoch: 14 step: 273 loss: 0.6931475400924683\n",
      "epoch: 14 step: 274 loss: 0.6931475400924683\n",
      "epoch: 14 step: 275 loss: 0.6931475400924683\n",
      "epoch: 14 step: 276 loss: 0.6931475400924683\n",
      "epoch: 14 step: 277 loss: 0.6931475400924683\n",
      "epoch: 14 step: 278 loss: 0.6931475400924683\n",
      "epoch: 14 step: 279 loss: 0.6931475400924683\n",
      "epoch: 14 step: 280 loss: 0.6931475400924683\n",
      "epoch: 14 step: 281 loss: 0.6931475400924683\n",
      "epoch: 14 step: 282 loss: 0.6931475400924683\n",
      "epoch: 14 step: 283 loss: 0.6931475400924683\n",
      "epoch: 14 step: 284 loss: 0.6931475400924683\n",
      "epoch: 14 step: 285 loss: 0.6931475400924683\n",
      "epoch: 14 step: 286 loss: 0.6931475400924683\n",
      "epoch: 14 step: 287 loss: 0.6931475400924683\n",
      "epoch: 14 step: 288 loss: 0.6931475400924683\n",
      "epoch: 14 step: 289 loss: 0.6931475400924683\n",
      "epoch: 14 step: 290 loss: 0.6931475400924683\n",
      "epoch: 14 step: 291 loss: 0.6931475400924683\n",
      "epoch: 14 step: 292 loss: 0.6931475400924683\n",
      "epoch: 14 step: 293 loss: 0.6931475400924683\n",
      "epoch: 14 step: 294 loss: 0.6931475400924683\n",
      "epoch: 14 step: 295 loss: 0.6931475400924683\n",
      "epoch: 14 step: 296 loss: 0.6931475400924683\n",
      "epoch: 14 step: 297 loss: 0.6931475400924683\n",
      "epoch: 14 step: 298 loss: 0.6931475400924683\n",
      "epoch: 14 step: 299 loss: 0.6931475400924683\n",
      "epoch: 14 step: 300 loss: 0.6931475400924683\n",
      "epoch: 14 step: 301 loss: 0.6931475400924683\n",
      "epoch: 14 step: 302 loss: 0.6931475400924683\n",
      "epoch: 14 step: 303 loss: 0.6931475400924683\n",
      "epoch: 14 step: 304 loss: 0.6931475400924683\n",
      "epoch: 14 step: 305 loss: 0.6931475400924683\n",
      "epoch: 14 step: 306 loss: 0.6931475400924683\n",
      "epoch: 14 step: 307 loss: 0.6931475400924683\n",
      "epoch: 14 step: 308 loss: 0.6931475400924683\n",
      "epoch: 14 step: 309 loss: 0.6931475400924683\n",
      "epoch: 14 step: 310 loss: 0.6931475400924683\n",
      "epoch: 14 step: 311 loss: 0.6931475400924683\n",
      "epoch: 14 step: 312 loss: 0.6931475400924683\n",
      "epoch: 14 step: 313 loss: 0.6931475400924683\n",
      "epoch: 14 step: 314 loss: 0.6931475400924683\n",
      "epoch: 14 step: 315 loss: 0.6931475400924683\n",
      "epoch: 14 step: 316 loss: 0.6931475400924683\n",
      "epoch: 14 step: 317 loss: 0.6931475400924683\n",
      "epoch: 14 step: 318 loss: 0.6931475400924683\n",
      "epoch: 14 step: 319 loss: 0.6931475400924683\n",
      "epoch: 14 step: 320 loss: 0.6931475400924683\n",
      "epoch: 14 step: 321 loss: 0.6931475400924683\n",
      "epoch: 14 step: 322 loss: 0.6931475400924683\n",
      "epoch: 14 step: 323 loss: 0.6931475400924683\n",
      "epoch: 14 step: 324 loss: 0.6931475400924683\n",
      "epoch: 14 step: 325 loss: 0.6931475400924683\n",
      "epoch: 14 step: 326 loss: 0.6931475400924683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 327 loss: 0.6931475400924683\n",
      "epoch: 14 step: 328 loss: 0.6931475400924683\n",
      "epoch: 14 step: 329 loss: 0.6931475400924683\n",
      "epoch: 14 step: 330 loss: 0.6931475400924683\n",
      "epoch: 14 step: 331 loss: 0.6931475400924683\n",
      "epoch: 14 step: 332 loss: 0.6931475400924683\n",
      "epoch: 14 step: 333 loss: 0.6931475400924683\n",
      "epoch: 14 step: 334 loss: 0.6931475400924683\n",
      "epoch: 14 step: 335 loss: 0.6931475400924683\n",
      "epoch: 14 step: 336 loss: 0.6931475400924683\n",
      "epoch: 14 step: 337 loss: 0.6931475400924683\n",
      "epoch: 14 step: 338 loss: 0.6931475400924683\n",
      "epoch: 14 step: 339 loss: 0.6931475400924683\n",
      "epoch: 14 step: 340 loss: 0.6931475400924683\n",
      "epoch: 14 step: 341 loss: 0.6931475400924683\n",
      "epoch: 14 step: 342 loss: 0.6931475400924683\n",
      "epoch: 14 step: 343 loss: 0.6931475400924683\n",
      "epoch: 14 step: 344 loss: 0.6931475400924683\n",
      "epoch: 14 step: 345 loss: 0.6931474804878235\n",
      "epoch: 14 step: 346 loss: 0.6931475400924683\n",
      "epoch: 14 step: 347 loss: 0.6931475400924683\n",
      "epoch: 14 step: 348 loss: 0.6931475400924683\n",
      "epoch: 14 step: 349 loss: 0.6931475400924683\n",
      "epoch: 14 step: 350 loss: 0.6931475400924683\n",
      "epoch: 14 step: 351 loss: 0.6931475400924683\n",
      "epoch: 14 step: 352 loss: 0.6931475400924683\n",
      "epoch: 14 step: 353 loss: 0.6931475400924683\n",
      "epoch: 14 step: 354 loss: 0.6931475400924683\n",
      "epoch: 14 step: 355 loss: 0.6931474804878235\n",
      "epoch: 14 step: 356 loss: 0.6931475400924683\n",
      "epoch: 14 step: 357 loss: 0.6931475400924683\n",
      "epoch: 14 step: 358 loss: 0.6931475400924683\n",
      "epoch: 14 step: 359 loss: 0.6931475400924683\n",
      "epoch: 14 step: 360 loss: 0.6931474804878235\n",
      "epoch: 14 step: 361 loss: 0.6931475400924683\n",
      "epoch: 14 step: 362 loss: 0.6931475400924683\n",
      "epoch: 14 step: 363 loss: 0.6931474804878235\n",
      "epoch: 14 step: 364 loss: 0.6931475400924683\n",
      "epoch: 14 step: 365 loss: 0.6931475400924683\n",
      "epoch: 14 step: 366 loss: 0.6931475400924683\n",
      "epoch: 14 step: 367 loss: 0.6931474804878235\n",
      "epoch: 14 step: 368 loss: 0.6931475400924683\n",
      "epoch: 14 step: 369 loss: 0.6931475400924683\n",
      "epoch: 14 step: 370 loss: 0.6931474804878235\n",
      "epoch: 14 step: 371 loss: 0.6931475400924683\n",
      "epoch: 14 step: 372 loss: 0.6931475400924683\n",
      "epoch: 14 step: 373 loss: 0.6931475400924683\n",
      "epoch: 14 step: 374 loss: 0.6931475400924683\n",
      "epoch: 14 step: 375 loss: 0.6931475400924683\n",
      "epoch: 14 step: 376 loss: 0.6931474804878235\n",
      "epoch: 14 step: 377 loss: 0.6931475400924683\n",
      "epoch: 14 step: 378 loss: 0.6931475400924683\n",
      "epoch: 14 step: 379 loss: 0.6931474804878235\n",
      "epoch: 14 step: 380 loss: 0.6931475400924683\n",
      "epoch: 14 step: 381 loss: 0.6931474804878235\n",
      "epoch: 14 step: 382 loss: 0.6931474804878235\n",
      "epoch: 14 step: 383 loss: 0.6931474804878235\n",
      "epoch: 14 step: 384 loss: 0.6931474804878235\n",
      "epoch: 14 step: 385 loss: 0.6931475400924683\n",
      "epoch: 14 step: 386 loss: 0.6931474804878235\n",
      "epoch: 14 step: 387 loss: 0.6931474804878235\n",
      "epoch: 14 step: 388 loss: 0.6931474804878235\n",
      "epoch: 14 step: 389 loss: 0.6931475400924683\n",
      "epoch: 14 step: 390 loss: 0.6931475400924683\n",
      "epoch: 14 step: 391 loss: 0.6931475400924683\n",
      "epoch: 14 step: 392 loss: 0.6931474804878235\n",
      "epoch: 14 step: 393 loss: 0.6931475400924683\n",
      "epoch: 14 step: 394 loss: 0.6931474804878235\n",
      "epoch: 14 step: 395 loss: 0.6931474804878235\n",
      "epoch: 14 step: 396 loss: 0.6931475400924683\n",
      "epoch: 14 step: 397 loss: 0.6931474804878235\n",
      "epoch: 14 step: 398 loss: 0.6931475400924683\n",
      "epoch: 14 step: 399 loss: 0.6931474804878235\n",
      "epoch: 14 step: 400 loss: 0.6931474804878235\n",
      "epoch: 14 step: 401 loss: 0.6931474804878235\n",
      "epoch: 14 step: 402 loss: 0.6931474804878235\n",
      "epoch: 14 step: 403 loss: 0.6931474804878235\n",
      "epoch: 14 step: 404 loss: 0.6931475400924683\n",
      "epoch: 14 step: 405 loss: 0.6931474804878235\n",
      "epoch: 14 step: 406 loss: 0.6931475400924683\n",
      "epoch: 14 step: 407 loss: 0.6931474804878235\n",
      "epoch: 14 step: 408 loss: 0.6931474804878235\n",
      "epoch: 14 step: 409 loss: 0.6931475400924683\n",
      "epoch: 14 step: 410 loss: 0.6931474804878235\n",
      "epoch: 14 step: 411 loss: 0.6931474804878235\n",
      "epoch: 14 step: 412 loss: 0.6931474804878235\n",
      "epoch: 14 step: 413 loss: 0.6931474804878235\n",
      "epoch: 14 step: 414 loss: 0.6931474804878235\n",
      "epoch: 14 step: 415 loss: 0.6931474804878235\n",
      "epoch: 14 step: 416 loss: 0.6931475400924683\n",
      "epoch: 14 step: 417 loss: 0.6931474804878235\n",
      "epoch: 14 step: 418 loss: 0.6931474804878235\n",
      "epoch: 14 step: 419 loss: 0.6931474804878235\n",
      "epoch: 14 step: 420 loss: 0.6931474804878235\n",
      "epoch: 14 step: 421 loss: 0.6931475400924683\n",
      "epoch: 14 step: 422 loss: 0.6931475400924683\n",
      "epoch: 14 step: 423 loss: 0.6931474804878235\n",
      "epoch: 14 step: 424 loss: 0.6931474804878235\n",
      "epoch: 14 step: 425 loss: 0.6931475400924683\n",
      "epoch: 14 step: 426 loss: 0.6931474804878235\n",
      "epoch: 14 step: 427 loss: 0.6931474804878235\n",
      "epoch: 14 step: 428 loss: 0.6931474804878235\n",
      "epoch: 14 step: 429 loss: 0.6931474804878235\n",
      "epoch: 14 step: 430 loss: 0.6931475400924683\n",
      "epoch: 14 step: 431 loss: 0.6931474804878235\n",
      "epoch: 14 step: 432 loss: 0.6931474804878235\n",
      "epoch: 14 step: 433 loss: 0.6931474804878235\n",
      "epoch: 14 step: 434 loss: 0.6931474804878235\n",
      "epoch: 14 step: 435 loss: 0.6931474804878235\n",
      "epoch: 14 step: 436 loss: 0.6931474804878235\n",
      "epoch: 14 step: 437 loss: 0.6931474804878235\n",
      "epoch: 14 step: 438 loss: 0.6931475400924683\n",
      "epoch: 14 step: 439 loss: 0.6931474804878235\n",
      "epoch: 14 step: 440 loss: 0.6931474804878235\n",
      "epoch: 14 step: 441 loss: 0.6931475400924683\n",
      "epoch: 14 step: 442 loss: 0.6931474804878235\n",
      "epoch: 14 step: 443 loss: 0.6931474804878235\n",
      "epoch: 14 step: 444 loss: 0.6931474804878235\n",
      "epoch: 14 step: 445 loss: 0.6931475400924683\n",
      "epoch: 14 step: 446 loss: 0.6931475400924683\n",
      "epoch: 14 step: 447 loss: 0.6931474804878235\n",
      "epoch: 14 step: 448 loss: 0.6931474804878235\n",
      "epoch: 14 step: 449 loss: 0.6931474804878235\n",
      "epoch: 14 step: 450 loss: 0.6931474804878235\n",
      "epoch: 14 step: 451 loss: 0.6931475400924683\n",
      "epoch: 14 step: 452 loss: 0.6931474804878235\n",
      "epoch: 14 step: 453 loss: 0.6931474804878235\n",
      "epoch: 14 step: 454 loss: 0.6931474804878235\n",
      "epoch: 14 step: 455 loss: 0.6931474804878235\n",
      "epoch: 14 step: 456 loss: 0.6931474804878235\n",
      "epoch: 14 step: 457 loss: 0.6931474804878235\n",
      "epoch: 14 step: 458 loss: 0.6931474804878235\n",
      "epoch: 14 step: 459 loss: 0.6931474804878235\n",
      "epoch: 14 step: 460 loss: 0.6931475400924683\n",
      "epoch: 14 step: 461 loss: 0.6931474804878235\n",
      "epoch: 14 step: 462 loss: 0.6931474804878235\n",
      "epoch: 14 step: 463 loss: 0.6931474804878235\n",
      "epoch: 14 step: 464 loss: 0.6931474804878235\n",
      "epoch: 14 step: 465 loss: 0.6931474804878235\n",
      "epoch: 14 step: 466 loss: 0.6931475400924683\n",
      "epoch: 14 step: 467 loss: 0.6931474804878235\n",
      "epoch: 14 step: 468 loss: 0.6931474804878235\n",
      "epoch: 14 step: 469 loss: 0.6931474804878235\n",
      "epoch: 14 step: 470 loss: 0.6931475400924683\n",
      "epoch: 14 step: 471 loss: 0.6931474804878235\n",
      "epoch: 14 step: 472 loss: 0.6931474804878235\n",
      "epoch: 14 step: 473 loss: 0.6931474804878235\n",
      "epoch: 14 step: 474 loss: 0.6931474804878235\n",
      "epoch: 14 step: 475 loss: 0.6931474804878235\n",
      "epoch: 14 step: 476 loss: 0.6931474804878235\n",
      "epoch: 14 step: 477 loss: 0.6931474804878235\n",
      "epoch: 14 step: 478 loss: 0.6931474804878235\n",
      "epoch: 14 step: 479 loss: 0.6931474804878235\n",
      "epoch: 14 step: 480 loss: 0.6931474804878235\n",
      "epoch: 14 step: 481 loss: 0.6931474804878235\n",
      "epoch: 14 step: 482 loss: 0.6931474804878235\n",
      "epoch: 14 step: 483 loss: 0.6931474804878235\n",
      "epoch: 14 step: 484 loss: 0.6931474804878235\n",
      "epoch: 14 step: 485 loss: 0.6931474804878235\n",
      "epoch: 14 step: 486 loss: 0.6931474804878235\n",
      "epoch: 14 step: 487 loss: 0.6931474804878235\n",
      "epoch: 14 step: 488 loss: 0.6931474804878235\n",
      "epoch: 14 step: 489 loss: 0.6931474804878235\n",
      "epoch: 14 step: 490 loss: 0.6931475400924683\n",
      "epoch: 14 step: 491 loss: 0.6931474804878235\n",
      "epoch: 14 step: 492 loss: 0.6931474804878235\n",
      "epoch: 14 step: 493 loss: 0.6931474804878235\n",
      "epoch: 14 step: 494 loss: 0.6931474804878235\n",
      "epoch: 14 step: 495 loss: 0.6931475400924683\n",
      "epoch: 14 step: 496 loss: 0.6931474804878235\n",
      "epoch: 14 step: 497 loss: 0.6931474804878235\n",
      "epoch: 14 step: 498 loss: 0.6931474804878235\n",
      "epoch: 14 step: 499 loss: 0.6931474804878235\n",
      "epoch: 14 step: 500 loss: 0.6931474804878235\n",
      "epoch: 14 step: 501 loss: 0.6931474804878235\n",
      "epoch: 14 step: 502 loss: 0.6931474804878235\n",
      "epoch: 14 step: 503 loss: 0.6931474804878235\n",
      "epoch: 14 step: 504 loss: 0.6931474804878235\n",
      "epoch: 14 step: 505 loss: 0.6931474804878235\n",
      "epoch: 14 step: 506 loss: 0.6931474804878235\n",
      "epoch: 14 step: 507 loss: 0.6931474804878235\n",
      "epoch: 14 step: 508 loss: 0.6931474804878235\n",
      "epoch: 14 step: 509 loss: 0.6931474804878235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 510 loss: 0.6931474804878235\n",
      "epoch: 14 step: 511 loss: 0.6931474804878235\n",
      "epoch: 14 step: 512 loss: 0.6931474804878235\n",
      "epoch: 14 step: 513 loss: 0.6931474804878235\n",
      "epoch: 14 step: 514 loss: 0.6931474804878235\n",
      "epoch: 14 step: 515 loss: 0.6931474804878235\n",
      "epoch: 14 step: 516 loss: 0.6931474804878235\n",
      "epoch: 14 step: 517 loss: 0.6931474804878235\n",
      "epoch: 14 step: 518 loss: 0.6931474804878235\n",
      "epoch: 14 step: 519 loss: 0.6931474804878235\n",
      "epoch: 14 step: 520 loss: 0.6931474804878235\n",
      "epoch: 14 step: 521 loss: 0.6931474804878235\n",
      "epoch: 14 step: 522 loss: 0.6931474804878235\n",
      "epoch: 14 step: 523 loss: 0.6931474804878235\n",
      "epoch: 14 step: 524 loss: 0.6931474804878235\n",
      "epoch: 14 step: 525 loss: 0.6931474804878235\n",
      "epoch: 14 step: 526 loss: 0.6931474804878235\n",
      "epoch: 14 step: 527 loss: 0.6931474804878235\n",
      "epoch: 14 step: 528 loss: 0.6931474804878235\n",
      "epoch: 14 step: 529 loss: 0.6931474804878235\n",
      "epoch: 14 step: 530 loss: 0.6931474804878235\n",
      "epoch: 14 step: 531 loss: 0.6931474804878235\n",
      "epoch: 14 step: 532 loss: 0.6931474804878235\n",
      "epoch: 14 step: 533 loss: 0.6931474804878235\n",
      "epoch: 14 step: 534 loss: 0.6931474804878235\n",
      "epoch: 14 step: 535 loss: 0.6931474804878235\n",
      "epoch: 14 step: 536 loss: 0.6931474804878235\n",
      "epoch: 14 step: 537 loss: 0.6931474804878235\n",
      "epoch: 14 step: 538 loss: 0.6931474804878235\n",
      "epoch: 14 step: 539 loss: 0.6931474804878235\n",
      "epoch: 14 step: 540 loss: 0.6931474804878235\n",
      "epoch: 14 step: 541 loss: 0.6931474804878235\n",
      "epoch: 14 step: 542 loss: 0.6931474804878235\n",
      "epoch: 14 step: 543 loss: 0.6931474804878235\n",
      "epoch: 14 step: 544 loss: 0.6931474804878235\n",
      "epoch: 14 step: 545 loss: 0.6931474804878235\n",
      "epoch: 14 step: 546 loss: 0.6931475400924683\n",
      "epoch: 14 step: 547 loss: 0.6931474804878235\n",
      "epoch: 14 step: 548 loss: 0.6931474804878235\n",
      "epoch: 14 step: 549 loss: 0.6931474804878235\n",
      "epoch: 14 step: 550 loss: 0.6931474804878235\n",
      "epoch: 14 step: 551 loss: 0.6931474804878235\n",
      "epoch: 14 step: 552 loss: 0.6931474804878235\n",
      "epoch: 14 step: 553 loss: 0.6931474804878235\n",
      "epoch: 14 step: 554 loss: 0.6931474804878235\n",
      "epoch: 14 step: 555 loss: 0.6931474804878235\n",
      "epoch: 14 step: 556 loss: 0.6931474804878235\n",
      "epoch: 14 step: 557 loss: 0.6931474804878235\n",
      "epoch: 14 step: 558 loss: 0.6931474804878235\n",
      "epoch: 14 step: 559 loss: 0.6931474804878235\n",
      "epoch: 14 step: 560 loss: 0.6931474804878235\n",
      "epoch: 14 step: 561 loss: 0.6931474804878235\n",
      "epoch: 14 step: 562 loss: 0.6931474804878235\n",
      "epoch: 14 step: 563 loss: 0.6931474804878235\n",
      "epoch: 14 step: 564 loss: 0.6931474804878235\n",
      "epoch: 14 step: 565 loss: 0.6931474804878235\n",
      "epoch: 14 step: 566 loss: 0.6931474804878235\n",
      "epoch: 14 step: 567 loss: 0.6931474804878235\n",
      "epoch: 14 step: 568 loss: 0.6931474804878235\n",
      "epoch: 14 step: 569 loss: 0.6931474804878235\n",
      "epoch: 14 step: 570 loss: 0.6931474804878235\n",
      "epoch: 14 step: 571 loss: 0.6931474804878235\n",
      "epoch: 14 step: 572 loss: 0.6931474804878235\n",
      "epoch: 14 step: 573 loss: 0.6931474804878235\n",
      "epoch: 14 step: 574 loss: 0.6931474804878235\n",
      "epoch: 14 step: 575 loss: 0.6931474804878235\n",
      "epoch: 14 step: 576 loss: 0.6931474804878235\n",
      "epoch: 14 step: 577 loss: 0.6931474804878235\n",
      "epoch: 14 step: 578 loss: 0.6931474804878235\n",
      "epoch: 14 step: 579 loss: 0.6931474804878235\n",
      "epoch: 14 step: 580 loss: 0.6931474804878235\n",
      "epoch: 14 step: 581 loss: 0.6931474804878235\n",
      "epoch: 14 step: 582 loss: 0.6931474804878235\n",
      "epoch: 14 step: 583 loss: 0.6931474804878235\n",
      "epoch: 14 step: 584 loss: 0.6931474804878235\n",
      "epoch: 14 step: 585 loss: 0.6931474804878235\n",
      "epoch: 14 step: 586 loss: 0.6931474804878235\n",
      "epoch: 14 step: 587 loss: 0.6931474804878235\n",
      "epoch: 14 step: 588 loss: 0.6931474804878235\n",
      "epoch: 14 step: 589 loss: 0.6931474804878235\n",
      "epoch: 14 step: 590 loss: 0.6931474804878235\n",
      "epoch: 14 step: 591 loss: 0.6931474804878235\n",
      "epoch: 14 step: 592 loss: 0.6931474804878235\n",
      "epoch: 14 step: 593 loss: 0.6931474804878235\n",
      "epoch: 14 step: 594 loss: 0.6931474804878235\n",
      "epoch: 14 step: 595 loss: 0.6931474804878235\n",
      "epoch: 14 step: 596 loss: 0.6931474804878235\n",
      "epoch: 14 step: 597 loss: 0.6931474804878235\n",
      "epoch: 14 step: 598 loss: 0.6931474804878235\n",
      "epoch: 14 step: 599 loss: 0.6931474804878235\n",
      "epoch: 14 step: 600 loss: 0.6931474804878235\n",
      "epoch: 14 step: 601 loss: 0.6931474804878235\n",
      "epoch: 14 step: 602 loss: 0.6931474804878235\n",
      "epoch: 14 step: 603 loss: 0.6931474804878235\n",
      "epoch: 14 step: 604 loss: 0.6931474804878235\n",
      "epoch: 14 step: 605 loss: 0.6931474804878235\n",
      "epoch: 14 step: 606 loss: 0.6931474804878235\n",
      "epoch: 14 step: 607 loss: 0.6931474804878235\n",
      "epoch: 14 step: 608 loss: 0.6931474804878235\n",
      "epoch: 14 step: 609 loss: 0.6931474804878235\n",
      "epoch: 14 step: 610 loss: 0.6931474804878235\n",
      "epoch: 14 step: 611 loss: 0.6931474804878235\n",
      "epoch: 14 step: 612 loss: 0.6931474804878235\n",
      "epoch: 14 step: 613 loss: 0.6931474804878235\n",
      "epoch: 14 step: 614 loss: 0.6931474804878235\n",
      "epoch: 14 step: 615 loss: 0.6931474804878235\n",
      "epoch: 14 step: 616 loss: 0.6931474804878235\n",
      "epoch: 14 step: 617 loss: 0.6931474804878235\n",
      "epoch: 14 step: 618 loss: 0.6931474804878235\n",
      "epoch: 14 step: 619 loss: 0.6931474804878235\n",
      "epoch: 14 step: 620 loss: 0.6931474804878235\n",
      "epoch: 14 step: 621 loss: 0.6931474804878235\n",
      "epoch: 14 step: 622 loss: 0.6931474208831787\n",
      "epoch: 14 step: 623 loss: 0.6931474804878235\n",
      "epoch: 14 step: 624 loss: 0.6931474804878235\n",
      "epoch: 14 step: 625 loss: 0.6931474804878235\n",
      "epoch: 14 step: 626 loss: 0.6931474804878235\n",
      "epoch: 14 step: 627 loss: 0.6931474804878235\n",
      "epoch: 14 step: 628 loss: 0.6931474208831787\n",
      "epoch: 14 step: 629 loss: 0.6931474208831787\n",
      "epoch: 14 step: 630 loss: 0.6931474804878235\n",
      "epoch: 14 step: 631 loss: 0.6931474804878235\n",
      "epoch: 14 step: 632 loss: 0.6931474804878235\n",
      "epoch: 14 step: 633 loss: 0.6931474804878235\n",
      "epoch: 14 step: 634 loss: 0.6931474804878235\n",
      "epoch: 14 step: 635 loss: 0.6931474804878235\n",
      "epoch: 14 step: 636 loss: 0.6931474804878235\n",
      "epoch: 14 step: 637 loss: 0.6931474208831787\n",
      "epoch: 14 step: 638 loss: 0.6931474208831787\n",
      "epoch: 14 step: 639 loss: 0.6931474208831787\n",
      "epoch: 14 step: 640 loss: 0.6931474804878235\n",
      "epoch: 14 step: 641 loss: 0.6931474804878235\n",
      "epoch: 14 step: 642 loss: 0.6931474804878235\n",
      "epoch: 14 step: 643 loss: 0.6931474804878235\n",
      "epoch: 14 step: 644 loss: 0.6931474804878235\n",
      "epoch: 14 step: 645 loss: 0.6931474804878235\n",
      "epoch: 14 step: 646 loss: 0.6931474208831787\n",
      "epoch: 14 step: 647 loss: 0.6931474804878235\n",
      "epoch: 14 step: 648 loss: 0.6931474804878235\n",
      "epoch: 14 step: 649 loss: 0.6931474804878235\n",
      "epoch: 14 step: 650 loss: 0.6931474804878235\n",
      "epoch: 14 step: 651 loss: 0.6931474804878235\n",
      "epoch: 14 step: 652 loss: 0.6931474208831787\n",
      "epoch: 14 step: 653 loss: 0.6931474804878235\n",
      "epoch: 14 step: 654 loss: 0.6931474208831787\n",
      "epoch: 14 step: 655 loss: 0.6931474804878235\n",
      "epoch: 14 step: 656 loss: 0.6931474804878235\n",
      "epoch: 14 step: 657 loss: 0.6931474804878235\n",
      "epoch: 14 step: 658 loss: 0.6931474804878235\n",
      "epoch: 14 step: 659 loss: 0.6931474804878235\n",
      "epoch: 14 step: 660 loss: 0.6931474804878235\n",
      "epoch: 14 step: 661 loss: 0.6931474208831787\n",
      "epoch: 14 step: 662 loss: 0.6931474804878235\n",
      "epoch: 14 step: 663 loss: 0.6931474804878235\n",
      "epoch: 14 step: 664 loss: 0.6931474804878235\n",
      "epoch: 14 step: 665 loss: 0.6931474208831787\n",
      "epoch: 14 step: 666 loss: 0.6931474804878235\n",
      "epoch: 14 step: 667 loss: 0.6931474208831787\n",
      "epoch: 14 step: 668 loss: 0.6931474208831787\n",
      "epoch: 14 step: 669 loss: 0.6931474208831787\n",
      "epoch: 14 step: 670 loss: 0.6931474804878235\n",
      "epoch: 14 step: 671 loss: 0.6931474208831787\n",
      "epoch: 14 step: 672 loss: 0.6931474208831787\n",
      "epoch: 14 step: 673 loss: 0.6931474208831787\n",
      "epoch: 14 step: 674 loss: 0.6931474804878235\n",
      "epoch: 14 step: 675 loss: 0.6931474208831787\n",
      "epoch: 14 step: 676 loss: 0.6931474208831787\n",
      "epoch: 14 step: 677 loss: 0.6931474208831787\n",
      "epoch: 14 step: 678 loss: 0.6931474804878235\n",
      "epoch: 14 step: 679 loss: 0.6931474208831787\n",
      "epoch: 14 step: 680 loss: 0.6931474208831787\n",
      "epoch: 14 step: 681 loss: 0.6931474208831787\n",
      "epoch: 14 step: 682 loss: 0.6931474208831787\n",
      "epoch: 14 step: 683 loss: 0.6931474804878235\n",
      "epoch: 14 step: 684 loss: 0.6931474208831787\n",
      "epoch: 14 step: 685 loss: 0.6931474208831787\n",
      "epoch: 14 step: 686 loss: 0.6931474804878235\n",
      "epoch: 14 step: 687 loss: 0.6931474208831787\n",
      "epoch: 14 step: 688 loss: 0.6931474804878235\n",
      "epoch: 14 step: 689 loss: 0.6931474804878235\n",
      "epoch: 14 step: 690 loss: 0.6931474208831787\n",
      "epoch: 14 step: 691 loss: 0.6931474804878235\n",
      "epoch: 14 step: 692 loss: 0.6931474208831787\n",
      "epoch: 14 step: 693 loss: 0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 694 loss: 0.6931474208831787\n",
      "epoch: 14 step: 695 loss: 0.6931474208831787\n",
      "epoch: 14 step: 696 loss: 0.6931474208831787\n",
      "epoch: 14 step: 697 loss: 0.6931474208831787\n",
      "epoch: 14 step: 698 loss: 0.6931474208831787\n",
      "epoch: 14 step: 699 loss: 0.6931474208831787\n",
      "epoch: 14 step: 700 loss: 0.6931474208831787\n",
      "epoch: 14 step: 701 loss: 0.6931474208831787\n",
      "epoch: 14 step: 702 loss: 0.6931474208831787\n",
      "epoch: 14 step: 703 loss: 0.6931474208831787\n",
      "epoch: 14 step: 704 loss: 0.6931474208831787\n",
      "epoch: 14 step: 705 loss: 0.6931474804878235\n",
      "epoch: 14 step: 706 loss: 0.6931474208831787\n",
      "epoch: 14 step: 707 loss: 0.6931474208831787\n",
      "epoch: 14 step: 708 loss: 0.6931474208831787\n",
      "epoch: 14 step: 709 loss: 0.6931474208831787\n",
      "epoch: 14 step: 710 loss: 0.6931474208831787\n",
      "epoch: 14 step: 711 loss: 0.6931474208831787\n",
      "epoch: 14 step: 712 loss: 0.6931474208831787\n",
      "epoch: 14 step: 713 loss: 0.6931474804878235\n",
      "epoch: 14 step: 714 loss: 0.6931474208831787\n",
      "epoch: 14 step: 715 loss: 0.6931474208831787\n",
      "epoch: 14 step: 716 loss: 0.6931474208831787\n",
      "epoch: 14 step: 717 loss: 0.6931474208831787\n",
      "epoch: 14 step: 718 loss: 0.6931474208831787\n",
      "epoch: 14 step: 719 loss: 0.6931474208831787\n",
      "epoch: 14 step: 720 loss: 0.6931474208831787\n",
      "epoch: 14 step: 721 loss: 0.6931474208831787\n",
      "epoch: 14 step: 722 loss: 0.6931474208831787\n",
      "epoch: 14 step: 723 loss: 0.6931474208831787\n",
      "epoch: 14 step: 724 loss: 0.6931474208831787\n",
      "epoch: 14 step: 725 loss: 0.6931474208831787\n",
      "epoch: 14 step: 726 loss: 0.6931474208831787\n",
      "epoch: 14 step: 727 loss: 0.6931474208831787\n",
      "epoch: 14 step: 728 loss: 0.6931474208831787\n",
      "epoch: 14 step: 729 loss: 0.6931474208831787\n",
      "epoch: 14 step: 730 loss: 0.6931474208831787\n",
      "epoch: 14 step: 731 loss: 0.6931474208831787\n",
      "epoch: 14 step: 732 loss: 0.6931474208831787\n",
      "epoch: 14 step: 733 loss: 0.6931474208831787\n",
      "epoch: 14 step: 734 loss: 0.6931474208831787\n",
      "epoch: 14 step: 735 loss: 0.6931474208831787\n",
      "epoch: 14 step: 736 loss: 0.6931474208831787\n",
      "epoch: 14 step: 737 loss: 0.6931474208831787\n",
      "epoch: 14 step: 738 loss: 0.6931474208831787\n",
      "epoch: 14 step: 739 loss: 0.6931474208831787\n",
      "epoch: 14 step: 740 loss: 0.6931474208831787\n",
      "epoch: 14 step: 741 loss: 0.6931474208831787\n",
      "epoch: 14 step: 742 loss: 0.6931474208831787\n",
      "epoch: 14 step: 743 loss: 0.6931474208831787\n",
      "epoch: 14 step: 744 loss: 0.6931474208831787\n",
      "epoch: 14 step: 745 loss: 0.6931474208831787\n",
      "epoch: 14 step: 746 loss: 0.6931474208831787\n",
      "epoch: 14 step: 747 loss: 0.6931474208831787\n",
      "epoch: 14 step: 748 loss: 0.6931474208831787\n",
      "epoch: 14 step: 749 loss: 0.6931474208831787\n",
      "epoch: 14 step: 750 loss: 0.6931474208831787\n",
      "epoch: 14 step: 751 loss: 0.6931474208831787\n",
      "epoch: 14 step: 752 loss: 0.6931474208831787\n",
      "epoch: 14 step: 753 loss: 0.6931474208831787\n",
      "epoch: 14 step: 754 loss: 0.6931474208831787\n",
      "epoch: 14 step: 755 loss: 0.6931474208831787\n",
      "epoch: 14 step: 756 loss: 0.6931474208831787\n",
      "epoch: 14 step: 757 loss: 0.6931474208831787\n",
      "epoch: 14 step: 758 loss: 0.6931474208831787\n",
      "epoch: 14 step: 759 loss: 0.6931474208831787\n",
      "epoch: 14 step: 760 loss: 0.6931474208831787\n",
      "epoch: 14 step: 761 loss: 0.6931474208831787\n",
      "epoch: 14 step: 762 loss: 0.6931474208831787\n",
      "epoch: 14 step: 763 loss: 0.6931474208831787\n",
      "epoch: 14 step: 764 loss: 0.6931474208831787\n",
      "epoch: 14 step: 765 loss: 0.6931474208831787\n",
      "epoch: 14 step: 766 loss: 0.6931474208831787\n",
      "epoch: 14 step: 767 loss: 0.6931474208831787\n",
      "epoch: 14 step: 768 loss: 0.6931474208831787\n",
      "epoch: 14 step: 769 loss: 0.6931474208831787\n",
      "epoch: 14 step: 770 loss: 0.6931474208831787\n",
      "epoch: 14 step: 771 loss: 0.6931474208831787\n",
      "epoch: 14 step: 772 loss: 0.6931474208831787\n",
      "epoch: 14 step: 773 loss: 0.6931474208831787\n",
      "epoch: 14 step: 774 loss: 0.6931474208831787\n",
      "epoch: 14 step: 775 loss: 0.6931474208831787\n",
      "epoch: 14 step: 776 loss: 0.6931474208831787\n",
      "epoch: 14 step: 777 loss: 0.6931474208831787\n",
      "epoch: 14 step: 778 loss: 0.6931474208831787\n",
      "epoch: 14 step: 779 loss: 0.6931474208831787\n",
      "epoch: 14 step: 780 loss: 0.6931474208831787\n",
      "epoch: 14 step: 781 loss: 0.6931474208831787\n",
      "epoch: 15 step: 1 loss: 0.6931474208831787\n",
      "epoch: 15 step: 2 loss: 0.6931474208831787\n",
      "epoch: 15 step: 3 loss: 0.6931474208831787\n",
      "epoch: 15 step: 4 loss: 0.6931474208831787\n",
      "epoch: 15 step: 5 loss: 0.6931474208831787\n",
      "epoch: 15 step: 6 loss: 0.6931474208831787\n",
      "epoch: 15 step: 7 loss: 0.6931474208831787\n",
      "epoch: 15 step: 8 loss: 0.6931474208831787\n",
      "epoch: 15 step: 9 loss: 0.6931474208831787\n",
      "epoch: 15 step: 10 loss: 0.6931474208831787\n",
      "epoch: 15 step: 11 loss: 0.6931474208831787\n",
      "epoch: 15 step: 12 loss: 0.6931474208831787\n",
      "epoch: 15 step: 13 loss: 0.6931474208831787\n",
      "epoch: 15 step: 14 loss: 0.6931474208831787\n",
      "epoch: 15 step: 15 loss: 0.6931474208831787\n",
      "epoch: 15 step: 16 loss: 0.6931474208831787\n",
      "epoch: 15 step: 17 loss: 0.6931474208831787\n",
      "epoch: 15 step: 18 loss: 0.6931474208831787\n",
      "epoch: 15 step: 19 loss: 0.6931474208831787\n",
      "epoch: 15 step: 20 loss: 0.6931474208831787\n",
      "epoch: 15 step: 21 loss: 0.6931474208831787\n",
      "epoch: 15 step: 22 loss: 0.6931474208831787\n",
      "epoch: 15 step: 23 loss: 0.6931474208831787\n",
      "epoch: 15 step: 24 loss: 0.6931474208831787\n",
      "epoch: 15 step: 25 loss: 0.6931474208831787\n",
      "epoch: 15 step: 26 loss: 0.6931474208831787\n",
      "epoch: 15 step: 27 loss: 0.6931474208831787\n",
      "epoch: 15 step: 28 loss: 0.6931474208831787\n",
      "epoch: 15 step: 29 loss: 0.6931474208831787\n",
      "epoch: 15 step: 30 loss: 0.6931474208831787\n",
      "epoch: 15 step: 31 loss: 0.6931474208831787\n",
      "epoch: 15 step: 32 loss: 0.6931474208831787\n",
      "epoch: 15 step: 33 loss: 0.6931474208831787\n",
      "epoch: 15 step: 34 loss: 0.6931474208831787\n",
      "epoch: 15 step: 35 loss: 0.6931474208831787\n",
      "epoch: 15 step: 36 loss: 0.6931474208831787\n",
      "epoch: 15 step: 37 loss: 0.6931474208831787\n",
      "epoch: 15 step: 38 loss: 0.6931474208831787\n",
      "epoch: 15 step: 39 loss: 0.6931474208831787\n",
      "epoch: 15 step: 40 loss: 0.6931474208831787\n",
      "epoch: 15 step: 41 loss: 0.6931474208831787\n",
      "epoch: 15 step: 42 loss: 0.6931474208831787\n",
      "epoch: 15 step: 43 loss: 0.6931474208831787\n",
      "epoch: 15 step: 44 loss: 0.6931474208831787\n",
      "epoch: 15 step: 45 loss: 0.6931474208831787\n",
      "epoch: 15 step: 46 loss: 0.6931474208831787\n",
      "epoch: 15 step: 47 loss: 0.6931474208831787\n",
      "epoch: 15 step: 48 loss: 0.6931474208831787\n",
      "epoch: 15 step: 49 loss: 0.6931474208831787\n",
      "epoch: 15 step: 50 loss: 0.6931474208831787\n",
      "epoch: 15 step: 51 loss: 0.6931474208831787\n",
      "epoch: 15 step: 52 loss: 0.6931474208831787\n",
      "epoch: 15 step: 53 loss: 0.6931474208831787\n",
      "epoch: 15 step: 54 loss: 0.6931474208831787\n",
      "epoch: 15 step: 55 loss: 0.6931474208831787\n",
      "epoch: 15 step: 56 loss: 0.6931474208831787\n",
      "epoch: 15 step: 57 loss: 0.6931474208831787\n",
      "epoch: 15 step: 58 loss: 0.6931474208831787\n",
      "epoch: 15 step: 59 loss: 0.6931474208831787\n",
      "epoch: 15 step: 60 loss: 0.6931474208831787\n",
      "epoch: 15 step: 61 loss: 0.6931474208831787\n",
      "epoch: 15 step: 62 loss: 0.6931474208831787\n",
      "epoch: 15 step: 63 loss: 0.6931474208831787\n",
      "epoch: 15 step: 64 loss: 0.6931474208831787\n",
      "epoch: 15 step: 65 loss: 0.6931474208831787\n",
      "epoch: 15 step: 66 loss: 0.6931474208831787\n",
      "epoch: 15 step: 67 loss: 0.6931474208831787\n",
      "epoch: 15 step: 68 loss: 0.6931474208831787\n",
      "epoch: 15 step: 69 loss: 0.6931474208831787\n",
      "epoch: 15 step: 70 loss: 0.6931474208831787\n",
      "epoch: 15 step: 71 loss: 0.6931474208831787\n",
      "epoch: 15 step: 72 loss: 0.6931474208831787\n",
      "epoch: 15 step: 73 loss: 0.6931474208831787\n",
      "epoch: 15 step: 74 loss: 0.6931474208831787\n",
      "epoch: 15 step: 75 loss: 0.6931474208831787\n",
      "epoch: 15 step: 76 loss: 0.6931474208831787\n",
      "epoch: 15 step: 77 loss: 0.6931474208831787\n",
      "epoch: 15 step: 78 loss: 0.6931474208831787\n",
      "epoch: 15 step: 79 loss: 0.6931474208831787\n",
      "epoch: 15 step: 80 loss: 0.6931474208831787\n",
      "epoch: 15 step: 81 loss: 0.6931474208831787\n",
      "epoch: 15 step: 82 loss: 0.6931474208831787\n",
      "epoch: 15 step: 83 loss: 0.6931474208831787\n",
      "epoch: 15 step: 84 loss: 0.6931474208831787\n",
      "epoch: 15 step: 85 loss: 0.6931474208831787\n",
      "epoch: 15 step: 86 loss: 0.6931474208831787\n",
      "epoch: 15 step: 87 loss: 0.6931474208831787\n",
      "epoch: 15 step: 88 loss: 0.6931474208831787\n",
      "epoch: 15 step: 89 loss: 0.6931474208831787\n",
      "epoch: 15 step: 90 loss: 0.6931474208831787\n",
      "epoch: 15 step: 91 loss: 0.6931474208831787\n",
      "epoch: 15 step: 92 loss: 0.6931474208831787\n",
      "epoch: 15 step: 93 loss: 0.6931474208831787\n",
      "epoch: 15 step: 94 loss: 0.6931474208831787\n",
      "epoch: 15 step: 95 loss: 0.6931474208831787\n",
      "epoch: 15 step: 96 loss: 0.6931474208831787\n",
      "epoch: 15 step: 97 loss: 0.6931474208831787\n",
      "epoch: 15 step: 98 loss: 0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 99 loss: 0.6931474208831787\n",
      "epoch: 15 step: 100 loss: 0.6931474208831787\n",
      "epoch: 15 step: 101 loss: 0.6931474208831787\n",
      "epoch: 15 step: 102 loss: 0.6931474208831787\n",
      "epoch: 15 step: 103 loss: 0.6931474208831787\n",
      "epoch: 15 step: 104 loss: 0.6931474208831787\n",
      "epoch: 15 step: 105 loss: 0.6931474208831787\n",
      "epoch: 15 step: 106 loss: 0.6931474208831787\n",
      "epoch: 15 step: 107 loss: 0.6931474208831787\n",
      "epoch: 15 step: 108 loss: 0.6931474208831787\n",
      "epoch: 15 step: 109 loss: 0.6931474208831787\n",
      "epoch: 15 step: 110 loss: 0.6931474208831787\n",
      "epoch: 15 step: 111 loss: 0.6931474208831787\n",
      "epoch: 15 step: 112 loss: 0.6931474208831787\n",
      "epoch: 15 step: 113 loss: 0.6931474208831787\n",
      "epoch: 15 step: 114 loss: 0.6931474208831787\n",
      "epoch: 15 step: 115 loss: 0.6931474208831787\n",
      "epoch: 15 step: 116 loss: 0.6931474208831787\n",
      "epoch: 15 step: 117 loss: 0.6931474208831787\n",
      "epoch: 15 step: 118 loss: 0.6931474208831787\n",
      "epoch: 15 step: 119 loss: 0.6931474208831787\n",
      "epoch: 15 step: 120 loss: 0.6931474208831787\n",
      "epoch: 15 step: 121 loss: 0.6931474208831787\n",
      "epoch: 15 step: 122 loss: 0.6931474208831787\n",
      "epoch: 15 step: 123 loss: 0.6931474208831787\n",
      "epoch: 15 step: 124 loss: 0.6931474208831787\n",
      "epoch: 15 step: 125 loss: 0.6931474208831787\n",
      "epoch: 15 step: 126 loss: 0.6931474208831787\n",
      "epoch: 15 step: 127 loss: 0.6931474208831787\n",
      "epoch: 15 step: 128 loss: 0.6931474208831787\n",
      "epoch: 15 step: 129 loss: 0.6931474208831787\n",
      "epoch: 15 step: 130 loss: 0.6931474208831787\n",
      "epoch: 15 step: 131 loss: 0.6931474208831787\n",
      "epoch: 15 step: 132 loss: 0.6931474208831787\n",
      "epoch: 15 step: 133 loss: 0.6931474208831787\n",
      "epoch: 15 step: 134 loss: 0.6931474208831787\n",
      "epoch: 15 step: 135 loss: 0.6931474208831787\n",
      "epoch: 15 step: 136 loss: 0.6931474208831787\n",
      "epoch: 15 step: 137 loss: 0.6931474208831787\n",
      "epoch: 15 step: 138 loss: 0.6931474208831787\n",
      "epoch: 15 step: 139 loss: 0.6931474208831787\n",
      "epoch: 15 step: 140 loss: 0.6931474208831787\n",
      "epoch: 15 step: 141 loss: 0.6931474208831787\n",
      "epoch: 15 step: 142 loss: 0.6931474208831787\n",
      "epoch: 15 step: 143 loss: 0.6931474208831787\n",
      "epoch: 15 step: 144 loss: 0.6931474208831787\n",
      "epoch: 15 step: 145 loss: 0.6931474208831787\n",
      "epoch: 15 step: 146 loss: 0.6931474208831787\n",
      "epoch: 15 step: 147 loss: 0.6931474208831787\n",
      "epoch: 15 step: 148 loss: 0.6931474208831787\n",
      "epoch: 15 step: 149 loss: 0.6931474208831787\n",
      "epoch: 15 step: 150 loss: 0.6931474208831787\n",
      "epoch: 15 step: 151 loss: 0.6931474208831787\n",
      "epoch: 15 step: 152 loss: 0.6931474208831787\n",
      "epoch: 15 step: 153 loss: 0.6931474208831787\n",
      "epoch: 15 step: 154 loss: 0.6931474208831787\n",
      "epoch: 15 step: 155 loss: 0.6931474208831787\n",
      "epoch: 15 step: 156 loss: 0.6931474208831787\n",
      "epoch: 15 step: 157 loss: 0.6931474208831787\n",
      "epoch: 15 step: 158 loss: 0.6931474208831787\n",
      "epoch: 15 step: 159 loss: 0.6931474208831787\n",
      "epoch: 15 step: 160 loss: 0.6931474208831787\n",
      "epoch: 15 step: 161 loss: 0.6931474208831787\n",
      "epoch: 15 step: 162 loss: 0.6931474208831787\n",
      "epoch: 15 step: 163 loss: 0.6931474208831787\n",
      "epoch: 15 step: 164 loss: 0.6931474208831787\n",
      "epoch: 15 step: 165 loss: 0.6931474208831787\n",
      "epoch: 15 step: 166 loss: 0.6931474208831787\n",
      "epoch: 15 step: 167 loss: 0.6931474208831787\n",
      "epoch: 15 step: 168 loss: 0.6931474208831787\n",
      "epoch: 15 step: 169 loss: 0.6931474208831787\n",
      "epoch: 15 step: 170 loss: 0.6931474208831787\n",
      "epoch: 15 step: 171 loss: 0.6931474208831787\n",
      "epoch: 15 step: 172 loss: 0.6931474208831787\n",
      "epoch: 15 step: 173 loss: 0.6931474208831787\n",
      "epoch: 15 step: 174 loss: 0.6931474208831787\n",
      "epoch: 15 step: 175 loss: 0.6931474208831787\n",
      "epoch: 15 step: 176 loss: 0.6931474208831787\n",
      "epoch: 15 step: 177 loss: 0.6931474208831787\n",
      "epoch: 15 step: 178 loss: 0.6931474208831787\n",
      "epoch: 15 step: 179 loss: 0.6931474208831787\n",
      "epoch: 15 step: 180 loss: 0.6931474208831787\n",
      "epoch: 15 step: 181 loss: 0.6931474208831787\n",
      "epoch: 15 step: 182 loss: 0.6931474208831787\n",
      "epoch: 15 step: 183 loss: 0.6931474208831787\n",
      "epoch: 15 step: 184 loss: 0.6931474208831787\n",
      "epoch: 15 step: 185 loss: 0.6931474208831787\n",
      "epoch: 15 step: 186 loss: 0.6931474208831787\n",
      "epoch: 15 step: 187 loss: 0.6931474208831787\n",
      "epoch: 15 step: 188 loss: 0.6931474208831787\n",
      "epoch: 15 step: 189 loss: 0.6931474208831787\n",
      "epoch: 15 step: 190 loss: 0.6931474208831787\n",
      "epoch: 15 step: 191 loss: 0.6931474208831787\n",
      "epoch: 15 step: 192 loss: 0.6931474208831787\n",
      "epoch: 15 step: 193 loss: 0.6931474208831787\n",
      "epoch: 15 step: 194 loss: 0.6931474208831787\n",
      "epoch: 15 step: 195 loss: 0.6931474208831787\n",
      "epoch: 15 step: 196 loss: 0.6931474208831787\n",
      "epoch: 15 step: 197 loss: 0.6931474208831787\n",
      "epoch: 15 step: 198 loss: 0.6931474208831787\n",
      "epoch: 15 step: 199 loss: 0.6931474208831787\n",
      "epoch: 15 step: 200 loss: 0.6931474208831787\n",
      "epoch: 15 step: 201 loss: 0.6931474208831787\n",
      "epoch: 15 step: 202 loss: 0.6931474208831787\n",
      "epoch: 15 step: 203 loss: 0.6931474208831787\n",
      "epoch: 15 step: 204 loss: 0.6931474208831787\n",
      "epoch: 15 step: 205 loss: 0.6931474208831787\n",
      "epoch: 15 step: 206 loss: 0.6931474208831787\n",
      "epoch: 15 step: 207 loss: 0.6931474208831787\n",
      "epoch: 15 step: 208 loss: 0.6931474208831787\n",
      "epoch: 15 step: 209 loss: 0.6931474208831787\n",
      "epoch: 15 step: 210 loss: 0.6931474208831787\n",
      "epoch: 15 step: 211 loss: 0.6931474208831787\n",
      "epoch: 15 step: 212 loss: 0.6931474208831787\n",
      "epoch: 15 step: 213 loss: 0.6931474208831787\n",
      "epoch: 15 step: 214 loss: 0.6931474208831787\n",
      "epoch: 15 step: 215 loss: 0.6931474208831787\n",
      "epoch: 15 step: 216 loss: 0.6931474208831787\n",
      "epoch: 15 step: 217 loss: 0.6931474208831787\n",
      "epoch: 15 step: 218 loss: 0.6931474208831787\n",
      "epoch: 15 step: 219 loss: 0.6931474208831787\n",
      "epoch: 15 step: 220 loss: 0.6931474208831787\n",
      "epoch: 15 step: 221 loss: 0.6931474208831787\n",
      "epoch: 15 step: 222 loss: 0.6931474208831787\n",
      "epoch: 15 step: 223 loss: 0.6931474208831787\n",
      "epoch: 15 step: 224 loss: 0.6931474208831787\n",
      "epoch: 15 step: 225 loss: 0.6931474208831787\n",
      "epoch: 15 step: 226 loss: 0.6931474208831787\n",
      "epoch: 15 step: 227 loss: 0.6931474208831787\n",
      "epoch: 15 step: 228 loss: 0.6931474208831787\n",
      "epoch: 15 step: 229 loss: 0.6931474208831787\n",
      "epoch: 15 step: 230 loss: 0.6931474208831787\n",
      "epoch: 15 step: 231 loss: 0.6931474208831787\n",
      "epoch: 15 step: 232 loss: 0.6931474208831787\n",
      "epoch: 15 step: 233 loss: 0.6931474208831787\n",
      "epoch: 15 step: 234 loss: 0.6931474208831787\n",
      "epoch: 15 step: 235 loss: 0.6931474208831787\n",
      "epoch: 15 step: 236 loss: 0.6931474208831787\n",
      "epoch: 15 step: 237 loss: 0.6931474208831787\n",
      "epoch: 15 step: 238 loss: 0.6931474208831787\n",
      "epoch: 15 step: 239 loss: 0.6931474208831787\n",
      "epoch: 15 step: 240 loss: 0.6931474208831787\n",
      "epoch: 15 step: 241 loss: 0.6931474208831787\n",
      "epoch: 15 step: 242 loss: 0.6931474208831787\n",
      "epoch: 15 step: 243 loss: 0.6931474208831787\n",
      "epoch: 15 step: 244 loss: 0.6931474208831787\n",
      "epoch: 15 step: 245 loss: 0.6931474208831787\n",
      "epoch: 15 step: 246 loss: 0.6931474208831787\n",
      "epoch: 15 step: 247 loss: 0.6931474208831787\n",
      "epoch: 15 step: 248 loss: 0.6931474208831787\n",
      "epoch: 15 step: 249 loss: 0.6931474208831787\n",
      "epoch: 15 step: 250 loss: 0.6931474208831787\n",
      "epoch: 15 step: 251 loss: 0.6931474208831787\n",
      "epoch: 15 step: 252 loss: 0.6931474208831787\n",
      "epoch: 15 step: 253 loss: 0.6931474208831787\n",
      "epoch: 15 step: 254 loss: 0.6931474208831787\n",
      "epoch: 15 step: 255 loss: 0.6931474208831787\n",
      "epoch: 15 step: 256 loss: 0.6931474208831787\n",
      "epoch: 15 step: 257 loss: 0.6931474208831787\n",
      "epoch: 15 step: 258 loss: 0.6931474208831787\n",
      "epoch: 15 step: 259 loss: 0.6931474208831787\n",
      "epoch: 15 step: 260 loss: 0.6931474208831787\n",
      "epoch: 15 step: 261 loss: 0.6931474208831787\n",
      "epoch: 15 step: 262 loss: 0.6931474208831787\n",
      "epoch: 15 step: 263 loss: 0.6931474208831787\n",
      "epoch: 15 step: 264 loss: 0.6931474208831787\n",
      "epoch: 15 step: 265 loss: 0.6931474208831787\n",
      "epoch: 15 step: 266 loss: 0.6931474208831787\n",
      "epoch: 15 step: 267 loss: 0.6931474208831787\n",
      "epoch: 15 step: 268 loss: 0.6931474208831787\n",
      "epoch: 15 step: 269 loss: 0.6931474208831787\n",
      "epoch: 15 step: 270 loss: 0.6931474208831787\n",
      "epoch: 15 step: 271 loss: 0.6931474208831787\n",
      "epoch: 15 step: 272 loss: 0.6931474208831787\n",
      "epoch: 15 step: 273 loss: 0.6931474208831787\n",
      "epoch: 15 step: 274 loss: 0.6931474208831787\n",
      "epoch: 15 step: 275 loss: 0.6931474208831787\n",
      "epoch: 15 step: 276 loss: 0.6931474208831787\n",
      "epoch: 15 step: 277 loss: 0.6931474208831787\n",
      "epoch: 15 step: 278 loss: 0.6931474208831787\n",
      "epoch: 15 step: 279 loss: 0.6931474208831787\n",
      "epoch: 15 step: 280 loss: 0.6931474208831787\n",
      "epoch: 15 step: 281 loss: 0.6931474208831787\n",
      "epoch: 15 step: 282 loss: 0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 283 loss: 0.6931474208831787\n",
      "epoch: 15 step: 284 loss: 0.6931474208831787\n",
      "epoch: 15 step: 285 loss: 0.6931474208831787\n",
      "epoch: 15 step: 286 loss: 0.6931474208831787\n",
      "epoch: 15 step: 287 loss: 0.6931474208831787\n",
      "epoch: 15 step: 288 loss: 0.6931474208831787\n",
      "epoch: 15 step: 289 loss: 0.6931474208831787\n",
      "epoch: 15 step: 290 loss: 0.6931474208831787\n",
      "epoch: 15 step: 291 loss: 0.6931474208831787\n",
      "epoch: 15 step: 292 loss: 0.6931474208831787\n",
      "epoch: 15 step: 293 loss: 0.6931474208831787\n",
      "epoch: 15 step: 294 loss: 0.6931474208831787\n",
      "epoch: 15 step: 295 loss: 0.6931474208831787\n",
      "epoch: 15 step: 296 loss: 0.6931474208831787\n",
      "epoch: 15 step: 297 loss: 0.6931474208831787\n",
      "epoch: 15 step: 298 loss: 0.6931474208831787\n",
      "epoch: 15 step: 299 loss: 0.6931474208831787\n",
      "epoch: 15 step: 300 loss: 0.6931474208831787\n",
      "epoch: 15 step: 301 loss: 0.6931474208831787\n",
      "epoch: 15 step: 302 loss: 0.6931474208831787\n",
      "epoch: 15 step: 303 loss: 0.6931474208831787\n",
      "epoch: 15 step: 304 loss: 0.6931474208831787\n",
      "epoch: 15 step: 305 loss: 0.6931474208831787\n",
      "epoch: 15 step: 306 loss: 0.6931474208831787\n",
      "epoch: 15 step: 307 loss: 0.6931474208831787\n",
      "epoch: 15 step: 308 loss: 0.6931474208831787\n",
      "epoch: 15 step: 309 loss: 0.6931474208831787\n",
      "epoch: 15 step: 310 loss: 0.6931474208831787\n",
      "epoch: 15 step: 311 loss: 0.6931474208831787\n",
      "epoch: 15 step: 312 loss: 0.6931474208831787\n",
      "epoch: 15 step: 313 loss: 0.6931474208831787\n",
      "epoch: 15 step: 314 loss: 0.6931474208831787\n",
      "epoch: 15 step: 315 loss: 0.6931474208831787\n",
      "epoch: 15 step: 316 loss: 0.6931474208831787\n",
      "epoch: 15 step: 317 loss: 0.6931474208831787\n",
      "epoch: 15 step: 318 loss: 0.6931474208831787\n",
      "epoch: 15 step: 319 loss: 0.6931474208831787\n",
      "epoch: 15 step: 320 loss: 0.6931474208831787\n",
      "epoch: 15 step: 321 loss: 0.6931474208831787\n",
      "epoch: 15 step: 322 loss: 0.6931474208831787\n",
      "epoch: 15 step: 323 loss: 0.6931474208831787\n",
      "epoch: 15 step: 324 loss: 0.6931474208831787\n",
      "epoch: 15 step: 325 loss: 0.6931474208831787\n",
      "epoch: 15 step: 326 loss: 0.6931474208831787\n",
      "epoch: 15 step: 327 loss: 0.6931474208831787\n",
      "epoch: 15 step: 328 loss: 0.6931474208831787\n",
      "epoch: 15 step: 329 loss: 0.6931474208831787\n",
      "epoch: 15 step: 330 loss: 0.6931474208831787\n",
      "epoch: 15 step: 331 loss: 0.6931474208831787\n",
      "epoch: 15 step: 332 loss: 0.6931474208831787\n",
      "epoch: 15 step: 333 loss: 0.6931474208831787\n",
      "epoch: 15 step: 334 loss: 0.6931474208831787\n",
      "epoch: 15 step: 335 loss: 0.6931474208831787\n",
      "epoch: 15 step: 336 loss: 0.6931474208831787\n",
      "epoch: 15 step: 337 loss: 0.6931474208831787\n",
      "epoch: 15 step: 338 loss: 0.6931474208831787\n",
      "epoch: 15 step: 339 loss: 0.6931473612785339\n",
      "epoch: 15 step: 340 loss: 0.6931474208831787\n",
      "epoch: 15 step: 341 loss: 0.6931474208831787\n",
      "epoch: 15 step: 342 loss: 0.6931474208831787\n",
      "epoch: 15 step: 343 loss: 0.6931474208831787\n",
      "epoch: 15 step: 344 loss: 0.6931474208831787\n",
      "epoch: 15 step: 345 loss: 0.6931473612785339\n",
      "epoch: 15 step: 346 loss: 0.6931474208831787\n",
      "epoch: 15 step: 347 loss: 0.6931474208831787\n",
      "epoch: 15 step: 348 loss: 0.6931474208831787\n",
      "epoch: 15 step: 349 loss: 0.6931474208831787\n",
      "epoch: 15 step: 350 loss: 0.6931474208831787\n",
      "epoch: 15 step: 351 loss: 0.6931474208831787\n",
      "epoch: 15 step: 352 loss: 0.6931474208831787\n",
      "epoch: 15 step: 353 loss: 0.6931474208831787\n",
      "epoch: 15 step: 354 loss: 0.6931474208831787\n",
      "epoch: 15 step: 355 loss: 0.6931474208831787\n",
      "epoch: 15 step: 356 loss: 0.6931474208831787\n",
      "epoch: 15 step: 357 loss: 0.6931474208831787\n",
      "epoch: 15 step: 358 loss: 0.6931473612785339\n",
      "epoch: 15 step: 359 loss: 0.6931474208831787\n",
      "epoch: 15 step: 360 loss: 0.6931474208831787\n",
      "epoch: 15 step: 361 loss: 0.6931473612785339\n",
      "epoch: 15 step: 362 loss: 0.6931473612785339\n",
      "epoch: 15 step: 363 loss: 0.6931474208831787\n",
      "epoch: 15 step: 364 loss: 0.6931474208831787\n",
      "epoch: 15 step: 365 loss: 0.6931474208831787\n",
      "epoch: 15 step: 366 loss: 0.6931474208831787\n",
      "epoch: 15 step: 367 loss: 0.6931474208831787\n",
      "epoch: 15 step: 368 loss: 0.6931474208831787\n",
      "epoch: 15 step: 369 loss: 0.6931474208831787\n",
      "epoch: 15 step: 370 loss: 0.6931474208831787\n",
      "epoch: 15 step: 371 loss: 0.6931473612785339\n",
      "epoch: 15 step: 372 loss: 0.6931473612785339\n",
      "epoch: 15 step: 373 loss: 0.6931474208831787\n",
      "epoch: 15 step: 374 loss: 0.6931474208831787\n",
      "epoch: 15 step: 375 loss: 0.6931474208831787\n",
      "epoch: 15 step: 376 loss: 0.6931474208831787\n",
      "epoch: 15 step: 377 loss: 0.6931473612785339\n",
      "epoch: 15 step: 378 loss: 0.6931474208831787\n",
      "epoch: 15 step: 379 loss: 0.6931474208831787\n",
      "epoch: 15 step: 380 loss: 0.6931474208831787\n",
      "epoch: 15 step: 381 loss: 0.6931473612785339\n",
      "epoch: 15 step: 382 loss: 0.6931473612785339\n",
      "epoch: 15 step: 383 loss: 0.6931474208831787\n",
      "epoch: 15 step: 384 loss: 0.6931473612785339\n",
      "epoch: 15 step: 385 loss: 0.6931473612785339\n",
      "epoch: 15 step: 386 loss: 0.6931474208831787\n",
      "epoch: 15 step: 387 loss: 0.6931473612785339\n",
      "epoch: 15 step: 388 loss: 0.6931474208831787\n",
      "epoch: 15 step: 389 loss: 0.6931473612785339\n",
      "epoch: 15 step: 390 loss: 0.6931474208831787\n",
      "epoch: 15 step: 391 loss: 0.6931474208831787\n",
      "epoch: 15 step: 392 loss: 0.6931473612785339\n",
      "epoch: 15 step: 393 loss: 0.6931473612785339\n",
      "epoch: 15 step: 394 loss: 0.6931474208831787\n",
      "epoch: 15 step: 395 loss: 0.6931474208831787\n",
      "epoch: 15 step: 396 loss: 0.6931473612785339\n",
      "epoch: 15 step: 397 loss: 0.6931473612785339\n",
      "epoch: 15 step: 398 loss: 0.6931474208831787\n",
      "epoch: 15 step: 399 loss: 0.6931473612785339\n",
      "epoch: 15 step: 400 loss: 0.6931474208831787\n",
      "epoch: 15 step: 401 loss: 0.6931474208831787\n",
      "epoch: 15 step: 402 loss: 0.6931473612785339\n",
      "epoch: 15 step: 403 loss: 0.6931473612785339\n",
      "epoch: 15 step: 404 loss: 0.6931474208831787\n",
      "epoch: 15 step: 405 loss: 0.6931473612785339\n",
      "epoch: 15 step: 406 loss: 0.6931473612785339\n",
      "epoch: 15 step: 407 loss: 0.6931473612785339\n",
      "epoch: 15 step: 408 loss: 0.6931473612785339\n",
      "epoch: 15 step: 409 loss: 0.6931473612785339\n",
      "epoch: 15 step: 410 loss: 0.6931474208831787\n",
      "epoch: 15 step: 411 loss: 0.6931473612785339\n",
      "epoch: 15 step: 412 loss: 0.6931473612785339\n",
      "epoch: 15 step: 413 loss: 0.6931473612785339\n",
      "epoch: 15 step: 414 loss: 0.6931473612785339\n",
      "epoch: 15 step: 415 loss: 0.6931473612785339\n",
      "epoch: 15 step: 416 loss: 0.6931473612785339\n",
      "epoch: 15 step: 417 loss: 0.6931474208831787\n",
      "epoch: 15 step: 418 loss: 0.6931473612785339\n",
      "epoch: 15 step: 419 loss: 0.6931473612785339\n",
      "epoch: 15 step: 420 loss: 0.6931473612785339\n",
      "epoch: 15 step: 421 loss: 0.6931473612785339\n",
      "epoch: 15 step: 422 loss: 0.6931474208831787\n",
      "epoch: 15 step: 423 loss: 0.6931473612785339\n",
      "epoch: 15 step: 424 loss: 0.6931473612785339\n",
      "epoch: 15 step: 425 loss: 0.6931473612785339\n",
      "epoch: 15 step: 426 loss: 0.6931474208831787\n",
      "epoch: 15 step: 427 loss: 0.6931473612785339\n",
      "epoch: 15 step: 428 loss: 0.6931474208831787\n",
      "epoch: 15 step: 429 loss: 0.6931473612785339\n",
      "epoch: 15 step: 430 loss: 0.6931474208831787\n",
      "epoch: 15 step: 431 loss: 0.6931473612785339\n",
      "epoch: 15 step: 432 loss: 0.6931474208831787\n",
      "epoch: 15 step: 433 loss: 0.6931473612785339\n",
      "epoch: 15 step: 434 loss: 0.6931473612785339\n",
      "epoch: 15 step: 435 loss: 0.6931473612785339\n",
      "epoch: 15 step: 436 loss: 0.6931473612785339\n",
      "epoch: 15 step: 437 loss: 0.6931473612785339\n",
      "epoch: 15 step: 438 loss: 0.6931474208831787\n",
      "epoch: 15 step: 439 loss: 0.6931473612785339\n",
      "epoch: 15 step: 440 loss: 0.6931473612785339\n",
      "epoch: 15 step: 441 loss: 0.6931473612785339\n",
      "epoch: 15 step: 442 loss: 0.6931473612785339\n",
      "epoch: 15 step: 443 loss: 0.6931473612785339\n",
      "epoch: 15 step: 444 loss: 0.6931473612785339\n",
      "epoch: 15 step: 445 loss: 0.6931473612785339\n",
      "epoch: 15 step: 446 loss: 0.6931474208831787\n",
      "epoch: 15 step: 447 loss: 0.6931474208831787\n",
      "epoch: 15 step: 448 loss: 0.6931473612785339\n",
      "epoch: 15 step: 449 loss: 0.6931473612785339\n",
      "epoch: 15 step: 450 loss: 0.6931473612785339\n",
      "epoch: 15 step: 451 loss: 0.6931473612785339\n",
      "epoch: 15 step: 452 loss: 0.6931473612785339\n",
      "epoch: 15 step: 453 loss: 0.6931473612785339\n",
      "epoch: 15 step: 454 loss: 0.6931473612785339\n",
      "epoch: 15 step: 455 loss: 0.6931473612785339\n",
      "epoch: 15 step: 456 loss: 0.6931473612785339\n",
      "epoch: 15 step: 457 loss: 0.6931473612785339\n",
      "epoch: 15 step: 458 loss: 0.6931473612785339\n",
      "epoch: 15 step: 459 loss: 0.6931473612785339\n",
      "epoch: 15 step: 460 loss: 0.6931473612785339\n",
      "epoch: 15 step: 461 loss: 0.6931473612785339\n",
      "epoch: 15 step: 462 loss: 0.6931473612785339\n",
      "epoch: 15 step: 463 loss: 0.6931473612785339\n",
      "epoch: 15 step: 464 loss: 0.6931473612785339\n",
      "epoch: 15 step: 465 loss: 0.6931473612785339\n",
      "epoch: 15 step: 466 loss: 0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 467 loss: 0.6931473612785339\n",
      "epoch: 15 step: 468 loss: 0.6931473612785339\n",
      "epoch: 15 step: 469 loss: 0.6931473612785339\n",
      "epoch: 15 step: 470 loss: 0.6931474208831787\n",
      "epoch: 15 step: 471 loss: 0.6931473612785339\n",
      "epoch: 15 step: 472 loss: 0.6931474208831787\n",
      "epoch: 15 step: 473 loss: 0.6931473612785339\n",
      "epoch: 15 step: 474 loss: 0.6931474208831787\n",
      "epoch: 15 step: 475 loss: 0.6931473612785339\n",
      "epoch: 15 step: 476 loss: 0.6931473612785339\n",
      "epoch: 15 step: 477 loss: 0.6931473612785339\n",
      "epoch: 15 step: 478 loss: 0.6931473612785339\n",
      "epoch: 15 step: 479 loss: 0.6931473612785339\n",
      "epoch: 15 step: 480 loss: 0.6931473612785339\n",
      "epoch: 15 step: 481 loss: 0.6931473612785339\n",
      "epoch: 15 step: 482 loss: 0.6931473612785339\n",
      "epoch: 15 step: 483 loss: 0.6931473612785339\n",
      "epoch: 15 step: 484 loss: 0.6931473612785339\n",
      "epoch: 15 step: 485 loss: 0.6931474208831787\n",
      "epoch: 15 step: 486 loss: 0.6931473612785339\n",
      "epoch: 15 step: 487 loss: 0.6931473612785339\n",
      "epoch: 15 step: 488 loss: 0.6931473612785339\n",
      "epoch: 15 step: 489 loss: 0.6931473612785339\n",
      "epoch: 15 step: 490 loss: 0.6931473612785339\n",
      "epoch: 15 step: 491 loss: 0.6931473612785339\n",
      "epoch: 15 step: 492 loss: 0.6931473612785339\n",
      "epoch: 15 step: 493 loss: 0.6931473612785339\n",
      "epoch: 15 step: 494 loss: 0.6931473612785339\n",
      "epoch: 15 step: 495 loss: 0.6931473612785339\n",
      "epoch: 15 step: 496 loss: 0.6931473612785339\n",
      "epoch: 15 step: 497 loss: 0.6931473612785339\n",
      "epoch: 15 step: 498 loss: 0.6931473612785339\n",
      "epoch: 15 step: 499 loss: 0.6931473612785339\n",
      "epoch: 15 step: 500 loss: 0.6931473612785339\n",
      "epoch: 15 step: 501 loss: 0.6931473612785339\n",
      "epoch: 15 step: 502 loss: 0.6931473612785339\n",
      "epoch: 15 step: 503 loss: 0.6931473612785339\n",
      "epoch: 15 step: 504 loss: 0.6931473612785339\n",
      "epoch: 15 step: 505 loss: 0.6931473612785339\n",
      "epoch: 15 step: 506 loss: 0.6931473612785339\n",
      "epoch: 15 step: 507 loss: 0.6931473612785339\n",
      "epoch: 15 step: 508 loss: 0.6931473612785339\n",
      "epoch: 15 step: 509 loss: 0.6931473612785339\n",
      "epoch: 15 step: 510 loss: 0.6931473612785339\n",
      "epoch: 15 step: 511 loss: 0.6931473612785339\n",
      "epoch: 15 step: 512 loss: 0.6931473612785339\n",
      "epoch: 15 step: 513 loss: 0.6931473612785339\n",
      "epoch: 15 step: 514 loss: 0.6931474208831787\n",
      "epoch: 15 step: 515 loss: 0.6931473612785339\n",
      "epoch: 15 step: 516 loss: 0.6931473612785339\n",
      "epoch: 15 step: 517 loss: 0.6931473612785339\n",
      "epoch: 15 step: 518 loss: 0.6931473612785339\n",
      "epoch: 15 step: 519 loss: 0.6931473612785339\n",
      "epoch: 15 step: 520 loss: 0.6931473612785339\n",
      "epoch: 15 step: 521 loss: 0.6931473612785339\n",
      "epoch: 15 step: 522 loss: 0.6931473612785339\n",
      "epoch: 15 step: 523 loss: 0.6931473612785339\n",
      "epoch: 15 step: 524 loss: 0.6931473612785339\n",
      "epoch: 15 step: 525 loss: 0.6931473612785339\n",
      "epoch: 15 step: 526 loss: 0.6931473612785339\n",
      "epoch: 15 step: 527 loss: 0.6931473612785339\n",
      "epoch: 15 step: 528 loss: 0.6931473612785339\n",
      "epoch: 15 step: 529 loss: 0.6931473612785339\n",
      "epoch: 15 step: 530 loss: 0.6931473612785339\n",
      "epoch: 15 step: 531 loss: 0.6931473612785339\n",
      "epoch: 15 step: 532 loss: 0.6931473612785339\n",
      "epoch: 15 step: 533 loss: 0.6931473612785339\n",
      "epoch: 15 step: 534 loss: 0.6931473612785339\n",
      "epoch: 15 step: 535 loss: 0.6931473612785339\n",
      "epoch: 15 step: 536 loss: 0.6931473612785339\n",
      "epoch: 15 step: 537 loss: 0.6931473612785339\n",
      "epoch: 15 step: 538 loss: 0.6931473612785339\n",
      "epoch: 15 step: 539 loss: 0.6931473612785339\n",
      "epoch: 15 step: 540 loss: 0.6931473612785339\n",
      "epoch: 15 step: 541 loss: 0.6931473612785339\n",
      "epoch: 15 step: 542 loss: 0.6931473612785339\n",
      "epoch: 15 step: 543 loss: 0.6931473612785339\n",
      "epoch: 15 step: 544 loss: 0.6931473612785339\n",
      "epoch: 15 step: 545 loss: 0.6931473612785339\n",
      "epoch: 15 step: 546 loss: 0.6931473612785339\n",
      "epoch: 15 step: 547 loss: 0.6931473612785339\n",
      "epoch: 15 step: 548 loss: 0.6931473612785339\n",
      "epoch: 15 step: 549 loss: 0.6931473612785339\n",
      "epoch: 15 step: 550 loss: 0.6931473612785339\n",
      "epoch: 15 step: 551 loss: 0.6931473612785339\n",
      "epoch: 15 step: 552 loss: 0.6931473612785339\n",
      "epoch: 15 step: 553 loss: 0.6931473612785339\n",
      "epoch: 15 step: 554 loss: 0.6931473612785339\n",
      "epoch: 15 step: 555 loss: 0.6931473612785339\n",
      "epoch: 15 step: 556 loss: 0.6931473612785339\n",
      "epoch: 15 step: 557 loss: 0.6931473612785339\n",
      "epoch: 15 step: 558 loss: 0.6931473612785339\n",
      "epoch: 15 step: 559 loss: 0.6931473612785339\n",
      "epoch: 15 step: 560 loss: 0.6931473612785339\n",
      "epoch: 15 step: 561 loss: 0.6931473612785339\n",
      "epoch: 15 step: 562 loss: 0.6931473612785339\n",
      "epoch: 15 step: 563 loss: 0.6931473612785339\n",
      "epoch: 15 step: 564 loss: 0.6931473612785339\n",
      "epoch: 15 step: 565 loss: 0.6931473612785339\n",
      "epoch: 15 step: 566 loss: 0.6931473612785339\n",
      "epoch: 15 step: 567 loss: 0.6931473612785339\n",
      "epoch: 15 step: 568 loss: 0.6931473612785339\n",
      "epoch: 15 step: 569 loss: 0.6931473612785339\n",
      "epoch: 15 step: 570 loss: 0.6931473612785339\n",
      "epoch: 15 step: 571 loss: 0.6931473612785339\n",
      "epoch: 15 step: 572 loss: 0.6931473612785339\n",
      "epoch: 15 step: 573 loss: 0.6931473612785339\n",
      "epoch: 15 step: 574 loss: 0.6931473612785339\n",
      "epoch: 15 step: 575 loss: 0.6931473612785339\n",
      "epoch: 15 step: 576 loss: 0.6931473612785339\n",
      "epoch: 15 step: 577 loss: 0.6931473612785339\n",
      "epoch: 15 step: 578 loss: 0.6931473612785339\n",
      "epoch: 15 step: 579 loss: 0.6931473612785339\n",
      "epoch: 15 step: 580 loss: 0.6931473612785339\n",
      "epoch: 15 step: 581 loss: 0.6931473612785339\n",
      "epoch: 15 step: 582 loss: 0.6931473612785339\n",
      "epoch: 15 step: 583 loss: 0.6931473612785339\n",
      "epoch: 15 step: 584 loss: 0.6931473612785339\n",
      "epoch: 15 step: 585 loss: 0.6931473612785339\n",
      "epoch: 15 step: 586 loss: 0.6931473612785339\n",
      "epoch: 15 step: 587 loss: 0.6931473612785339\n",
      "epoch: 15 step: 588 loss: 0.6931473612785339\n",
      "epoch: 15 step: 589 loss: 0.6931473612785339\n",
      "epoch: 15 step: 590 loss: 0.6931473612785339\n",
      "epoch: 15 step: 591 loss: 0.6931473612785339\n",
      "epoch: 15 step: 592 loss: 0.6931473612785339\n",
      "epoch: 15 step: 593 loss: 0.6931473612785339\n",
      "epoch: 15 step: 594 loss: 0.6931473612785339\n",
      "epoch: 15 step: 595 loss: 0.6931473612785339\n",
      "epoch: 15 step: 596 loss: 0.6931473612785339\n",
      "epoch: 15 step: 597 loss: 0.6931473612785339\n",
      "epoch: 15 step: 598 loss: 0.6931473612785339\n",
      "epoch: 15 step: 599 loss: 0.6931473612785339\n",
      "epoch: 15 step: 600 loss: 0.6931474208831787\n",
      "epoch: 15 step: 601 loss: 0.6931473612785339\n",
      "epoch: 15 step: 602 loss: 0.6931473612785339\n",
      "epoch: 15 step: 603 loss: 0.6931473612785339\n",
      "epoch: 15 step: 604 loss: 0.6931473612785339\n",
      "epoch: 15 step: 605 loss: 0.6931473612785339\n",
      "epoch: 15 step: 606 loss: 0.6931473612785339\n",
      "epoch: 15 step: 607 loss: 0.6931473612785339\n",
      "epoch: 15 step: 608 loss: 0.6931473612785339\n",
      "epoch: 15 step: 609 loss: 0.6931473612785339\n",
      "epoch: 15 step: 610 loss: 0.6931473612785339\n",
      "epoch: 15 step: 611 loss: 0.6931473612785339\n",
      "epoch: 15 step: 612 loss: 0.6931473612785339\n",
      "epoch: 15 step: 613 loss: 0.6931473612785339\n",
      "epoch: 15 step: 614 loss: 0.6931473612785339\n",
      "epoch: 15 step: 615 loss: 0.6931473612785339\n",
      "epoch: 15 step: 616 loss: 0.6931473612785339\n",
      "epoch: 15 step: 617 loss: 0.6931473612785339\n",
      "epoch: 15 step: 618 loss: 0.6931474208831787\n",
      "epoch: 15 step: 619 loss: 0.6931473612785339\n",
      "epoch: 15 step: 620 loss: 0.6931473612785339\n",
      "epoch: 15 step: 621 loss: 0.6931473612785339\n",
      "epoch: 15 step: 622 loss: 0.6931473612785339\n",
      "epoch: 15 step: 623 loss: 0.6931473612785339\n",
      "epoch: 15 step: 624 loss: 0.6931473612785339\n",
      "epoch: 15 step: 625 loss: 0.6931473612785339\n",
      "epoch: 15 step: 626 loss: 0.6931473612785339\n",
      "epoch: 15 step: 627 loss: 0.6931473612785339\n",
      "epoch: 15 step: 628 loss: 0.6931473612785339\n",
      "epoch: 15 step: 629 loss: 0.6931473612785339\n",
      "epoch: 15 step: 630 loss: 0.6931473612785339\n",
      "epoch: 15 step: 631 loss: 0.6931473612785339\n",
      "epoch: 15 step: 632 loss: 0.6931473612785339\n",
      "epoch: 15 step: 633 loss: 0.6931473612785339\n",
      "epoch: 15 step: 634 loss: 0.6931473612785339\n",
      "epoch: 15 step: 635 loss: 0.6931473612785339\n",
      "epoch: 15 step: 636 loss: 0.6931473612785339\n",
      "epoch: 15 step: 637 loss: 0.6931473612785339\n",
      "epoch: 15 step: 638 loss: 0.6931473612785339\n",
      "epoch: 15 step: 639 loss: 0.6931473612785339\n",
      "epoch: 15 step: 640 loss: 0.6931473612785339\n",
      "epoch: 15 step: 641 loss: 0.6931473612785339\n",
      "epoch: 15 step: 642 loss: 0.6931473612785339\n",
      "epoch: 15 step: 643 loss: 0.6931473612785339\n",
      "epoch: 15 step: 644 loss: 0.6931473612785339\n",
      "epoch: 15 step: 645 loss: 0.6931473612785339\n",
      "epoch: 15 step: 646 loss: 0.6931473612785339\n",
      "epoch: 15 step: 647 loss: 0.6931473612785339\n",
      "epoch: 15 step: 648 loss: 0.6931473612785339\n",
      "epoch: 15 step: 649 loss: 0.6931473612785339\n",
      "epoch: 15 step: 650 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 651 loss: 0.6931473612785339\n",
      "epoch: 15 step: 652 loss: 0.6931473612785339\n",
      "epoch: 15 step: 653 loss: 0.6931473612785339\n",
      "epoch: 15 step: 654 loss: 0.6931473612785339\n",
      "epoch: 15 step: 655 loss: 0.6931473612785339\n",
      "epoch: 15 step: 656 loss: 0.6931473612785339\n",
      "epoch: 15 step: 657 loss: 0.6931473612785339\n",
      "epoch: 15 step: 658 loss: 0.6931473612785339\n",
      "epoch: 15 step: 659 loss: 0.6931473612785339\n",
      "epoch: 15 step: 660 loss: 0.6931473612785339\n",
      "epoch: 15 step: 661 loss: 0.6931473612785339\n",
      "epoch: 15 step: 662 loss: 0.6931473612785339\n",
      "epoch: 15 step: 663 loss: 0.6931473612785339\n",
      "epoch: 15 step: 664 loss: 0.6931473612785339\n",
      "epoch: 15 step: 665 loss: 0.6931473612785339\n",
      "epoch: 15 step: 666 loss: 0.6931473612785339\n",
      "epoch: 15 step: 667 loss: 0.6931473612785339\n",
      "epoch: 15 step: 668 loss: 0.6931473612785339\n",
      "epoch: 15 step: 669 loss: 0.6931473612785339\n",
      "epoch: 15 step: 670 loss: 0.6931473612785339\n",
      "epoch: 15 step: 671 loss: 0.6931473612785339\n",
      "epoch: 15 step: 672 loss: 0.6931473612785339\n",
      "epoch: 15 step: 673 loss: 0.6931473612785339\n",
      "epoch: 15 step: 674 loss: 0.6931473612785339\n",
      "epoch: 15 step: 675 loss: 0.6931473612785339\n",
      "epoch: 15 step: 676 loss: 0.6931473612785339\n",
      "epoch: 15 step: 677 loss: 0.6931473612785339\n",
      "epoch: 15 step: 678 loss: 0.6931473612785339\n",
      "epoch: 15 step: 679 loss: 0.6931473612785339\n",
      "epoch: 15 step: 680 loss: 0.6931473612785339\n",
      "epoch: 15 step: 681 loss: 0.6931473612785339\n",
      "epoch: 15 step: 682 loss: 0.6931473612785339\n",
      "epoch: 15 step: 683 loss: 0.6931473612785339\n",
      "epoch: 15 step: 684 loss: 0.6931473612785339\n",
      "epoch: 15 step: 685 loss: 0.6931473612785339\n",
      "epoch: 15 step: 686 loss: 0.6931473612785339\n",
      "epoch: 15 step: 687 loss: 0.6931473612785339\n",
      "epoch: 15 step: 688 loss: 0.6931473612785339\n",
      "epoch: 15 step: 689 loss: 0.6931473612785339\n",
      "epoch: 15 step: 690 loss: 0.6931473612785339\n",
      "epoch: 15 step: 691 loss: 0.6931473612785339\n",
      "epoch: 15 step: 692 loss: 0.6931473612785339\n",
      "epoch: 15 step: 693 loss: 0.6931473612785339\n",
      "epoch: 15 step: 694 loss: 0.6931473612785339\n",
      "epoch: 15 step: 695 loss: 0.6931473612785339\n",
      "epoch: 15 step: 696 loss: 0.6931473612785339\n",
      "epoch: 15 step: 697 loss: 0.6931473612785339\n",
      "epoch: 15 step: 698 loss: 0.6931473612785339\n",
      "epoch: 15 step: 699 loss: 0.6931473612785339\n",
      "epoch: 15 step: 700 loss: 0.6931473612785339\n",
      "epoch: 15 step: 701 loss: 0.6931473612785339\n",
      "epoch: 15 step: 702 loss: 0.6931473612785339\n",
      "epoch: 15 step: 703 loss: 0.6931473612785339\n",
      "epoch: 15 step: 704 loss: 0.6931473612785339\n",
      "epoch: 15 step: 705 loss: 0.6931473612785339\n",
      "epoch: 15 step: 706 loss: 0.6931473612785339\n",
      "epoch: 15 step: 707 loss: 0.6931473612785339\n",
      "epoch: 15 step: 708 loss: 0.6931473612785339\n",
      "epoch: 15 step: 709 loss: 0.6931473612785339\n",
      "epoch: 15 step: 710 loss: 0.6931473612785339\n",
      "epoch: 15 step: 711 loss: 0.6931473612785339\n",
      "epoch: 15 step: 712 loss: 0.6931473612785339\n",
      "epoch: 15 step: 713 loss: 0.6931473612785339\n",
      "epoch: 15 step: 714 loss: 0.6931473612785339\n",
      "epoch: 15 step: 715 loss: 0.6931473612785339\n",
      "epoch: 15 step: 716 loss: 0.6931473612785339\n",
      "epoch: 15 step: 717 loss: 0.6931473612785339\n",
      "epoch: 15 step: 718 loss: 0.6931473612785339\n",
      "epoch: 15 step: 719 loss: 0.6931473612785339\n",
      "epoch: 15 step: 720 loss: 0.6931473612785339\n",
      "epoch: 15 step: 721 loss: 0.6931473612785339\n",
      "epoch: 15 step: 722 loss: 0.6931473612785339\n",
      "epoch: 15 step: 723 loss: 0.6931473612785339\n",
      "epoch: 15 step: 724 loss: 0.6931473612785339\n",
      "epoch: 15 step: 725 loss: 0.6931473612785339\n",
      "epoch: 15 step: 726 loss: 0.6931473612785339\n",
      "epoch: 15 step: 727 loss: 0.6931473612785339\n",
      "epoch: 15 step: 728 loss: 0.6931473612785339\n",
      "epoch: 15 step: 729 loss: 0.6931473612785339\n",
      "epoch: 15 step: 730 loss: 0.6931473612785339\n",
      "epoch: 15 step: 731 loss: 0.6931473612785339\n",
      "epoch: 15 step: 732 loss: 0.6931473612785339\n",
      "epoch: 15 step: 733 loss: 0.6931473612785339\n",
      "epoch: 15 step: 734 loss: 0.6931473612785339\n",
      "epoch: 15 step: 735 loss: 0.6931473612785339\n",
      "epoch: 15 step: 736 loss: 0.6931473612785339\n",
      "epoch: 15 step: 737 loss: 0.6931473612785339\n",
      "epoch: 15 step: 738 loss: 0.6931473612785339\n",
      "epoch: 15 step: 739 loss: 0.6931473612785339\n",
      "epoch: 15 step: 740 loss: 0.6931473612785339\n",
      "epoch: 15 step: 741 loss: 0.6931473612785339\n",
      "epoch: 15 step: 742 loss: 0.6931473612785339\n",
      "epoch: 15 step: 743 loss: 0.6931473612785339\n",
      "epoch: 15 step: 744 loss: 0.6931473612785339\n",
      "epoch: 15 step: 745 loss: 0.6931473612785339\n",
      "epoch: 15 step: 746 loss: 0.6931473612785339\n",
      "epoch: 15 step: 747 loss: 0.6931473612785339\n",
      "epoch: 15 step: 748 loss: 0.6931473612785339\n",
      "epoch: 15 step: 749 loss: 0.6931473612785339\n",
      "epoch: 15 step: 750 loss: 0.6931473612785339\n",
      "epoch: 15 step: 751 loss: 0.6931473612785339\n",
      "epoch: 15 step: 752 loss: 0.6931473612785339\n",
      "epoch: 15 step: 753 loss: 0.6931473612785339\n",
      "epoch: 15 step: 754 loss: 0.6931473612785339\n",
      "epoch: 15 step: 755 loss: 0.6931473612785339\n",
      "epoch: 15 step: 756 loss: 0.6931473612785339\n",
      "epoch: 15 step: 757 loss: 0.6931473612785339\n",
      "epoch: 15 step: 758 loss: 0.6931473612785339\n",
      "epoch: 15 step: 759 loss: 0.6931473612785339\n",
      "epoch: 15 step: 760 loss: 0.6931473612785339\n",
      "epoch: 15 step: 761 loss: 0.6931473612785339\n",
      "epoch: 15 step: 762 loss: 0.6931473612785339\n",
      "epoch: 15 step: 763 loss: 0.6931473612785339\n",
      "epoch: 15 step: 764 loss: 0.6931473612785339\n",
      "epoch: 15 step: 765 loss: 0.6931473612785339\n",
      "epoch: 15 step: 766 loss: 0.6931473612785339\n",
      "epoch: 15 step: 767 loss: 0.6931473612785339\n",
      "epoch: 15 step: 768 loss: 0.6931473612785339\n",
      "epoch: 15 step: 769 loss: 0.6931473612785339\n",
      "epoch: 15 step: 770 loss: 0.6931473612785339\n",
      "epoch: 15 step: 771 loss: 0.6931473612785339\n",
      "epoch: 15 step: 772 loss: 0.6931473612785339\n",
      "epoch: 15 step: 773 loss: 0.6931473612785339\n",
      "epoch: 15 step: 774 loss: 0.6931473612785339\n",
      "epoch: 15 step: 775 loss: 0.6931473612785339\n",
      "epoch: 15 step: 776 loss: 0.6931473612785339\n",
      "epoch: 15 step: 777 loss: 0.6931473612785339\n",
      "epoch: 15 step: 778 loss: 0.6931473612785339\n",
      "epoch: 15 step: 779 loss: 0.6931473612785339\n",
      "epoch: 15 step: 780 loss: 0.6931473612785339\n",
      "epoch: 15 step: 781 loss: 0.6931473612785339\n",
      "epoch: 16 step: 1 loss: 0.6931473612785339\n",
      "epoch: 16 step: 2 loss: 0.6931473612785339\n",
      "epoch: 16 step: 3 loss: 0.6931473612785339\n",
      "epoch: 16 step: 4 loss: 0.6931473612785339\n",
      "epoch: 16 step: 5 loss: 0.6931473612785339\n",
      "epoch: 16 step: 6 loss: 0.6931473612785339\n",
      "epoch: 16 step: 7 loss: 0.6931473612785339\n",
      "epoch: 16 step: 8 loss: 0.6931473612785339\n",
      "epoch: 16 step: 9 loss: 0.6931473612785339\n",
      "epoch: 16 step: 10 loss: 0.6931473612785339\n",
      "epoch: 16 step: 11 loss: 0.6931473612785339\n",
      "epoch: 16 step: 12 loss: 0.6931473612785339\n",
      "epoch: 16 step: 13 loss: 0.6931473612785339\n",
      "epoch: 16 step: 14 loss: 0.6931473612785339\n",
      "epoch: 16 step: 15 loss: 0.6931473612785339\n",
      "epoch: 16 step: 16 loss: 0.6931473612785339\n",
      "epoch: 16 step: 17 loss: 0.6931473612785339\n",
      "epoch: 16 step: 18 loss: 0.6931473612785339\n",
      "epoch: 16 step: 19 loss: 0.6931473612785339\n",
      "epoch: 16 step: 20 loss: 0.6931473612785339\n",
      "epoch: 16 step: 21 loss: 0.6931473612785339\n",
      "epoch: 16 step: 22 loss: 0.6931473612785339\n",
      "epoch: 16 step: 23 loss: 0.6931473612785339\n",
      "epoch: 16 step: 24 loss: 0.6931473612785339\n",
      "epoch: 16 step: 25 loss: 0.6931473612785339\n",
      "epoch: 16 step: 26 loss: 0.6931473612785339\n",
      "epoch: 16 step: 27 loss: 0.6931473612785339\n",
      "epoch: 16 step: 28 loss: 0.6931473612785339\n",
      "epoch: 16 step: 29 loss: 0.6931473612785339\n",
      "epoch: 16 step: 30 loss: 0.6931473612785339\n",
      "epoch: 16 step: 31 loss: 0.6931473612785339\n",
      "epoch: 16 step: 32 loss: 0.6931473612785339\n",
      "epoch: 16 step: 33 loss: 0.6931473612785339\n",
      "epoch: 16 step: 34 loss: 0.6931473612785339\n",
      "epoch: 16 step: 35 loss: 0.6931473612785339\n",
      "epoch: 16 step: 36 loss: 0.6931473612785339\n",
      "epoch: 16 step: 37 loss: 0.6931473612785339\n",
      "epoch: 16 step: 38 loss: 0.6931473612785339\n",
      "epoch: 16 step: 39 loss: 0.6931473612785339\n",
      "epoch: 16 step: 40 loss: 0.6931473612785339\n",
      "epoch: 16 step: 41 loss: 0.6931473612785339\n",
      "epoch: 16 step: 42 loss: 0.6931473612785339\n",
      "epoch: 16 step: 43 loss: 0.6931473612785339\n",
      "epoch: 16 step: 44 loss: 0.6931473612785339\n",
      "epoch: 16 step: 45 loss: 0.6931473612785339\n",
      "epoch: 16 step: 46 loss: 0.6931473612785339\n",
      "epoch: 16 step: 47 loss: 0.6931473612785339\n",
      "epoch: 16 step: 48 loss: 0.6931473612785339\n",
      "epoch: 16 step: 49 loss: 0.6931473612785339\n",
      "epoch: 16 step: 50 loss: 0.6931473612785339\n",
      "epoch: 16 step: 51 loss: 0.6931473612785339\n",
      "epoch: 16 step: 52 loss: 0.6931473612785339\n",
      "epoch: 16 step: 53 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 54 loss: 0.6931473612785339\n",
      "epoch: 16 step: 55 loss: 0.6931473612785339\n",
      "epoch: 16 step: 56 loss: 0.6931473612785339\n",
      "epoch: 16 step: 57 loss: 0.6931473612785339\n",
      "epoch: 16 step: 58 loss: 0.6931473612785339\n",
      "epoch: 16 step: 59 loss: 0.6931473612785339\n",
      "epoch: 16 step: 60 loss: 0.6931473612785339\n",
      "epoch: 16 step: 61 loss: 0.6931473612785339\n",
      "epoch: 16 step: 62 loss: 0.6931473612785339\n",
      "epoch: 16 step: 63 loss: 0.6931473612785339\n",
      "epoch: 16 step: 64 loss: 0.6931473612785339\n",
      "epoch: 16 step: 65 loss: 0.6931473612785339\n",
      "epoch: 16 step: 66 loss: 0.6931473612785339\n",
      "epoch: 16 step: 67 loss: 0.6931473612785339\n",
      "epoch: 16 step: 68 loss: 0.6931473612785339\n",
      "epoch: 16 step: 69 loss: 0.6931473612785339\n",
      "epoch: 16 step: 70 loss: 0.6931473612785339\n",
      "epoch: 16 step: 71 loss: 0.6931473612785339\n",
      "epoch: 16 step: 72 loss: 0.6931473612785339\n",
      "epoch: 16 step: 73 loss: 0.6931473612785339\n",
      "epoch: 16 step: 74 loss: 0.6931473612785339\n",
      "epoch: 16 step: 75 loss: 0.6931473612785339\n",
      "epoch: 16 step: 76 loss: 0.6931473612785339\n",
      "epoch: 16 step: 77 loss: 0.6931473612785339\n",
      "epoch: 16 step: 78 loss: 0.6931473612785339\n",
      "epoch: 16 step: 79 loss: 0.6931473612785339\n",
      "epoch: 16 step: 80 loss: 0.6931473612785339\n",
      "epoch: 16 step: 81 loss: 0.6931473612785339\n",
      "epoch: 16 step: 82 loss: 0.6931473612785339\n",
      "epoch: 16 step: 83 loss: 0.6931473612785339\n",
      "epoch: 16 step: 84 loss: 0.6931473612785339\n",
      "epoch: 16 step: 85 loss: 0.6931473612785339\n",
      "epoch: 16 step: 86 loss: 0.6931473612785339\n",
      "epoch: 16 step: 87 loss: 0.6931473612785339\n",
      "epoch: 16 step: 88 loss: 0.6931473612785339\n",
      "epoch: 16 step: 89 loss: 0.6931473612785339\n",
      "epoch: 16 step: 90 loss: 0.6931473612785339\n",
      "epoch: 16 step: 91 loss: 0.6931473612785339\n",
      "epoch: 16 step: 92 loss: 0.6931473612785339\n",
      "epoch: 16 step: 93 loss: 0.6931473612785339\n",
      "epoch: 16 step: 94 loss: 0.6931473612785339\n",
      "epoch: 16 step: 95 loss: 0.6931473612785339\n",
      "epoch: 16 step: 96 loss: 0.6931473612785339\n",
      "epoch: 16 step: 97 loss: 0.6931473612785339\n",
      "epoch: 16 step: 98 loss: 0.6931473612785339\n",
      "epoch: 16 step: 99 loss: 0.6931473612785339\n",
      "epoch: 16 step: 100 loss: 0.6931473612785339\n",
      "epoch: 16 step: 101 loss: 0.6931473612785339\n",
      "epoch: 16 step: 102 loss: 0.6931473612785339\n",
      "epoch: 16 step: 103 loss: 0.6931473612785339\n",
      "epoch: 16 step: 104 loss: 0.6931473612785339\n",
      "epoch: 16 step: 105 loss: 0.6931473612785339\n",
      "epoch: 16 step: 106 loss: 0.6931473612785339\n",
      "epoch: 16 step: 107 loss: 0.6931473612785339\n",
      "epoch: 16 step: 108 loss: 0.6931473612785339\n",
      "epoch: 16 step: 109 loss: 0.6931473612785339\n",
      "epoch: 16 step: 110 loss: 0.6931473612785339\n",
      "epoch: 16 step: 111 loss: 0.6931473612785339\n",
      "epoch: 16 step: 112 loss: 0.6931473612785339\n",
      "epoch: 16 step: 113 loss: 0.6931473612785339\n",
      "epoch: 16 step: 114 loss: 0.6931473612785339\n",
      "epoch: 16 step: 115 loss: 0.6931473612785339\n",
      "epoch: 16 step: 116 loss: 0.6931473612785339\n",
      "epoch: 16 step: 117 loss: 0.6931473612785339\n",
      "epoch: 16 step: 118 loss: 0.6931473612785339\n",
      "epoch: 16 step: 119 loss: 0.6931473612785339\n",
      "epoch: 16 step: 120 loss: 0.6931473612785339\n",
      "epoch: 16 step: 121 loss: 0.6931473612785339\n",
      "epoch: 16 step: 122 loss: 0.6931473612785339\n",
      "epoch: 16 step: 123 loss: 0.6931473612785339\n",
      "epoch: 16 step: 124 loss: 0.6931473612785339\n",
      "epoch: 16 step: 125 loss: 0.6931473612785339\n",
      "epoch: 16 step: 126 loss: 0.6931473612785339\n",
      "epoch: 16 step: 127 loss: 0.6931473612785339\n",
      "epoch: 16 step: 128 loss: 0.6931473612785339\n",
      "epoch: 16 step: 129 loss: 0.6931473612785339\n",
      "epoch: 16 step: 130 loss: 0.6931473612785339\n",
      "epoch: 16 step: 131 loss: 0.6931473612785339\n",
      "epoch: 16 step: 132 loss: 0.6931473612785339\n",
      "epoch: 16 step: 133 loss: 0.6931473612785339\n",
      "epoch: 16 step: 134 loss: 0.6931473612785339\n",
      "epoch: 16 step: 135 loss: 0.6931473612785339\n",
      "epoch: 16 step: 136 loss: 0.6931473612785339\n",
      "epoch: 16 step: 137 loss: 0.6931473612785339\n",
      "epoch: 16 step: 138 loss: 0.6931473612785339\n",
      "epoch: 16 step: 139 loss: 0.6931473612785339\n",
      "epoch: 16 step: 140 loss: 0.6931473612785339\n",
      "epoch: 16 step: 141 loss: 0.6931473612785339\n",
      "epoch: 16 step: 142 loss: 0.6931473612785339\n",
      "epoch: 16 step: 143 loss: 0.6931473612785339\n",
      "epoch: 16 step: 144 loss: 0.6931473612785339\n",
      "epoch: 16 step: 145 loss: 0.6931473612785339\n",
      "epoch: 16 step: 146 loss: 0.6931473612785339\n",
      "epoch: 16 step: 147 loss: 0.6931473612785339\n",
      "epoch: 16 step: 148 loss: 0.6931473612785339\n",
      "epoch: 16 step: 149 loss: 0.6931473612785339\n",
      "epoch: 16 step: 150 loss: 0.6931473612785339\n",
      "epoch: 16 step: 151 loss: 0.6931473612785339\n",
      "epoch: 16 step: 152 loss: 0.6931473612785339\n",
      "epoch: 16 step: 153 loss: 0.6931473612785339\n",
      "epoch: 16 step: 154 loss: 0.6931473612785339\n",
      "epoch: 16 step: 155 loss: 0.6931473612785339\n",
      "epoch: 16 step: 156 loss: 0.6931473612785339\n",
      "epoch: 16 step: 157 loss: 0.6931473612785339\n",
      "epoch: 16 step: 158 loss: 0.6931473612785339\n",
      "epoch: 16 step: 159 loss: 0.6931473612785339\n",
      "epoch: 16 step: 160 loss: 0.6931473612785339\n",
      "epoch: 16 step: 161 loss: 0.6931473612785339\n",
      "epoch: 16 step: 162 loss: 0.6931473612785339\n",
      "epoch: 16 step: 163 loss: 0.6931473612785339\n",
      "epoch: 16 step: 164 loss: 0.6931473612785339\n",
      "epoch: 16 step: 165 loss: 0.6931473612785339\n",
      "epoch: 16 step: 166 loss: 0.6931473612785339\n",
      "epoch: 16 step: 167 loss: 0.6931473612785339\n",
      "epoch: 16 step: 168 loss: 0.6931473612785339\n",
      "epoch: 16 step: 169 loss: 0.6931473612785339\n",
      "epoch: 16 step: 170 loss: 0.6931473612785339\n",
      "epoch: 16 step: 171 loss: 0.6931473612785339\n",
      "epoch: 16 step: 172 loss: 0.6931473612785339\n",
      "epoch: 16 step: 173 loss: 0.6931473612785339\n",
      "epoch: 16 step: 174 loss: 0.6931473612785339\n",
      "epoch: 16 step: 175 loss: 0.6931473612785339\n",
      "epoch: 16 step: 176 loss: 0.6931473612785339\n",
      "epoch: 16 step: 177 loss: 0.6931473612785339\n",
      "epoch: 16 step: 178 loss: 0.6931473612785339\n",
      "epoch: 16 step: 179 loss: 0.6931473612785339\n",
      "epoch: 16 step: 180 loss: 0.6931473612785339\n",
      "epoch: 16 step: 181 loss: 0.6931473612785339\n",
      "epoch: 16 step: 182 loss: 0.6931473612785339\n",
      "epoch: 16 step: 183 loss: 0.6931473612785339\n",
      "epoch: 16 step: 184 loss: 0.6931473612785339\n",
      "epoch: 16 step: 185 loss: 0.6931473612785339\n",
      "epoch: 16 step: 186 loss: 0.6931473612785339\n",
      "epoch: 16 step: 187 loss: 0.6931473612785339\n",
      "epoch: 16 step: 188 loss: 0.6931473612785339\n",
      "epoch: 16 step: 189 loss: 0.6931473612785339\n",
      "epoch: 16 step: 190 loss: 0.6931473612785339\n",
      "epoch: 16 step: 191 loss: 0.6931473612785339\n",
      "epoch: 16 step: 192 loss: 0.6931473612785339\n",
      "epoch: 16 step: 193 loss: 0.6931473612785339\n",
      "epoch: 16 step: 194 loss: 0.6931473612785339\n",
      "epoch: 16 step: 195 loss: 0.6931473612785339\n",
      "epoch: 16 step: 196 loss: 0.6931473612785339\n",
      "epoch: 16 step: 197 loss: 0.6931473612785339\n",
      "epoch: 16 step: 198 loss: 0.6931473612785339\n",
      "epoch: 16 step: 199 loss: 0.6931473612785339\n",
      "epoch: 16 step: 200 loss: 0.6931473612785339\n",
      "epoch: 16 step: 201 loss: 0.6931473612785339\n",
      "epoch: 16 step: 202 loss: 0.6931473612785339\n",
      "epoch: 16 step: 203 loss: 0.6931473612785339\n",
      "epoch: 16 step: 204 loss: 0.6931473612785339\n",
      "epoch: 16 step: 205 loss: 0.6931473612785339\n",
      "epoch: 16 step: 206 loss: 0.6931473612785339\n",
      "epoch: 16 step: 207 loss: 0.6931473612785339\n",
      "epoch: 16 step: 208 loss: 0.6931473612785339\n",
      "epoch: 16 step: 209 loss: 0.6931473612785339\n",
      "epoch: 16 step: 210 loss: 0.6931473612785339\n",
      "epoch: 16 step: 211 loss: 0.6931473612785339\n",
      "epoch: 16 step: 212 loss: 0.6931473612785339\n",
      "epoch: 16 step: 213 loss: 0.6931473612785339\n",
      "epoch: 16 step: 214 loss: 0.6931473612785339\n",
      "epoch: 16 step: 215 loss: 0.6931473612785339\n",
      "epoch: 16 step: 216 loss: 0.6931473612785339\n",
      "epoch: 16 step: 217 loss: 0.6931473612785339\n",
      "epoch: 16 step: 218 loss: 0.6931473612785339\n",
      "epoch: 16 step: 219 loss: 0.6931473612785339\n",
      "epoch: 16 step: 220 loss: 0.6931473612785339\n",
      "epoch: 16 step: 221 loss: 0.6931473612785339\n",
      "epoch: 16 step: 222 loss: 0.6931473612785339\n",
      "epoch: 16 step: 223 loss: 0.6931473612785339\n",
      "epoch: 16 step: 224 loss: 0.6931473612785339\n",
      "epoch: 16 step: 225 loss: 0.6931473612785339\n",
      "epoch: 16 step: 226 loss: 0.6931473612785339\n",
      "epoch: 16 step: 227 loss: 0.6931473612785339\n",
      "epoch: 16 step: 228 loss: 0.6931473612785339\n",
      "epoch: 16 step: 229 loss: 0.6931473612785339\n",
      "epoch: 16 step: 230 loss: 0.6931473612785339\n",
      "epoch: 16 step: 231 loss: 0.6931473612785339\n",
      "epoch: 16 step: 232 loss: 0.6931473612785339\n",
      "epoch: 16 step: 233 loss: 0.6931473612785339\n",
      "epoch: 16 step: 234 loss: 0.6931473612785339\n",
      "epoch: 16 step: 235 loss: 0.6931473612785339\n",
      "epoch: 16 step: 236 loss: 0.6931473612785339\n",
      "epoch: 16 step: 237 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 238 loss: 0.6931473612785339\n",
      "epoch: 16 step: 239 loss: 0.6931473612785339\n",
      "epoch: 16 step: 240 loss: 0.6931473612785339\n",
      "epoch: 16 step: 241 loss: 0.6931473612785339\n",
      "epoch: 16 step: 242 loss: 0.6931473612785339\n",
      "epoch: 16 step: 243 loss: 0.6931473612785339\n",
      "epoch: 16 step: 244 loss: 0.6931473612785339\n",
      "epoch: 16 step: 245 loss: 0.6931473612785339\n",
      "epoch: 16 step: 246 loss: 0.6931473612785339\n",
      "epoch: 16 step: 247 loss: 0.6931473612785339\n",
      "epoch: 16 step: 248 loss: 0.6931473612785339\n",
      "epoch: 16 step: 249 loss: 0.6931473612785339\n",
      "epoch: 16 step: 250 loss: 0.6931473612785339\n",
      "epoch: 16 step: 251 loss: 0.6931473612785339\n",
      "epoch: 16 step: 252 loss: 0.6931473612785339\n",
      "epoch: 16 step: 253 loss: 0.6931473612785339\n",
      "epoch: 16 step: 254 loss: 0.6931473612785339\n",
      "epoch: 16 step: 255 loss: 0.6931473612785339\n",
      "epoch: 16 step: 256 loss: 0.6931473612785339\n",
      "epoch: 16 step: 257 loss: 0.6931473612785339\n",
      "epoch: 16 step: 258 loss: 0.6931473612785339\n",
      "epoch: 16 step: 259 loss: 0.6931473612785339\n",
      "epoch: 16 step: 260 loss: 0.6931473612785339\n",
      "epoch: 16 step: 261 loss: 0.6931473612785339\n",
      "epoch: 16 step: 262 loss: 0.6931473612785339\n",
      "epoch: 16 step: 263 loss: 0.6931473612785339\n",
      "epoch: 16 step: 264 loss: 0.6931473612785339\n",
      "epoch: 16 step: 265 loss: 0.6931473612785339\n",
      "epoch: 16 step: 266 loss: 0.6931473612785339\n",
      "epoch: 16 step: 267 loss: 0.6931473612785339\n",
      "epoch: 16 step: 268 loss: 0.6931473612785339\n",
      "epoch: 16 step: 269 loss: 0.6931473612785339\n",
      "epoch: 16 step: 270 loss: 0.6931473612785339\n",
      "epoch: 16 step: 271 loss: 0.6931473612785339\n",
      "epoch: 16 step: 272 loss: 0.6931473612785339\n",
      "epoch: 16 step: 273 loss: 0.6931473612785339\n",
      "epoch: 16 step: 274 loss: 0.6931473612785339\n",
      "epoch: 16 step: 275 loss: 0.6931473612785339\n",
      "epoch: 16 step: 276 loss: 0.6931473612785339\n",
      "epoch: 16 step: 277 loss: 0.6931473612785339\n",
      "epoch: 16 step: 278 loss: 0.6931473612785339\n",
      "epoch: 16 step: 279 loss: 0.6931473612785339\n",
      "epoch: 16 step: 280 loss: 0.6931473612785339\n",
      "epoch: 16 step: 281 loss: 0.6931473612785339\n",
      "epoch: 16 step: 282 loss: 0.6931473612785339\n",
      "epoch: 16 step: 283 loss: 0.6931473612785339\n",
      "epoch: 16 step: 284 loss: 0.6931473612785339\n",
      "epoch: 16 step: 285 loss: 0.6931473612785339\n",
      "epoch: 16 step: 286 loss: 0.6931473612785339\n",
      "epoch: 16 step: 287 loss: 0.6931473612785339\n",
      "epoch: 16 step: 288 loss: 0.6931473612785339\n",
      "epoch: 16 step: 289 loss: 0.6931473612785339\n",
      "epoch: 16 step: 290 loss: 0.6931473612785339\n",
      "epoch: 16 step: 291 loss: 0.6931473612785339\n",
      "epoch: 16 step: 292 loss: 0.6931473612785339\n",
      "epoch: 16 step: 293 loss: 0.6931473612785339\n",
      "epoch: 16 step: 294 loss: 0.6931473612785339\n",
      "epoch: 16 step: 295 loss: 0.6931473612785339\n",
      "epoch: 16 step: 296 loss: 0.6931473612785339\n",
      "epoch: 16 step: 297 loss: 0.6931473612785339\n",
      "epoch: 16 step: 298 loss: 0.6931473612785339\n",
      "epoch: 16 step: 299 loss: 0.6931473612785339\n",
      "epoch: 16 step: 300 loss: 0.6931473612785339\n",
      "epoch: 16 step: 301 loss: 0.6931473612785339\n",
      "epoch: 16 step: 302 loss: 0.6931473612785339\n",
      "epoch: 16 step: 303 loss: 0.6931473612785339\n",
      "epoch: 16 step: 304 loss: 0.6931473612785339\n",
      "epoch: 16 step: 305 loss: 0.6931473612785339\n",
      "epoch: 16 step: 306 loss: 0.6931473612785339\n",
      "epoch: 16 step: 307 loss: 0.6931473612785339\n",
      "epoch: 16 step: 308 loss: 0.6931473612785339\n",
      "epoch: 16 step: 309 loss: 0.6931473612785339\n",
      "epoch: 16 step: 310 loss: 0.6931473612785339\n",
      "epoch: 16 step: 311 loss: 0.6931473612785339\n",
      "epoch: 16 step: 312 loss: 0.6931473612785339\n",
      "epoch: 16 step: 313 loss: 0.6931473612785339\n",
      "epoch: 16 step: 314 loss: 0.6931473612785339\n",
      "epoch: 16 step: 315 loss: 0.6931473612785339\n",
      "epoch: 16 step: 316 loss: 0.6931473612785339\n",
      "epoch: 16 step: 317 loss: 0.6931473612785339\n",
      "epoch: 16 step: 318 loss: 0.6931473612785339\n",
      "epoch: 16 step: 319 loss: 0.6931473612785339\n",
      "epoch: 16 step: 320 loss: 0.6931473612785339\n",
      "epoch: 16 step: 321 loss: 0.6931473612785339\n",
      "epoch: 16 step: 322 loss: 0.6931473612785339\n",
      "epoch: 16 step: 323 loss: 0.6931473612785339\n",
      "epoch: 16 step: 324 loss: 0.6931473612785339\n",
      "epoch: 16 step: 325 loss: 0.6931473612785339\n",
      "epoch: 16 step: 326 loss: 0.6931473612785339\n",
      "epoch: 16 step: 327 loss: 0.6931473612785339\n",
      "epoch: 16 step: 328 loss: 0.6931473612785339\n",
      "epoch: 16 step: 329 loss: 0.6931473612785339\n",
      "epoch: 16 step: 330 loss: 0.6931473612785339\n",
      "epoch: 16 step: 331 loss: 0.6931473612785339\n",
      "epoch: 16 step: 332 loss: 0.6931473612785339\n",
      "epoch: 16 step: 333 loss: 0.6931473612785339\n",
      "epoch: 16 step: 334 loss: 0.6931473612785339\n",
      "epoch: 16 step: 335 loss: 0.6931473612785339\n",
      "epoch: 16 step: 336 loss: 0.6931473612785339\n",
      "epoch: 16 step: 337 loss: 0.6931473612785339\n",
      "epoch: 16 step: 338 loss: 0.6931473612785339\n",
      "epoch: 16 step: 339 loss: 0.6931473612785339\n",
      "epoch: 16 step: 340 loss: 0.6931473612785339\n",
      "epoch: 16 step: 341 loss: 0.6931473612785339\n",
      "epoch: 16 step: 342 loss: 0.6931473612785339\n",
      "epoch: 16 step: 343 loss: 0.6931473612785339\n",
      "epoch: 16 step: 344 loss: 0.6931473612785339\n",
      "epoch: 16 step: 345 loss: 0.6931473612785339\n",
      "epoch: 16 step: 346 loss: 0.6931473612785339\n",
      "epoch: 16 step: 347 loss: 0.6931473612785339\n",
      "epoch: 16 step: 348 loss: 0.6931473612785339\n",
      "epoch: 16 step: 349 loss: 0.6931473612785339\n",
      "epoch: 16 step: 350 loss: 0.6931473612785339\n",
      "epoch: 16 step: 351 loss: 0.6931473612785339\n",
      "epoch: 16 step: 352 loss: 0.6931473612785339\n",
      "epoch: 16 step: 353 loss: 0.6931473612785339\n",
      "epoch: 16 step: 354 loss: 0.6931473612785339\n",
      "epoch: 16 step: 355 loss: 0.6931473612785339\n",
      "epoch: 16 step: 356 loss: 0.6931473612785339\n",
      "epoch: 16 step: 357 loss: 0.6931473612785339\n",
      "epoch: 16 step: 358 loss: 0.6931473612785339\n",
      "epoch: 16 step: 359 loss: 0.6931473612785339\n",
      "epoch: 16 step: 360 loss: 0.6931473612785339\n",
      "epoch: 16 step: 361 loss: 0.6931473612785339\n",
      "epoch: 16 step: 362 loss: 0.6931473612785339\n",
      "epoch: 16 step: 363 loss: 0.6931473612785339\n",
      "epoch: 16 step: 364 loss: 0.6931473612785339\n",
      "epoch: 16 step: 365 loss: 0.6931473612785339\n",
      "epoch: 16 step: 366 loss: 0.6931473612785339\n",
      "epoch: 16 step: 367 loss: 0.6931473612785339\n",
      "epoch: 16 step: 368 loss: 0.6931473612785339\n",
      "epoch: 16 step: 369 loss: 0.6931473612785339\n",
      "epoch: 16 step: 370 loss: 0.6931473612785339\n",
      "epoch: 16 step: 371 loss: 0.6931473612785339\n",
      "epoch: 16 step: 372 loss: 0.6931473612785339\n",
      "epoch: 16 step: 373 loss: 0.6931473612785339\n",
      "epoch: 16 step: 374 loss: 0.6931473612785339\n",
      "epoch: 16 step: 375 loss: 0.6931473612785339\n",
      "epoch: 16 step: 376 loss: 0.6931473612785339\n",
      "epoch: 16 step: 377 loss: 0.6931473612785339\n",
      "epoch: 16 step: 378 loss: 0.6931473612785339\n",
      "epoch: 16 step: 379 loss: 0.6931473612785339\n",
      "epoch: 16 step: 380 loss: 0.6931473612785339\n",
      "epoch: 16 step: 381 loss: 0.6931473612785339\n",
      "epoch: 16 step: 382 loss: 0.6931473612785339\n",
      "epoch: 16 step: 383 loss: 0.6931473612785339\n",
      "epoch: 16 step: 384 loss: 0.6931473612785339\n",
      "epoch: 16 step: 385 loss: 0.6931473612785339\n",
      "epoch: 16 step: 386 loss: 0.6931473612785339\n",
      "epoch: 16 step: 387 loss: 0.6931473612785339\n",
      "epoch: 16 step: 388 loss: 0.6931473612785339\n",
      "epoch: 16 step: 389 loss: 0.6931473612785339\n",
      "epoch: 16 step: 390 loss: 0.6931473612785339\n",
      "epoch: 16 step: 391 loss: 0.6931473612785339\n",
      "epoch: 16 step: 392 loss: 0.6931473612785339\n",
      "epoch: 16 step: 393 loss: 0.6931473612785339\n",
      "epoch: 16 step: 394 loss: 0.6931473612785339\n",
      "epoch: 16 step: 395 loss: 0.6931473612785339\n",
      "epoch: 16 step: 396 loss: 0.6931473612785339\n",
      "epoch: 16 step: 397 loss: 0.6931473612785339\n",
      "epoch: 16 step: 398 loss: 0.6931473612785339\n",
      "epoch: 16 step: 399 loss: 0.6931473612785339\n",
      "epoch: 16 step: 400 loss: 0.6931473612785339\n",
      "epoch: 16 step: 401 loss: 0.6931473612785339\n",
      "epoch: 16 step: 402 loss: 0.6931473612785339\n",
      "epoch: 16 step: 403 loss: 0.6931473612785339\n",
      "epoch: 16 step: 404 loss: 0.6931473612785339\n",
      "epoch: 16 step: 405 loss: 0.6931473612785339\n",
      "epoch: 16 step: 406 loss: 0.6931473612785339\n",
      "epoch: 16 step: 407 loss: 0.6931473612785339\n",
      "epoch: 16 step: 408 loss: 0.6931473612785339\n",
      "epoch: 16 step: 409 loss: 0.6931473612785339\n",
      "epoch: 16 step: 410 loss: 0.6931473612785339\n",
      "epoch: 16 step: 411 loss: 0.6931473612785339\n",
      "epoch: 16 step: 412 loss: 0.6931473612785339\n",
      "epoch: 16 step: 413 loss: 0.6931473612785339\n",
      "epoch: 16 step: 414 loss: 0.6931473612785339\n",
      "epoch: 16 step: 415 loss: 0.6931473612785339\n",
      "epoch: 16 step: 416 loss: 0.6931473612785339\n",
      "epoch: 16 step: 417 loss: 0.6931473612785339\n",
      "epoch: 16 step: 418 loss: 0.6931473612785339\n",
      "epoch: 16 step: 419 loss: 0.6931473612785339\n",
      "epoch: 16 step: 420 loss: 0.6931473612785339\n",
      "epoch: 16 step: 421 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 422 loss: 0.6931473612785339\n",
      "epoch: 16 step: 423 loss: 0.6931473612785339\n",
      "epoch: 16 step: 424 loss: 0.6931473612785339\n",
      "epoch: 16 step: 425 loss: 0.6931473612785339\n",
      "epoch: 16 step: 426 loss: 0.6931473612785339\n",
      "epoch: 16 step: 427 loss: 0.6931473612785339\n",
      "epoch: 16 step: 428 loss: 0.6931473612785339\n",
      "epoch: 16 step: 429 loss: 0.6931473612785339\n",
      "epoch: 16 step: 430 loss: 0.6931473612785339\n",
      "epoch: 16 step: 431 loss: 0.6931473612785339\n",
      "epoch: 16 step: 432 loss: 0.6931473612785339\n",
      "epoch: 16 step: 433 loss: 0.6931473612785339\n",
      "epoch: 16 step: 434 loss: 0.6931473612785339\n",
      "epoch: 16 step: 435 loss: 0.6931473612785339\n",
      "epoch: 16 step: 436 loss: 0.6931473612785339\n",
      "epoch: 16 step: 437 loss: 0.6931473612785339\n",
      "epoch: 16 step: 438 loss: 0.6931473612785339\n",
      "epoch: 16 step: 439 loss: 0.6931473612785339\n",
      "epoch: 16 step: 440 loss: 0.6931473612785339\n",
      "epoch: 16 step: 441 loss: 0.6931473612785339\n",
      "epoch: 16 step: 442 loss: 0.6931473612785339\n",
      "epoch: 16 step: 443 loss: 0.6931473612785339\n",
      "epoch: 16 step: 444 loss: 0.6931473612785339\n",
      "epoch: 16 step: 445 loss: 0.6931473612785339\n",
      "epoch: 16 step: 446 loss: 0.6931473612785339\n",
      "epoch: 16 step: 447 loss: 0.6931473612785339\n",
      "epoch: 16 step: 448 loss: 0.6931473612785339\n",
      "epoch: 16 step: 449 loss: 0.6931473612785339\n",
      "epoch: 16 step: 450 loss: 0.6931473612785339\n",
      "epoch: 16 step: 451 loss: 0.6931473612785339\n",
      "epoch: 16 step: 452 loss: 0.6931473612785339\n",
      "epoch: 16 step: 453 loss: 0.6931473612785339\n",
      "epoch: 16 step: 454 loss: 0.6931473612785339\n",
      "epoch: 16 step: 455 loss: 0.6931473612785339\n",
      "epoch: 16 step: 456 loss: 0.6931473612785339\n",
      "epoch: 16 step: 457 loss: 0.6931473612785339\n",
      "epoch: 16 step: 458 loss: 0.6931473612785339\n",
      "epoch: 16 step: 459 loss: 0.6931473612785339\n",
      "epoch: 16 step: 460 loss: 0.6931473612785339\n",
      "epoch: 16 step: 461 loss: 0.6931473612785339\n",
      "epoch: 16 step: 462 loss: 0.6931473612785339\n",
      "epoch: 16 step: 463 loss: 0.6931473612785339\n",
      "epoch: 16 step: 464 loss: 0.6931473612785339\n",
      "epoch: 16 step: 465 loss: 0.6931473612785339\n",
      "epoch: 16 step: 466 loss: 0.6931473612785339\n",
      "epoch: 16 step: 467 loss: 0.6931473612785339\n",
      "epoch: 16 step: 468 loss: 0.6931473612785339\n",
      "epoch: 16 step: 469 loss: 0.6931473612785339\n",
      "epoch: 16 step: 470 loss: 0.6931473612785339\n",
      "epoch: 16 step: 471 loss: 0.6931473612785339\n",
      "epoch: 16 step: 472 loss: 0.6931473612785339\n",
      "epoch: 16 step: 473 loss: 0.6931473612785339\n",
      "epoch: 16 step: 474 loss: 0.6931473612785339\n",
      "epoch: 16 step: 475 loss: 0.6931473612785339\n",
      "epoch: 16 step: 476 loss: 0.6931473612785339\n",
      "epoch: 16 step: 477 loss: 0.6931473612785339\n",
      "epoch: 16 step: 478 loss: 0.6931473612785339\n",
      "epoch: 16 step: 479 loss: 0.6931473612785339\n",
      "epoch: 16 step: 480 loss: 0.6931473612785339\n",
      "epoch: 16 step: 481 loss: 0.6931473612785339\n",
      "epoch: 16 step: 482 loss: 0.6931473612785339\n",
      "epoch: 16 step: 483 loss: 0.6931473612785339\n",
      "epoch: 16 step: 484 loss: 0.6931473612785339\n",
      "epoch: 16 step: 485 loss: 0.6931473612785339\n",
      "epoch: 16 step: 486 loss: 0.6931473612785339\n",
      "epoch: 16 step: 487 loss: 0.6931473612785339\n",
      "epoch: 16 step: 488 loss: 0.6931473612785339\n",
      "epoch: 16 step: 489 loss: 0.6931473612785339\n",
      "epoch: 16 step: 490 loss: 0.6931473612785339\n",
      "epoch: 16 step: 491 loss: 0.6931473612785339\n",
      "epoch: 16 step: 492 loss: 0.6931473612785339\n",
      "epoch: 16 step: 493 loss: 0.6931473612785339\n",
      "epoch: 16 step: 494 loss: 0.6931473612785339\n",
      "epoch: 16 step: 495 loss: 0.6931473612785339\n",
      "epoch: 16 step: 496 loss: 0.6931473612785339\n",
      "epoch: 16 step: 497 loss: 0.6931473612785339\n",
      "epoch: 16 step: 498 loss: 0.6931473612785339\n",
      "epoch: 16 step: 499 loss: 0.6931473612785339\n",
      "epoch: 16 step: 500 loss: 0.6931473612785339\n",
      "epoch: 16 step: 501 loss: 0.6931473612785339\n",
      "epoch: 16 step: 502 loss: 0.6931473612785339\n",
      "epoch: 16 step: 503 loss: 0.6931473612785339\n",
      "epoch: 16 step: 504 loss: 0.6931473612785339\n",
      "epoch: 16 step: 505 loss: 0.6931473612785339\n",
      "epoch: 16 step: 506 loss: 0.6931473612785339\n",
      "epoch: 16 step: 507 loss: 0.6931473612785339\n",
      "epoch: 16 step: 508 loss: 0.6931473612785339\n",
      "epoch: 16 step: 509 loss: 0.6931473612785339\n",
      "epoch: 16 step: 510 loss: 0.6931473612785339\n",
      "epoch: 16 step: 511 loss: 0.6931473612785339\n",
      "epoch: 16 step: 512 loss: 0.6931473612785339\n",
      "epoch: 16 step: 513 loss: 0.6931473612785339\n",
      "epoch: 16 step: 514 loss: 0.6931473612785339\n",
      "epoch: 16 step: 515 loss: 0.6931473612785339\n",
      "epoch: 16 step: 516 loss: 0.6931473612785339\n",
      "epoch: 16 step: 517 loss: 0.6931473612785339\n",
      "epoch: 16 step: 518 loss: 0.6931473612785339\n",
      "epoch: 16 step: 519 loss: 0.6931473612785339\n",
      "epoch: 16 step: 520 loss: 0.6931473612785339\n",
      "epoch: 16 step: 521 loss: 0.6931473612785339\n",
      "epoch: 16 step: 522 loss: 0.6931473612785339\n",
      "epoch: 16 step: 523 loss: 0.6931473612785339\n",
      "epoch: 16 step: 524 loss: 0.6931473612785339\n",
      "epoch: 16 step: 525 loss: 0.6931473612785339\n",
      "epoch: 16 step: 526 loss: 0.6931473612785339\n",
      "epoch: 16 step: 527 loss: 0.6931473612785339\n",
      "epoch: 16 step: 528 loss: 0.6931473612785339\n",
      "epoch: 16 step: 529 loss: 0.6931473612785339\n",
      "epoch: 16 step: 530 loss: 0.6931473612785339\n",
      "epoch: 16 step: 531 loss: 0.6931473612785339\n",
      "epoch: 16 step: 532 loss: 0.6931473612785339\n",
      "epoch: 16 step: 533 loss: 0.6931473612785339\n",
      "epoch: 16 step: 534 loss: 0.6931473612785339\n",
      "epoch: 16 step: 535 loss: 0.6931473612785339\n",
      "epoch: 16 step: 536 loss: 0.6931473612785339\n",
      "epoch: 16 step: 537 loss: 0.6931473612785339\n",
      "epoch: 16 step: 538 loss: 0.6931473612785339\n",
      "epoch: 16 step: 539 loss: 0.6931473612785339\n",
      "epoch: 16 step: 540 loss: 0.6931473612785339\n",
      "epoch: 16 step: 541 loss: 0.6931473612785339\n",
      "epoch: 16 step: 542 loss: 0.6931473612785339\n",
      "epoch: 16 step: 543 loss: 0.6931473612785339\n",
      "epoch: 16 step: 544 loss: 0.6931473612785339\n",
      "epoch: 16 step: 545 loss: 0.6931473612785339\n",
      "epoch: 16 step: 546 loss: 0.6931473612785339\n",
      "epoch: 16 step: 547 loss: 0.6931473612785339\n",
      "epoch: 16 step: 548 loss: 0.6931473612785339\n",
      "epoch: 16 step: 549 loss: 0.6931473612785339\n",
      "epoch: 16 step: 550 loss: 0.6931473612785339\n",
      "epoch: 16 step: 551 loss: 0.6931473612785339\n",
      "epoch: 16 step: 552 loss: 0.6931473612785339\n",
      "epoch: 16 step: 553 loss: 0.6931473612785339\n",
      "epoch: 16 step: 554 loss: 0.6931473612785339\n",
      "epoch: 16 step: 555 loss: 0.6931473612785339\n",
      "epoch: 16 step: 556 loss: 0.6931473612785339\n",
      "epoch: 16 step: 557 loss: 0.6931473612785339\n",
      "epoch: 16 step: 558 loss: 0.6931473612785339\n",
      "epoch: 16 step: 559 loss: 0.6931473612785339\n",
      "epoch: 16 step: 560 loss: 0.6931473612785339\n",
      "epoch: 16 step: 561 loss: 0.6931473612785339\n",
      "epoch: 16 step: 562 loss: 0.6931473612785339\n",
      "epoch: 16 step: 563 loss: 0.6931473612785339\n",
      "epoch: 16 step: 564 loss: 0.6931473612785339\n",
      "epoch: 16 step: 565 loss: 0.6931473612785339\n",
      "epoch: 16 step: 566 loss: 0.6931473612785339\n",
      "epoch: 16 step: 567 loss: 0.6931473612785339\n",
      "epoch: 16 step: 568 loss: 0.6931473612785339\n",
      "epoch: 16 step: 569 loss: 0.6931473612785339\n",
      "epoch: 16 step: 570 loss: 0.6931473612785339\n",
      "epoch: 16 step: 571 loss: 0.6931473612785339\n",
      "epoch: 16 step: 572 loss: 0.6931473612785339\n",
      "epoch: 16 step: 573 loss: 0.6931473612785339\n",
      "epoch: 16 step: 574 loss: 0.6931473612785339\n",
      "epoch: 16 step: 575 loss: 0.6931473612785339\n",
      "epoch: 16 step: 576 loss: 0.6931473612785339\n",
      "epoch: 16 step: 577 loss: 0.6931473612785339\n",
      "epoch: 16 step: 578 loss: 0.6931473612785339\n",
      "epoch: 16 step: 579 loss: 0.6931473612785339\n",
      "epoch: 16 step: 580 loss: 0.6931473612785339\n",
      "epoch: 16 step: 581 loss: 0.6931473612785339\n",
      "epoch: 16 step: 582 loss: 0.6931473612785339\n",
      "epoch: 16 step: 583 loss: 0.6931473612785339\n",
      "epoch: 16 step: 584 loss: 0.6931473612785339\n",
      "epoch: 16 step: 585 loss: 0.6931473612785339\n",
      "epoch: 16 step: 586 loss: 0.6931473612785339\n",
      "epoch: 16 step: 587 loss: 0.6931473612785339\n",
      "epoch: 16 step: 588 loss: 0.6931473612785339\n",
      "epoch: 16 step: 589 loss: 0.6931473612785339\n",
      "epoch: 16 step: 590 loss: 0.6931473612785339\n",
      "epoch: 16 step: 591 loss: 0.6931473612785339\n",
      "epoch: 16 step: 592 loss: 0.6931473612785339\n",
      "epoch: 16 step: 593 loss: 0.6931473612785339\n",
      "epoch: 16 step: 594 loss: 0.6931473612785339\n",
      "epoch: 16 step: 595 loss: 0.6931473612785339\n",
      "epoch: 16 step: 596 loss: 0.6931473612785339\n",
      "epoch: 16 step: 597 loss: 0.6931473612785339\n",
      "epoch: 16 step: 598 loss: 0.6931473612785339\n",
      "epoch: 16 step: 599 loss: 0.6931473612785339\n",
      "epoch: 16 step: 600 loss: 0.6931473612785339\n",
      "epoch: 16 step: 601 loss: 0.6931473612785339\n",
      "epoch: 16 step: 602 loss: 0.6931473612785339\n",
      "epoch: 16 step: 603 loss: 0.6931473612785339\n",
      "epoch: 16 step: 604 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 605 loss: 0.6931473612785339\n",
      "epoch: 16 step: 606 loss: 0.6931473612785339\n",
      "epoch: 16 step: 607 loss: 0.6931473612785339\n",
      "epoch: 16 step: 608 loss: 0.6931473612785339\n",
      "epoch: 16 step: 609 loss: 0.6931473612785339\n",
      "epoch: 16 step: 610 loss: 0.6931473612785339\n",
      "epoch: 16 step: 611 loss: 0.6931473612785339\n",
      "epoch: 16 step: 612 loss: 0.6931473612785339\n",
      "epoch: 16 step: 613 loss: 0.6931473612785339\n",
      "epoch: 16 step: 614 loss: 0.6931473612785339\n",
      "epoch: 16 step: 615 loss: 0.6931473612785339\n",
      "epoch: 16 step: 616 loss: 0.6931473612785339\n",
      "epoch: 16 step: 617 loss: 0.6931473612785339\n",
      "epoch: 16 step: 618 loss: 0.6931473612785339\n",
      "epoch: 16 step: 619 loss: 0.6931473612785339\n",
      "epoch: 16 step: 620 loss: 0.6931473612785339\n",
      "epoch: 16 step: 621 loss: 0.6931473612785339\n",
      "epoch: 16 step: 622 loss: 0.6931473612785339\n",
      "epoch: 16 step: 623 loss: 0.6931473612785339\n",
      "epoch: 16 step: 624 loss: 0.6931473612785339\n",
      "epoch: 16 step: 625 loss: 0.6931473612785339\n",
      "epoch: 16 step: 626 loss: 0.6931473612785339\n",
      "epoch: 16 step: 627 loss: 0.6931473612785339\n",
      "epoch: 16 step: 628 loss: 0.6931473612785339\n",
      "epoch: 16 step: 629 loss: 0.6931473612785339\n",
      "epoch: 16 step: 630 loss: 0.6931473612785339\n",
      "epoch: 16 step: 631 loss: 0.6931473612785339\n",
      "epoch: 16 step: 632 loss: 0.6931473612785339\n",
      "epoch: 16 step: 633 loss: 0.6931473612785339\n",
      "epoch: 16 step: 634 loss: 0.6931473612785339\n",
      "epoch: 16 step: 635 loss: 0.6931473612785339\n",
      "epoch: 16 step: 636 loss: 0.6931473612785339\n",
      "epoch: 16 step: 637 loss: 0.6931473612785339\n",
      "epoch: 16 step: 638 loss: 0.6931473612785339\n",
      "epoch: 16 step: 639 loss: 0.6931473612785339\n",
      "epoch: 16 step: 640 loss: 0.6931473612785339\n",
      "epoch: 16 step: 641 loss: 0.6931473612785339\n",
      "epoch: 16 step: 642 loss: 0.6931473612785339\n",
      "epoch: 16 step: 643 loss: 0.6931473612785339\n",
      "epoch: 16 step: 644 loss: 0.6931473612785339\n",
      "epoch: 16 step: 645 loss: 0.6931473612785339\n",
      "epoch: 16 step: 646 loss: 0.6931473612785339\n",
      "epoch: 16 step: 647 loss: 0.6931473612785339\n",
      "epoch: 16 step: 648 loss: 0.6931473612785339\n",
      "epoch: 16 step: 649 loss: 0.6931473612785339\n",
      "epoch: 16 step: 650 loss: 0.6931473612785339\n",
      "epoch: 16 step: 651 loss: 0.6931473612785339\n",
      "epoch: 16 step: 652 loss: 0.6931473612785339\n",
      "epoch: 16 step: 653 loss: 0.6931473612785339\n",
      "epoch: 16 step: 654 loss: 0.6931473612785339\n",
      "epoch: 16 step: 655 loss: 0.6931473612785339\n",
      "epoch: 16 step: 656 loss: 0.6931473612785339\n",
      "epoch: 16 step: 657 loss: 0.6931473612785339\n",
      "epoch: 16 step: 658 loss: 0.6931473612785339\n",
      "epoch: 16 step: 659 loss: 0.6931473612785339\n",
      "epoch: 16 step: 660 loss: 0.6931473612785339\n",
      "epoch: 16 step: 661 loss: 0.6931473612785339\n",
      "epoch: 16 step: 662 loss: 0.6931473612785339\n",
      "epoch: 16 step: 663 loss: 0.6931473612785339\n",
      "epoch: 16 step: 664 loss: 0.6931473612785339\n",
      "epoch: 16 step: 665 loss: 0.6931473612785339\n",
      "epoch: 16 step: 666 loss: 0.6931473612785339\n",
      "epoch: 16 step: 667 loss: 0.6931473612785339\n",
      "epoch: 16 step: 668 loss: 0.6931473016738892\n",
      "epoch: 16 step: 669 loss: 0.6931473612785339\n",
      "epoch: 16 step: 670 loss: 0.6931473612785339\n",
      "epoch: 16 step: 671 loss: 0.6931473612785339\n",
      "epoch: 16 step: 672 loss: 0.6931473612785339\n",
      "epoch: 16 step: 673 loss: 0.6931473612785339\n",
      "epoch: 16 step: 674 loss: 0.6931473612785339\n",
      "epoch: 16 step: 675 loss: 0.6931473612785339\n",
      "epoch: 16 step: 676 loss: 0.6931473612785339\n",
      "epoch: 16 step: 677 loss: 0.6931473612785339\n",
      "epoch: 16 step: 678 loss: 0.6931473016738892\n",
      "epoch: 16 step: 679 loss: 0.6931473016738892\n",
      "epoch: 16 step: 680 loss: 0.6931473612785339\n",
      "epoch: 16 step: 681 loss: 0.6931473612785339\n",
      "epoch: 16 step: 682 loss: 0.6931473612785339\n",
      "epoch: 16 step: 683 loss: 0.6931473612785339\n",
      "epoch: 16 step: 684 loss: 0.6931473612785339\n",
      "epoch: 16 step: 685 loss: 0.6931473612785339\n",
      "epoch: 16 step: 686 loss: 0.6931473612785339\n",
      "epoch: 16 step: 687 loss: 0.6931473612785339\n",
      "epoch: 16 step: 688 loss: 0.6931473612785339\n",
      "epoch: 16 step: 689 loss: 0.6931473612785339\n",
      "epoch: 16 step: 690 loss: 0.6931473612785339\n",
      "epoch: 16 step: 691 loss: 0.6931473016738892\n",
      "epoch: 16 step: 692 loss: 0.6931473612785339\n",
      "epoch: 16 step: 693 loss: 0.6931473612785339\n",
      "epoch: 16 step: 694 loss: 0.6931473612785339\n",
      "epoch: 16 step: 695 loss: 0.6931473612785339\n",
      "epoch: 16 step: 696 loss: 0.6931473016738892\n",
      "epoch: 16 step: 697 loss: 0.6931473612785339\n",
      "epoch: 16 step: 698 loss: 0.6931473612785339\n",
      "epoch: 16 step: 699 loss: 0.6931473612785339\n",
      "epoch: 16 step: 700 loss: 0.6931473612785339\n",
      "epoch: 16 step: 701 loss: 0.6931473612785339\n",
      "epoch: 16 step: 702 loss: 0.6931473612785339\n",
      "epoch: 16 step: 703 loss: 0.6931473016738892\n",
      "epoch: 16 step: 704 loss: 0.6931473612785339\n",
      "epoch: 16 step: 705 loss: 0.6931473016738892\n",
      "epoch: 16 step: 706 loss: 0.6931473612785339\n",
      "epoch: 16 step: 707 loss: 0.6931473016738892\n",
      "epoch: 16 step: 708 loss: 0.6931473612785339\n",
      "epoch: 16 step: 709 loss: 0.6931473612785339\n",
      "epoch: 16 step: 710 loss: 0.6931473612785339\n",
      "epoch: 16 step: 711 loss: 0.6931473016738892\n",
      "epoch: 16 step: 712 loss: 0.6931473612785339\n",
      "epoch: 16 step: 713 loss: 0.6931473612785339\n",
      "epoch: 16 step: 714 loss: 0.6931473612785339\n",
      "epoch: 16 step: 715 loss: 0.6931473612785339\n",
      "epoch: 16 step: 716 loss: 0.6931473016738892\n",
      "epoch: 16 step: 717 loss: 0.6931473612785339\n",
      "epoch: 16 step: 718 loss: 0.6931473612785339\n",
      "epoch: 16 step: 719 loss: 0.6931473612785339\n",
      "epoch: 16 step: 720 loss: 0.6931473016738892\n",
      "epoch: 16 step: 721 loss: 0.6931473612785339\n",
      "epoch: 16 step: 722 loss: 0.6931473612785339\n",
      "epoch: 16 step: 723 loss: 0.6931473612785339\n",
      "epoch: 16 step: 724 loss: 0.6931473612785339\n",
      "epoch: 16 step: 725 loss: 0.6931473612785339\n",
      "epoch: 16 step: 726 loss: 0.6931473612785339\n",
      "epoch: 16 step: 727 loss: 0.6931473016738892\n",
      "epoch: 16 step: 728 loss: 0.6931473612785339\n",
      "epoch: 16 step: 729 loss: 0.6931473612785339\n",
      "epoch: 16 step: 730 loss: 0.6931473612785339\n",
      "epoch: 16 step: 731 loss: 0.6931473612785339\n",
      "epoch: 16 step: 732 loss: 0.6931473612785339\n",
      "epoch: 16 step: 733 loss: 0.6931473612785339\n",
      "epoch: 16 step: 734 loss: 0.6931473016738892\n",
      "epoch: 16 step: 735 loss: 0.6931473612785339\n",
      "epoch: 16 step: 736 loss: 0.6931473612785339\n",
      "epoch: 16 step: 737 loss: 0.6931473612785339\n",
      "epoch: 16 step: 738 loss: 0.6931473612785339\n",
      "epoch: 16 step: 739 loss: 0.6931473612785339\n",
      "epoch: 16 step: 740 loss: 0.6931473612785339\n",
      "epoch: 16 step: 741 loss: 0.6931473612785339\n",
      "epoch: 16 step: 742 loss: 0.6931473612785339\n",
      "epoch: 16 step: 743 loss: 0.6931473016738892\n",
      "epoch: 16 step: 744 loss: 0.6931473016738892\n",
      "epoch: 16 step: 745 loss: 0.6931473016738892\n",
      "epoch: 16 step: 746 loss: 0.6931473612785339\n",
      "epoch: 16 step: 747 loss: 0.6931473612785339\n",
      "epoch: 16 step: 748 loss: 0.6931473612785339\n",
      "epoch: 16 step: 749 loss: 0.6931473612785339\n",
      "epoch: 16 step: 750 loss: 0.6931473612785339\n",
      "epoch: 16 step: 751 loss: 0.6931473016738892\n",
      "epoch: 16 step: 752 loss: 0.6931473612785339\n",
      "epoch: 16 step: 753 loss: 0.6931473612785339\n",
      "epoch: 16 step: 754 loss: 0.6931473612785339\n",
      "epoch: 16 step: 755 loss: 0.6931473016738892\n",
      "epoch: 16 step: 756 loss: 0.6931473612785339\n",
      "epoch: 16 step: 757 loss: 0.6931473016738892\n",
      "epoch: 16 step: 758 loss: 0.6931473612785339\n",
      "epoch: 16 step: 759 loss: 0.6931473016738892\n",
      "epoch: 16 step: 760 loss: 0.6931473612785339\n",
      "epoch: 16 step: 761 loss: 0.6931473612785339\n",
      "epoch: 16 step: 762 loss: 0.6931473016738892\n",
      "epoch: 16 step: 763 loss: 0.6931473612785339\n",
      "epoch: 16 step: 764 loss: 0.6931473612785339\n",
      "epoch: 16 step: 765 loss: 0.6931473612785339\n",
      "epoch: 16 step: 766 loss: 0.6931473612785339\n",
      "epoch: 16 step: 767 loss: 0.6931473016738892\n",
      "epoch: 16 step: 768 loss: 0.6931473016738892\n",
      "epoch: 16 step: 769 loss: 0.6931473016738892\n",
      "epoch: 16 step: 770 loss: 0.6931473612785339\n",
      "epoch: 16 step: 771 loss: 0.6931473612785339\n",
      "epoch: 16 step: 772 loss: 0.6931473612785339\n",
      "epoch: 16 step: 773 loss: 0.6931473612785339\n",
      "epoch: 16 step: 774 loss: 0.6931473612785339\n",
      "epoch: 16 step: 775 loss: 0.6931473016738892\n",
      "epoch: 16 step: 776 loss: 0.6931473612785339\n",
      "epoch: 16 step: 777 loss: 0.6931473016738892\n",
      "epoch: 16 step: 778 loss: 0.6931473016738892\n",
      "epoch: 16 step: 779 loss: 0.6931473612785339\n",
      "epoch: 16 step: 780 loss: 0.6931473016738892\n",
      "epoch: 16 step: 781 loss: 0.6931473612785339\n",
      "epoch: 17 step: 1 loss: 0.6931473016738892\n",
      "epoch: 17 step: 2 loss: 0.6931473016738892\n",
      "epoch: 17 step: 3 loss: 0.6931473612785339\n",
      "epoch: 17 step: 4 loss: 0.6931473612785339\n",
      "epoch: 17 step: 5 loss: 0.6931473016738892\n",
      "epoch: 17 step: 6 loss: 0.6931473612785339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 7 loss: 0.6931473612785339\n",
      "epoch: 17 step: 8 loss: 0.6931473016738892\n",
      "epoch: 17 step: 9 loss: 0.6931473016738892\n",
      "epoch: 17 step: 10 loss: 0.6931473612785339\n",
      "epoch: 17 step: 11 loss: 0.6931473016738892\n",
      "epoch: 17 step: 12 loss: 0.6931473612785339\n",
      "epoch: 17 step: 13 loss: 0.6931473016738892\n",
      "epoch: 17 step: 14 loss: 0.6931473016738892\n",
      "epoch: 17 step: 15 loss: 0.6931473016738892\n",
      "epoch: 17 step: 16 loss: 0.6931473612785339\n",
      "epoch: 17 step: 17 loss: 0.6931473612785339\n",
      "epoch: 17 step: 18 loss: 0.6931473612785339\n",
      "epoch: 17 step: 19 loss: 0.6931473612785339\n",
      "epoch: 17 step: 20 loss: 0.6931473016738892\n",
      "epoch: 17 step: 21 loss: 0.6931473612785339\n",
      "epoch: 17 step: 22 loss: 0.6931473016738892\n",
      "epoch: 17 step: 23 loss: 0.6931473612785339\n",
      "epoch: 17 step: 24 loss: 0.6931473016738892\n",
      "epoch: 17 step: 25 loss: 0.6931473612785339\n",
      "epoch: 17 step: 26 loss: 0.6931473612785339\n",
      "epoch: 17 step: 27 loss: 0.6931473612785339\n",
      "epoch: 17 step: 28 loss: 0.6931473016738892\n",
      "epoch: 17 step: 29 loss: 0.6931473016738892\n",
      "epoch: 17 step: 30 loss: 0.6931473612785339\n",
      "epoch: 17 step: 31 loss: 0.6931473612785339\n",
      "epoch: 17 step: 32 loss: 0.6931473016738892\n",
      "epoch: 17 step: 33 loss: 0.6931473016738892\n",
      "epoch: 17 step: 34 loss: 0.6931473016738892\n",
      "epoch: 17 step: 35 loss: 0.6931473612785339\n",
      "epoch: 17 step: 36 loss: 0.6931473016738892\n",
      "epoch: 17 step: 37 loss: 0.6931473612785339\n",
      "epoch: 17 step: 38 loss: 0.6931473612785339\n",
      "epoch: 17 step: 39 loss: 0.6931473612785339\n",
      "epoch: 17 step: 40 loss: 0.6931473612785339\n",
      "epoch: 17 step: 41 loss: 0.6931473612785339\n",
      "epoch: 17 step: 42 loss: 0.6931473016738892\n",
      "epoch: 17 step: 43 loss: 0.6931473016738892\n",
      "epoch: 17 step: 44 loss: 0.6931473612785339\n",
      "epoch: 17 step: 45 loss: 0.6931473612785339\n",
      "epoch: 17 step: 46 loss: 0.6931473016738892\n",
      "epoch: 17 step: 47 loss: 0.6931473612785339\n",
      "epoch: 17 step: 48 loss: 0.6931473016738892\n",
      "epoch: 17 step: 49 loss: 0.6931473016738892\n",
      "epoch: 17 step: 50 loss: 0.6931473016738892\n",
      "epoch: 17 step: 51 loss: 0.6931473016738892\n",
      "epoch: 17 step: 52 loss: 0.6931473016738892\n",
      "epoch: 17 step: 53 loss: 0.6931473016738892\n",
      "epoch: 17 step: 54 loss: 0.6931473016738892\n",
      "epoch: 17 step: 55 loss: 0.6931473016738892\n",
      "epoch: 17 step: 56 loss: 0.6931473612785339\n",
      "epoch: 17 step: 57 loss: 0.6931473016738892\n",
      "epoch: 17 step: 58 loss: 0.6931473016738892\n",
      "epoch: 17 step: 59 loss: 0.6931473016738892\n",
      "epoch: 17 step: 60 loss: 0.6931473016738892\n",
      "epoch: 17 step: 61 loss: 0.6931473016738892\n",
      "epoch: 17 step: 62 loss: 0.6931473016738892\n",
      "epoch: 17 step: 63 loss: 0.6931473016738892\n",
      "epoch: 17 step: 64 loss: 0.6931473016738892\n",
      "epoch: 17 step: 65 loss: 0.6931473016738892\n",
      "epoch: 17 step: 66 loss: 0.6931473016738892\n",
      "epoch: 17 step: 67 loss: 0.6931473016738892\n",
      "epoch: 17 step: 68 loss: 0.6931473016738892\n",
      "epoch: 17 step: 69 loss: 0.6931473016738892\n",
      "epoch: 17 step: 70 loss: 0.6931473612785339\n",
      "epoch: 17 step: 71 loss: 0.6931473016738892\n",
      "epoch: 17 step: 72 loss: 0.6931473016738892\n",
      "epoch: 17 step: 73 loss: 0.6931473612785339\n",
      "epoch: 17 step: 74 loss: 0.6931473016738892\n",
      "epoch: 17 step: 75 loss: 0.6931473016738892\n",
      "epoch: 17 step: 76 loss: 0.6931473016738892\n",
      "epoch: 17 step: 77 loss: 0.6931473016738892\n",
      "epoch: 17 step: 78 loss: 0.6931473016738892\n",
      "epoch: 17 step: 79 loss: 0.6931473016738892\n",
      "epoch: 17 step: 80 loss: 0.6931473016738892\n",
      "epoch: 17 step: 81 loss: 0.6931473016738892\n",
      "epoch: 17 step: 82 loss: 0.6931473016738892\n",
      "epoch: 17 step: 83 loss: 0.6931473016738892\n",
      "epoch: 17 step: 84 loss: 0.6931473016738892\n",
      "epoch: 17 step: 85 loss: 0.6931473016738892\n",
      "epoch: 17 step: 86 loss: 0.6931473016738892\n",
      "epoch: 17 step: 87 loss: 0.6931473016738892\n",
      "epoch: 17 step: 88 loss: 0.6931473016738892\n",
      "epoch: 17 step: 89 loss: 0.6931473016738892\n",
      "epoch: 17 step: 90 loss: 0.6931473016738892\n",
      "epoch: 17 step: 91 loss: 0.6931473016738892\n",
      "epoch: 17 step: 92 loss: 0.6931473016738892\n",
      "epoch: 17 step: 93 loss: 0.6931473016738892\n",
      "epoch: 17 step: 94 loss: 0.6931473016738892\n",
      "epoch: 17 step: 95 loss: 0.6931473016738892\n",
      "epoch: 17 step: 96 loss: 0.6931473016738892\n",
      "epoch: 17 step: 97 loss: 0.6931473016738892\n",
      "epoch: 17 step: 98 loss: 0.6931473016738892\n",
      "epoch: 17 step: 99 loss: 0.6931473016738892\n",
      "epoch: 17 step: 100 loss: 0.6931473016738892\n",
      "epoch: 17 step: 101 loss: 0.6931473016738892\n",
      "epoch: 17 step: 102 loss: 0.6931473016738892\n",
      "epoch: 17 step: 103 loss: 0.6931473016738892\n",
      "epoch: 17 step: 104 loss: 0.6931473016738892\n",
      "epoch: 17 step: 105 loss: 0.6931473016738892\n",
      "epoch: 17 step: 106 loss: 0.6931473016738892\n",
      "epoch: 17 step: 107 loss: 0.6931473016738892\n",
      "epoch: 17 step: 108 loss: 0.6931473016738892\n",
      "epoch: 17 step: 109 loss: 0.6931473016738892\n",
      "epoch: 17 step: 110 loss: 0.6931473016738892\n",
      "epoch: 17 step: 111 loss: 0.6931473016738892\n",
      "epoch: 17 step: 112 loss: 0.6931473016738892\n",
      "epoch: 17 step: 113 loss: 0.6931473016738892\n",
      "epoch: 17 step: 114 loss: 0.6931473016738892\n",
      "epoch: 17 step: 115 loss: 0.6931473016738892\n",
      "epoch: 17 step: 116 loss: 0.6931473016738892\n",
      "epoch: 17 step: 117 loss: 0.6931473016738892\n",
      "epoch: 17 step: 118 loss: 0.6931473016738892\n",
      "epoch: 17 step: 119 loss: 0.6931473016738892\n",
      "epoch: 17 step: 120 loss: 0.6931473016738892\n",
      "epoch: 17 step: 121 loss: 0.6931473016738892\n",
      "epoch: 17 step: 122 loss: 0.6931473016738892\n",
      "epoch: 17 step: 123 loss: 0.6931473016738892\n",
      "epoch: 17 step: 124 loss: 0.6931473016738892\n",
      "epoch: 17 step: 125 loss: 0.6931473016738892\n",
      "epoch: 17 step: 126 loss: 0.6931473016738892\n",
      "epoch: 17 step: 127 loss: 0.6931473016738892\n",
      "epoch: 17 step: 128 loss: 0.6931473016738892\n",
      "epoch: 17 step: 129 loss: 0.6931473016738892\n",
      "epoch: 17 step: 130 loss: 0.6931473016738892\n",
      "epoch: 17 step: 131 loss: 0.6931473016738892\n",
      "epoch: 17 step: 132 loss: 0.6931473016738892\n",
      "epoch: 17 step: 133 loss: 0.6931473016738892\n",
      "epoch: 17 step: 134 loss: 0.6931473016738892\n",
      "epoch: 17 step: 135 loss: 0.6931473016738892\n",
      "epoch: 17 step: 136 loss: 0.6931473016738892\n",
      "epoch: 17 step: 137 loss: 0.6931473016738892\n",
      "epoch: 17 step: 138 loss: 0.6931473016738892\n",
      "epoch: 17 step: 139 loss: 0.6931473016738892\n",
      "epoch: 17 step: 140 loss: 0.6931473016738892\n",
      "epoch: 17 step: 141 loss: 0.6931473016738892\n",
      "epoch: 17 step: 142 loss: 0.6931473016738892\n",
      "epoch: 17 step: 143 loss: 0.6931473016738892\n",
      "epoch: 17 step: 144 loss: 0.6931473016738892\n",
      "epoch: 17 step: 145 loss: 0.6931473016738892\n",
      "epoch: 17 step: 146 loss: 0.6931473016738892\n",
      "epoch: 17 step: 147 loss: 0.6931473016738892\n",
      "epoch: 17 step: 148 loss: 0.6931473016738892\n",
      "epoch: 17 step: 149 loss: 0.6931473016738892\n",
      "epoch: 17 step: 150 loss: 0.6931473016738892\n",
      "epoch: 17 step: 151 loss: 0.6931473016738892\n",
      "epoch: 17 step: 152 loss: 0.6931473016738892\n",
      "epoch: 17 step: 153 loss: 0.6931473016738892\n",
      "epoch: 17 step: 154 loss: 0.6931473016738892\n",
      "epoch: 17 step: 155 loss: 0.6931473016738892\n",
      "epoch: 17 step: 156 loss: 0.6931473016738892\n",
      "epoch: 17 step: 157 loss: 0.6931473016738892\n",
      "epoch: 17 step: 158 loss: 0.6931473016738892\n",
      "epoch: 17 step: 159 loss: 0.6931473016738892\n",
      "epoch: 17 step: 160 loss: 0.6931473016738892\n",
      "epoch: 17 step: 161 loss: 0.6931473016738892\n",
      "epoch: 17 step: 162 loss: 0.6931473016738892\n",
      "epoch: 17 step: 163 loss: 0.6931473016738892\n",
      "epoch: 17 step: 164 loss: 0.6931473016738892\n",
      "epoch: 17 step: 165 loss: 0.6931473016738892\n",
      "epoch: 17 step: 166 loss: 0.6931473016738892\n",
      "epoch: 17 step: 167 loss: 0.6931473016738892\n",
      "epoch: 17 step: 168 loss: 0.6931473016738892\n",
      "epoch: 17 step: 169 loss: 0.6931473016738892\n",
      "epoch: 17 step: 170 loss: 0.6931473016738892\n",
      "epoch: 17 step: 171 loss: 0.6931473016738892\n",
      "epoch: 17 step: 172 loss: 0.6931473016738892\n",
      "epoch: 17 step: 173 loss: 0.6931473016738892\n",
      "epoch: 17 step: 174 loss: 0.6931473016738892\n",
      "epoch: 17 step: 175 loss: 0.6931473016738892\n",
      "epoch: 17 step: 176 loss: 0.6931473016738892\n",
      "epoch: 17 step: 177 loss: 0.6931473016738892\n",
      "epoch: 17 step: 178 loss: 0.6931473016738892\n",
      "epoch: 17 step: 179 loss: 0.6931473016738892\n",
      "epoch: 17 step: 180 loss: 0.6931473016738892\n",
      "epoch: 17 step: 181 loss: 0.6931473016738892\n",
      "epoch: 17 step: 182 loss: 0.6931473016738892\n",
      "epoch: 17 step: 183 loss: 0.6931473016738892\n",
      "epoch: 17 step: 184 loss: 0.6931473016738892\n",
      "epoch: 17 step: 185 loss: 0.6931473016738892\n",
      "epoch: 17 step: 186 loss: 0.6931473016738892\n",
      "epoch: 17 step: 187 loss: 0.6931473016738892\n",
      "epoch: 17 step: 188 loss: 0.6931473016738892\n",
      "epoch: 17 step: 189 loss: 0.6931473016738892\n",
      "epoch: 17 step: 190 loss: 0.6931473016738892\n",
      "epoch: 17 step: 191 loss: 0.6931473016738892\n",
      "epoch: 17 step: 192 loss: 0.6931473016738892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 193 loss: 0.6931473016738892\n",
      "epoch: 17 step: 194 loss: 0.6931473016738892\n",
      "epoch: 17 step: 195 loss: 0.6931473016738892\n",
      "epoch: 17 step: 196 loss: 0.6931473016738892\n",
      "epoch: 17 step: 197 loss: 0.6931473016738892\n",
      "epoch: 17 step: 198 loss: 0.6931473016738892\n",
      "epoch: 17 step: 199 loss: 0.6931473016738892\n",
      "epoch: 17 step: 200 loss: 0.6931473016738892\n",
      "epoch: 17 step: 201 loss: 0.6931473016738892\n",
      "epoch: 17 step: 202 loss: 0.6931473016738892\n",
      "epoch: 17 step: 203 loss: 0.6931473016738892\n",
      "epoch: 17 step: 204 loss: 0.6931473016738892\n",
      "epoch: 17 step: 205 loss: 0.6931473016738892\n",
      "epoch: 17 step: 206 loss: 0.6931473016738892\n",
      "epoch: 17 step: 207 loss: 0.6931473016738892\n",
      "epoch: 17 step: 208 loss: 0.6931473016738892\n",
      "epoch: 17 step: 209 loss: 0.6931473016738892\n",
      "epoch: 17 step: 210 loss: 0.6931473016738892\n",
      "epoch: 17 step: 211 loss: 0.6931473016738892\n",
      "epoch: 17 step: 212 loss: 0.6931473016738892\n",
      "epoch: 17 step: 213 loss: 0.6931473016738892\n",
      "epoch: 17 step: 214 loss: 0.6931473016738892\n",
      "epoch: 17 step: 215 loss: 0.6931473016738892\n",
      "epoch: 17 step: 216 loss: 0.6931473016738892\n",
      "epoch: 17 step: 217 loss: 0.6931473016738892\n",
      "epoch: 17 step: 218 loss: 0.6931473016738892\n",
      "epoch: 17 step: 219 loss: 0.6931473016738892\n",
      "epoch: 17 step: 220 loss: 0.6931473016738892\n",
      "epoch: 17 step: 221 loss: 0.6931473016738892\n",
      "epoch: 17 step: 222 loss: 0.6931473016738892\n",
      "epoch: 17 step: 223 loss: 0.6931473016738892\n",
      "epoch: 17 step: 224 loss: 0.6931473016738892\n",
      "epoch: 17 step: 225 loss: 0.6931473016738892\n",
      "epoch: 17 step: 226 loss: 0.6931473016738892\n",
      "epoch: 17 step: 227 loss: 0.6931473016738892\n",
      "epoch: 17 step: 228 loss: 0.6931473016738892\n",
      "epoch: 17 step: 229 loss: 0.6931473016738892\n",
      "epoch: 17 step: 230 loss: 0.6931473016738892\n",
      "epoch: 17 step: 231 loss: 0.6931473016738892\n",
      "epoch: 17 step: 232 loss: 0.6931473016738892\n",
      "epoch: 17 step: 233 loss: 0.6931473016738892\n",
      "epoch: 17 step: 234 loss: 0.6931473016738892\n",
      "epoch: 17 step: 235 loss: 0.6931473016738892\n",
      "epoch: 17 step: 236 loss: 0.6931473016738892\n",
      "epoch: 17 step: 237 loss: 0.6931473016738892\n",
      "epoch: 17 step: 238 loss: 0.6931473016738892\n",
      "epoch: 17 step: 239 loss: 0.6931473016738892\n",
      "epoch: 17 step: 240 loss: 0.6931473016738892\n",
      "epoch: 17 step: 241 loss: 0.6931473016738892\n",
      "epoch: 17 step: 242 loss: 0.6931473016738892\n",
      "epoch: 17 step: 243 loss: 0.6931473016738892\n",
      "epoch: 17 step: 244 loss: 0.6931473016738892\n",
      "epoch: 17 step: 245 loss: 0.6931473016738892\n",
      "epoch: 17 step: 246 loss: 0.6931473016738892\n",
      "epoch: 17 step: 247 loss: 0.6931473016738892\n",
      "epoch: 17 step: 248 loss: 0.6931473016738892\n",
      "epoch: 17 step: 249 loss: 0.6931473016738892\n",
      "epoch: 17 step: 250 loss: 0.6931473016738892\n",
      "epoch: 17 step: 251 loss: 0.6931473016738892\n",
      "epoch: 17 step: 252 loss: 0.6931473016738892\n",
      "epoch: 17 step: 253 loss: 0.6931473016738892\n",
      "epoch: 17 step: 254 loss: 0.6931473016738892\n",
      "epoch: 17 step: 255 loss: 0.6931473016738892\n",
      "epoch: 17 step: 256 loss: 0.6931473016738892\n",
      "epoch: 17 step: 257 loss: 0.6931473016738892\n",
      "epoch: 17 step: 258 loss: 0.6931473016738892\n",
      "epoch: 17 step: 259 loss: 0.6931473016738892\n",
      "epoch: 17 step: 260 loss: 0.6931473016738892\n",
      "epoch: 17 step: 261 loss: 0.6931473016738892\n",
      "epoch: 17 step: 262 loss: 0.6931473016738892\n",
      "epoch: 17 step: 263 loss: 0.6931473016738892\n",
      "epoch: 17 step: 264 loss: 0.6931473016738892\n",
      "epoch: 17 step: 265 loss: 0.6931473016738892\n",
      "epoch: 17 step: 266 loss: 0.6931473016738892\n",
      "epoch: 17 step: 267 loss: 0.6931473016738892\n",
      "epoch: 17 step: 268 loss: 0.6931473016738892\n",
      "epoch: 17 step: 269 loss: 0.6931473016738892\n",
      "epoch: 17 step: 270 loss: 0.6931473016738892\n",
      "epoch: 17 step: 271 loss: 0.6931473016738892\n",
      "epoch: 17 step: 272 loss: 0.6931473016738892\n",
      "epoch: 17 step: 273 loss: 0.6931473016738892\n",
      "epoch: 17 step: 274 loss: 0.6931473016738892\n",
      "epoch: 17 step: 275 loss: 0.6931473016738892\n",
      "epoch: 17 step: 276 loss: 0.6931473016738892\n",
      "epoch: 17 step: 277 loss: 0.6931473016738892\n",
      "epoch: 17 step: 278 loss: 0.6931473016738892\n",
      "epoch: 17 step: 279 loss: 0.6931473016738892\n",
      "epoch: 17 step: 280 loss: 0.6931473016738892\n",
      "epoch: 17 step: 281 loss: 0.6931473016738892\n",
      "epoch: 17 step: 282 loss: 0.6931473016738892\n",
      "epoch: 17 step: 283 loss: 0.6931473016738892\n",
      "epoch: 17 step: 284 loss: 0.6931473016738892\n",
      "epoch: 17 step: 285 loss: 0.6931473016738892\n",
      "epoch: 17 step: 286 loss: 0.6931473016738892\n",
      "epoch: 17 step: 287 loss: 0.6931473016738892\n",
      "epoch: 17 step: 288 loss: 0.6931473016738892\n",
      "epoch: 17 step: 289 loss: 0.6931473016738892\n",
      "epoch: 17 step: 290 loss: 0.6931473016738892\n",
      "epoch: 17 step: 291 loss: 0.6931473016738892\n",
      "epoch: 17 step: 292 loss: 0.6931473016738892\n",
      "epoch: 17 step: 293 loss: 0.6931473016738892\n",
      "epoch: 17 step: 294 loss: 0.6931473016738892\n",
      "epoch: 17 step: 295 loss: 0.6931473016738892\n",
      "epoch: 17 step: 296 loss: 0.6931473016738892\n",
      "epoch: 17 step: 297 loss: 0.6931473016738892\n",
      "epoch: 17 step: 298 loss: 0.6931473016738892\n",
      "epoch: 17 step: 299 loss: 0.6931473016738892\n",
      "epoch: 17 step: 300 loss: 0.6931473016738892\n",
      "epoch: 17 step: 301 loss: 0.6931473016738892\n",
      "epoch: 17 step: 302 loss: 0.6931473016738892\n",
      "epoch: 17 step: 303 loss: 0.6931473016738892\n",
      "epoch: 17 step: 304 loss: 0.6931473016738892\n",
      "epoch: 17 step: 305 loss: 0.6931473016738892\n",
      "epoch: 17 step: 306 loss: 0.6931473016738892\n",
      "epoch: 17 step: 307 loss: 0.6931473016738892\n",
      "epoch: 17 step: 308 loss: 0.6931473016738892\n",
      "epoch: 17 step: 309 loss: 0.6931473016738892\n",
      "epoch: 17 step: 310 loss: 0.6931473016738892\n",
      "epoch: 17 step: 311 loss: 0.6931473016738892\n",
      "epoch: 17 step: 312 loss: 0.6931473016738892\n",
      "epoch: 17 step: 313 loss: 0.6931473016738892\n",
      "epoch: 17 step: 314 loss: 0.6931473016738892\n",
      "epoch: 17 step: 315 loss: 0.6931473016738892\n",
      "epoch: 17 step: 316 loss: 0.6931473016738892\n",
      "epoch: 17 step: 317 loss: 0.6931473016738892\n",
      "epoch: 17 step: 318 loss: 0.6931473016738892\n",
      "epoch: 17 step: 319 loss: 0.6931473016738892\n",
      "epoch: 17 step: 320 loss: 0.6931473016738892\n",
      "epoch: 17 step: 321 loss: 0.6931473016738892\n",
      "epoch: 17 step: 322 loss: 0.6931473016738892\n",
      "epoch: 17 step: 323 loss: 0.6931473016738892\n",
      "epoch: 17 step: 324 loss: 0.6931473016738892\n",
      "epoch: 17 step: 325 loss: 0.6931473016738892\n",
      "epoch: 17 step: 326 loss: 0.6931473016738892\n",
      "epoch: 17 step: 327 loss: 0.6931473016738892\n",
      "epoch: 17 step: 328 loss: 0.6931473016738892\n",
      "epoch: 17 step: 329 loss: 0.6931473016738892\n",
      "epoch: 17 step: 330 loss: 0.6931473016738892\n",
      "epoch: 17 step: 331 loss: 0.6931473016738892\n",
      "epoch: 17 step: 332 loss: 0.6931473016738892\n",
      "epoch: 17 step: 333 loss: 0.6931473016738892\n",
      "epoch: 17 step: 334 loss: 0.6931473016738892\n",
      "epoch: 17 step: 335 loss: 0.6931473016738892\n",
      "epoch: 17 step: 336 loss: 0.6931473016738892\n",
      "epoch: 17 step: 337 loss: 0.6931473016738892\n",
      "epoch: 17 step: 338 loss: 0.6931473016738892\n",
      "epoch: 17 step: 339 loss: 0.6931473016738892\n",
      "epoch: 17 step: 340 loss: 0.6931473016738892\n",
      "epoch: 17 step: 341 loss: 0.6931473016738892\n",
      "epoch: 17 step: 342 loss: 0.6931473016738892\n",
      "epoch: 17 step: 343 loss: 0.6931473016738892\n",
      "epoch: 17 step: 344 loss: 0.6931473016738892\n",
      "epoch: 17 step: 345 loss: 0.6931473016738892\n",
      "epoch: 17 step: 346 loss: 0.6931473016738892\n",
      "epoch: 17 step: 347 loss: 0.6931473016738892\n",
      "epoch: 17 step: 348 loss: 0.6931473016738892\n",
      "epoch: 17 step: 349 loss: 0.6931473016738892\n",
      "epoch: 17 step: 350 loss: 0.6931473016738892\n",
      "epoch: 17 step: 351 loss: 0.6931473016738892\n",
      "epoch: 17 step: 352 loss: 0.6931473016738892\n",
      "epoch: 17 step: 353 loss: 0.6931473016738892\n",
      "epoch: 17 step: 354 loss: 0.6931473016738892\n",
      "epoch: 17 step: 355 loss: 0.6931473016738892\n",
      "epoch: 17 step: 356 loss: 0.6931473016738892\n",
      "epoch: 17 step: 357 loss: 0.6931473016738892\n",
      "epoch: 17 step: 358 loss: 0.6931473016738892\n",
      "epoch: 17 step: 359 loss: 0.6931473016738892\n",
      "epoch: 17 step: 360 loss: 0.6931473016738892\n",
      "epoch: 17 step: 361 loss: 0.6931473016738892\n",
      "epoch: 17 step: 362 loss: 0.6931473016738892\n",
      "epoch: 17 step: 363 loss: 0.6931473016738892\n",
      "epoch: 17 step: 364 loss: 0.6931473016738892\n",
      "epoch: 17 step: 365 loss: 0.6931473016738892\n",
      "epoch: 17 step: 366 loss: 0.6931473016738892\n",
      "epoch: 17 step: 367 loss: 0.6931473016738892\n",
      "epoch: 17 step: 368 loss: 0.6931473016738892\n",
      "epoch: 17 step: 369 loss: 0.6931473016738892\n",
      "epoch: 17 step: 370 loss: 0.6931473016738892\n",
      "epoch: 17 step: 371 loss: 0.6931473016738892\n",
      "epoch: 17 step: 372 loss: 0.6931473016738892\n",
      "epoch: 17 step: 373 loss: 0.6931473016738892\n",
      "epoch: 17 step: 374 loss: 0.6931473016738892\n",
      "epoch: 17 step: 375 loss: 0.6931473016738892\n",
      "epoch: 17 step: 376 loss: 0.6931473016738892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 377 loss: 0.6931473016738892\n",
      "epoch: 17 step: 378 loss: 0.6931473016738892\n",
      "epoch: 17 step: 379 loss: 0.6931473016738892\n",
      "epoch: 17 step: 380 loss: 0.6931473016738892\n",
      "epoch: 17 step: 381 loss: 0.6931473016738892\n",
      "epoch: 17 step: 382 loss: 0.6931473016738892\n",
      "epoch: 17 step: 383 loss: 0.6931473016738892\n",
      "epoch: 17 step: 384 loss: 0.6931473016738892\n",
      "epoch: 17 step: 385 loss: 0.6931473016738892\n",
      "epoch: 17 step: 386 loss: 0.6931473016738892\n",
      "epoch: 17 step: 387 loss: 0.6931473016738892\n",
      "epoch: 17 step: 388 loss: 0.6931473016738892\n",
      "epoch: 17 step: 389 loss: 0.6931473016738892\n",
      "epoch: 17 step: 390 loss: 0.6931473016738892\n",
      "epoch: 17 step: 391 loss: 0.6931473016738892\n",
      "epoch: 17 step: 392 loss: 0.6931473016738892\n",
      "epoch: 17 step: 393 loss: 0.6931473016738892\n",
      "epoch: 17 step: 394 loss: 0.6931473016738892\n",
      "epoch: 17 step: 395 loss: 0.6931473016738892\n",
      "epoch: 17 step: 396 loss: 0.6931473016738892\n",
      "epoch: 17 step: 397 loss: 0.6931473016738892\n",
      "epoch: 17 step: 398 loss: 0.6931473016738892\n",
      "epoch: 17 step: 399 loss: 0.6931473016738892\n",
      "epoch: 17 step: 400 loss: 0.6931473016738892\n",
      "epoch: 17 step: 401 loss: 0.6931473016738892\n",
      "epoch: 17 step: 402 loss: 0.6931473016738892\n",
      "epoch: 17 step: 403 loss: 0.6931473016738892\n",
      "epoch: 17 step: 404 loss: 0.6931473016738892\n",
      "epoch: 17 step: 405 loss: 0.6931473016738892\n",
      "epoch: 17 step: 406 loss: 0.6931473016738892\n",
      "epoch: 17 step: 407 loss: 0.6931473016738892\n",
      "epoch: 17 step: 408 loss: 0.6931473016738892\n",
      "epoch: 17 step: 409 loss: 0.6931473016738892\n",
      "epoch: 17 step: 410 loss: 0.6931473016738892\n",
      "epoch: 17 step: 411 loss: 0.6931473016738892\n",
      "epoch: 17 step: 412 loss: 0.6931473016738892\n",
      "epoch: 17 step: 413 loss: 0.6931473016738892\n",
      "epoch: 17 step: 414 loss: 0.6931473016738892\n",
      "epoch: 17 step: 415 loss: 0.6931473016738892\n",
      "epoch: 17 step: 416 loss: 0.6931473016738892\n",
      "epoch: 17 step: 417 loss: 0.6931473016738892\n",
      "epoch: 17 step: 418 loss: 0.6931473016738892\n",
      "epoch: 17 step: 419 loss: 0.6931473016738892\n",
      "epoch: 17 step: 420 loss: 0.6931473016738892\n",
      "epoch: 17 step: 421 loss: 0.6931473016738892\n",
      "epoch: 17 step: 422 loss: 0.6931473016738892\n",
      "epoch: 17 step: 423 loss: 0.6931473016738892\n",
      "epoch: 17 step: 424 loss: 0.6931473016738892\n",
      "epoch: 17 step: 425 loss: 0.6931473016738892\n",
      "epoch: 17 step: 426 loss: 0.6931473016738892\n",
      "epoch: 17 step: 427 loss: 0.6931473016738892\n",
      "epoch: 17 step: 428 loss: 0.6931473016738892\n",
      "epoch: 17 step: 429 loss: 0.6931473016738892\n",
      "epoch: 17 step: 430 loss: 0.6931473016738892\n",
      "epoch: 17 step: 431 loss: 0.6931473016738892\n",
      "epoch: 17 step: 432 loss: 0.6931473016738892\n",
      "epoch: 17 step: 433 loss: 0.6931473016738892\n",
      "epoch: 17 step: 434 loss: 0.6931473016738892\n",
      "epoch: 17 step: 435 loss: 0.6931473016738892\n",
      "epoch: 17 step: 436 loss: 0.6931473016738892\n",
      "epoch: 17 step: 437 loss: 0.6931473016738892\n",
      "epoch: 17 step: 438 loss: 0.6931473016738892\n",
      "epoch: 17 step: 439 loss: 0.6931473016738892\n",
      "epoch: 17 step: 440 loss: 0.6931473016738892\n",
      "epoch: 17 step: 441 loss: 0.6931473016738892\n",
      "epoch: 17 step: 442 loss: 0.6931473016738892\n",
      "epoch: 17 step: 443 loss: 0.6931473016738892\n",
      "epoch: 17 step: 444 loss: 0.6931473016738892\n",
      "epoch: 17 step: 445 loss: 0.6931473016738892\n",
      "epoch: 17 step: 446 loss: 0.6931473016738892\n",
      "epoch: 17 step: 447 loss: 0.6931473016738892\n",
      "epoch: 17 step: 448 loss: 0.6931473016738892\n",
      "epoch: 17 step: 449 loss: 0.6931473016738892\n",
      "epoch: 17 step: 450 loss: 0.6931473016738892\n",
      "epoch: 17 step: 451 loss: 0.6931473016738892\n",
      "epoch: 17 step: 452 loss: 0.6931473016738892\n",
      "epoch: 17 step: 453 loss: 0.6931473016738892\n",
      "epoch: 17 step: 454 loss: 0.6931473016738892\n",
      "epoch: 17 step: 455 loss: 0.6931473016738892\n",
      "epoch: 17 step: 456 loss: 0.6931473016738892\n",
      "epoch: 17 step: 457 loss: 0.6931473016738892\n",
      "epoch: 17 step: 458 loss: 0.6931473016738892\n",
      "epoch: 17 step: 459 loss: 0.6931473016738892\n",
      "epoch: 17 step: 460 loss: 0.6931473016738892\n",
      "epoch: 17 step: 461 loss: 0.6931473016738892\n",
      "epoch: 17 step: 462 loss: 0.6931473016738892\n",
      "epoch: 17 step: 463 loss: 0.6931473016738892\n",
      "epoch: 17 step: 464 loss: 0.6931473016738892\n",
      "epoch: 17 step: 465 loss: 0.6931473016738892\n",
      "epoch: 17 step: 466 loss: 0.6931473016738892\n",
      "epoch: 17 step: 467 loss: 0.6931473016738892\n",
      "epoch: 17 step: 468 loss: 0.6931473016738892\n",
      "epoch: 17 step: 469 loss: 0.6931473016738892\n",
      "epoch: 17 step: 470 loss: 0.6931473016738892\n",
      "epoch: 17 step: 471 loss: 0.6931473016738892\n",
      "epoch: 17 step: 472 loss: 0.6931473016738892\n",
      "epoch: 17 step: 473 loss: 0.6931473016738892\n",
      "epoch: 17 step: 474 loss: 0.6931473016738892\n",
      "epoch: 17 step: 475 loss: 0.6931473016738892\n",
      "epoch: 17 step: 476 loss: 0.6931473016738892\n",
      "epoch: 17 step: 477 loss: 0.6931473016738892\n",
      "epoch: 17 step: 478 loss: 0.6931473016738892\n",
      "epoch: 17 step: 479 loss: 0.6931473016738892\n",
      "epoch: 17 step: 480 loss: 0.6931473016738892\n",
      "epoch: 17 step: 481 loss: 0.6931473016738892\n",
      "epoch: 17 step: 482 loss: 0.6931473016738892\n",
      "epoch: 17 step: 483 loss: 0.6931473016738892\n",
      "epoch: 17 step: 484 loss: 0.6931473016738892\n",
      "epoch: 17 step: 485 loss: 0.6931473016738892\n",
      "epoch: 17 step: 486 loss: 0.6931473016738892\n",
      "epoch: 17 step: 487 loss: 0.6931473016738892\n",
      "epoch: 17 step: 488 loss: 0.6931473016738892\n",
      "epoch: 17 step: 489 loss: 0.6931473016738892\n",
      "epoch: 17 step: 490 loss: 0.6931473016738892\n",
      "epoch: 17 step: 491 loss: 0.6931473016738892\n",
      "epoch: 17 step: 492 loss: 0.6931473016738892\n",
      "epoch: 17 step: 493 loss: 0.6931473016738892\n",
      "epoch: 17 step: 494 loss: 0.6931473016738892\n",
      "epoch: 17 step: 495 loss: 0.6931473016738892\n",
      "epoch: 17 step: 496 loss: 0.6931473016738892\n",
      "epoch: 17 step: 497 loss: 0.6931473016738892\n",
      "epoch: 17 step: 498 loss: 0.6931473016738892\n",
      "epoch: 17 step: 499 loss: 0.6931473016738892\n",
      "epoch: 17 step: 500 loss: 0.6931473016738892\n",
      "epoch: 17 step: 501 loss: 0.6931473016738892\n",
      "epoch: 17 step: 502 loss: 0.6931473016738892\n",
      "epoch: 17 step: 503 loss: 0.6931473016738892\n",
      "epoch: 17 step: 504 loss: 0.6931473016738892\n",
      "epoch: 17 step: 505 loss: 0.6931473016738892\n",
      "epoch: 17 step: 506 loss: 0.6931473016738892\n",
      "epoch: 17 step: 507 loss: 0.6931473016738892\n",
      "epoch: 17 step: 508 loss: 0.6931473016738892\n",
      "epoch: 17 step: 509 loss: 0.6931473016738892\n",
      "epoch: 17 step: 510 loss: 0.6931473016738892\n",
      "epoch: 17 step: 511 loss: 0.6931473016738892\n",
      "epoch: 17 step: 512 loss: 0.6931473016738892\n",
      "epoch: 17 step: 513 loss: 0.6931473016738892\n",
      "epoch: 17 step: 514 loss: 0.6931473016738892\n",
      "epoch: 17 step: 515 loss: 0.6931473016738892\n",
      "epoch: 17 step: 516 loss: 0.6931473016738892\n",
      "epoch: 17 step: 517 loss: 0.6931473016738892\n",
      "epoch: 17 step: 518 loss: 0.6931473016738892\n",
      "epoch: 17 step: 519 loss: 0.6931473016738892\n",
      "epoch: 17 step: 520 loss: 0.6931473016738892\n",
      "epoch: 17 step: 521 loss: 0.6931473016738892\n",
      "epoch: 17 step: 522 loss: 0.6931473016738892\n",
      "epoch: 17 step: 523 loss: 0.6931473016738892\n",
      "epoch: 17 step: 524 loss: 0.6931473016738892\n",
      "epoch: 17 step: 525 loss: 0.6931473016738892\n",
      "epoch: 17 step: 526 loss: 0.6931473016738892\n",
      "epoch: 17 step: 527 loss: 0.6931473016738892\n",
      "epoch: 17 step: 528 loss: 0.6931473016738892\n",
      "epoch: 17 step: 529 loss: 0.6931473016738892\n",
      "epoch: 17 step: 530 loss: 0.6931473016738892\n",
      "epoch: 17 step: 531 loss: 0.6931473016738892\n",
      "epoch: 17 step: 532 loss: 0.6931473016738892\n",
      "epoch: 17 step: 533 loss: 0.6931473016738892\n",
      "epoch: 17 step: 534 loss: 0.6931473016738892\n",
      "epoch: 17 step: 535 loss: 0.6931473016738892\n",
      "epoch: 17 step: 536 loss: 0.6931473016738892\n",
      "epoch: 17 step: 537 loss: 0.6931473016738892\n",
      "epoch: 17 step: 538 loss: 0.6931473016738892\n",
      "epoch: 17 step: 539 loss: 0.6931473016738892\n",
      "epoch: 17 step: 540 loss: 0.6931473016738892\n",
      "epoch: 17 step: 541 loss: 0.6931473016738892\n",
      "epoch: 17 step: 542 loss: 0.6931473016738892\n",
      "epoch: 17 step: 543 loss: 0.6931473016738892\n",
      "epoch: 17 step: 544 loss: 0.6931473016738892\n",
      "epoch: 17 step: 545 loss: 0.6931473016738892\n",
      "epoch: 17 step: 546 loss: 0.6931473016738892\n",
      "epoch: 17 step: 547 loss: 0.6931473016738892\n",
      "epoch: 17 step: 548 loss: 0.6931473016738892\n",
      "epoch: 17 step: 549 loss: 0.6931473016738892\n",
      "epoch: 17 step: 550 loss: 0.6931473016738892\n",
      "epoch: 17 step: 551 loss: 0.6931473016738892\n",
      "epoch: 17 step: 552 loss: 0.6931473016738892\n",
      "epoch: 17 step: 553 loss: 0.6931473016738892\n",
      "epoch: 17 step: 554 loss: 0.6931473016738892\n",
      "epoch: 17 step: 555 loss: 0.6931473016738892\n",
      "epoch: 17 step: 556 loss: 0.6931473016738892\n",
      "epoch: 17 step: 557 loss: 0.6931473016738892\n",
      "epoch: 17 step: 558 loss: 0.6931473016738892\n",
      "epoch: 17 step: 559 loss: 0.6931473016738892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 560 loss: 0.6931473016738892\n",
      "epoch: 17 step: 561 loss: 0.6931473016738892\n",
      "epoch: 17 step: 562 loss: 0.6931473016738892\n",
      "epoch: 17 step: 563 loss: 0.6931473016738892\n",
      "epoch: 17 step: 564 loss: 0.6931473016738892\n",
      "epoch: 17 step: 565 loss: 0.6931473016738892\n",
      "epoch: 17 step: 566 loss: 0.6931473016738892\n",
      "epoch: 17 step: 567 loss: 0.6931473016738892\n",
      "epoch: 17 step: 568 loss: 0.6931473016738892\n",
      "epoch: 17 step: 569 loss: 0.6931473016738892\n",
      "epoch: 17 step: 570 loss: 0.6931473016738892\n",
      "epoch: 17 step: 571 loss: 0.6931473016738892\n",
      "epoch: 17 step: 572 loss: 0.6931473016738892\n",
      "epoch: 17 step: 573 loss: 0.6931473016738892\n",
      "epoch: 17 step: 574 loss: 0.6931473016738892\n",
      "epoch: 17 step: 575 loss: 0.6931473016738892\n",
      "epoch: 17 step: 576 loss: 0.6931473016738892\n",
      "epoch: 17 step: 577 loss: 0.6931473016738892\n",
      "epoch: 17 step: 578 loss: 0.6931473016738892\n",
      "epoch: 17 step: 579 loss: 0.6931473016738892\n",
      "epoch: 17 step: 580 loss: 0.6931473016738892\n",
      "epoch: 17 step: 581 loss: 0.6931473016738892\n",
      "epoch: 17 step: 582 loss: 0.6931473016738892\n",
      "epoch: 17 step: 583 loss: 0.6931473016738892\n",
      "epoch: 17 step: 584 loss: 0.6931473016738892\n",
      "epoch: 17 step: 585 loss: 0.6931473016738892\n",
      "epoch: 17 step: 586 loss: 0.6931473016738892\n",
      "epoch: 17 step: 587 loss: 0.6931473016738892\n",
      "epoch: 17 step: 588 loss: 0.6931473016738892\n",
      "epoch: 17 step: 589 loss: 0.6931473016738892\n",
      "epoch: 17 step: 590 loss: 0.6931473016738892\n",
      "epoch: 17 step: 591 loss: 0.6931473016738892\n",
      "epoch: 17 step: 592 loss: 0.6931473016738892\n",
      "epoch: 17 step: 593 loss: 0.6931473016738892\n",
      "epoch: 17 step: 594 loss: 0.6931473016738892\n",
      "epoch: 17 step: 595 loss: 0.6931473016738892\n",
      "epoch: 17 step: 596 loss: 0.6931473016738892\n",
      "epoch: 17 step: 597 loss: 0.6931473016738892\n",
      "epoch: 17 step: 598 loss: 0.6931473016738892\n",
      "epoch: 17 step: 599 loss: 0.6931473016738892\n",
      "epoch: 17 step: 600 loss: 0.6931473016738892\n",
      "epoch: 17 step: 601 loss: 0.6931473016738892\n",
      "epoch: 17 step: 602 loss: 0.6931473016738892\n",
      "epoch: 17 step: 603 loss: 0.6931473016738892\n",
      "epoch: 17 step: 604 loss: 0.6931473016738892\n",
      "epoch: 17 step: 605 loss: 0.6931473016738892\n",
      "epoch: 17 step: 606 loss: 0.6931473016738892\n",
      "epoch: 17 step: 607 loss: 0.6931473016738892\n",
      "epoch: 17 step: 608 loss: 0.6931473016738892\n",
      "epoch: 17 step: 609 loss: 0.6931473016738892\n",
      "epoch: 17 step: 610 loss: 0.6931473016738892\n",
      "epoch: 17 step: 611 loss: 0.6931473016738892\n",
      "epoch: 17 step: 612 loss: 0.6931473016738892\n",
      "epoch: 17 step: 613 loss: 0.6931473016738892\n",
      "epoch: 17 step: 614 loss: 0.6931473016738892\n",
      "epoch: 17 step: 615 loss: 0.6931473016738892\n",
      "epoch: 17 step: 616 loss: 0.6931473016738892\n",
      "epoch: 17 step: 617 loss: 0.6931473016738892\n",
      "epoch: 17 step: 618 loss: 0.6931473016738892\n",
      "epoch: 17 step: 619 loss: 0.6931473016738892\n",
      "epoch: 17 step: 620 loss: 0.6931473016738892\n",
      "epoch: 17 step: 621 loss: 0.6931473016738892\n",
      "epoch: 17 step: 622 loss: 0.6931473016738892\n",
      "epoch: 17 step: 623 loss: 0.6931473016738892\n",
      "epoch: 17 step: 624 loss: 0.6931473016738892\n",
      "epoch: 17 step: 625 loss: 0.6931473016738892\n",
      "epoch: 17 step: 626 loss: 0.6931473016738892\n",
      "epoch: 17 step: 627 loss: 0.6931473016738892\n",
      "epoch: 17 step: 628 loss: 0.6931473016738892\n",
      "epoch: 17 step: 629 loss: 0.6931473016738892\n",
      "epoch: 17 step: 630 loss: 0.6931473016738892\n",
      "epoch: 17 step: 631 loss: 0.6931473016738892\n",
      "epoch: 17 step: 632 loss: 0.6931473016738892\n",
      "epoch: 17 step: 633 loss: 0.6931473016738892\n",
      "epoch: 17 step: 634 loss: 0.6931473016738892\n",
      "epoch: 17 step: 635 loss: 0.6931473016738892\n",
      "epoch: 17 step: 636 loss: 0.6931473016738892\n",
      "epoch: 17 step: 637 loss: 0.6931473016738892\n",
      "epoch: 17 step: 638 loss: 0.6931473016738892\n",
      "epoch: 17 step: 639 loss: 0.6931473016738892\n",
      "epoch: 17 step: 640 loss: 0.6931473016738892\n",
      "epoch: 17 step: 641 loss: 0.6931473016738892\n",
      "epoch: 17 step: 642 loss: 0.6931473016738892\n",
      "epoch: 17 step: 643 loss: 0.6931473016738892\n",
      "epoch: 17 step: 644 loss: 0.6931473016738892\n",
      "epoch: 17 step: 645 loss: 0.6931473016738892\n",
      "epoch: 17 step: 646 loss: 0.6931473016738892\n",
      "epoch: 17 step: 647 loss: 0.6931473016738892\n",
      "epoch: 17 step: 648 loss: 0.6931473016738892\n",
      "epoch: 17 step: 649 loss: 0.6931473016738892\n",
      "epoch: 17 step: 650 loss: 0.6931473016738892\n",
      "epoch: 17 step: 651 loss: 0.6931473016738892\n",
      "epoch: 17 step: 652 loss: 0.6931473016738892\n",
      "epoch: 17 step: 653 loss: 0.6931473016738892\n",
      "epoch: 17 step: 654 loss: 0.6931473016738892\n",
      "epoch: 17 step: 655 loss: 0.6931473016738892\n",
      "epoch: 17 step: 656 loss: 0.6931473016738892\n",
      "epoch: 17 step: 657 loss: 0.6931473016738892\n",
      "epoch: 17 step: 658 loss: 0.6931473016738892\n",
      "epoch: 17 step: 659 loss: 0.6931473016738892\n",
      "epoch: 17 step: 660 loss: 0.6931473016738892\n",
      "epoch: 17 step: 661 loss: 0.6931473016738892\n",
      "epoch: 17 step: 662 loss: 0.6931473016738892\n",
      "epoch: 17 step: 663 loss: 0.6931473016738892\n",
      "epoch: 17 step: 664 loss: 0.6931473016738892\n",
      "epoch: 17 step: 665 loss: 0.6931473016738892\n",
      "epoch: 17 step: 666 loss: 0.6931473016738892\n",
      "epoch: 17 step: 667 loss: 0.6931473016738892\n",
      "epoch: 17 step: 668 loss: 0.6931473016738892\n",
      "epoch: 17 step: 669 loss: 0.6931472420692444\n",
      "epoch: 17 step: 670 loss: 0.6931473016738892\n",
      "epoch: 17 step: 671 loss: 0.6931473016738892\n",
      "epoch: 17 step: 672 loss: 0.6931473016738892\n",
      "epoch: 17 step: 673 loss: 0.6931472420692444\n",
      "epoch: 17 step: 674 loss: 0.6931473016738892\n",
      "epoch: 17 step: 675 loss: 0.6931472420692444\n",
      "epoch: 17 step: 676 loss: 0.6931472420692444\n",
      "epoch: 17 step: 677 loss: 0.6931473016738892\n",
      "epoch: 17 step: 678 loss: 0.6931472420692444\n",
      "epoch: 17 step: 679 loss: 0.6931473016738892\n",
      "epoch: 17 step: 680 loss: 0.6931473016738892\n",
      "epoch: 17 step: 681 loss: 0.6931473016738892\n",
      "epoch: 17 step: 682 loss: 0.6931473016738892\n",
      "epoch: 17 step: 683 loss: 0.6931473016738892\n",
      "epoch: 17 step: 684 loss: 0.6931471824645996\n",
      "epoch: 17 step: 685 loss: 0.6931472420692444\n",
      "epoch: 17 step: 686 loss: 0.6931473016738892\n",
      "epoch: 17 step: 687 loss: 0.6931473016738892\n",
      "epoch: 17 step: 688 loss: 0.6931473016738892\n",
      "epoch: 17 step: 689 loss: 0.6931473016738892\n",
      "epoch: 17 step: 690 loss: 0.6931473016738892\n",
      "epoch: 17 step: 691 loss: 0.6931472420692444\n",
      "epoch: 17 step: 692 loss: 0.6931473016738892\n",
      "epoch: 17 step: 693 loss: 0.6931471824645996\n",
      "epoch: 17 step: 694 loss: 0.6931472420692444\n",
      "epoch: 17 step: 695 loss: 0.6931471824645996\n",
      "epoch: 17 step: 696 loss: 0.6931472420692444\n",
      "epoch: 17 step: 697 loss: 0.6931473016738892\n",
      "epoch: 17 step: 698 loss: 0.6931473016738892\n",
      "epoch: 17 step: 699 loss: 0.6931471824645996\n",
      "epoch: 17 step: 700 loss: 0.6931473016738892\n",
      "epoch: 17 step: 701 loss: 0.6931472420692444\n",
      "epoch: 17 step: 702 loss: 0.6931473016738892\n",
      "epoch: 17 step: 703 loss: 0.6931473016738892\n",
      "epoch: 17 step: 704 loss: 0.6931473016738892\n",
      "epoch: 17 step: 705 loss: 0.6931473016738892\n",
      "epoch: 17 step: 706 loss: 0.6931472420692444\n",
      "epoch: 17 step: 707 loss: 0.6931471824645996\n",
      "epoch: 17 step: 708 loss: 0.6931472420692444\n",
      "epoch: 17 step: 709 loss: 0.6931473016738892\n",
      "epoch: 17 step: 710 loss: 0.6931473016738892\n",
      "epoch: 17 step: 711 loss: 0.6931471824645996\n",
      "epoch: 17 step: 712 loss: 0.6931472420692444\n",
      "epoch: 17 step: 713 loss: 0.6931471824645996\n",
      "epoch: 17 step: 714 loss: 0.6931472420692444\n",
      "epoch: 17 step: 715 loss: 0.6931472420692444\n",
      "epoch: 17 step: 716 loss: 0.6931471824645996\n",
      "epoch: 17 step: 717 loss: 0.6931473016738892\n",
      "epoch: 17 step: 718 loss: 0.6931471824645996\n",
      "epoch: 17 step: 719 loss: 0.6931473016738892\n",
      "epoch: 17 step: 720 loss: 0.6931471824645996\n",
      "epoch: 17 step: 721 loss: 0.6931473016738892\n",
      "epoch: 17 step: 722 loss: 0.6931472420692444\n",
      "epoch: 17 step: 723 loss: 0.6931473016738892\n",
      "epoch: 17 step: 724 loss: 0.6931472420692444\n",
      "epoch: 17 step: 725 loss: 0.6931471824645996\n",
      "epoch: 17 step: 726 loss: 0.6931471824645996\n",
      "epoch: 17 step: 727 loss: 0.6931471824645996\n",
      "epoch: 17 step: 728 loss: 0.6931471824645996\n",
      "epoch: 17 step: 729 loss: 0.6931471824645996\n",
      "epoch: 17 step: 730 loss: 0.6931471824645996\n",
      "epoch: 17 step: 731 loss: 0.6931471824645996\n",
      "epoch: 17 step: 732 loss: 0.6931473016738892\n",
      "epoch: 17 step: 733 loss: 0.6931471824645996\n",
      "epoch: 17 step: 734 loss: 0.6931473016738892\n",
      "epoch: 17 step: 735 loss: 0.6931473016738892\n",
      "epoch: 17 step: 736 loss: 0.6931471824645996\n",
      "epoch: 17 step: 737 loss: 0.6931471824645996\n",
      "epoch: 17 step: 738 loss: 0.6931472420692444\n",
      "epoch: 17 step: 739 loss: 0.6931471824645996\n",
      "epoch: 17 step: 740 loss: 0.6931473016738892\n",
      "epoch: 17 step: 741 loss: 0.6931471824645996\n",
      "epoch: 17 step: 742 loss: 0.6931471824645996\n",
      "epoch: 17 step: 743 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 744 loss: 0.6931472420692444\n",
      "epoch: 17 step: 745 loss: 0.6931473016738892\n",
      "epoch: 17 step: 746 loss: 0.6931472420692444\n",
      "epoch: 17 step: 747 loss: 0.6931471824645996\n",
      "epoch: 17 step: 748 loss: 0.6931471824645996\n",
      "epoch: 17 step: 749 loss: 0.6931473016738892\n",
      "epoch: 17 step: 750 loss: 0.6931471824645996\n",
      "epoch: 17 step: 751 loss: 0.6931473016738892\n",
      "epoch: 17 step: 752 loss: 0.6931472420692444\n",
      "epoch: 17 step: 753 loss: 0.6931471824645996\n",
      "epoch: 17 step: 754 loss: 0.6931471824645996\n",
      "epoch: 17 step: 755 loss: 0.6931471824645996\n",
      "epoch: 17 step: 756 loss: 0.6931471824645996\n",
      "epoch: 17 step: 757 loss: 0.6931471824645996\n",
      "epoch: 17 step: 758 loss: 0.6931471824645996\n",
      "epoch: 17 step: 759 loss: 0.6931471824645996\n",
      "epoch: 17 step: 760 loss: 0.6931471824645996\n",
      "epoch: 17 step: 761 loss: 0.6931471824645996\n",
      "epoch: 17 step: 762 loss: 0.6931471824645996\n",
      "epoch: 17 step: 763 loss: 0.6931473016738892\n",
      "epoch: 17 step: 764 loss: 0.6931471824645996\n",
      "epoch: 17 step: 765 loss: 0.6931471824645996\n",
      "epoch: 17 step: 766 loss: 0.6931471824645996\n",
      "epoch: 17 step: 767 loss: 0.6931472420692444\n",
      "epoch: 17 step: 768 loss: 0.6931471824645996\n",
      "epoch: 17 step: 769 loss: 0.6931471824645996\n",
      "epoch: 17 step: 770 loss: 0.6931471824645996\n",
      "epoch: 17 step: 771 loss: 0.6931472420692444\n",
      "epoch: 17 step: 772 loss: 0.6931472420692444\n",
      "epoch: 17 step: 773 loss: 0.6931471824645996\n",
      "epoch: 17 step: 774 loss: 0.6931471824645996\n",
      "epoch: 17 step: 775 loss: 0.6931471824645996\n",
      "epoch: 17 step: 776 loss: 0.6931472420692444\n",
      "epoch: 17 step: 777 loss: 0.6931472420692444\n",
      "epoch: 17 step: 778 loss: 0.6931471824645996\n",
      "epoch: 17 step: 779 loss: 0.6931472420692444\n",
      "epoch: 17 step: 780 loss: 0.6931473016738892\n",
      "epoch: 17 step: 781 loss: 0.6931471824645996\n",
      "epoch: 18 step: 1 loss: 0.6931471824645996\n",
      "epoch: 18 step: 2 loss: 0.6931471824645996\n",
      "epoch: 18 step: 3 loss: 0.6931471824645996\n",
      "epoch: 18 step: 4 loss: 0.6931472420692444\n",
      "epoch: 18 step: 5 loss: 0.6931471824645996\n",
      "epoch: 18 step: 6 loss: 0.6931471824645996\n",
      "epoch: 18 step: 7 loss: 0.6931471824645996\n",
      "epoch: 18 step: 8 loss: 0.6931472420692444\n",
      "epoch: 18 step: 9 loss: 0.6931471824645996\n",
      "epoch: 18 step: 10 loss: 0.6931471824645996\n",
      "epoch: 18 step: 11 loss: 0.6931471824645996\n",
      "epoch: 18 step: 12 loss: 0.6931471824645996\n",
      "epoch: 18 step: 13 loss: 0.6931471824645996\n",
      "epoch: 18 step: 14 loss: 0.6931471824645996\n",
      "epoch: 18 step: 15 loss: 0.6931471824645996\n",
      "epoch: 18 step: 16 loss: 0.6931471824645996\n",
      "epoch: 18 step: 17 loss: 0.6931471824645996\n",
      "epoch: 18 step: 18 loss: 0.6931471824645996\n",
      "epoch: 18 step: 19 loss: 0.6931472420692444\n",
      "epoch: 18 step: 20 loss: 0.6931471824645996\n",
      "epoch: 18 step: 21 loss: 0.6931471824645996\n",
      "epoch: 18 step: 22 loss: 0.6931472420692444\n",
      "epoch: 18 step: 23 loss: 0.6931471824645996\n",
      "epoch: 18 step: 24 loss: 0.6931471824645996\n",
      "epoch: 18 step: 25 loss: 0.6931471824645996\n",
      "epoch: 18 step: 26 loss: 0.6931471824645996\n",
      "epoch: 18 step: 27 loss: 0.6931471824645996\n",
      "epoch: 18 step: 28 loss: 0.6931471824645996\n",
      "epoch: 18 step: 29 loss: 0.6931471824645996\n",
      "epoch: 18 step: 30 loss: 0.6931471824645996\n",
      "epoch: 18 step: 31 loss: 0.6931471824645996\n",
      "epoch: 18 step: 32 loss: 0.6931471824645996\n",
      "epoch: 18 step: 33 loss: 0.6931471824645996\n",
      "epoch: 18 step: 34 loss: 0.6931472420692444\n",
      "epoch: 18 step: 35 loss: 0.6931471824645996\n",
      "epoch: 18 step: 36 loss: 0.6931471824645996\n",
      "epoch: 18 step: 37 loss: 0.6931471824645996\n",
      "epoch: 18 step: 38 loss: 0.6931471824645996\n",
      "epoch: 18 step: 39 loss: 0.6931471824645996\n",
      "epoch: 18 step: 40 loss: 0.6931471824645996\n",
      "epoch: 18 step: 41 loss: 0.6931471824645996\n",
      "epoch: 18 step: 42 loss: 0.6931471824645996\n",
      "epoch: 18 step: 43 loss: 0.6931471824645996\n",
      "epoch: 18 step: 44 loss: 0.6931471824645996\n",
      "epoch: 18 step: 45 loss: 0.6931472420692444\n",
      "epoch: 18 step: 46 loss: 0.6931471824645996\n",
      "epoch: 18 step: 47 loss: 0.6931471824645996\n",
      "epoch: 18 step: 48 loss: 0.6931471824645996\n",
      "epoch: 18 step: 49 loss: 0.6931471824645996\n",
      "epoch: 18 step: 50 loss: 0.6931471824645996\n",
      "epoch: 18 step: 51 loss: 0.6931471824645996\n",
      "epoch: 18 step: 52 loss: 0.6931471824645996\n",
      "epoch: 18 step: 53 loss: 0.6931471824645996\n",
      "epoch: 18 step: 54 loss: 0.6931471824645996\n",
      "epoch: 18 step: 55 loss: 0.6931471824645996\n",
      "epoch: 18 step: 56 loss: 0.6931471824645996\n",
      "epoch: 18 step: 57 loss: 0.6931471824645996\n",
      "epoch: 18 step: 58 loss: 0.6931472420692444\n",
      "epoch: 18 step: 59 loss: 0.6931471824645996\n",
      "epoch: 18 step: 60 loss: 0.6931471824645996\n",
      "epoch: 18 step: 61 loss: 0.6931471824645996\n",
      "epoch: 18 step: 62 loss: 0.6931471824645996\n",
      "epoch: 18 step: 63 loss: 0.6931473016738892\n",
      "epoch: 18 step: 64 loss: 0.6931471824645996\n",
      "epoch: 18 step: 65 loss: 0.6931471824645996\n",
      "epoch: 18 step: 66 loss: 0.6931471824645996\n",
      "epoch: 18 step: 67 loss: 0.6931471824645996\n",
      "epoch: 18 step: 68 loss: 0.6931471824645996\n",
      "epoch: 18 step: 69 loss: 0.6931471824645996\n",
      "epoch: 18 step: 70 loss: 0.6931471824645996\n",
      "epoch: 18 step: 71 loss: 0.6931471824645996\n",
      "epoch: 18 step: 72 loss: 0.6931471824645996\n",
      "epoch: 18 step: 73 loss: 0.6931471824645996\n",
      "epoch: 18 step: 74 loss: 0.6931471824645996\n",
      "epoch: 18 step: 75 loss: 0.6931471824645996\n",
      "epoch: 18 step: 76 loss: 0.6931471824645996\n",
      "epoch: 18 step: 77 loss: 0.6931472420692444\n",
      "epoch: 18 step: 78 loss: 0.6931471824645996\n",
      "epoch: 18 step: 79 loss: 0.6931471824645996\n",
      "epoch: 18 step: 80 loss: 0.6931471824645996\n",
      "epoch: 18 step: 81 loss: 0.6931471824645996\n",
      "epoch: 18 step: 82 loss: 0.6931471824645996\n",
      "epoch: 18 step: 83 loss: 0.6931471824645996\n",
      "epoch: 18 step: 84 loss: 0.6931471824645996\n",
      "epoch: 18 step: 85 loss: 0.6931471824645996\n",
      "epoch: 18 step: 86 loss: 0.6931471824645996\n",
      "epoch: 18 step: 87 loss: 0.6931471824645996\n",
      "epoch: 18 step: 88 loss: 0.6931471824645996\n",
      "epoch: 18 step: 89 loss: 0.6931471824645996\n",
      "epoch: 18 step: 90 loss: 0.6931471824645996\n",
      "epoch: 18 step: 91 loss: 0.6931471824645996\n",
      "epoch: 18 step: 92 loss: 0.6931471824645996\n",
      "epoch: 18 step: 93 loss: 0.6931471824645996\n",
      "epoch: 18 step: 94 loss: 0.6931471824645996\n",
      "epoch: 18 step: 95 loss: 0.6931471824645996\n",
      "epoch: 18 step: 96 loss: 0.6931471824645996\n",
      "epoch: 18 step: 97 loss: 0.6931471824645996\n",
      "epoch: 18 step: 98 loss: 0.6931471824645996\n",
      "epoch: 18 step: 99 loss: 0.6931473016738892\n",
      "epoch: 18 step: 100 loss: 0.6931471824645996\n",
      "epoch: 18 step: 101 loss: 0.6931471824645996\n",
      "epoch: 18 step: 102 loss: 0.6931471824645996\n",
      "epoch: 18 step: 103 loss: 0.6931471824645996\n",
      "epoch: 18 step: 104 loss: 0.6931471824645996\n",
      "epoch: 18 step: 105 loss: 0.6931471824645996\n",
      "epoch: 18 step: 106 loss: 0.6931471824645996\n",
      "epoch: 18 step: 107 loss: 0.6931471824645996\n",
      "epoch: 18 step: 108 loss: 0.6931471824645996\n",
      "epoch: 18 step: 109 loss: 0.6931471824645996\n",
      "epoch: 18 step: 110 loss: 0.6931471824645996\n",
      "epoch: 18 step: 111 loss: 0.6931471824645996\n",
      "epoch: 18 step: 112 loss: 0.6931471824645996\n",
      "epoch: 18 step: 113 loss: 0.6931471824645996\n",
      "epoch: 18 step: 114 loss: 0.6931471824645996\n",
      "epoch: 18 step: 115 loss: 0.6931471824645996\n",
      "epoch: 18 step: 116 loss: 0.6931471824645996\n",
      "epoch: 18 step: 117 loss: 0.6931471824645996\n",
      "epoch: 18 step: 118 loss: 0.6931471824645996\n",
      "epoch: 18 step: 119 loss: 0.6931471824645996\n",
      "epoch: 18 step: 120 loss: 0.6931471824645996\n",
      "epoch: 18 step: 121 loss: 0.6931471824645996\n",
      "epoch: 18 step: 122 loss: 0.6931471824645996\n",
      "epoch: 18 step: 123 loss: 0.6931471824645996\n",
      "epoch: 18 step: 124 loss: 0.6931471824645996\n",
      "epoch: 18 step: 125 loss: 0.6931471824645996\n",
      "epoch: 18 step: 126 loss: 0.6931471824645996\n",
      "epoch: 18 step: 127 loss: 0.6931471824645996\n",
      "epoch: 18 step: 128 loss: 0.6931472420692444\n",
      "epoch: 18 step: 129 loss: 0.6931471824645996\n",
      "epoch: 18 step: 130 loss: 0.6931471824645996\n",
      "epoch: 18 step: 131 loss: 0.6931471824645996\n",
      "epoch: 18 step: 132 loss: 0.6931471824645996\n",
      "epoch: 18 step: 133 loss: 0.6931471824645996\n",
      "epoch: 18 step: 134 loss: 0.6931471824645996\n",
      "epoch: 18 step: 135 loss: 0.6931471824645996\n",
      "epoch: 18 step: 136 loss: 0.6931471824645996\n",
      "epoch: 18 step: 137 loss: 0.6931471824645996\n",
      "epoch: 18 step: 138 loss: 0.6931471824645996\n",
      "epoch: 18 step: 139 loss: 0.6931471824645996\n",
      "epoch: 18 step: 140 loss: 0.6931471824645996\n",
      "epoch: 18 step: 141 loss: 0.6931471824645996\n",
      "epoch: 18 step: 142 loss: 0.6931471824645996\n",
      "epoch: 18 step: 143 loss: 0.6931472420692444\n",
      "epoch: 18 step: 144 loss: 0.6931471824645996\n",
      "epoch: 18 step: 145 loss: 0.6931471824645996\n",
      "epoch: 18 step: 146 loss: 0.6931471824645996\n",
      "epoch: 18 step: 147 loss: 0.6931471824645996\n",
      "epoch: 18 step: 148 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 149 loss: 0.6931471824645996\n",
      "epoch: 18 step: 150 loss: 0.6931471824645996\n",
      "epoch: 18 step: 151 loss: 0.6931471824645996\n",
      "epoch: 18 step: 152 loss: 0.6931471824645996\n",
      "epoch: 18 step: 153 loss: 0.6931471824645996\n",
      "epoch: 18 step: 154 loss: 0.6931471824645996\n",
      "epoch: 18 step: 155 loss: 0.6931471824645996\n",
      "epoch: 18 step: 156 loss: 0.6931471824645996\n",
      "epoch: 18 step: 157 loss: 0.6931471824645996\n",
      "epoch: 18 step: 158 loss: 0.6931471824645996\n",
      "epoch: 18 step: 159 loss: 0.6931471824645996\n",
      "epoch: 18 step: 160 loss: 0.6931471824645996\n",
      "epoch: 18 step: 161 loss: 0.6931471824645996\n",
      "epoch: 18 step: 162 loss: 0.6931471824645996\n",
      "epoch: 18 step: 163 loss: 0.6931471824645996\n",
      "epoch: 18 step: 164 loss: 0.6931471824645996\n",
      "epoch: 18 step: 165 loss: 0.6931471824645996\n",
      "epoch: 18 step: 166 loss: 0.6931471824645996\n",
      "epoch: 18 step: 167 loss: 0.6931471824645996\n",
      "epoch: 18 step: 168 loss: 0.6931471824645996\n",
      "epoch: 18 step: 169 loss: 0.6931471824645996\n",
      "epoch: 18 step: 170 loss: 0.6931471824645996\n",
      "epoch: 18 step: 171 loss: 0.6931471824645996\n",
      "epoch: 18 step: 172 loss: 0.6931472420692444\n",
      "epoch: 18 step: 173 loss: 0.6931471824645996\n",
      "epoch: 18 step: 174 loss: 0.6931471824645996\n",
      "epoch: 18 step: 175 loss: 0.6931471824645996\n",
      "epoch: 18 step: 176 loss: 0.6931471824645996\n",
      "epoch: 18 step: 177 loss: 0.6931471824645996\n",
      "epoch: 18 step: 178 loss: 0.6931471824645996\n",
      "epoch: 18 step: 179 loss: 0.6931471824645996\n",
      "epoch: 18 step: 180 loss: 0.6931471824645996\n",
      "epoch: 18 step: 181 loss: 0.6931471824645996\n",
      "epoch: 18 step: 182 loss: 0.6931471824645996\n",
      "epoch: 18 step: 183 loss: 0.6931471824645996\n",
      "epoch: 18 step: 184 loss: 0.6931471824645996\n",
      "epoch: 18 step: 185 loss: 0.6931471824645996\n",
      "epoch: 18 step: 186 loss: 0.6931471824645996\n",
      "epoch: 18 step: 187 loss: 0.6931471824645996\n",
      "epoch: 18 step: 188 loss: 0.6931471824645996\n",
      "epoch: 18 step: 189 loss: 0.6931471824645996\n",
      "epoch: 18 step: 190 loss: 0.6931471824645996\n",
      "epoch: 18 step: 191 loss: 0.6931471824645996\n",
      "epoch: 18 step: 192 loss: 0.6931471824645996\n",
      "epoch: 18 step: 193 loss: 0.6931471824645996\n",
      "epoch: 18 step: 194 loss: 0.6931471824645996\n",
      "epoch: 18 step: 195 loss: 0.6931471824645996\n",
      "epoch: 18 step: 196 loss: 0.6931471824645996\n",
      "epoch: 18 step: 197 loss: 0.6931471824645996\n",
      "epoch: 18 step: 198 loss: 0.6931471824645996\n",
      "epoch: 18 step: 199 loss: 0.6931471824645996\n",
      "epoch: 18 step: 200 loss: 0.6931471824645996\n",
      "epoch: 18 step: 201 loss: 0.6931471824645996\n",
      "epoch: 18 step: 202 loss: 0.6931471824645996\n",
      "epoch: 18 step: 203 loss: 0.6931471824645996\n",
      "epoch: 18 step: 204 loss: 0.6931471824645996\n",
      "epoch: 18 step: 205 loss: 0.6931471824645996\n",
      "epoch: 18 step: 206 loss: 0.6931471824645996\n",
      "epoch: 18 step: 207 loss: 0.6931471824645996\n",
      "epoch: 18 step: 208 loss: 0.6931471824645996\n",
      "epoch: 18 step: 209 loss: 0.6931471824645996\n",
      "epoch: 18 step: 210 loss: 0.6931471824645996\n",
      "epoch: 18 step: 211 loss: 0.6931471824645996\n",
      "epoch: 18 step: 212 loss: 0.6931471824645996\n",
      "epoch: 18 step: 213 loss: 0.6931471824645996\n",
      "epoch: 18 step: 214 loss: 0.6931471824645996\n",
      "epoch: 18 step: 215 loss: 0.6931471824645996\n",
      "epoch: 18 step: 216 loss: 0.6931471824645996\n",
      "epoch: 18 step: 217 loss: 0.6931471824645996\n",
      "epoch: 18 step: 218 loss: 0.6931471824645996\n",
      "epoch: 18 step: 219 loss: 0.6931471824645996\n",
      "epoch: 18 step: 220 loss: 0.6931471824645996\n",
      "epoch: 18 step: 221 loss: 0.6931471824645996\n",
      "epoch: 18 step: 222 loss: 0.6931471824645996\n",
      "epoch: 18 step: 223 loss: 0.6931471824645996\n",
      "epoch: 18 step: 224 loss: 0.6931471824645996\n",
      "epoch: 18 step: 225 loss: 0.6931471824645996\n",
      "epoch: 18 step: 226 loss: 0.6931471824645996\n",
      "epoch: 18 step: 227 loss: 0.6931471824645996\n",
      "epoch: 18 step: 228 loss: 0.6931471824645996\n",
      "epoch: 18 step: 229 loss: 0.6931471824645996\n",
      "epoch: 18 step: 230 loss: 0.6931471824645996\n",
      "epoch: 18 step: 231 loss: 0.6931471824645996\n",
      "epoch: 18 step: 232 loss: 0.6931471824645996\n",
      "epoch: 18 step: 233 loss: 0.6931471824645996\n",
      "epoch: 18 step: 234 loss: 0.6931471824645996\n",
      "epoch: 18 step: 235 loss: 0.6931471824645996\n",
      "epoch: 18 step: 236 loss: 0.6931471824645996\n",
      "epoch: 18 step: 237 loss: 0.6931471824645996\n",
      "epoch: 18 step: 238 loss: 0.6931471824645996\n",
      "epoch: 18 step: 239 loss: 0.6931471824645996\n",
      "epoch: 18 step: 240 loss: 0.6931471824645996\n",
      "epoch: 18 step: 241 loss: 0.6931471824645996\n",
      "epoch: 18 step: 242 loss: 0.6931471824645996\n",
      "epoch: 18 step: 243 loss: 0.6931471824645996\n",
      "epoch: 18 step: 244 loss: 0.6931471824645996\n",
      "epoch: 18 step: 245 loss: 0.6931471824645996\n",
      "epoch: 18 step: 246 loss: 0.6931471824645996\n",
      "epoch: 18 step: 247 loss: 0.6931471824645996\n",
      "epoch: 18 step: 248 loss: 0.6931471824645996\n",
      "epoch: 18 step: 249 loss: 0.6931471824645996\n",
      "epoch: 18 step: 250 loss: 0.6931471824645996\n",
      "epoch: 18 step: 251 loss: 0.6931471824645996\n",
      "epoch: 18 step: 252 loss: 0.6931471824645996\n",
      "epoch: 18 step: 253 loss: 0.6931471824645996\n",
      "epoch: 18 step: 254 loss: 0.6931471824645996\n",
      "epoch: 18 step: 255 loss: 0.6931471824645996\n",
      "epoch: 18 step: 256 loss: 0.6931471824645996\n",
      "epoch: 18 step: 257 loss: 0.6931471824645996\n",
      "epoch: 18 step: 258 loss: 0.6931471824645996\n",
      "epoch: 18 step: 259 loss: 0.6931471824645996\n",
      "epoch: 18 step: 260 loss: 0.6931471824645996\n",
      "epoch: 18 step: 261 loss: 0.6931471824645996\n",
      "epoch: 18 step: 262 loss: 0.6931471824645996\n",
      "epoch: 18 step: 263 loss: 0.6931471824645996\n",
      "epoch: 18 step: 264 loss: 0.6931471824645996\n",
      "epoch: 18 step: 265 loss: 0.6931471824645996\n",
      "epoch: 18 step: 266 loss: 0.6931471824645996\n",
      "epoch: 18 step: 267 loss: 0.6931471824645996\n",
      "epoch: 18 step: 268 loss: 0.6931471824645996\n",
      "epoch: 18 step: 269 loss: 0.6931471824645996\n",
      "epoch: 18 step: 270 loss: 0.6931471824645996\n",
      "epoch: 18 step: 271 loss: 0.6931471824645996\n",
      "epoch: 18 step: 272 loss: 0.6931471824645996\n",
      "epoch: 18 step: 273 loss: 0.6931471824645996\n",
      "epoch: 18 step: 274 loss: 0.6931471824645996\n",
      "epoch: 18 step: 275 loss: 0.6931471824645996\n",
      "epoch: 18 step: 276 loss: 0.6931471824645996\n",
      "epoch: 18 step: 277 loss: 0.6931471824645996\n",
      "epoch: 18 step: 278 loss: 0.6931471824645996\n",
      "epoch: 18 step: 279 loss: 0.6931471824645996\n",
      "epoch: 18 step: 280 loss: 0.6931471824645996\n",
      "epoch: 18 step: 281 loss: 0.6931471824645996\n",
      "epoch: 18 step: 282 loss: 0.6931471824645996\n",
      "epoch: 18 step: 283 loss: 0.6931471824645996\n",
      "epoch: 18 step: 284 loss: 0.6931471824645996\n",
      "epoch: 18 step: 285 loss: 0.6931471824645996\n",
      "epoch: 18 step: 286 loss: 0.6931471824645996\n",
      "epoch: 18 step: 287 loss: 0.6931471824645996\n",
      "epoch: 18 step: 288 loss: 0.6931471824645996\n",
      "epoch: 18 step: 289 loss: 0.6931471824645996\n",
      "epoch: 18 step: 290 loss: 0.6931471824645996\n",
      "epoch: 18 step: 291 loss: 0.6931471824645996\n",
      "epoch: 18 step: 292 loss: 0.6931471824645996\n",
      "epoch: 18 step: 293 loss: 0.6931471824645996\n",
      "epoch: 18 step: 294 loss: 0.6931471824645996\n",
      "epoch: 18 step: 295 loss: 0.6931471824645996\n",
      "epoch: 18 step: 296 loss: 0.6931471824645996\n",
      "epoch: 18 step: 297 loss: 0.6931471824645996\n",
      "epoch: 18 step: 298 loss: 0.6931471824645996\n",
      "epoch: 18 step: 299 loss: 0.6931471824645996\n",
      "epoch: 18 step: 300 loss: 0.6931471824645996\n",
      "epoch: 18 step: 301 loss: 0.6931471824645996\n",
      "epoch: 18 step: 302 loss: 0.6931471824645996\n",
      "epoch: 18 step: 303 loss: 0.6931471824645996\n",
      "epoch: 18 step: 304 loss: 0.6931471824645996\n",
      "epoch: 18 step: 305 loss: 0.6931471824645996\n",
      "epoch: 18 step: 306 loss: 0.6931471824645996\n",
      "epoch: 18 step: 307 loss: 0.6931471824645996\n",
      "epoch: 18 step: 308 loss: 0.6931471824645996\n",
      "epoch: 18 step: 309 loss: 0.6931471824645996\n",
      "epoch: 18 step: 310 loss: 0.6931471824645996\n",
      "epoch: 18 step: 311 loss: 0.6931471824645996\n",
      "epoch: 18 step: 312 loss: 0.6931471824645996\n",
      "epoch: 18 step: 313 loss: 0.6931471824645996\n",
      "epoch: 18 step: 314 loss: 0.6931471824645996\n",
      "epoch: 18 step: 315 loss: 0.6931471824645996\n",
      "epoch: 18 step: 316 loss: 0.6931471824645996\n",
      "epoch: 18 step: 317 loss: 0.6931471824645996\n",
      "epoch: 18 step: 318 loss: 0.6931471824645996\n",
      "epoch: 18 step: 319 loss: 0.6931471824645996\n",
      "epoch: 18 step: 320 loss: 0.6931471824645996\n",
      "epoch: 18 step: 321 loss: 0.6931471824645996\n",
      "epoch: 18 step: 322 loss: 0.6931471824645996\n",
      "epoch: 18 step: 323 loss: 0.6931471824645996\n",
      "epoch: 18 step: 324 loss: 0.6931471824645996\n",
      "epoch: 18 step: 325 loss: 0.6931471824645996\n",
      "epoch: 18 step: 326 loss: 0.6931471824645996\n",
      "epoch: 18 step: 327 loss: 0.6931471824645996\n",
      "epoch: 18 step: 328 loss: 0.6931471824645996\n",
      "epoch: 18 step: 329 loss: 0.6931471824645996\n",
      "epoch: 18 step: 330 loss: 0.6931471824645996\n",
      "epoch: 18 step: 331 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 332 loss: 0.6931471824645996\n",
      "epoch: 18 step: 333 loss: 0.6931471824645996\n",
      "epoch: 18 step: 334 loss: 0.6931471824645996\n",
      "epoch: 18 step: 335 loss: 0.6931471824645996\n",
      "epoch: 18 step: 336 loss: 0.6931471824645996\n",
      "epoch: 18 step: 337 loss: 0.6931471824645996\n",
      "epoch: 18 step: 338 loss: 0.6931471824645996\n",
      "epoch: 18 step: 339 loss: 0.6931471824645996\n",
      "epoch: 18 step: 340 loss: 0.6931471824645996\n",
      "epoch: 18 step: 341 loss: 0.6931471824645996\n",
      "epoch: 18 step: 342 loss: 0.6931471824645996\n",
      "epoch: 18 step: 343 loss: 0.6931471824645996\n",
      "epoch: 18 step: 344 loss: 0.6931471824645996\n",
      "epoch: 18 step: 345 loss: 0.6931471824645996\n",
      "epoch: 18 step: 346 loss: 0.6931471824645996\n",
      "epoch: 18 step: 347 loss: 0.6931471824645996\n",
      "epoch: 18 step: 348 loss: 0.6931471824645996\n",
      "epoch: 18 step: 349 loss: 0.6931471824645996\n",
      "epoch: 18 step: 350 loss: 0.6931471824645996\n",
      "epoch: 18 step: 351 loss: 0.6931471824645996\n",
      "epoch: 18 step: 352 loss: 0.6931471824645996\n",
      "epoch: 18 step: 353 loss: 0.6931471824645996\n",
      "epoch: 18 step: 354 loss: 0.6931471824645996\n",
      "epoch: 18 step: 355 loss: 0.6931471824645996\n",
      "epoch: 18 step: 356 loss: 0.6931471824645996\n",
      "epoch: 18 step: 357 loss: 0.6931471824645996\n",
      "epoch: 18 step: 358 loss: 0.6931471824645996\n",
      "epoch: 18 step: 359 loss: 0.6931471824645996\n",
      "epoch: 18 step: 360 loss: 0.6931471824645996\n",
      "epoch: 18 step: 361 loss: 0.6931471824645996\n",
      "epoch: 18 step: 362 loss: 0.6931471824645996\n",
      "epoch: 18 step: 363 loss: 0.6931471824645996\n",
      "epoch: 18 step: 364 loss: 0.6931471824645996\n",
      "epoch: 18 step: 365 loss: 0.6931471824645996\n",
      "epoch: 18 step: 366 loss: 0.6931471824645996\n",
      "epoch: 18 step: 367 loss: 0.6931471824645996\n",
      "epoch: 18 step: 368 loss: 0.6931471824645996\n",
      "epoch: 18 step: 369 loss: 0.6931471824645996\n",
      "epoch: 18 step: 370 loss: 0.6931471824645996\n",
      "epoch: 18 step: 371 loss: 0.6931471824645996\n",
      "epoch: 18 step: 372 loss: 0.6931471824645996\n",
      "epoch: 18 step: 373 loss: 0.6931471824645996\n",
      "epoch: 18 step: 374 loss: 0.6931471824645996\n",
      "epoch: 18 step: 375 loss: 0.6931471824645996\n",
      "epoch: 18 step: 376 loss: 0.6931471824645996\n",
      "epoch: 18 step: 377 loss: 0.6931471824645996\n",
      "epoch: 18 step: 378 loss: 0.6931471824645996\n",
      "epoch: 18 step: 379 loss: 0.6931471824645996\n",
      "epoch: 18 step: 380 loss: 0.6931471824645996\n",
      "epoch: 18 step: 381 loss: 0.6931471824645996\n",
      "epoch: 18 step: 382 loss: 0.6931471824645996\n",
      "epoch: 18 step: 383 loss: 0.6931471824645996\n",
      "epoch: 18 step: 384 loss: 0.6931471824645996\n",
      "epoch: 18 step: 385 loss: 0.6931471824645996\n",
      "epoch: 18 step: 386 loss: 0.6931471824645996\n",
      "epoch: 18 step: 387 loss: 0.6931471824645996\n",
      "epoch: 18 step: 388 loss: 0.6931471824645996\n",
      "epoch: 18 step: 389 loss: 0.6931471824645996\n",
      "epoch: 18 step: 390 loss: 0.6931471824645996\n",
      "epoch: 18 step: 391 loss: 0.6931471824645996\n",
      "epoch: 18 step: 392 loss: 0.6931471824645996\n",
      "epoch: 18 step: 393 loss: 0.6931471824645996\n",
      "epoch: 18 step: 394 loss: 0.6931471824645996\n",
      "epoch: 18 step: 395 loss: 0.6931471824645996\n",
      "epoch: 18 step: 396 loss: 0.6931471824645996\n",
      "epoch: 18 step: 397 loss: 0.6931471824645996\n",
      "epoch: 18 step: 398 loss: 0.6931471824645996\n",
      "epoch: 18 step: 399 loss: 0.6931471824645996\n",
      "epoch: 18 step: 400 loss: 0.6931471824645996\n",
      "epoch: 18 step: 401 loss: 0.6931471824645996\n",
      "epoch: 18 step: 402 loss: 0.6931471824645996\n",
      "epoch: 18 step: 403 loss: 0.6931471824645996\n",
      "epoch: 18 step: 404 loss: 0.6931471824645996\n",
      "epoch: 18 step: 405 loss: 0.6931471824645996\n",
      "epoch: 18 step: 406 loss: 0.6931471824645996\n",
      "epoch: 18 step: 407 loss: 0.6931471824645996\n",
      "epoch: 18 step: 408 loss: 0.6931471824645996\n",
      "epoch: 18 step: 409 loss: 0.6931471824645996\n",
      "epoch: 18 step: 410 loss: 0.6931471824645996\n",
      "epoch: 18 step: 411 loss: 0.6931471824645996\n",
      "epoch: 18 step: 412 loss: 0.6931471824645996\n",
      "epoch: 18 step: 413 loss: 0.6931471824645996\n",
      "epoch: 18 step: 414 loss: 0.6931471824645996\n",
      "epoch: 18 step: 415 loss: 0.6931471824645996\n",
      "epoch: 18 step: 416 loss: 0.6931471824645996\n",
      "epoch: 18 step: 417 loss: 0.6931471824645996\n",
      "epoch: 18 step: 418 loss: 0.6931471824645996\n",
      "epoch: 18 step: 419 loss: 0.6931471824645996\n",
      "epoch: 18 step: 420 loss: 0.6931471824645996\n",
      "epoch: 18 step: 421 loss: 0.6931471824645996\n",
      "epoch: 18 step: 422 loss: 0.6931471824645996\n",
      "epoch: 18 step: 423 loss: 0.6931471824645996\n",
      "epoch: 18 step: 424 loss: 0.6931471824645996\n",
      "epoch: 18 step: 425 loss: 0.6931471824645996\n",
      "epoch: 18 step: 426 loss: 0.6931471824645996\n",
      "epoch: 18 step: 427 loss: 0.6931471824645996\n",
      "epoch: 18 step: 428 loss: 0.6931471824645996\n",
      "epoch: 18 step: 429 loss: 0.6931471824645996\n",
      "epoch: 18 step: 430 loss: 0.6931471824645996\n",
      "epoch: 18 step: 431 loss: 0.6931471824645996\n",
      "epoch: 18 step: 432 loss: 0.6931471824645996\n",
      "epoch: 18 step: 433 loss: 0.6931471824645996\n",
      "epoch: 18 step: 434 loss: 0.6931471824645996\n",
      "epoch: 18 step: 435 loss: 0.6931471824645996\n",
      "epoch: 18 step: 436 loss: 0.6931471824645996\n",
      "epoch: 18 step: 437 loss: 0.6931471824645996\n",
      "epoch: 18 step: 438 loss: 0.6931471824645996\n",
      "epoch: 18 step: 439 loss: 0.6931471824645996\n",
      "epoch: 18 step: 440 loss: 0.6931471824645996\n",
      "epoch: 18 step: 441 loss: 0.6931471824645996\n",
      "epoch: 18 step: 442 loss: 0.6931471824645996\n",
      "epoch: 18 step: 443 loss: 0.6931471824645996\n",
      "epoch: 18 step: 444 loss: 0.6931471824645996\n",
      "epoch: 18 step: 445 loss: 0.6931471824645996\n",
      "epoch: 18 step: 446 loss: 0.6931471824645996\n",
      "epoch: 18 step: 447 loss: 0.6931471824645996\n",
      "epoch: 18 step: 448 loss: 0.6931471824645996\n",
      "epoch: 18 step: 449 loss: 0.6931471824645996\n",
      "epoch: 18 step: 450 loss: 0.6931471824645996\n",
      "epoch: 18 step: 451 loss: 0.6931471824645996\n",
      "epoch: 18 step: 452 loss: 0.6931471824645996\n",
      "epoch: 18 step: 453 loss: 0.6931471824645996\n",
      "epoch: 18 step: 454 loss: 0.6931471824645996\n",
      "epoch: 18 step: 455 loss: 0.6931471824645996\n",
      "epoch: 18 step: 456 loss: 0.6931471824645996\n",
      "epoch: 18 step: 457 loss: 0.6931471824645996\n",
      "epoch: 18 step: 458 loss: 0.6931471824645996\n",
      "epoch: 18 step: 459 loss: 0.6931471824645996\n",
      "epoch: 18 step: 460 loss: 0.6931471824645996\n",
      "epoch: 18 step: 461 loss: 0.6931471824645996\n",
      "epoch: 18 step: 462 loss: 0.6931471824645996\n",
      "epoch: 18 step: 463 loss: 0.6931471824645996\n",
      "epoch: 18 step: 464 loss: 0.6931471824645996\n",
      "epoch: 18 step: 465 loss: 0.6931471824645996\n",
      "epoch: 18 step: 466 loss: 0.6931471824645996\n",
      "epoch: 18 step: 467 loss: 0.6931471824645996\n",
      "epoch: 18 step: 468 loss: 0.6931471824645996\n",
      "epoch: 18 step: 469 loss: 0.6931471824645996\n",
      "epoch: 18 step: 470 loss: 0.6931471824645996\n",
      "epoch: 18 step: 471 loss: 0.6931471824645996\n",
      "epoch: 18 step: 472 loss: 0.6931471824645996\n",
      "epoch: 18 step: 473 loss: 0.6931471824645996\n",
      "epoch: 18 step: 474 loss: 0.6931471824645996\n",
      "epoch: 18 step: 475 loss: 0.6931471824645996\n",
      "epoch: 18 step: 476 loss: 0.6931471824645996\n",
      "epoch: 18 step: 477 loss: 0.6931471824645996\n",
      "epoch: 18 step: 478 loss: 0.6931471824645996\n",
      "epoch: 18 step: 479 loss: 0.6931471824645996\n",
      "epoch: 18 step: 480 loss: 0.6931471824645996\n",
      "epoch: 18 step: 481 loss: 0.6931471824645996\n",
      "epoch: 18 step: 482 loss: 0.6931471824645996\n",
      "epoch: 18 step: 483 loss: 0.6931471824645996\n",
      "epoch: 18 step: 484 loss: 0.6931471824645996\n",
      "epoch: 18 step: 485 loss: 0.6931471824645996\n",
      "epoch: 18 step: 486 loss: 0.6931471824645996\n",
      "epoch: 18 step: 487 loss: 0.6931471824645996\n",
      "epoch: 18 step: 488 loss: 0.6931471824645996\n",
      "epoch: 18 step: 489 loss: 0.6931471824645996\n",
      "epoch: 18 step: 490 loss: 0.6931471824645996\n",
      "epoch: 18 step: 491 loss: 0.6931471824645996\n",
      "epoch: 18 step: 492 loss: 0.6931471824645996\n",
      "epoch: 18 step: 493 loss: 0.6931471824645996\n",
      "epoch: 18 step: 494 loss: 0.6931471824645996\n",
      "epoch: 18 step: 495 loss: 0.6931471824645996\n",
      "epoch: 18 step: 496 loss: 0.6931471824645996\n",
      "epoch: 18 step: 497 loss: 0.6931471824645996\n",
      "epoch: 18 step: 498 loss: 0.6931471824645996\n",
      "epoch: 18 step: 499 loss: 0.6931471824645996\n",
      "epoch: 18 step: 500 loss: 0.6931471824645996\n",
      "epoch: 18 step: 501 loss: 0.6931471824645996\n",
      "epoch: 18 step: 502 loss: 0.6931471824645996\n",
      "epoch: 18 step: 503 loss: 0.6931471824645996\n",
      "epoch: 18 step: 504 loss: 0.6931471824645996\n",
      "epoch: 18 step: 505 loss: 0.6931471824645996\n",
      "epoch: 18 step: 506 loss: 0.6931471824645996\n",
      "epoch: 18 step: 507 loss: 0.6931471824645996\n",
      "epoch: 18 step: 508 loss: 0.6931471824645996\n",
      "epoch: 18 step: 509 loss: 0.6931471824645996\n",
      "epoch: 18 step: 510 loss: 0.6931471824645996\n",
      "epoch: 18 step: 511 loss: 0.6931471824645996\n",
      "epoch: 18 step: 512 loss: 0.6931471824645996\n",
      "epoch: 18 step: 513 loss: 0.6931471824645996\n",
      "epoch: 18 step: 514 loss: 0.6931471824645996\n",
      "epoch: 18 step: 515 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 516 loss: 0.6931471824645996\n",
      "epoch: 18 step: 517 loss: 0.6931471824645996\n",
      "epoch: 18 step: 518 loss: 0.6931471824645996\n",
      "epoch: 18 step: 519 loss: 0.6931471824645996\n",
      "epoch: 18 step: 520 loss: 0.6931471824645996\n",
      "epoch: 18 step: 521 loss: 0.6931471824645996\n",
      "epoch: 18 step: 522 loss: 0.6931471824645996\n",
      "epoch: 18 step: 523 loss: 0.6931471824645996\n",
      "epoch: 18 step: 524 loss: 0.6931471824645996\n",
      "epoch: 18 step: 525 loss: 0.6931471824645996\n",
      "epoch: 18 step: 526 loss: 0.6931471824645996\n",
      "epoch: 18 step: 527 loss: 0.6931471824645996\n",
      "epoch: 18 step: 528 loss: 0.6931471824645996\n",
      "epoch: 18 step: 529 loss: 0.6931471824645996\n",
      "epoch: 18 step: 530 loss: 0.6931471824645996\n",
      "epoch: 18 step: 531 loss: 0.6931471824645996\n",
      "epoch: 18 step: 532 loss: 0.6931471824645996\n",
      "epoch: 18 step: 533 loss: 0.6931471824645996\n",
      "epoch: 18 step: 534 loss: 0.6931471824645996\n",
      "epoch: 18 step: 535 loss: 0.6931471824645996\n",
      "epoch: 18 step: 536 loss: 0.6931471824645996\n",
      "epoch: 18 step: 537 loss: 0.6931471824645996\n",
      "epoch: 18 step: 538 loss: 0.6931471824645996\n",
      "epoch: 18 step: 539 loss: 0.6931471824645996\n",
      "epoch: 18 step: 540 loss: 0.6931471824645996\n",
      "epoch: 18 step: 541 loss: 0.6931471824645996\n",
      "epoch: 18 step: 542 loss: 0.6931471824645996\n",
      "epoch: 18 step: 543 loss: 0.6931471824645996\n",
      "epoch: 18 step: 544 loss: 0.6931471824645996\n",
      "epoch: 18 step: 545 loss: 0.6931471824645996\n",
      "epoch: 18 step: 546 loss: 0.6931471824645996\n",
      "epoch: 18 step: 547 loss: 0.6931471824645996\n",
      "epoch: 18 step: 548 loss: 0.6931471824645996\n",
      "epoch: 18 step: 549 loss: 0.6931471824645996\n",
      "epoch: 18 step: 550 loss: 0.6931471824645996\n",
      "epoch: 18 step: 551 loss: 0.6931471824645996\n",
      "epoch: 18 step: 552 loss: 0.6931471824645996\n",
      "epoch: 18 step: 553 loss: 0.6931471824645996\n",
      "epoch: 18 step: 554 loss: 0.6931471824645996\n",
      "epoch: 18 step: 555 loss: 0.6931471824645996\n",
      "epoch: 18 step: 556 loss: 0.6931471824645996\n",
      "epoch: 18 step: 557 loss: 0.6931471824645996\n",
      "epoch: 18 step: 558 loss: 0.6931471824645996\n",
      "epoch: 18 step: 559 loss: 0.6931471824645996\n",
      "epoch: 18 step: 560 loss: 0.6931471824645996\n",
      "epoch: 18 step: 561 loss: 0.6931471824645996\n",
      "epoch: 18 step: 562 loss: 0.6931471824645996\n",
      "epoch: 18 step: 563 loss: 0.6931471824645996\n",
      "epoch: 18 step: 564 loss: 0.6931471824645996\n",
      "epoch: 18 step: 565 loss: 0.6931471824645996\n",
      "epoch: 18 step: 566 loss: 0.6931471824645996\n",
      "epoch: 18 step: 567 loss: 0.6931471824645996\n",
      "epoch: 18 step: 568 loss: 0.6931471824645996\n",
      "epoch: 18 step: 569 loss: 0.6931471824645996\n",
      "epoch: 18 step: 570 loss: 0.6931471824645996\n",
      "epoch: 18 step: 571 loss: 0.6931471824645996\n",
      "epoch: 18 step: 572 loss: 0.6931471824645996\n",
      "epoch: 18 step: 573 loss: 0.6931471824645996\n",
      "epoch: 18 step: 574 loss: 0.6931471824645996\n",
      "epoch: 18 step: 575 loss: 0.6931471824645996\n",
      "epoch: 18 step: 576 loss: 0.6931472420692444\n",
      "epoch: 18 step: 577 loss: 0.6931471824645996\n",
      "epoch: 18 step: 578 loss: 0.6931471824645996\n",
      "epoch: 18 step: 579 loss: 0.6931471824645996\n",
      "epoch: 18 step: 580 loss: 0.6931471824645996\n",
      "epoch: 18 step: 581 loss: 0.6931471824645996\n",
      "epoch: 18 step: 582 loss: 0.6931471824645996\n",
      "epoch: 18 step: 583 loss: 0.6931471824645996\n",
      "epoch: 18 step: 584 loss: 0.6931471824645996\n",
      "epoch: 18 step: 585 loss: 0.6931471824645996\n",
      "epoch: 18 step: 586 loss: 0.6931471824645996\n",
      "epoch: 18 step: 587 loss: 0.6931471824645996\n",
      "epoch: 18 step: 588 loss: 0.6931471824645996\n",
      "epoch: 18 step: 589 loss: 0.6931471824645996\n",
      "epoch: 18 step: 590 loss: 0.6931471824645996\n",
      "epoch: 18 step: 591 loss: 0.6931471824645996\n",
      "epoch: 18 step: 592 loss: 0.6931471824645996\n",
      "epoch: 18 step: 593 loss: 0.6931471824645996\n",
      "epoch: 18 step: 594 loss: 0.6931471824645996\n",
      "epoch: 18 step: 595 loss: 0.6931472420692444\n",
      "epoch: 18 step: 596 loss: 0.6931471824645996\n",
      "epoch: 18 step: 597 loss: 0.6931471824645996\n",
      "epoch: 18 step: 598 loss: 0.6931471824645996\n",
      "epoch: 18 step: 599 loss: 0.6931471824645996\n",
      "epoch: 18 step: 600 loss: 0.6931471824645996\n",
      "epoch: 18 step: 601 loss: 0.6931471824645996\n",
      "epoch: 18 step: 602 loss: 0.6931471824645996\n",
      "epoch: 18 step: 603 loss: 0.6931471824645996\n",
      "epoch: 18 step: 604 loss: 0.6931471824645996\n",
      "epoch: 18 step: 605 loss: 0.6931471824645996\n",
      "epoch: 18 step: 606 loss: 0.6931472420692444\n",
      "epoch: 18 step: 607 loss: 0.6931471824645996\n",
      "epoch: 18 step: 608 loss: 0.6931471824645996\n",
      "epoch: 18 step: 609 loss: 0.6931471824645996\n",
      "epoch: 18 step: 610 loss: 0.6931471824645996\n",
      "epoch: 18 step: 611 loss: 0.6931471824645996\n",
      "epoch: 18 step: 612 loss: 0.6931471824645996\n",
      "epoch: 18 step: 613 loss: 0.6931471824645996\n",
      "epoch: 18 step: 614 loss: 0.6931471824645996\n",
      "epoch: 18 step: 615 loss: 0.6931471824645996\n",
      "epoch: 18 step: 616 loss: 0.6931471824645996\n",
      "epoch: 18 step: 617 loss: 0.6931471824645996\n",
      "epoch: 18 step: 618 loss: 0.6931471824645996\n",
      "epoch: 18 step: 619 loss: 0.6931471824645996\n",
      "epoch: 18 step: 620 loss: 0.6931471824645996\n",
      "epoch: 18 step: 621 loss: 0.6931471824645996\n",
      "epoch: 18 step: 622 loss: 0.6931471824645996\n",
      "epoch: 18 step: 623 loss: 0.6931471824645996\n",
      "epoch: 18 step: 624 loss: 0.6931471824645996\n",
      "epoch: 18 step: 625 loss: 0.6931471824645996\n",
      "epoch: 18 step: 626 loss: 0.6931471824645996\n",
      "epoch: 18 step: 627 loss: 0.6931471824645996\n",
      "epoch: 18 step: 628 loss: 0.6931471824645996\n",
      "epoch: 18 step: 629 loss: 0.6931471824645996\n",
      "epoch: 18 step: 630 loss: 0.6931471824645996\n",
      "epoch: 18 step: 631 loss: 0.6931471824645996\n",
      "epoch: 18 step: 632 loss: 0.6931471824645996\n",
      "epoch: 18 step: 633 loss: 0.6931471824645996\n",
      "epoch: 18 step: 634 loss: 0.6931471824645996\n",
      "epoch: 18 step: 635 loss: 0.6931471824645996\n",
      "epoch: 18 step: 636 loss: 0.6931471824645996\n",
      "epoch: 18 step: 637 loss: 0.6931471824645996\n",
      "epoch: 18 step: 638 loss: 0.6931471824645996\n",
      "epoch: 18 step: 639 loss: 0.6931471824645996\n",
      "epoch: 18 step: 640 loss: 0.6931471824645996\n",
      "epoch: 18 step: 641 loss: 0.6931471824645996\n",
      "epoch: 18 step: 642 loss: 0.6931471824645996\n",
      "epoch: 18 step: 643 loss: 0.6931471824645996\n",
      "epoch: 18 step: 644 loss: 0.6931471824645996\n",
      "epoch: 18 step: 645 loss: 0.6931471824645996\n",
      "epoch: 18 step: 646 loss: 0.6931471824645996\n",
      "epoch: 18 step: 647 loss: 0.6931471824645996\n",
      "epoch: 18 step: 648 loss: 0.6931471824645996\n",
      "epoch: 18 step: 649 loss: 0.6931471824645996\n",
      "epoch: 18 step: 650 loss: 0.6931471824645996\n",
      "epoch: 18 step: 651 loss: 0.6931471824645996\n",
      "epoch: 18 step: 652 loss: 0.6931471824645996\n",
      "epoch: 18 step: 653 loss: 0.6931471824645996\n",
      "epoch: 18 step: 654 loss: 0.6931471824645996\n",
      "epoch: 18 step: 655 loss: 0.6931471824645996\n",
      "epoch: 18 step: 656 loss: 0.6931471824645996\n",
      "epoch: 18 step: 657 loss: 0.6931471824645996\n",
      "epoch: 18 step: 658 loss: 0.6931471824645996\n",
      "epoch: 18 step: 659 loss: 0.6931471824645996\n",
      "epoch: 18 step: 660 loss: 0.6931471824645996\n",
      "epoch: 18 step: 661 loss: 0.6931471824645996\n",
      "epoch: 18 step: 662 loss: 0.6931471824645996\n",
      "epoch: 18 step: 663 loss: 0.6931471824645996\n",
      "epoch: 18 step: 664 loss: 0.6931471824645996\n",
      "epoch: 18 step: 665 loss: 0.6931471824645996\n",
      "epoch: 18 step: 666 loss: 0.6931471824645996\n",
      "epoch: 18 step: 667 loss: 0.6931471824645996\n",
      "epoch: 18 step: 668 loss: 0.6931471824645996\n",
      "epoch: 18 step: 669 loss: 0.6931471824645996\n",
      "epoch: 18 step: 670 loss: 0.6931471824645996\n",
      "epoch: 18 step: 671 loss: 0.6931471824645996\n",
      "epoch: 18 step: 672 loss: 0.6931471824645996\n",
      "epoch: 18 step: 673 loss: 0.6931471824645996\n",
      "epoch: 18 step: 674 loss: 0.6931471824645996\n",
      "epoch: 18 step: 675 loss: 0.6931471824645996\n",
      "epoch: 18 step: 676 loss: 0.6931471824645996\n",
      "epoch: 18 step: 677 loss: 0.6931471824645996\n",
      "epoch: 18 step: 678 loss: 0.6931471824645996\n",
      "epoch: 18 step: 679 loss: 0.6931471824645996\n",
      "epoch: 18 step: 680 loss: 0.6931471824645996\n",
      "epoch: 18 step: 681 loss: 0.6931471824645996\n",
      "epoch: 18 step: 682 loss: 0.6931471824645996\n",
      "epoch: 18 step: 683 loss: 0.6931471824645996\n",
      "epoch: 18 step: 684 loss: 0.6931471824645996\n",
      "epoch: 18 step: 685 loss: 0.6931471824645996\n",
      "epoch: 18 step: 686 loss: 0.6931471824645996\n",
      "epoch: 18 step: 687 loss: 0.6931471824645996\n",
      "epoch: 18 step: 688 loss: 0.6931471824645996\n",
      "epoch: 18 step: 689 loss: 0.6931471824645996\n",
      "epoch: 18 step: 690 loss: 0.6931471824645996\n",
      "epoch: 18 step: 691 loss: 0.6931471824645996\n",
      "epoch: 18 step: 692 loss: 0.6931471824645996\n",
      "epoch: 18 step: 693 loss: 0.6931471824645996\n",
      "epoch: 18 step: 694 loss: 0.6931471824645996\n",
      "epoch: 18 step: 695 loss: 0.6931471824645996\n",
      "epoch: 18 step: 696 loss: 0.6931471824645996\n",
      "epoch: 18 step: 697 loss: 0.6931471824645996\n",
      "epoch: 18 step: 698 loss: 0.6931471824645996\n",
      "epoch: 18 step: 699 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 700 loss: 0.6931471824645996\n",
      "epoch: 18 step: 701 loss: 0.6931471824645996\n",
      "epoch: 18 step: 702 loss: 0.6931471824645996\n",
      "epoch: 18 step: 703 loss: 0.6931471824645996\n",
      "epoch: 18 step: 704 loss: 0.6931471824645996\n",
      "epoch: 18 step: 705 loss: 0.6931471824645996\n",
      "epoch: 18 step: 706 loss: 0.6931471824645996\n",
      "epoch: 18 step: 707 loss: 0.6931471824645996\n",
      "epoch: 18 step: 708 loss: 0.6931471824645996\n",
      "epoch: 18 step: 709 loss: 0.6931471824645996\n",
      "epoch: 18 step: 710 loss: 0.6931471824645996\n",
      "epoch: 18 step: 711 loss: 0.6931471824645996\n",
      "epoch: 18 step: 712 loss: 0.6931471824645996\n",
      "epoch: 18 step: 713 loss: 0.6931471824645996\n",
      "epoch: 18 step: 714 loss: 0.6931471824645996\n",
      "epoch: 18 step: 715 loss: 0.6931471824645996\n",
      "epoch: 18 step: 716 loss: 0.6931471824645996\n",
      "epoch: 18 step: 717 loss: 0.6931471824645996\n",
      "epoch: 18 step: 718 loss: 0.6931471824645996\n",
      "epoch: 18 step: 719 loss: 0.6931471824645996\n",
      "epoch: 18 step: 720 loss: 0.6931471824645996\n",
      "epoch: 18 step: 721 loss: 0.6931471824645996\n",
      "epoch: 18 step: 722 loss: 0.6931471824645996\n",
      "epoch: 18 step: 723 loss: 0.6931471824645996\n",
      "epoch: 18 step: 724 loss: 0.6931471824645996\n",
      "epoch: 18 step: 725 loss: 0.6931471824645996\n",
      "epoch: 18 step: 726 loss: 0.6931471824645996\n",
      "epoch: 18 step: 727 loss: 0.6931471824645996\n",
      "epoch: 18 step: 728 loss: 0.6931471824645996\n",
      "epoch: 18 step: 729 loss: 0.6931471824645996\n",
      "epoch: 18 step: 730 loss: 0.6931471824645996\n",
      "epoch: 18 step: 731 loss: 0.6931471824645996\n",
      "epoch: 18 step: 732 loss: 0.6931471824645996\n",
      "epoch: 18 step: 733 loss: 0.6931471824645996\n",
      "epoch: 18 step: 734 loss: 0.6931471824645996\n",
      "epoch: 18 step: 735 loss: 0.6931471824645996\n",
      "epoch: 18 step: 736 loss: 0.6931471824645996\n",
      "epoch: 18 step: 737 loss: 0.6931471824645996\n",
      "epoch: 18 step: 738 loss: 0.6931471824645996\n",
      "epoch: 18 step: 739 loss: 0.6931471824645996\n",
      "epoch: 18 step: 740 loss: 0.6931471824645996\n",
      "epoch: 18 step: 741 loss: 0.6931471824645996\n",
      "epoch: 18 step: 742 loss: 0.6931471824645996\n",
      "epoch: 18 step: 743 loss: 0.6931471824645996\n",
      "epoch: 18 step: 744 loss: 0.6931471824645996\n",
      "epoch: 18 step: 745 loss: 0.6931471824645996\n",
      "epoch: 18 step: 746 loss: 0.6931471824645996\n",
      "epoch: 18 step: 747 loss: 0.6931471824645996\n",
      "epoch: 18 step: 748 loss: 0.6931471824645996\n",
      "epoch: 18 step: 749 loss: 0.6931471824645996\n",
      "epoch: 18 step: 750 loss: 0.6931471824645996\n",
      "epoch: 18 step: 751 loss: 0.6931471824645996\n",
      "epoch: 18 step: 752 loss: 0.6931471824645996\n",
      "epoch: 18 step: 753 loss: 0.6931471824645996\n",
      "epoch: 18 step: 754 loss: 0.6931471824645996\n",
      "epoch: 18 step: 755 loss: 0.6931471824645996\n",
      "epoch: 18 step: 756 loss: 0.6931471824645996\n",
      "epoch: 18 step: 757 loss: 0.6931471824645996\n",
      "epoch: 18 step: 758 loss: 0.6931471824645996\n",
      "epoch: 18 step: 759 loss: 0.6931471824645996\n",
      "epoch: 18 step: 760 loss: 0.6931471824645996\n",
      "epoch: 18 step: 761 loss: 0.6931471824645996\n",
      "epoch: 18 step: 762 loss: 0.6931471824645996\n",
      "epoch: 18 step: 763 loss: 0.6931471824645996\n",
      "epoch: 18 step: 764 loss: 0.6931471824645996\n",
      "epoch: 18 step: 765 loss: 0.6931471824645996\n",
      "epoch: 18 step: 766 loss: 0.6931471824645996\n",
      "epoch: 18 step: 767 loss: 0.6931471824645996\n",
      "epoch: 18 step: 768 loss: 0.6931471824645996\n",
      "epoch: 18 step: 769 loss: 0.6931471824645996\n",
      "epoch: 18 step: 770 loss: 0.6931471824645996\n",
      "epoch: 18 step: 771 loss: 0.6931471824645996\n",
      "epoch: 18 step: 772 loss: 0.6931471824645996\n",
      "epoch: 18 step: 773 loss: 0.6931471824645996\n",
      "epoch: 18 step: 774 loss: 0.6931471824645996\n",
      "epoch: 18 step: 775 loss: 0.6931471824645996\n",
      "epoch: 18 step: 776 loss: 0.6931471824645996\n",
      "epoch: 18 step: 777 loss: 0.6931471824645996\n",
      "epoch: 18 step: 778 loss: 0.6931471824645996\n",
      "epoch: 18 step: 779 loss: 0.6931471824645996\n",
      "epoch: 18 step: 780 loss: 0.6931471824645996\n",
      "epoch: 18 step: 781 loss: 0.6931471824645996\n",
      "epoch: 19 step: 1 loss: 0.6931471824645996\n",
      "epoch: 19 step: 2 loss: 0.6931471824645996\n",
      "epoch: 19 step: 3 loss: 0.6931471824645996\n",
      "epoch: 19 step: 4 loss: 0.6931471824645996\n",
      "epoch: 19 step: 5 loss: 0.6931471824645996\n",
      "epoch: 19 step: 6 loss: 0.6931471824645996\n",
      "epoch: 19 step: 7 loss: 0.6931471824645996\n",
      "epoch: 19 step: 8 loss: 0.6931471824645996\n",
      "epoch: 19 step: 9 loss: 0.6931471824645996\n",
      "epoch: 19 step: 10 loss: 0.6931471824645996\n",
      "epoch: 19 step: 11 loss: 0.6931471824645996\n",
      "epoch: 19 step: 12 loss: 0.6931471824645996\n",
      "epoch: 19 step: 13 loss: 0.6931471824645996\n",
      "epoch: 19 step: 14 loss: 0.6931471824645996\n",
      "epoch: 19 step: 15 loss: 0.6931471824645996\n",
      "epoch: 19 step: 16 loss: 0.6931471824645996\n",
      "epoch: 19 step: 17 loss: 0.6931471824645996\n",
      "epoch: 19 step: 18 loss: 0.6931471824645996\n",
      "epoch: 19 step: 19 loss: 0.6931471824645996\n",
      "epoch: 19 step: 20 loss: 0.6931471824645996\n",
      "epoch: 19 step: 21 loss: 0.6931471824645996\n",
      "epoch: 19 step: 22 loss: 0.6931471824645996\n",
      "epoch: 19 step: 23 loss: 0.6931471824645996\n",
      "epoch: 19 step: 24 loss: 0.6931471824645996\n",
      "epoch: 19 step: 25 loss: 0.6931471824645996\n",
      "epoch: 19 step: 26 loss: 0.6931471824645996\n",
      "epoch: 19 step: 27 loss: 0.6931471824645996\n",
      "epoch: 19 step: 28 loss: 0.6931471824645996\n",
      "epoch: 19 step: 29 loss: 0.6931471824645996\n",
      "epoch: 19 step: 30 loss: 0.6931471824645996\n",
      "epoch: 19 step: 31 loss: 0.6931471824645996\n",
      "epoch: 19 step: 32 loss: 0.6931471824645996\n",
      "epoch: 19 step: 33 loss: 0.6931471824645996\n",
      "epoch: 19 step: 34 loss: 0.6931471824645996\n",
      "epoch: 19 step: 35 loss: 0.6931471824645996\n",
      "epoch: 19 step: 36 loss: 0.6931471824645996\n",
      "epoch: 19 step: 37 loss: 0.6931471824645996\n",
      "epoch: 19 step: 38 loss: 0.6931471824645996\n",
      "epoch: 19 step: 39 loss: 0.6931471824645996\n",
      "epoch: 19 step: 40 loss: 0.6931471824645996\n",
      "epoch: 19 step: 41 loss: 0.6931471824645996\n",
      "epoch: 19 step: 42 loss: 0.6931471824645996\n",
      "epoch: 19 step: 43 loss: 0.6931471824645996\n",
      "epoch: 19 step: 44 loss: 0.6931471824645996\n",
      "epoch: 19 step: 45 loss: 0.6931471824645996\n",
      "epoch: 19 step: 46 loss: 0.6931471824645996\n",
      "epoch: 19 step: 47 loss: 0.6931471824645996\n",
      "epoch: 19 step: 48 loss: 0.6931471824645996\n",
      "epoch: 19 step: 49 loss: 0.6931471824645996\n",
      "epoch: 19 step: 50 loss: 0.6931471824645996\n",
      "epoch: 19 step: 51 loss: 0.6931471824645996\n",
      "epoch: 19 step: 52 loss: 0.6931471824645996\n",
      "epoch: 19 step: 53 loss: 0.6931471824645996\n",
      "epoch: 19 step: 54 loss: 0.6931471824645996\n",
      "epoch: 19 step: 55 loss: 0.6931471824645996\n",
      "epoch: 19 step: 56 loss: 0.6931471824645996\n",
      "epoch: 19 step: 57 loss: 0.6931471824645996\n",
      "epoch: 19 step: 58 loss: 0.6931471824645996\n",
      "epoch: 19 step: 59 loss: 0.6931471824645996\n",
      "epoch: 19 step: 60 loss: 0.6931471824645996\n",
      "epoch: 19 step: 61 loss: 0.6931471824645996\n",
      "epoch: 19 step: 62 loss: 0.6931471824645996\n",
      "epoch: 19 step: 63 loss: 0.6931471824645996\n",
      "epoch: 19 step: 64 loss: 0.6931471824645996\n",
      "epoch: 19 step: 65 loss: 0.6931471824645996\n",
      "epoch: 19 step: 66 loss: 0.6931471824645996\n",
      "epoch: 19 step: 67 loss: 0.6931471824645996\n",
      "epoch: 19 step: 68 loss: 0.6931471824645996\n",
      "epoch: 19 step: 69 loss: 0.6931471824645996\n",
      "epoch: 19 step: 70 loss: 0.6931471824645996\n",
      "epoch: 19 step: 71 loss: 0.6931471824645996\n",
      "epoch: 19 step: 72 loss: 0.6931471824645996\n",
      "epoch: 19 step: 73 loss: 0.6931471824645996\n",
      "epoch: 19 step: 74 loss: 0.6931471824645996\n",
      "epoch: 19 step: 75 loss: 0.6931471824645996\n",
      "epoch: 19 step: 76 loss: 0.6931471824645996\n",
      "epoch: 19 step: 77 loss: 0.6931471824645996\n",
      "epoch: 19 step: 78 loss: 0.6931471824645996\n",
      "epoch: 19 step: 79 loss: 0.6931471824645996\n",
      "epoch: 19 step: 80 loss: 0.6931471824645996\n",
      "epoch: 19 step: 81 loss: 0.6931471824645996\n",
      "epoch: 19 step: 82 loss: 0.6931471824645996\n",
      "epoch: 19 step: 83 loss: 0.6931471824645996\n",
      "epoch: 19 step: 84 loss: 0.6931471824645996\n",
      "epoch: 19 step: 85 loss: 0.6931471824645996\n",
      "epoch: 19 step: 86 loss: 0.6931471824645996\n",
      "epoch: 19 step: 87 loss: 0.6931471824645996\n",
      "epoch: 19 step: 88 loss: 0.6931471824645996\n",
      "epoch: 19 step: 89 loss: 0.6931471824645996\n",
      "epoch: 19 step: 90 loss: 0.6931471824645996\n",
      "epoch: 19 step: 91 loss: 0.6931471824645996\n",
      "epoch: 19 step: 92 loss: 0.6931471824645996\n",
      "epoch: 19 step: 93 loss: 0.6931471824645996\n",
      "epoch: 19 step: 94 loss: 0.6931471824645996\n",
      "epoch: 19 step: 95 loss: 0.6931471824645996\n",
      "epoch: 19 step: 96 loss: 0.6931471824645996\n",
      "epoch: 19 step: 97 loss: 0.6931471824645996\n",
      "epoch: 19 step: 98 loss: 0.6931471824645996\n",
      "epoch: 19 step: 99 loss: 0.6931471824645996\n",
      "epoch: 19 step: 100 loss: 0.6931471824645996\n",
      "epoch: 19 step: 101 loss: 0.6931471824645996\n",
      "epoch: 19 step: 102 loss: 0.6931471824645996\n",
      "epoch: 19 step: 103 loss: 0.6931471824645996\n",
      "epoch: 19 step: 104 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 105 loss: 0.6931471824645996\n",
      "epoch: 19 step: 106 loss: 0.6931471824645996\n",
      "epoch: 19 step: 107 loss: 0.6931471824645996\n",
      "epoch: 19 step: 108 loss: 0.6931471824645996\n",
      "epoch: 19 step: 109 loss: 0.6931471824645996\n",
      "epoch: 19 step: 110 loss: 0.6931471824645996\n",
      "epoch: 19 step: 111 loss: 0.6931471824645996\n",
      "epoch: 19 step: 112 loss: 0.6931471824645996\n",
      "epoch: 19 step: 113 loss: 0.6931471824645996\n",
      "epoch: 19 step: 114 loss: 0.6931471824645996\n",
      "epoch: 19 step: 115 loss: 0.6931471824645996\n",
      "epoch: 19 step: 116 loss: 0.6931471824645996\n",
      "epoch: 19 step: 117 loss: 0.6931471824645996\n",
      "epoch: 19 step: 118 loss: 0.6931471824645996\n",
      "epoch: 19 step: 119 loss: 0.6931471824645996\n",
      "epoch: 19 step: 120 loss: 0.6931471824645996\n",
      "epoch: 19 step: 121 loss: 0.6931471824645996\n",
      "epoch: 19 step: 122 loss: 0.6931471824645996\n",
      "epoch: 19 step: 123 loss: 0.6931471824645996\n",
      "epoch: 19 step: 124 loss: 0.6931471824645996\n",
      "epoch: 19 step: 125 loss: 0.6931471824645996\n",
      "epoch: 19 step: 126 loss: 0.6931471824645996\n",
      "epoch: 19 step: 127 loss: 0.6931471824645996\n",
      "epoch: 19 step: 128 loss: 0.6931471824645996\n",
      "epoch: 19 step: 129 loss: 0.6931471824645996\n",
      "epoch: 19 step: 130 loss: 0.6931471824645996\n",
      "epoch: 19 step: 131 loss: 0.6931471824645996\n",
      "epoch: 19 step: 132 loss: 0.6931471824645996\n",
      "epoch: 19 step: 133 loss: 0.6931471824645996\n",
      "epoch: 19 step: 134 loss: 0.6931471824645996\n",
      "epoch: 19 step: 135 loss: 0.6931471824645996\n",
      "epoch: 19 step: 136 loss: 0.6931471824645996\n",
      "epoch: 19 step: 137 loss: 0.6931471824645996\n",
      "epoch: 19 step: 138 loss: 0.6931471824645996\n",
      "epoch: 19 step: 139 loss: 0.6931471824645996\n",
      "epoch: 19 step: 140 loss: 0.6931471824645996\n",
      "epoch: 19 step: 141 loss: 0.6931471824645996\n",
      "epoch: 19 step: 142 loss: 0.6931471824645996\n",
      "epoch: 19 step: 143 loss: 0.6931471824645996\n",
      "epoch: 19 step: 144 loss: 0.6931471824645996\n",
      "epoch: 19 step: 145 loss: 0.6931471824645996\n",
      "epoch: 19 step: 146 loss: 0.6931471824645996\n",
      "epoch: 19 step: 147 loss: 0.6931471824645996\n",
      "epoch: 19 step: 148 loss: 0.6931471824645996\n",
      "epoch: 19 step: 149 loss: 0.6931471824645996\n",
      "epoch: 19 step: 150 loss: 0.6931471824645996\n",
      "epoch: 19 step: 151 loss: 0.6931471824645996\n",
      "epoch: 19 step: 152 loss: 0.6931471824645996\n",
      "epoch: 19 step: 153 loss: 0.6931471824645996\n",
      "epoch: 19 step: 154 loss: 0.6931471824645996\n",
      "epoch: 19 step: 155 loss: 0.6931471824645996\n",
      "epoch: 19 step: 156 loss: 0.6931471824645996\n",
      "epoch: 19 step: 157 loss: 0.6931471824645996\n",
      "epoch: 19 step: 158 loss: 0.6931471824645996\n",
      "epoch: 19 step: 159 loss: 0.6931471824645996\n",
      "epoch: 19 step: 160 loss: 0.6931471824645996\n",
      "epoch: 19 step: 161 loss: 0.6931471824645996\n",
      "epoch: 19 step: 162 loss: 0.6931471824645996\n",
      "epoch: 19 step: 163 loss: 0.6931471824645996\n",
      "epoch: 19 step: 164 loss: 0.6931471824645996\n",
      "epoch: 19 step: 165 loss: 0.6931471824645996\n",
      "epoch: 19 step: 166 loss: 0.6931471824645996\n",
      "epoch: 19 step: 167 loss: 0.6931471824645996\n",
      "epoch: 19 step: 168 loss: 0.6931471824645996\n",
      "epoch: 19 step: 169 loss: 0.6931471824645996\n",
      "epoch: 19 step: 170 loss: 0.6931471824645996\n",
      "epoch: 19 step: 171 loss: 0.6931471824645996\n",
      "epoch: 19 step: 172 loss: 0.6931471824645996\n",
      "epoch: 19 step: 173 loss: 0.6931471824645996\n",
      "epoch: 19 step: 174 loss: 0.6931471824645996\n",
      "epoch: 19 step: 175 loss: 0.6931471824645996\n",
      "epoch: 19 step: 176 loss: 0.6931471824645996\n",
      "epoch: 19 step: 177 loss: 0.6931471824645996\n",
      "epoch: 19 step: 178 loss: 0.6931471824645996\n",
      "epoch: 19 step: 179 loss: 0.6931471824645996\n",
      "epoch: 19 step: 180 loss: 0.6931471824645996\n",
      "epoch: 19 step: 181 loss: 0.6931471824645996\n",
      "epoch: 19 step: 182 loss: 0.6931471824645996\n",
      "epoch: 19 step: 183 loss: 0.6931471824645996\n",
      "epoch: 19 step: 184 loss: 0.6931471824645996\n",
      "epoch: 19 step: 185 loss: 0.6931471824645996\n",
      "epoch: 19 step: 186 loss: 0.6931471824645996\n",
      "epoch: 19 step: 187 loss: 0.6931471824645996\n",
      "epoch: 19 step: 188 loss: 0.6931471824645996\n",
      "epoch: 19 step: 189 loss: 0.6931471824645996\n",
      "epoch: 19 step: 190 loss: 0.6931471824645996\n",
      "epoch: 19 step: 191 loss: 0.6931471824645996\n",
      "epoch: 19 step: 192 loss: 0.6931471824645996\n",
      "epoch: 19 step: 193 loss: 0.6931471824645996\n",
      "epoch: 19 step: 194 loss: 0.6931471824645996\n",
      "epoch: 19 step: 195 loss: 0.6931471824645996\n",
      "epoch: 19 step: 196 loss: 0.6931471824645996\n",
      "epoch: 19 step: 197 loss: 0.6931471824645996\n",
      "epoch: 19 step: 198 loss: 0.6931471824645996\n",
      "epoch: 19 step: 199 loss: 0.6931471824645996\n",
      "epoch: 19 step: 200 loss: 0.6931471824645996\n",
      "epoch: 19 step: 201 loss: 0.6931471824645996\n",
      "epoch: 19 step: 202 loss: 0.6931471824645996\n",
      "epoch: 19 step: 203 loss: 0.6931471824645996\n",
      "epoch: 19 step: 204 loss: 0.6931471824645996\n",
      "epoch: 19 step: 205 loss: 0.6931471824645996\n",
      "epoch: 19 step: 206 loss: 0.6931471824645996\n",
      "epoch: 19 step: 207 loss: 0.6931471824645996\n",
      "epoch: 19 step: 208 loss: 0.6931471824645996\n",
      "epoch: 19 step: 209 loss: 0.6931471824645996\n",
      "epoch: 19 step: 210 loss: 0.6931471824645996\n",
      "epoch: 19 step: 211 loss: 0.6931471824645996\n",
      "epoch: 19 step: 212 loss: 0.6931471824645996\n",
      "epoch: 19 step: 213 loss: 0.6931471824645996\n",
      "epoch: 19 step: 214 loss: 0.6931471824645996\n",
      "epoch: 19 step: 215 loss: 0.6931471824645996\n",
      "epoch: 19 step: 216 loss: 0.6931471824645996\n",
      "epoch: 19 step: 217 loss: 0.6931471824645996\n",
      "epoch: 19 step: 218 loss: 0.6931471824645996\n",
      "epoch: 19 step: 219 loss: 0.6931471824645996\n",
      "epoch: 19 step: 220 loss: 0.6931471824645996\n",
      "epoch: 19 step: 221 loss: 0.6931471824645996\n",
      "epoch: 19 step: 222 loss: 0.6931471824645996\n",
      "epoch: 19 step: 223 loss: 0.6931471824645996\n",
      "epoch: 19 step: 224 loss: 0.6931471824645996\n",
      "epoch: 19 step: 225 loss: 0.6931471824645996\n",
      "epoch: 19 step: 226 loss: 0.6931471824645996\n",
      "epoch: 19 step: 227 loss: 0.6931471824645996\n",
      "epoch: 19 step: 228 loss: 0.6931471824645996\n",
      "epoch: 19 step: 229 loss: 0.6931471824645996\n",
      "epoch: 19 step: 230 loss: 0.6931471824645996\n",
      "epoch: 19 step: 231 loss: 0.6931471824645996\n",
      "epoch: 19 step: 232 loss: 0.6931471824645996\n",
      "epoch: 19 step: 233 loss: 0.6931471824645996\n",
      "epoch: 19 step: 234 loss: 0.6931471824645996\n",
      "epoch: 19 step: 235 loss: 0.6931471824645996\n",
      "epoch: 19 step: 236 loss: 0.6931471824645996\n",
      "epoch: 19 step: 237 loss: 0.6931471824645996\n",
      "epoch: 19 step: 238 loss: 0.6931471824645996\n",
      "epoch: 19 step: 239 loss: 0.6931471824645996\n",
      "epoch: 19 step: 240 loss: 0.6931471824645996\n",
      "epoch: 19 step: 241 loss: 0.6931471824645996\n",
      "epoch: 19 step: 242 loss: 0.6931471824645996\n",
      "epoch: 19 step: 243 loss: 0.6931471824645996\n",
      "epoch: 19 step: 244 loss: 0.6931471824645996\n",
      "epoch: 19 step: 245 loss: 0.6931471824645996\n",
      "epoch: 19 step: 246 loss: 0.6931471824645996\n",
      "epoch: 19 step: 247 loss: 0.6931471824645996\n",
      "epoch: 19 step: 248 loss: 0.6931471824645996\n",
      "epoch: 19 step: 249 loss: 0.6931471824645996\n",
      "epoch: 19 step: 250 loss: 0.6931471824645996\n",
      "epoch: 19 step: 251 loss: 0.6931471824645996\n",
      "epoch: 19 step: 252 loss: 0.6931471824645996\n",
      "epoch: 19 step: 253 loss: 0.6931471824645996\n",
      "epoch: 19 step: 254 loss: 0.6931471824645996\n",
      "epoch: 19 step: 255 loss: 0.6931471824645996\n",
      "epoch: 19 step: 256 loss: 0.6931471824645996\n",
      "epoch: 19 step: 257 loss: 0.6931471824645996\n",
      "epoch: 19 step: 258 loss: 0.6931471824645996\n",
      "epoch: 19 step: 259 loss: 0.6931471824645996\n",
      "epoch: 19 step: 260 loss: 0.6931471824645996\n",
      "epoch: 19 step: 261 loss: 0.6931471824645996\n",
      "epoch: 19 step: 262 loss: 0.6931471824645996\n",
      "epoch: 19 step: 263 loss: 0.6931471824645996\n",
      "epoch: 19 step: 264 loss: 0.6931471824645996\n",
      "epoch: 19 step: 265 loss: 0.6931471824645996\n",
      "epoch: 19 step: 266 loss: 0.6931471824645996\n",
      "epoch: 19 step: 267 loss: 0.6931471824645996\n",
      "epoch: 19 step: 268 loss: 0.6931471824645996\n",
      "epoch: 19 step: 269 loss: 0.6931471824645996\n",
      "epoch: 19 step: 270 loss: 0.6931471824645996\n",
      "epoch: 19 step: 271 loss: 0.6931471824645996\n",
      "epoch: 19 step: 272 loss: 0.6931471824645996\n",
      "epoch: 19 step: 273 loss: 0.6931471824645996\n",
      "epoch: 19 step: 274 loss: 0.6931471824645996\n",
      "epoch: 19 step: 275 loss: 0.6931471824645996\n",
      "epoch: 19 step: 276 loss: 0.6931471824645996\n",
      "epoch: 19 step: 277 loss: 0.6931471824645996\n",
      "epoch: 19 step: 278 loss: 0.6931471824645996\n",
      "epoch: 19 step: 279 loss: 0.6931471824645996\n",
      "epoch: 19 step: 280 loss: 0.6931471824645996\n",
      "epoch: 19 step: 281 loss: 0.6931471824645996\n",
      "epoch: 19 step: 282 loss: 0.6931471824645996\n",
      "epoch: 19 step: 283 loss: 0.6931471824645996\n",
      "epoch: 19 step: 284 loss: 0.6931471824645996\n",
      "epoch: 19 step: 285 loss: 0.6931471824645996\n",
      "epoch: 19 step: 286 loss: 0.6931471824645996\n",
      "epoch: 19 step: 287 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 288 loss: 0.6931471824645996\n",
      "epoch: 19 step: 289 loss: 0.6931471824645996\n",
      "epoch: 19 step: 290 loss: 0.6931471824645996\n",
      "epoch: 19 step: 291 loss: 0.6931471824645996\n",
      "epoch: 19 step: 292 loss: 0.6931471824645996\n",
      "epoch: 19 step: 293 loss: 0.6931471824645996\n",
      "epoch: 19 step: 294 loss: 0.6931471824645996\n",
      "epoch: 19 step: 295 loss: 0.6931471824645996\n",
      "epoch: 19 step: 296 loss: 0.6931471824645996\n",
      "epoch: 19 step: 297 loss: 0.6931471824645996\n",
      "epoch: 19 step: 298 loss: 0.6931471824645996\n",
      "epoch: 19 step: 299 loss: 0.6931471824645996\n",
      "epoch: 19 step: 300 loss: 0.6931471824645996\n",
      "epoch: 19 step: 301 loss: 0.6931471824645996\n",
      "epoch: 19 step: 302 loss: 0.6931471824645996\n",
      "epoch: 19 step: 303 loss: 0.6931471824645996\n",
      "epoch: 19 step: 304 loss: 0.6931471824645996\n",
      "epoch: 19 step: 305 loss: 0.6931471824645996\n",
      "epoch: 19 step: 306 loss: 0.6931471824645996\n",
      "epoch: 19 step: 307 loss: 0.6931471824645996\n",
      "epoch: 19 step: 308 loss: 0.6931471824645996\n",
      "epoch: 19 step: 309 loss: 0.6931471824645996\n",
      "epoch: 19 step: 310 loss: 0.6931471824645996\n",
      "epoch: 19 step: 311 loss: 0.6931471824645996\n",
      "epoch: 19 step: 312 loss: 0.6931471824645996\n",
      "epoch: 19 step: 313 loss: 0.6931471824645996\n",
      "epoch: 19 step: 314 loss: 0.6931471824645996\n",
      "epoch: 19 step: 315 loss: 0.6931471824645996\n",
      "epoch: 19 step: 316 loss: 0.6931471824645996\n",
      "epoch: 19 step: 317 loss: 0.6931471824645996\n",
      "epoch: 19 step: 318 loss: 0.6931471824645996\n",
      "epoch: 19 step: 319 loss: 0.6931471824645996\n",
      "epoch: 19 step: 320 loss: 0.6931471824645996\n",
      "epoch: 19 step: 321 loss: 0.6931471824645996\n",
      "epoch: 19 step: 322 loss: 0.6931471824645996\n",
      "epoch: 19 step: 323 loss: 0.6931471824645996\n",
      "epoch: 19 step: 324 loss: 0.6931471824645996\n",
      "epoch: 19 step: 325 loss: 0.6931471824645996\n",
      "epoch: 19 step: 326 loss: 0.6931471824645996\n",
      "epoch: 19 step: 327 loss: 0.6931471824645996\n",
      "epoch: 19 step: 328 loss: 0.6931471824645996\n",
      "epoch: 19 step: 329 loss: 0.6931471824645996\n",
      "epoch: 19 step: 330 loss: 0.6931471824645996\n",
      "epoch: 19 step: 331 loss: 0.6931471824645996\n",
      "epoch: 19 step: 332 loss: 0.6931471824645996\n",
      "epoch: 19 step: 333 loss: 0.6931471824645996\n",
      "epoch: 19 step: 334 loss: 0.6931471824645996\n",
      "epoch: 19 step: 335 loss: 0.6931471824645996\n",
      "epoch: 19 step: 336 loss: 0.6931471824645996\n",
      "epoch: 19 step: 337 loss: 0.6931471824645996\n",
      "epoch: 19 step: 338 loss: 0.6931471824645996\n",
      "epoch: 19 step: 339 loss: 0.6931471824645996\n",
      "epoch: 19 step: 340 loss: 0.6931471824645996\n",
      "epoch: 19 step: 341 loss: 0.6931471824645996\n",
      "epoch: 19 step: 342 loss: 0.6931471824645996\n",
      "epoch: 19 step: 343 loss: 0.6931471824645996\n",
      "epoch: 19 step: 344 loss: 0.6931471824645996\n",
      "epoch: 19 step: 345 loss: 0.6931471824645996\n",
      "epoch: 19 step: 346 loss: 0.6931471824645996\n",
      "epoch: 19 step: 347 loss: 0.6931471824645996\n",
      "epoch: 19 step: 348 loss: 0.6931471824645996\n",
      "epoch: 19 step: 349 loss: 0.6931471824645996\n",
      "epoch: 19 step: 350 loss: 0.6931471824645996\n",
      "epoch: 19 step: 351 loss: 0.6931471824645996\n",
      "epoch: 19 step: 352 loss: 0.6931471824645996\n",
      "epoch: 19 step: 353 loss: 0.6931471824645996\n",
      "epoch: 19 step: 354 loss: 0.6931471824645996\n",
      "epoch: 19 step: 355 loss: 0.6931471824645996\n",
      "epoch: 19 step: 356 loss: 0.6931471824645996\n",
      "epoch: 19 step: 357 loss: 0.6931471824645996\n",
      "epoch: 19 step: 358 loss: 0.6931471824645996\n",
      "epoch: 19 step: 359 loss: 0.6931471824645996\n",
      "epoch: 19 step: 360 loss: 0.6931471824645996\n",
      "epoch: 19 step: 361 loss: 0.6931471824645996\n",
      "epoch: 19 step: 362 loss: 0.6931471824645996\n",
      "epoch: 19 step: 363 loss: 0.6931471824645996\n",
      "epoch: 19 step: 364 loss: 0.6931471824645996\n",
      "epoch: 19 step: 365 loss: 0.6931471824645996\n",
      "epoch: 19 step: 366 loss: 0.6931471824645996\n",
      "epoch: 19 step: 367 loss: 0.6931471824645996\n",
      "epoch: 19 step: 368 loss: 0.6931471824645996\n",
      "epoch: 19 step: 369 loss: 0.6931471824645996\n",
      "epoch: 19 step: 370 loss: 0.6931471824645996\n",
      "epoch: 19 step: 371 loss: 0.6931471824645996\n",
      "epoch: 19 step: 372 loss: 0.6931471824645996\n",
      "epoch: 19 step: 373 loss: 0.6931471824645996\n",
      "epoch: 19 step: 374 loss: 0.6931471824645996\n",
      "epoch: 19 step: 375 loss: 0.6931471824645996\n",
      "epoch: 19 step: 376 loss: 0.6931471824645996\n",
      "epoch: 19 step: 377 loss: 0.6931471824645996\n",
      "epoch: 19 step: 378 loss: 0.6931471824645996\n",
      "epoch: 19 step: 379 loss: 0.6931471824645996\n",
      "epoch: 19 step: 380 loss: 0.6931471824645996\n",
      "epoch: 19 step: 381 loss: 0.6931471824645996\n",
      "epoch: 19 step: 382 loss: 0.6931471824645996\n",
      "epoch: 19 step: 383 loss: 0.6931471824645996\n",
      "epoch: 19 step: 384 loss: 0.6931471824645996\n",
      "epoch: 19 step: 385 loss: 0.6931471824645996\n",
      "epoch: 19 step: 386 loss: 0.6931471824645996\n",
      "epoch: 19 step: 387 loss: 0.6931471824645996\n",
      "epoch: 19 step: 388 loss: 0.6931471824645996\n",
      "epoch: 19 step: 389 loss: 0.6931471824645996\n",
      "epoch: 19 step: 390 loss: 0.6931471824645996\n",
      "epoch: 19 step: 391 loss: 0.6931471824645996\n",
      "epoch: 19 step: 392 loss: 0.6931471824645996\n",
      "epoch: 19 step: 393 loss: 0.6931471824645996\n",
      "epoch: 19 step: 394 loss: 0.6931471824645996\n",
      "epoch: 19 step: 395 loss: 0.6931471824645996\n",
      "epoch: 19 step: 396 loss: 0.6931471824645996\n",
      "epoch: 19 step: 397 loss: 0.6931471824645996\n",
      "epoch: 19 step: 398 loss: 0.6931471824645996\n",
      "epoch: 19 step: 399 loss: 0.6931471824645996\n",
      "epoch: 19 step: 400 loss: 0.6931471824645996\n",
      "epoch: 19 step: 401 loss: 0.6931471824645996\n",
      "epoch: 19 step: 402 loss: 0.6931471824645996\n",
      "epoch: 19 step: 403 loss: 0.6931471824645996\n",
      "epoch: 19 step: 404 loss: 0.6931471824645996\n",
      "epoch: 19 step: 405 loss: 0.6931471824645996\n",
      "epoch: 19 step: 406 loss: 0.6931471824645996\n",
      "epoch: 19 step: 407 loss: 0.6931471824645996\n",
      "epoch: 19 step: 408 loss: 0.6931471824645996\n",
      "epoch: 19 step: 409 loss: 0.6931471824645996\n",
      "epoch: 19 step: 410 loss: 0.6931471824645996\n",
      "epoch: 19 step: 411 loss: 0.6931471824645996\n",
      "epoch: 19 step: 412 loss: 0.6931471824645996\n",
      "epoch: 19 step: 413 loss: 0.6931471824645996\n",
      "epoch: 19 step: 414 loss: 0.6931471824645996\n",
      "epoch: 19 step: 415 loss: 0.6931471824645996\n",
      "epoch: 19 step: 416 loss: 0.6931471824645996\n",
      "epoch: 19 step: 417 loss: 0.6931471824645996\n",
      "epoch: 19 step: 418 loss: 0.6931471824645996\n",
      "epoch: 19 step: 419 loss: 0.6931471824645996\n",
      "epoch: 19 step: 420 loss: 0.6931471824645996\n",
      "epoch: 19 step: 421 loss: 0.6931471824645996\n",
      "epoch: 19 step: 422 loss: 0.6931471824645996\n",
      "epoch: 19 step: 423 loss: 0.6931471824645996\n",
      "epoch: 19 step: 424 loss: 0.6931471824645996\n",
      "epoch: 19 step: 425 loss: 0.6931471824645996\n",
      "epoch: 19 step: 426 loss: 0.6931471824645996\n",
      "epoch: 19 step: 427 loss: 0.6931471824645996\n",
      "epoch: 19 step: 428 loss: 0.6931471824645996\n",
      "epoch: 19 step: 429 loss: 0.6931471824645996\n",
      "epoch: 19 step: 430 loss: 0.6931471824645996\n",
      "epoch: 19 step: 431 loss: 0.6931471824645996\n",
      "epoch: 19 step: 432 loss: 0.6931471824645996\n",
      "epoch: 19 step: 433 loss: 0.6931471824645996\n",
      "epoch: 19 step: 434 loss: 0.6931471824645996\n",
      "epoch: 19 step: 435 loss: 0.6931471824645996\n",
      "epoch: 19 step: 436 loss: 0.6931471824645996\n",
      "epoch: 19 step: 437 loss: 0.6931471824645996\n",
      "epoch: 19 step: 438 loss: 0.6931471824645996\n",
      "epoch: 19 step: 439 loss: 0.6931471824645996\n",
      "epoch: 19 step: 440 loss: 0.6931471824645996\n",
      "epoch: 19 step: 441 loss: 0.6931471824645996\n",
      "epoch: 19 step: 442 loss: 0.6931471824645996\n",
      "epoch: 19 step: 443 loss: 0.6931471824645996\n",
      "epoch: 19 step: 444 loss: 0.6931471824645996\n",
      "epoch: 19 step: 445 loss: 0.6931471824645996\n",
      "epoch: 19 step: 446 loss: 0.6931471824645996\n",
      "epoch: 19 step: 447 loss: 0.6931471824645996\n",
      "epoch: 19 step: 448 loss: 0.6931471824645996\n",
      "epoch: 19 step: 449 loss: 0.6931471824645996\n",
      "epoch: 19 step: 450 loss: 0.6931471824645996\n",
      "epoch: 19 step: 451 loss: 0.6931471824645996\n",
      "epoch: 19 step: 452 loss: 0.6931471824645996\n",
      "epoch: 19 step: 453 loss: 0.6931471824645996\n",
      "epoch: 19 step: 454 loss: 0.6931471824645996\n",
      "epoch: 19 step: 455 loss: 0.6931471824645996\n",
      "epoch: 19 step: 456 loss: 0.6931471824645996\n",
      "epoch: 19 step: 457 loss: 0.6931471824645996\n",
      "epoch: 19 step: 458 loss: 0.6931471824645996\n",
      "epoch: 19 step: 459 loss: 0.6931471824645996\n",
      "epoch: 19 step: 460 loss: 0.6931471824645996\n",
      "epoch: 19 step: 461 loss: 0.6931471824645996\n",
      "epoch: 19 step: 462 loss: 0.6931471824645996\n",
      "epoch: 19 step: 463 loss: 0.6931471824645996\n",
      "epoch: 19 step: 464 loss: 0.6931471824645996\n",
      "epoch: 19 step: 465 loss: 0.6931471824645996\n",
      "epoch: 19 step: 466 loss: 0.6931471824645996\n",
      "epoch: 19 step: 467 loss: 0.6931471824645996\n",
      "epoch: 19 step: 468 loss: 0.6931471824645996\n",
      "epoch: 19 step: 469 loss: 0.6931471824645996\n",
      "epoch: 19 step: 470 loss: 0.6931471824645996\n",
      "epoch: 19 step: 471 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 472 loss: 0.6931471824645996\n",
      "epoch: 19 step: 473 loss: 0.6931471824645996\n",
      "epoch: 19 step: 474 loss: 0.6931471824645996\n",
      "epoch: 19 step: 475 loss: 0.6931471824645996\n",
      "epoch: 19 step: 476 loss: 0.6931471824645996\n",
      "epoch: 19 step: 477 loss: 0.6931471824645996\n",
      "epoch: 19 step: 478 loss: 0.6931471824645996\n",
      "epoch: 19 step: 479 loss: 0.6931471824645996\n",
      "epoch: 19 step: 480 loss: 0.6931471824645996\n",
      "epoch: 19 step: 481 loss: 0.6931471824645996\n",
      "epoch: 19 step: 482 loss: 0.6931471824645996\n",
      "epoch: 19 step: 483 loss: 0.6931471824645996\n",
      "epoch: 19 step: 484 loss: 0.6931471824645996\n",
      "epoch: 19 step: 485 loss: 0.6931471824645996\n",
      "epoch: 19 step: 486 loss: 0.6931471824645996\n",
      "epoch: 19 step: 487 loss: 0.6931471824645996\n",
      "epoch: 19 step: 488 loss: 0.6931471824645996\n",
      "epoch: 19 step: 489 loss: 0.6931471824645996\n",
      "epoch: 19 step: 490 loss: 0.6931471824645996\n",
      "epoch: 19 step: 491 loss: 0.6931471824645996\n",
      "epoch: 19 step: 492 loss: 0.6931471824645996\n",
      "epoch: 19 step: 493 loss: 0.6931471824645996\n",
      "epoch: 19 step: 494 loss: 0.6931471824645996\n",
      "epoch: 19 step: 495 loss: 0.6931471824645996\n",
      "epoch: 19 step: 496 loss: 0.6931471824645996\n",
      "epoch: 19 step: 497 loss: 0.6931471824645996\n",
      "epoch: 19 step: 498 loss: 0.6931471824645996\n",
      "epoch: 19 step: 499 loss: 0.6931471824645996\n",
      "epoch: 19 step: 500 loss: 0.6931471824645996\n",
      "epoch: 19 step: 501 loss: 0.6931471824645996\n",
      "epoch: 19 step: 502 loss: 0.6931471824645996\n",
      "epoch: 19 step: 503 loss: 0.6931471824645996\n",
      "epoch: 19 step: 504 loss: 0.6931471824645996\n",
      "epoch: 19 step: 505 loss: 0.6931471824645996\n",
      "epoch: 19 step: 506 loss: 0.6931471824645996\n",
      "epoch: 19 step: 507 loss: 0.6931471824645996\n",
      "epoch: 19 step: 508 loss: 0.6931471824645996\n",
      "epoch: 19 step: 509 loss: 0.6931471824645996\n",
      "epoch: 19 step: 510 loss: 0.6931471824645996\n",
      "epoch: 19 step: 511 loss: 0.6931471824645996\n",
      "epoch: 19 step: 512 loss: 0.6931471824645996\n",
      "epoch: 19 step: 513 loss: 0.6931471824645996\n",
      "epoch: 19 step: 514 loss: 0.6931471824645996\n",
      "epoch: 19 step: 515 loss: 0.6931471824645996\n",
      "epoch: 19 step: 516 loss: 0.6931471824645996\n",
      "epoch: 19 step: 517 loss: 0.6931471824645996\n",
      "epoch: 19 step: 518 loss: 0.6931471824645996\n",
      "epoch: 19 step: 519 loss: 0.6931471824645996\n",
      "epoch: 19 step: 520 loss: 0.6931471824645996\n",
      "epoch: 19 step: 521 loss: 0.6931471824645996\n",
      "epoch: 19 step: 522 loss: 0.6931471824645996\n",
      "epoch: 19 step: 523 loss: 0.6931471824645996\n",
      "epoch: 19 step: 524 loss: 0.6931471824645996\n",
      "epoch: 19 step: 525 loss: 0.6931471824645996\n",
      "epoch: 19 step: 526 loss: 0.6931471824645996\n",
      "epoch: 19 step: 527 loss: 0.6931471824645996\n",
      "epoch: 19 step: 528 loss: 0.6931471824645996\n",
      "epoch: 19 step: 529 loss: 0.6931471824645996\n",
      "epoch: 19 step: 530 loss: 0.6931471824645996\n",
      "epoch: 19 step: 531 loss: 0.6931471824645996\n",
      "epoch: 19 step: 532 loss: 0.6931471824645996\n",
      "epoch: 19 step: 533 loss: 0.6931471824645996\n",
      "epoch: 19 step: 534 loss: 0.6931471824645996\n",
      "epoch: 19 step: 535 loss: 0.6931471824645996\n",
      "epoch: 19 step: 536 loss: 0.6931471824645996\n",
      "epoch: 19 step: 537 loss: 0.6931471824645996\n",
      "epoch: 19 step: 538 loss: 0.6931471824645996\n",
      "epoch: 19 step: 539 loss: 0.6931471824645996\n",
      "epoch: 19 step: 540 loss: 0.6931471824645996\n",
      "epoch: 19 step: 541 loss: 0.6931471824645996\n",
      "epoch: 19 step: 542 loss: 0.6931471824645996\n",
      "epoch: 19 step: 543 loss: 0.6931471824645996\n",
      "epoch: 19 step: 544 loss: 0.6931471824645996\n",
      "epoch: 19 step: 545 loss: 0.6931471824645996\n",
      "epoch: 19 step: 546 loss: 0.6931471824645996\n",
      "epoch: 19 step: 547 loss: 0.6931471824645996\n",
      "epoch: 19 step: 548 loss: 0.6931471824645996\n",
      "epoch: 19 step: 549 loss: 0.6931471824645996\n",
      "epoch: 19 step: 550 loss: 0.6931471824645996\n",
      "epoch: 19 step: 551 loss: 0.6931471824645996\n",
      "epoch: 19 step: 552 loss: 0.6931471824645996\n",
      "epoch: 19 step: 553 loss: 0.6931471824645996\n",
      "epoch: 19 step: 554 loss: 0.6931471824645996\n",
      "epoch: 19 step: 555 loss: 0.6931471824645996\n",
      "epoch: 19 step: 556 loss: 0.6931471824645996\n",
      "epoch: 19 step: 557 loss: 0.6931471824645996\n",
      "epoch: 19 step: 558 loss: 0.6931471824645996\n",
      "epoch: 19 step: 559 loss: 0.6931471824645996\n",
      "epoch: 19 step: 560 loss: 0.6931471824645996\n",
      "epoch: 19 step: 561 loss: 0.6931471824645996\n",
      "epoch: 19 step: 562 loss: 0.6931471824645996\n",
      "epoch: 19 step: 563 loss: 0.6931471824645996\n",
      "epoch: 19 step: 564 loss: 0.6931471824645996\n",
      "epoch: 19 step: 565 loss: 0.6931471824645996\n",
      "epoch: 19 step: 566 loss: 0.6931471824645996\n",
      "epoch: 19 step: 567 loss: 0.6931471824645996\n",
      "epoch: 19 step: 568 loss: 0.6931471824645996\n",
      "epoch: 19 step: 569 loss: 0.6931471824645996\n",
      "epoch: 19 step: 570 loss: 0.6931471824645996\n",
      "epoch: 19 step: 571 loss: 0.6931471824645996\n",
      "epoch: 19 step: 572 loss: 0.6931471824645996\n",
      "epoch: 19 step: 573 loss: 0.6931471824645996\n",
      "epoch: 19 step: 574 loss: 0.6931471824645996\n",
      "epoch: 19 step: 575 loss: 0.6931471824645996\n",
      "epoch: 19 step: 576 loss: 0.6931471824645996\n",
      "epoch: 19 step: 577 loss: 0.6931471824645996\n",
      "epoch: 19 step: 578 loss: 0.6931471824645996\n",
      "epoch: 19 step: 579 loss: 0.6931471824645996\n",
      "epoch: 19 step: 580 loss: 0.6931471824645996\n",
      "epoch: 19 step: 581 loss: 0.6931471824645996\n",
      "epoch: 19 step: 582 loss: 0.6931471824645996\n",
      "epoch: 19 step: 583 loss: 0.6931471824645996\n",
      "epoch: 19 step: 584 loss: 0.6931471824645996\n",
      "epoch: 19 step: 585 loss: 0.6931471824645996\n",
      "epoch: 19 step: 586 loss: 0.6931471824645996\n",
      "epoch: 19 step: 587 loss: 0.6931471824645996\n",
      "epoch: 19 step: 588 loss: 0.6931471824645996\n",
      "epoch: 19 step: 589 loss: 0.6931471824645996\n",
      "epoch: 19 step: 590 loss: 0.6931471824645996\n",
      "epoch: 19 step: 591 loss: 0.6931471824645996\n",
      "epoch: 19 step: 592 loss: 0.6931471824645996\n",
      "epoch: 19 step: 593 loss: 0.6931471824645996\n",
      "epoch: 19 step: 594 loss: 0.6931471824645996\n",
      "epoch: 19 step: 595 loss: 0.6931471824645996\n",
      "epoch: 19 step: 596 loss: 0.6931471824645996\n",
      "epoch: 19 step: 597 loss: 0.6931471824645996\n",
      "epoch: 19 step: 598 loss: 0.6931471824645996\n",
      "epoch: 19 step: 599 loss: 0.6931471824645996\n",
      "epoch: 19 step: 600 loss: 0.6931471824645996\n",
      "epoch: 19 step: 601 loss: 0.6931471824645996\n",
      "epoch: 19 step: 602 loss: 0.6931471824645996\n",
      "epoch: 19 step: 603 loss: 0.6931471824645996\n",
      "epoch: 19 step: 604 loss: 0.6931471824645996\n",
      "epoch: 19 step: 605 loss: 0.6931471824645996\n",
      "epoch: 19 step: 606 loss: 0.6931471824645996\n",
      "epoch: 19 step: 607 loss: 0.6931471824645996\n",
      "epoch: 19 step: 608 loss: 0.6931471824645996\n",
      "epoch: 19 step: 609 loss: 0.6931471824645996\n",
      "epoch: 19 step: 610 loss: 0.6931471824645996\n",
      "epoch: 19 step: 611 loss: 0.6931471824645996\n",
      "epoch: 19 step: 612 loss: 0.6931471824645996\n",
      "epoch: 19 step: 613 loss: 0.6931471824645996\n",
      "epoch: 19 step: 614 loss: 0.6931471824645996\n",
      "epoch: 19 step: 615 loss: 0.6931471824645996\n",
      "epoch: 19 step: 616 loss: 0.6931471824645996\n",
      "epoch: 19 step: 617 loss: 0.6931471824645996\n",
      "epoch: 19 step: 618 loss: 0.6931471824645996\n",
      "epoch: 19 step: 619 loss: 0.6931471824645996\n",
      "epoch: 19 step: 620 loss: 0.6931471824645996\n",
      "epoch: 19 step: 621 loss: 0.6931471824645996\n",
      "epoch: 19 step: 622 loss: 0.6931471824645996\n",
      "epoch: 19 step: 623 loss: 0.6931471824645996\n",
      "epoch: 19 step: 624 loss: 0.6931471824645996\n",
      "epoch: 19 step: 625 loss: 0.6931471824645996\n",
      "epoch: 19 step: 626 loss: 0.6931471824645996\n",
      "epoch: 19 step: 627 loss: 0.6931471824645996\n",
      "epoch: 19 step: 628 loss: 0.6931471824645996\n",
      "epoch: 19 step: 629 loss: 0.6931471824645996\n",
      "epoch: 19 step: 630 loss: 0.6931471824645996\n",
      "epoch: 19 step: 631 loss: 0.6931471824645996\n",
      "epoch: 19 step: 632 loss: 0.6931471824645996\n",
      "epoch: 19 step: 633 loss: 0.6931471824645996\n",
      "epoch: 19 step: 634 loss: 0.6931471824645996\n",
      "epoch: 19 step: 635 loss: 0.6931471824645996\n",
      "epoch: 19 step: 636 loss: 0.6931471824645996\n",
      "epoch: 19 step: 637 loss: 0.6931471824645996\n",
      "epoch: 19 step: 638 loss: 0.6931471824645996\n",
      "epoch: 19 step: 639 loss: 0.6931471824645996\n",
      "epoch: 19 step: 640 loss: 0.6931471824645996\n",
      "epoch: 19 step: 641 loss: 0.6931471824645996\n",
      "epoch: 19 step: 642 loss: 0.6931471824645996\n",
      "epoch: 19 step: 643 loss: 0.6931471824645996\n",
      "epoch: 19 step: 644 loss: 0.6931471824645996\n",
      "epoch: 19 step: 645 loss: 0.6931471824645996\n",
      "epoch: 19 step: 646 loss: 0.6931471824645996\n",
      "epoch: 19 step: 647 loss: 0.6931471824645996\n",
      "epoch: 19 step: 648 loss: 0.6931471824645996\n",
      "epoch: 19 step: 649 loss: 0.6931471824645996\n",
      "epoch: 19 step: 650 loss: 0.6931471824645996\n",
      "epoch: 19 step: 651 loss: 0.6931471824645996\n",
      "epoch: 19 step: 652 loss: 0.6931471824645996\n",
      "epoch: 19 step: 653 loss: 0.6931471824645996\n",
      "epoch: 19 step: 654 loss: 0.6931471824645996\n",
      "epoch: 19 step: 655 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 656 loss: 0.6931471824645996\n",
      "epoch: 19 step: 657 loss: 0.6931471824645996\n",
      "epoch: 19 step: 658 loss: 0.6931471824645996\n",
      "epoch: 19 step: 659 loss: 0.6931471824645996\n",
      "epoch: 19 step: 660 loss: 0.6931471824645996\n",
      "epoch: 19 step: 661 loss: 0.6931471824645996\n",
      "epoch: 19 step: 662 loss: 0.6931471824645996\n",
      "epoch: 19 step: 663 loss: 0.6931471824645996\n",
      "epoch: 19 step: 664 loss: 0.6931471824645996\n",
      "epoch: 19 step: 665 loss: 0.6931471824645996\n",
      "epoch: 19 step: 666 loss: 0.6931471824645996\n",
      "epoch: 19 step: 667 loss: 0.6931471824645996\n",
      "epoch: 19 step: 668 loss: 0.6931471824645996\n",
      "epoch: 19 step: 669 loss: 0.6931471824645996\n",
      "epoch: 19 step: 670 loss: 0.6931471824645996\n",
      "epoch: 19 step: 671 loss: 0.6931471824645996\n",
      "epoch: 19 step: 672 loss: 0.6931471824645996\n",
      "epoch: 19 step: 673 loss: 0.6931471824645996\n",
      "epoch: 19 step: 674 loss: 0.6931471824645996\n",
      "epoch: 19 step: 675 loss: 0.6931471824645996\n",
      "epoch: 19 step: 676 loss: 0.6931471824645996\n",
      "epoch: 19 step: 677 loss: 0.6931471824645996\n",
      "epoch: 19 step: 678 loss: 0.6931471824645996\n",
      "epoch: 19 step: 679 loss: 0.6931471824645996\n",
      "epoch: 19 step: 680 loss: 0.6931471824645996\n",
      "epoch: 19 step: 681 loss: 0.6931471824645996\n",
      "epoch: 19 step: 682 loss: 0.6931471824645996\n",
      "epoch: 19 step: 683 loss: 0.6931471824645996\n",
      "epoch: 19 step: 684 loss: 0.6931471824645996\n",
      "epoch: 19 step: 685 loss: 0.6931471824645996\n",
      "epoch: 19 step: 686 loss: 0.6931471824645996\n",
      "epoch: 19 step: 687 loss: 0.6931471824645996\n",
      "epoch: 19 step: 688 loss: 0.6931471824645996\n",
      "epoch: 19 step: 689 loss: 0.6931471824645996\n",
      "epoch: 19 step: 690 loss: 0.6931471824645996\n",
      "epoch: 19 step: 691 loss: 0.6931471824645996\n",
      "epoch: 19 step: 692 loss: 0.6931471824645996\n",
      "epoch: 19 step: 693 loss: 0.6931471824645996\n",
      "epoch: 19 step: 694 loss: 0.6931471824645996\n",
      "epoch: 19 step: 695 loss: 0.6931471824645996\n",
      "epoch: 19 step: 696 loss: 0.6931471824645996\n",
      "epoch: 19 step: 697 loss: 0.6931471824645996\n",
      "epoch: 19 step: 698 loss: 0.6931471824645996\n",
      "epoch: 19 step: 699 loss: 0.6931471824645996\n",
      "epoch: 19 step: 700 loss: 0.6931471824645996\n",
      "epoch: 19 step: 701 loss: 0.6931471824645996\n",
      "epoch: 19 step: 702 loss: 0.6931471824645996\n",
      "epoch: 19 step: 703 loss: 0.6931471824645996\n",
      "epoch: 19 step: 704 loss: 0.6931471824645996\n",
      "epoch: 19 step: 705 loss: 0.6931471824645996\n",
      "epoch: 19 step: 706 loss: 0.6931471824645996\n",
      "epoch: 19 step: 707 loss: 0.6931471824645996\n",
      "epoch: 19 step: 708 loss: 0.6931471824645996\n",
      "epoch: 19 step: 709 loss: 0.6931471824645996\n",
      "epoch: 19 step: 710 loss: 0.6931471824645996\n",
      "epoch: 19 step: 711 loss: 0.6931471824645996\n",
      "epoch: 19 step: 712 loss: 0.6931471824645996\n",
      "epoch: 19 step: 713 loss: 0.6931471824645996\n",
      "epoch: 19 step: 714 loss: 0.6931471824645996\n",
      "epoch: 19 step: 715 loss: 0.6931471824645996\n",
      "epoch: 19 step: 716 loss: 0.6931471824645996\n",
      "epoch: 19 step: 717 loss: 0.6931471824645996\n",
      "epoch: 19 step: 718 loss: 0.6931471824645996\n",
      "epoch: 19 step: 719 loss: 0.6931471824645996\n",
      "epoch: 19 step: 720 loss: 0.6931471824645996\n",
      "epoch: 19 step: 721 loss: 0.6931471824645996\n",
      "epoch: 19 step: 722 loss: 0.6931471824645996\n",
      "epoch: 19 step: 723 loss: 0.6931471824645996\n",
      "epoch: 19 step: 724 loss: 0.6931471824645996\n",
      "epoch: 19 step: 725 loss: 0.6931471824645996\n",
      "epoch: 19 step: 726 loss: 0.6931471824645996\n",
      "epoch: 19 step: 727 loss: 0.6931471824645996\n",
      "epoch: 19 step: 728 loss: 0.6931471824645996\n",
      "epoch: 19 step: 729 loss: 0.6931471824645996\n",
      "epoch: 19 step: 730 loss: 0.6931471824645996\n",
      "epoch: 19 step: 731 loss: 0.6931471824645996\n",
      "epoch: 19 step: 732 loss: 0.6931471824645996\n",
      "epoch: 19 step: 733 loss: 0.6931471824645996\n",
      "epoch: 19 step: 734 loss: 0.6931471824645996\n",
      "epoch: 19 step: 735 loss: 0.6931471824645996\n",
      "epoch: 19 step: 736 loss: 0.6931471824645996\n",
      "epoch: 19 step: 737 loss: 0.6931471824645996\n",
      "epoch: 19 step: 738 loss: 0.6931471824645996\n",
      "epoch: 19 step: 739 loss: 0.6931471824645996\n",
      "epoch: 19 step: 740 loss: 0.6931471824645996\n",
      "epoch: 19 step: 741 loss: 0.6931471824645996\n",
      "epoch: 19 step: 742 loss: 0.6931471824645996\n",
      "epoch: 19 step: 743 loss: 0.6931471824645996\n",
      "epoch: 19 step: 744 loss: 0.6931471824645996\n",
      "epoch: 19 step: 745 loss: 0.6931471824645996\n",
      "epoch: 19 step: 746 loss: 0.6931471824645996\n",
      "epoch: 19 step: 747 loss: 0.6931471824645996\n",
      "epoch: 19 step: 748 loss: 0.6931471824645996\n",
      "epoch: 19 step: 749 loss: 0.6931471824645996\n",
      "epoch: 19 step: 750 loss: 0.6931471824645996\n",
      "epoch: 19 step: 751 loss: 0.6931471824645996\n",
      "epoch: 19 step: 752 loss: 0.6931471824645996\n",
      "epoch: 19 step: 753 loss: 0.6931471824645996\n",
      "epoch: 19 step: 754 loss: 0.6931471824645996\n",
      "epoch: 19 step: 755 loss: 0.6931471824645996\n",
      "epoch: 19 step: 756 loss: 0.6931471824645996\n",
      "epoch: 19 step: 757 loss: 0.6931471824645996\n",
      "epoch: 19 step: 758 loss: 0.6931471824645996\n",
      "epoch: 19 step: 759 loss: 0.6931471824645996\n",
      "epoch: 19 step: 760 loss: 0.6931471824645996\n",
      "epoch: 19 step: 761 loss: 0.6931471824645996\n",
      "epoch: 19 step: 762 loss: 0.6931471824645996\n",
      "epoch: 19 step: 763 loss: 0.6931471824645996\n",
      "epoch: 19 step: 764 loss: 0.6931471824645996\n",
      "epoch: 19 step: 765 loss: 0.6931471824645996\n",
      "epoch: 19 step: 766 loss: 0.6931471824645996\n",
      "epoch: 19 step: 767 loss: 0.6931471824645996\n",
      "epoch: 19 step: 768 loss: 0.6931471824645996\n",
      "epoch: 19 step: 769 loss: 0.6931471824645996\n",
      "epoch: 19 step: 770 loss: 0.6931471824645996\n",
      "epoch: 19 step: 771 loss: 0.6931471824645996\n",
      "epoch: 19 step: 772 loss: 0.6931471824645996\n",
      "epoch: 19 step: 773 loss: 0.6931471824645996\n",
      "epoch: 19 step: 774 loss: 0.6931471824645996\n",
      "epoch: 19 step: 775 loss: 0.6931471824645996\n",
      "epoch: 19 step: 776 loss: 0.6931471824645996\n",
      "epoch: 19 step: 777 loss: 0.6931471824645996\n",
      "epoch: 19 step: 778 loss: 0.6931471824645996\n",
      "epoch: 19 step: 779 loss: 0.6931471824645996\n",
      "epoch: 19 step: 780 loss: 0.6931471824645996\n",
      "epoch: 19 step: 781 loss: 0.6931471824645996\n",
      "epoch: 20 step: 1 loss: 0.6931471824645996\n",
      "epoch: 20 step: 2 loss: 0.6931471824645996\n",
      "epoch: 20 step: 3 loss: 0.6931471824645996\n",
      "epoch: 20 step: 4 loss: 0.6931471824645996\n",
      "epoch: 20 step: 5 loss: 0.6931471824645996\n",
      "epoch: 20 step: 6 loss: 0.6931471824645996\n",
      "epoch: 20 step: 7 loss: 0.6931471824645996\n",
      "epoch: 20 step: 8 loss: 0.6931471824645996\n",
      "epoch: 20 step: 9 loss: 0.6931471824645996\n",
      "epoch: 20 step: 10 loss: 0.6931471824645996\n",
      "epoch: 20 step: 11 loss: 0.6931471824645996\n",
      "epoch: 20 step: 12 loss: 0.6931471824645996\n",
      "epoch: 20 step: 13 loss: 0.6931471824645996\n",
      "epoch: 20 step: 14 loss: 0.6931471824645996\n",
      "epoch: 20 step: 15 loss: 0.6931471824645996\n",
      "epoch: 20 step: 16 loss: 0.6931471824645996\n",
      "epoch: 20 step: 17 loss: 0.6931471824645996\n",
      "epoch: 20 step: 18 loss: 0.6931471824645996\n",
      "epoch: 20 step: 19 loss: 0.6931471824645996\n",
      "epoch: 20 step: 20 loss: 0.6931471824645996\n",
      "epoch: 20 step: 21 loss: 0.6931471824645996\n",
      "epoch: 20 step: 22 loss: 0.6931471824645996\n",
      "epoch: 20 step: 23 loss: 0.6931471824645996\n",
      "epoch: 20 step: 24 loss: 0.6931471824645996\n",
      "epoch: 20 step: 25 loss: 0.6931471824645996\n",
      "epoch: 20 step: 26 loss: 0.6931471824645996\n",
      "epoch: 20 step: 27 loss: 0.6931471824645996\n",
      "epoch: 20 step: 28 loss: 0.6931471824645996\n",
      "epoch: 20 step: 29 loss: 0.6931471824645996\n",
      "epoch: 20 step: 30 loss: 0.6931471824645996\n",
      "epoch: 20 step: 31 loss: 0.6931471824645996\n",
      "epoch: 20 step: 32 loss: 0.6931471824645996\n",
      "epoch: 20 step: 33 loss: 0.6931471824645996\n",
      "epoch: 20 step: 34 loss: 0.6931471824645996\n",
      "epoch: 20 step: 35 loss: 0.6931471824645996\n",
      "epoch: 20 step: 36 loss: 0.6931471824645996\n",
      "epoch: 20 step: 37 loss: 0.6931471824645996\n",
      "epoch: 20 step: 38 loss: 0.6931471824645996\n",
      "epoch: 20 step: 39 loss: 0.6931471824645996\n",
      "epoch: 20 step: 40 loss: 0.6931471824645996\n",
      "epoch: 20 step: 41 loss: 0.6931471824645996\n",
      "epoch: 20 step: 42 loss: 0.6931471824645996\n",
      "epoch: 20 step: 43 loss: 0.6931471824645996\n",
      "epoch: 20 step: 44 loss: 0.6931471824645996\n",
      "epoch: 20 step: 45 loss: 0.6931471824645996\n",
      "epoch: 20 step: 46 loss: 0.6931471824645996\n",
      "epoch: 20 step: 47 loss: 0.6931471824645996\n",
      "epoch: 20 step: 48 loss: 0.6931471824645996\n",
      "epoch: 20 step: 49 loss: 0.6931471824645996\n",
      "epoch: 20 step: 50 loss: 0.6931471824645996\n",
      "epoch: 20 step: 51 loss: 0.6931471824645996\n",
      "epoch: 20 step: 52 loss: 0.6931471824645996\n",
      "epoch: 20 step: 53 loss: 0.6931471824645996\n",
      "epoch: 20 step: 54 loss: 0.6931471824645996\n",
      "epoch: 20 step: 55 loss: 0.6931471824645996\n",
      "epoch: 20 step: 56 loss: 0.6931471824645996\n",
      "epoch: 20 step: 57 loss: 0.6931471824645996\n",
      "epoch: 20 step: 58 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 59 loss: 0.6931471824645996\n",
      "epoch: 20 step: 60 loss: 0.6931471824645996\n",
      "epoch: 20 step: 61 loss: 0.6931471824645996\n",
      "epoch: 20 step: 62 loss: 0.6931471824645996\n",
      "epoch: 20 step: 63 loss: 0.6931471824645996\n",
      "epoch: 20 step: 64 loss: 0.6931471824645996\n",
      "epoch: 20 step: 65 loss: 0.6931471824645996\n",
      "epoch: 20 step: 66 loss: 0.6931471824645996\n",
      "epoch: 20 step: 67 loss: 0.6931471824645996\n",
      "epoch: 20 step: 68 loss: 0.6931471824645996\n",
      "epoch: 20 step: 69 loss: 0.6931471824645996\n",
      "epoch: 20 step: 70 loss: 0.6931471824645996\n",
      "epoch: 20 step: 71 loss: 0.6931471824645996\n",
      "epoch: 20 step: 72 loss: 0.6931471824645996\n",
      "epoch: 20 step: 73 loss: 0.6931471824645996\n",
      "epoch: 20 step: 74 loss: 0.6931471824645996\n",
      "epoch: 20 step: 75 loss: 0.6931471824645996\n",
      "epoch: 20 step: 76 loss: 0.6931471824645996\n",
      "epoch: 20 step: 77 loss: 0.6931471824645996\n",
      "epoch: 20 step: 78 loss: 0.6931471824645996\n",
      "epoch: 20 step: 79 loss: 0.6931471824645996\n",
      "epoch: 20 step: 80 loss: 0.6931471824645996\n",
      "epoch: 20 step: 81 loss: 0.6931471824645996\n",
      "epoch: 20 step: 82 loss: 0.6931471824645996\n",
      "epoch: 20 step: 83 loss: 0.6931471824645996\n",
      "epoch: 20 step: 84 loss: 0.6931471824645996\n",
      "epoch: 20 step: 85 loss: 0.6931471824645996\n",
      "epoch: 20 step: 86 loss: 0.6931471824645996\n",
      "epoch: 20 step: 87 loss: 0.6931471824645996\n",
      "epoch: 20 step: 88 loss: 0.6931471824645996\n",
      "epoch: 20 step: 89 loss: 0.6931471824645996\n",
      "epoch: 20 step: 90 loss: 0.6931471824645996\n",
      "epoch: 20 step: 91 loss: 0.6931471824645996\n",
      "epoch: 20 step: 92 loss: 0.6931471824645996\n",
      "epoch: 20 step: 93 loss: 0.6931471824645996\n",
      "epoch: 20 step: 94 loss: 0.6931471824645996\n",
      "epoch: 20 step: 95 loss: 0.6931471824645996\n",
      "epoch: 20 step: 96 loss: 0.6931471824645996\n",
      "epoch: 20 step: 97 loss: 0.6931471824645996\n",
      "epoch: 20 step: 98 loss: 0.6931471824645996\n",
      "epoch: 20 step: 99 loss: 0.6931471824645996\n",
      "epoch: 20 step: 100 loss: 0.6931471824645996\n",
      "epoch: 20 step: 101 loss: 0.6931471824645996\n",
      "epoch: 20 step: 102 loss: 0.6931471824645996\n",
      "epoch: 20 step: 103 loss: 0.6931471824645996\n",
      "epoch: 20 step: 104 loss: 0.6931471824645996\n",
      "epoch: 20 step: 105 loss: 0.6931471824645996\n",
      "epoch: 20 step: 106 loss: 0.6931471824645996\n",
      "epoch: 20 step: 107 loss: 0.6931471824645996\n",
      "epoch: 20 step: 108 loss: 0.6931471824645996\n",
      "epoch: 20 step: 109 loss: 0.6931471824645996\n",
      "epoch: 20 step: 110 loss: 0.6931471824645996\n",
      "epoch: 20 step: 111 loss: 0.6931471824645996\n",
      "epoch: 20 step: 112 loss: 0.6931471824645996\n",
      "epoch: 20 step: 113 loss: 0.6931471824645996\n",
      "epoch: 20 step: 114 loss: 0.6931471824645996\n",
      "epoch: 20 step: 115 loss: 0.6931471824645996\n",
      "epoch: 20 step: 116 loss: 0.6931471824645996\n",
      "epoch: 20 step: 117 loss: 0.6931471824645996\n",
      "epoch: 20 step: 118 loss: 0.6931471824645996\n",
      "epoch: 20 step: 119 loss: 0.6931471824645996\n",
      "epoch: 20 step: 120 loss: 0.6931471824645996\n",
      "epoch: 20 step: 121 loss: 0.6931471824645996\n",
      "epoch: 20 step: 122 loss: 0.6931471824645996\n",
      "epoch: 20 step: 123 loss: 0.6931471824645996\n",
      "epoch: 20 step: 124 loss: 0.6931471824645996\n",
      "epoch: 20 step: 125 loss: 0.6931471824645996\n",
      "epoch: 20 step: 126 loss: 0.6931471824645996\n",
      "epoch: 20 step: 127 loss: 0.6931471824645996\n",
      "epoch: 20 step: 128 loss: 0.6931471824645996\n",
      "epoch: 20 step: 129 loss: 0.6931471824645996\n",
      "epoch: 20 step: 130 loss: 0.6931471824645996\n",
      "epoch: 20 step: 131 loss: 0.6931471824645996\n",
      "epoch: 20 step: 132 loss: 0.6931471824645996\n",
      "epoch: 20 step: 133 loss: 0.6931471824645996\n",
      "epoch: 20 step: 134 loss: 0.6931471824645996\n",
      "epoch: 20 step: 135 loss: 0.6931471824645996\n",
      "epoch: 20 step: 136 loss: 0.6931471824645996\n",
      "epoch: 20 step: 137 loss: 0.6931471824645996\n",
      "epoch: 20 step: 138 loss: 0.6931471824645996\n",
      "epoch: 20 step: 139 loss: 0.6931471824645996\n",
      "epoch: 20 step: 140 loss: 0.6931471824645996\n",
      "epoch: 20 step: 141 loss: 0.6931471824645996\n",
      "epoch: 20 step: 142 loss: 0.6931471824645996\n",
      "epoch: 20 step: 143 loss: 0.6931471824645996\n",
      "epoch: 20 step: 144 loss: 0.6931471824645996\n",
      "epoch: 20 step: 145 loss: 0.6931471824645996\n",
      "epoch: 20 step: 146 loss: 0.6931471824645996\n",
      "epoch: 20 step: 147 loss: 0.6931471824645996\n",
      "epoch: 20 step: 148 loss: 0.6931471824645996\n",
      "epoch: 20 step: 149 loss: 0.6931471824645996\n",
      "epoch: 20 step: 150 loss: 0.6931471824645996\n",
      "epoch: 20 step: 151 loss: 0.6931471824645996\n",
      "epoch: 20 step: 152 loss: 0.6931471824645996\n",
      "epoch: 20 step: 153 loss: 0.6931471824645996\n",
      "epoch: 20 step: 154 loss: 0.6931471824645996\n",
      "epoch: 20 step: 155 loss: 0.6931471824645996\n",
      "epoch: 20 step: 156 loss: 0.6931471824645996\n",
      "epoch: 20 step: 157 loss: 0.6931471824645996\n",
      "epoch: 20 step: 158 loss: 0.6931471824645996\n",
      "epoch: 20 step: 159 loss: 0.6931471824645996\n",
      "epoch: 20 step: 160 loss: 0.6931471824645996\n",
      "epoch: 20 step: 161 loss: 0.6931471824645996\n",
      "epoch: 20 step: 162 loss: 0.6931471824645996\n",
      "epoch: 20 step: 163 loss: 0.6931471824645996\n",
      "epoch: 20 step: 164 loss: 0.6931471824645996\n",
      "epoch: 20 step: 165 loss: 0.6931471824645996\n",
      "epoch: 20 step: 166 loss: 0.6931471824645996\n",
      "epoch: 20 step: 167 loss: 0.6931471824645996\n",
      "epoch: 20 step: 168 loss: 0.6931471824645996\n",
      "epoch: 20 step: 169 loss: 0.6931471824645996\n",
      "epoch: 20 step: 170 loss: 0.6931471824645996\n",
      "epoch: 20 step: 171 loss: 0.6931471824645996\n",
      "epoch: 20 step: 172 loss: 0.6931471824645996\n",
      "epoch: 20 step: 173 loss: 0.6931471824645996\n",
      "epoch: 20 step: 174 loss: 0.6931471824645996\n",
      "epoch: 20 step: 175 loss: 0.6931471824645996\n",
      "epoch: 20 step: 176 loss: 0.6931471824645996\n",
      "epoch: 20 step: 177 loss: 0.6931471824645996\n",
      "epoch: 20 step: 178 loss: 0.6931471824645996\n",
      "epoch: 20 step: 179 loss: 0.6931471824645996\n",
      "epoch: 20 step: 180 loss: 0.6931471824645996\n",
      "epoch: 20 step: 181 loss: 0.6931471824645996\n",
      "epoch: 20 step: 182 loss: 0.6931471824645996\n",
      "epoch: 20 step: 183 loss: 0.6931471824645996\n",
      "epoch: 20 step: 184 loss: 0.6931471824645996\n",
      "epoch: 20 step: 185 loss: 0.6931471824645996\n",
      "epoch: 20 step: 186 loss: 0.6931471824645996\n",
      "epoch: 20 step: 187 loss: 0.6931471824645996\n",
      "epoch: 20 step: 188 loss: 0.6931471824645996\n",
      "epoch: 20 step: 189 loss: 0.6931471824645996\n",
      "epoch: 20 step: 190 loss: 0.6931471824645996\n",
      "epoch: 20 step: 191 loss: 0.6931471824645996\n",
      "epoch: 20 step: 192 loss: 0.6931471824645996\n",
      "epoch: 20 step: 193 loss: 0.6931471824645996\n",
      "epoch: 20 step: 194 loss: 0.6931471824645996\n",
      "epoch: 20 step: 195 loss: 0.6931471824645996\n",
      "epoch: 20 step: 196 loss: 0.6931471824645996\n",
      "epoch: 20 step: 197 loss: 0.6931471824645996\n",
      "epoch: 20 step: 198 loss: 0.6931471824645996\n",
      "epoch: 20 step: 199 loss: 0.6931471824645996\n",
      "epoch: 20 step: 200 loss: 0.6931471824645996\n",
      "epoch: 20 step: 201 loss: 0.6931471824645996\n",
      "epoch: 20 step: 202 loss: 0.6931471824645996\n",
      "epoch: 20 step: 203 loss: 0.6931471824645996\n",
      "epoch: 20 step: 204 loss: 0.6931471824645996\n",
      "epoch: 20 step: 205 loss: 0.6931471824645996\n",
      "epoch: 20 step: 206 loss: 0.6931471824645996\n",
      "epoch: 20 step: 207 loss: 0.6931471824645996\n",
      "epoch: 20 step: 208 loss: 0.6931471824645996\n",
      "epoch: 20 step: 209 loss: 0.6931471824645996\n",
      "epoch: 20 step: 210 loss: 0.6931471824645996\n",
      "epoch: 20 step: 211 loss: 0.6931471824645996\n",
      "epoch: 20 step: 212 loss: 0.6931471824645996\n",
      "epoch: 20 step: 213 loss: 0.6931471824645996\n",
      "epoch: 20 step: 214 loss: 0.6931471824645996\n",
      "epoch: 20 step: 215 loss: 0.6931471824645996\n",
      "epoch: 20 step: 216 loss: 0.6931471824645996\n",
      "epoch: 20 step: 217 loss: 0.6931471824645996\n",
      "epoch: 20 step: 218 loss: 0.6931471824645996\n",
      "epoch: 20 step: 219 loss: 0.6931471824645996\n",
      "epoch: 20 step: 220 loss: 0.6931471824645996\n",
      "epoch: 20 step: 221 loss: 0.6931471824645996\n",
      "epoch: 20 step: 222 loss: 0.6931471824645996\n",
      "epoch: 20 step: 223 loss: 0.6931471824645996\n",
      "epoch: 20 step: 224 loss: 0.6931471824645996\n",
      "epoch: 20 step: 225 loss: 0.6931471824645996\n",
      "epoch: 20 step: 226 loss: 0.6931471824645996\n",
      "epoch: 20 step: 227 loss: 0.6931471824645996\n",
      "epoch: 20 step: 228 loss: 0.6931471824645996\n",
      "epoch: 20 step: 229 loss: 0.6931471824645996\n",
      "epoch: 20 step: 230 loss: 0.6931471824645996\n",
      "epoch: 20 step: 231 loss: 0.6931471824645996\n",
      "epoch: 20 step: 232 loss: 0.6931471824645996\n",
      "epoch: 20 step: 233 loss: 0.6931471824645996\n",
      "epoch: 20 step: 234 loss: 0.6931471824645996\n",
      "epoch: 20 step: 235 loss: 0.6931471824645996\n",
      "epoch: 20 step: 236 loss: 0.6931471824645996\n",
      "epoch: 20 step: 237 loss: 0.6931471824645996\n",
      "epoch: 20 step: 238 loss: 0.6931471824645996\n",
      "epoch: 20 step: 239 loss: 0.6931471824645996\n",
      "epoch: 20 step: 240 loss: 0.6931471824645996\n",
      "epoch: 20 step: 241 loss: 0.6931471824645996\n",
      "epoch: 20 step: 242 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 243 loss: 0.6931471824645996\n",
      "epoch: 20 step: 244 loss: 0.6931471824645996\n",
      "epoch: 20 step: 245 loss: 0.6931471824645996\n",
      "epoch: 20 step: 246 loss: 0.6931471824645996\n",
      "epoch: 20 step: 247 loss: 0.6931471824645996\n",
      "epoch: 20 step: 248 loss: 0.6931471824645996\n",
      "epoch: 20 step: 249 loss: 0.6931471824645996\n",
      "epoch: 20 step: 250 loss: 0.6931471824645996\n",
      "epoch: 20 step: 251 loss: 0.6931471824645996\n",
      "epoch: 20 step: 252 loss: 0.6931471824645996\n",
      "epoch: 20 step: 253 loss: 0.6931471824645996\n",
      "epoch: 20 step: 254 loss: 0.6931471824645996\n",
      "epoch: 20 step: 255 loss: 0.6931471824645996\n",
      "epoch: 20 step: 256 loss: 0.6931471824645996\n",
      "epoch: 20 step: 257 loss: 0.6931471824645996\n",
      "epoch: 20 step: 258 loss: 0.6931471824645996\n",
      "epoch: 20 step: 259 loss: 0.6931471824645996\n",
      "epoch: 20 step: 260 loss: 0.6931471824645996\n",
      "epoch: 20 step: 261 loss: 0.6931471824645996\n",
      "epoch: 20 step: 262 loss: 0.6931471824645996\n",
      "epoch: 20 step: 263 loss: 0.6931471824645996\n",
      "epoch: 20 step: 264 loss: 0.6931471824645996\n",
      "epoch: 20 step: 265 loss: 0.6931471824645996\n",
      "epoch: 20 step: 266 loss: 0.6931471824645996\n",
      "epoch: 20 step: 267 loss: 0.6931471824645996\n",
      "epoch: 20 step: 268 loss: 0.6931471824645996\n",
      "epoch: 20 step: 269 loss: 0.6931471824645996\n",
      "epoch: 20 step: 270 loss: 0.6931471824645996\n",
      "epoch: 20 step: 271 loss: 0.6931471824645996\n",
      "epoch: 20 step: 272 loss: 0.6931471824645996\n",
      "epoch: 20 step: 273 loss: 0.6931471824645996\n",
      "epoch: 20 step: 274 loss: 0.6931471824645996\n",
      "epoch: 20 step: 275 loss: 0.6931471824645996\n",
      "epoch: 20 step: 276 loss: 0.6931471824645996\n",
      "epoch: 20 step: 277 loss: 0.6931471824645996\n",
      "epoch: 20 step: 278 loss: 0.6931471824645996\n",
      "epoch: 20 step: 279 loss: 0.6931471824645996\n",
      "epoch: 20 step: 280 loss: 0.6931471824645996\n",
      "epoch: 20 step: 281 loss: 0.6931471824645996\n",
      "epoch: 20 step: 282 loss: 0.6931471824645996\n",
      "epoch: 20 step: 283 loss: 0.6931471824645996\n",
      "epoch: 20 step: 284 loss: 0.6931471824645996\n",
      "epoch: 20 step: 285 loss: 0.6931471824645996\n",
      "epoch: 20 step: 286 loss: 0.6931471824645996\n",
      "epoch: 20 step: 287 loss: 0.6931471824645996\n",
      "epoch: 20 step: 288 loss: 0.6931471824645996\n",
      "epoch: 20 step: 289 loss: 0.6931471824645996\n",
      "epoch: 20 step: 290 loss: 0.6931471824645996\n",
      "epoch: 20 step: 291 loss: 0.6931471824645996\n",
      "epoch: 20 step: 292 loss: 0.6931471824645996\n",
      "epoch: 20 step: 293 loss: 0.6931471824645996\n",
      "epoch: 20 step: 294 loss: 0.6931471824645996\n",
      "epoch: 20 step: 295 loss: 0.6931471824645996\n",
      "epoch: 20 step: 296 loss: 0.6931471824645996\n",
      "epoch: 20 step: 297 loss: 0.6931471824645996\n",
      "epoch: 20 step: 298 loss: 0.6931471824645996\n",
      "epoch: 20 step: 299 loss: 0.6931471824645996\n",
      "epoch: 20 step: 300 loss: 0.6931471824645996\n",
      "epoch: 20 step: 301 loss: 0.6931471824645996\n",
      "epoch: 20 step: 302 loss: 0.6931471824645996\n",
      "epoch: 20 step: 303 loss: 0.6931471824645996\n",
      "epoch: 20 step: 304 loss: 0.6931471824645996\n",
      "epoch: 20 step: 305 loss: 0.6931471824645996\n",
      "epoch: 20 step: 306 loss: 0.6931471824645996\n",
      "epoch: 20 step: 307 loss: 0.6931471824645996\n",
      "epoch: 20 step: 308 loss: 0.6931471824645996\n",
      "epoch: 20 step: 309 loss: 0.6931471824645996\n",
      "epoch: 20 step: 310 loss: 0.6931471824645996\n",
      "epoch: 20 step: 311 loss: 0.6931471824645996\n",
      "epoch: 20 step: 312 loss: 0.6931471824645996\n",
      "epoch: 20 step: 313 loss: 0.6931471824645996\n",
      "epoch: 20 step: 314 loss: 0.6931471824645996\n",
      "epoch: 20 step: 315 loss: 0.6931471824645996\n",
      "epoch: 20 step: 316 loss: 0.6931471824645996\n",
      "epoch: 20 step: 317 loss: 0.6931471824645996\n",
      "epoch: 20 step: 318 loss: 0.6931471824645996\n",
      "epoch: 20 step: 319 loss: 0.6931471824645996\n",
      "epoch: 20 step: 320 loss: 0.6931471824645996\n",
      "epoch: 20 step: 321 loss: 0.6931471824645996\n",
      "epoch: 20 step: 322 loss: 0.6931471824645996\n",
      "epoch: 20 step: 323 loss: 0.6931471824645996\n",
      "epoch: 20 step: 324 loss: 0.6931471824645996\n",
      "epoch: 20 step: 325 loss: 0.6931471824645996\n",
      "epoch: 20 step: 326 loss: 0.6931471824645996\n",
      "epoch: 20 step: 327 loss: 0.6931471824645996\n",
      "epoch: 20 step: 328 loss: 0.6931471824645996\n",
      "epoch: 20 step: 329 loss: 0.6931471824645996\n",
      "epoch: 20 step: 330 loss: 0.6931471824645996\n",
      "epoch: 20 step: 331 loss: 0.6931471824645996\n",
      "epoch: 20 step: 332 loss: 0.6931471824645996\n",
      "epoch: 20 step: 333 loss: 0.6931471824645996\n",
      "epoch: 20 step: 334 loss: 0.6931471824645996\n",
      "epoch: 20 step: 335 loss: 0.6931471824645996\n",
      "epoch: 20 step: 336 loss: 0.6931471824645996\n",
      "epoch: 20 step: 337 loss: 0.6931471824645996\n",
      "epoch: 20 step: 338 loss: 0.6931471824645996\n",
      "epoch: 20 step: 339 loss: 0.6931471824645996\n",
      "epoch: 20 step: 340 loss: 0.6931471824645996\n",
      "epoch: 20 step: 341 loss: 0.6931471824645996\n",
      "epoch: 20 step: 342 loss: 0.6931471824645996\n",
      "epoch: 20 step: 343 loss: 0.6931471824645996\n",
      "epoch: 20 step: 344 loss: 0.6931471824645996\n",
      "epoch: 20 step: 345 loss: 0.6931471824645996\n",
      "epoch: 20 step: 346 loss: 0.6931471824645996\n",
      "epoch: 20 step: 347 loss: 0.6931471824645996\n",
      "epoch: 20 step: 348 loss: 0.6931471824645996\n",
      "epoch: 20 step: 349 loss: 0.6931471824645996\n",
      "epoch: 20 step: 350 loss: 0.6931471824645996\n",
      "epoch: 20 step: 351 loss: 0.6931471824645996\n",
      "epoch: 20 step: 352 loss: 0.6931471824645996\n",
      "epoch: 20 step: 353 loss: 0.6931471824645996\n",
      "epoch: 20 step: 354 loss: 0.6931471824645996\n",
      "epoch: 20 step: 355 loss: 0.6931471824645996\n",
      "epoch: 20 step: 356 loss: 0.6931471824645996\n",
      "epoch: 20 step: 357 loss: 0.6931471824645996\n",
      "epoch: 20 step: 358 loss: 0.6931471824645996\n",
      "epoch: 20 step: 359 loss: 0.6931471824645996\n",
      "epoch: 20 step: 360 loss: 0.6931471824645996\n",
      "epoch: 20 step: 361 loss: 0.6931471824645996\n",
      "epoch: 20 step: 362 loss: 0.6931471824645996\n",
      "epoch: 20 step: 363 loss: 0.6931471824645996\n",
      "epoch: 20 step: 364 loss: 0.6931471824645996\n",
      "epoch: 20 step: 365 loss: 0.6931471824645996\n",
      "epoch: 20 step: 366 loss: 0.6931471824645996\n",
      "epoch: 20 step: 367 loss: 0.6931471824645996\n",
      "epoch: 20 step: 368 loss: 0.6931471824645996\n",
      "epoch: 20 step: 369 loss: 0.6931471824645996\n",
      "epoch: 20 step: 370 loss: 0.6931471824645996\n",
      "epoch: 20 step: 371 loss: 0.6931471824645996\n",
      "epoch: 20 step: 372 loss: 0.6931471824645996\n",
      "epoch: 20 step: 373 loss: 0.6931471824645996\n",
      "epoch: 20 step: 374 loss: 0.6931471824645996\n",
      "epoch: 20 step: 375 loss: 0.6931471824645996\n",
      "epoch: 20 step: 376 loss: 0.6931471824645996\n",
      "epoch: 20 step: 377 loss: 0.6931471824645996\n",
      "epoch: 20 step: 378 loss: 0.6931471824645996\n",
      "epoch: 20 step: 379 loss: 0.6931471824645996\n",
      "epoch: 20 step: 380 loss: 0.6931471824645996\n",
      "epoch: 20 step: 381 loss: 0.6931471824645996\n",
      "epoch: 20 step: 382 loss: 0.6931471824645996\n",
      "epoch: 20 step: 383 loss: 0.6931471824645996\n",
      "epoch: 20 step: 384 loss: 0.6931471824645996\n",
      "epoch: 20 step: 385 loss: 0.6931471824645996\n",
      "epoch: 20 step: 386 loss: 0.6931471824645996\n",
      "epoch: 20 step: 387 loss: 0.6931471824645996\n",
      "epoch: 20 step: 388 loss: 0.6931471824645996\n",
      "epoch: 20 step: 389 loss: 0.6931471824645996\n",
      "epoch: 20 step: 390 loss: 0.6931471824645996\n",
      "epoch: 20 step: 391 loss: 0.6931471824645996\n",
      "epoch: 20 step: 392 loss: 0.6931471824645996\n",
      "epoch: 20 step: 393 loss: 0.6931471824645996\n",
      "epoch: 20 step: 394 loss: 0.6931471824645996\n",
      "epoch: 20 step: 395 loss: 0.6931471824645996\n",
      "epoch: 20 step: 396 loss: 0.6931471824645996\n",
      "epoch: 20 step: 397 loss: 0.6931471824645996\n",
      "epoch: 20 step: 398 loss: 0.6931471824645996\n",
      "epoch: 20 step: 399 loss: 0.6931471824645996\n",
      "epoch: 20 step: 400 loss: 0.6931471824645996\n",
      "epoch: 20 step: 401 loss: 0.6931471824645996\n",
      "epoch: 20 step: 402 loss: 0.6931471824645996\n",
      "epoch: 20 step: 403 loss: 0.6931471824645996\n",
      "epoch: 20 step: 404 loss: 0.6931471824645996\n",
      "epoch: 20 step: 405 loss: 0.6931471824645996\n",
      "epoch: 20 step: 406 loss: 0.6931471824645996\n",
      "epoch: 20 step: 407 loss: 0.6931471824645996\n",
      "epoch: 20 step: 408 loss: 0.6931471824645996\n",
      "epoch: 20 step: 409 loss: 0.6931471824645996\n",
      "epoch: 20 step: 410 loss: 0.6931471824645996\n",
      "epoch: 20 step: 411 loss: 0.6931471824645996\n",
      "epoch: 20 step: 412 loss: 0.6931471824645996\n",
      "epoch: 20 step: 413 loss: 0.6931471824645996\n",
      "epoch: 20 step: 414 loss: 0.6931471824645996\n",
      "epoch: 20 step: 415 loss: 0.6931471824645996\n",
      "epoch: 20 step: 416 loss: 0.6931471824645996\n",
      "epoch: 20 step: 417 loss: 0.6931471824645996\n",
      "epoch: 20 step: 418 loss: 0.6931471824645996\n",
      "epoch: 20 step: 419 loss: 0.6931471824645996\n",
      "epoch: 20 step: 420 loss: 0.6931471824645996\n",
      "epoch: 20 step: 421 loss: 0.6931471824645996\n",
      "epoch: 20 step: 422 loss: 0.6931471824645996\n",
      "epoch: 20 step: 423 loss: 0.6931471824645996\n",
      "epoch: 20 step: 424 loss: 0.6931471824645996\n",
      "epoch: 20 step: 425 loss: 0.6931471824645996\n",
      "epoch: 20 step: 426 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 427 loss: 0.6931471824645996\n",
      "epoch: 20 step: 428 loss: 0.6931471824645996\n",
      "epoch: 20 step: 429 loss: 0.6931471824645996\n",
      "epoch: 20 step: 430 loss: 0.6931471824645996\n",
      "epoch: 20 step: 431 loss: 0.6931471824645996\n",
      "epoch: 20 step: 432 loss: 0.6931471824645996\n",
      "epoch: 20 step: 433 loss: 0.6931471824645996\n",
      "epoch: 20 step: 434 loss: 0.6931471824645996\n",
      "epoch: 20 step: 435 loss: 0.6931471824645996\n",
      "epoch: 20 step: 436 loss: 0.6931471824645996\n",
      "epoch: 20 step: 437 loss: 0.6931471824645996\n",
      "epoch: 20 step: 438 loss: 0.6931471824645996\n",
      "epoch: 20 step: 439 loss: 0.6931471824645996\n",
      "epoch: 20 step: 440 loss: 0.6931471824645996\n",
      "epoch: 20 step: 441 loss: 0.6931471824645996\n",
      "epoch: 20 step: 442 loss: 0.6931471824645996\n",
      "epoch: 20 step: 443 loss: 0.6931471824645996\n",
      "epoch: 20 step: 444 loss: 0.6931471824645996\n",
      "epoch: 20 step: 445 loss: 0.6931471824645996\n",
      "epoch: 20 step: 446 loss: 0.6931471824645996\n",
      "epoch: 20 step: 447 loss: 0.6931471824645996\n",
      "epoch: 20 step: 448 loss: 0.6931471824645996\n",
      "epoch: 20 step: 449 loss: 0.6931471824645996\n",
      "epoch: 20 step: 450 loss: 0.6931471824645996\n",
      "epoch: 20 step: 451 loss: 0.6931471824645996\n",
      "epoch: 20 step: 452 loss: 0.6931471824645996\n",
      "epoch: 20 step: 453 loss: 0.6931471824645996\n",
      "epoch: 20 step: 454 loss: 0.6931471824645996\n",
      "epoch: 20 step: 455 loss: 0.6931471824645996\n",
      "epoch: 20 step: 456 loss: 0.6931471824645996\n",
      "epoch: 20 step: 457 loss: 0.6931471824645996\n",
      "epoch: 20 step: 458 loss: 0.6931471824645996\n",
      "epoch: 20 step: 459 loss: 0.6931471824645996\n",
      "epoch: 20 step: 460 loss: 0.6931471824645996\n",
      "epoch: 20 step: 461 loss: 0.6931471824645996\n",
      "epoch: 20 step: 462 loss: 0.6931471824645996\n",
      "epoch: 20 step: 463 loss: 0.6931471824645996\n",
      "epoch: 20 step: 464 loss: 0.6931471824645996\n",
      "epoch: 20 step: 465 loss: 0.6931471824645996\n",
      "epoch: 20 step: 466 loss: 0.6931471824645996\n",
      "epoch: 20 step: 467 loss: 0.6931471824645996\n",
      "epoch: 20 step: 468 loss: 0.6931471824645996\n",
      "epoch: 20 step: 469 loss: 0.6931471824645996\n",
      "epoch: 20 step: 470 loss: 0.6931471824645996\n",
      "epoch: 20 step: 471 loss: 0.6931471824645996\n",
      "epoch: 20 step: 472 loss: 0.6931471824645996\n",
      "epoch: 20 step: 473 loss: 0.6931471824645996\n",
      "epoch: 20 step: 474 loss: 0.6931471824645996\n",
      "epoch: 20 step: 475 loss: 0.6931471824645996\n",
      "epoch: 20 step: 476 loss: 0.6931471824645996\n",
      "epoch: 20 step: 477 loss: 0.6931471824645996\n",
      "epoch: 20 step: 478 loss: 0.6931471824645996\n",
      "epoch: 20 step: 479 loss: 0.6931471824645996\n",
      "epoch: 20 step: 480 loss: 0.6931471824645996\n",
      "epoch: 20 step: 481 loss: 0.6931471824645996\n",
      "epoch: 20 step: 482 loss: 0.6931471824645996\n",
      "epoch: 20 step: 483 loss: 0.6931471824645996\n",
      "epoch: 20 step: 484 loss: 0.6931471824645996\n",
      "epoch: 20 step: 485 loss: 0.6931471824645996\n",
      "epoch: 20 step: 486 loss: 0.6931471824645996\n",
      "epoch: 20 step: 487 loss: 0.6931471824645996\n",
      "epoch: 20 step: 488 loss: 0.6931471824645996\n",
      "epoch: 20 step: 489 loss: 0.6931471824645996\n",
      "epoch: 20 step: 490 loss: 0.6931471824645996\n",
      "epoch: 20 step: 491 loss: 0.6931471824645996\n",
      "epoch: 20 step: 492 loss: 0.6931471824645996\n",
      "epoch: 20 step: 493 loss: 0.6931471824645996\n",
      "epoch: 20 step: 494 loss: 0.6931471824645996\n",
      "epoch: 20 step: 495 loss: 0.6931471824645996\n",
      "epoch: 20 step: 496 loss: 0.6931471824645996\n",
      "epoch: 20 step: 497 loss: 0.6931471824645996\n",
      "epoch: 20 step: 498 loss: 0.6931471824645996\n",
      "epoch: 20 step: 499 loss: 0.6931471824645996\n",
      "epoch: 20 step: 500 loss: 0.6931471824645996\n",
      "epoch: 20 step: 501 loss: 0.6931471824645996\n",
      "epoch: 20 step: 502 loss: 0.6931471824645996\n",
      "epoch: 20 step: 503 loss: 0.6931471824645996\n",
      "epoch: 20 step: 504 loss: 0.6931471824645996\n",
      "epoch: 20 step: 505 loss: 0.6931471824645996\n",
      "epoch: 20 step: 506 loss: 0.6931471824645996\n",
      "epoch: 20 step: 507 loss: 0.6931471824645996\n",
      "epoch: 20 step: 508 loss: 0.6931471824645996\n",
      "epoch: 20 step: 509 loss: 0.6931471824645996\n",
      "epoch: 20 step: 510 loss: 0.6931471824645996\n",
      "epoch: 20 step: 511 loss: 0.6931471824645996\n",
      "epoch: 20 step: 512 loss: 0.6931471824645996\n",
      "epoch: 20 step: 513 loss: 0.6931471824645996\n",
      "epoch: 20 step: 514 loss: 0.6931471824645996\n",
      "epoch: 20 step: 515 loss: 0.6931471824645996\n",
      "epoch: 20 step: 516 loss: 0.6931471824645996\n",
      "epoch: 20 step: 517 loss: 0.6931471824645996\n",
      "epoch: 20 step: 518 loss: 0.6931471824645996\n",
      "epoch: 20 step: 519 loss: 0.6931471824645996\n",
      "epoch: 20 step: 520 loss: 0.6931471824645996\n",
      "epoch: 20 step: 521 loss: 0.6931471824645996\n",
      "epoch: 20 step: 522 loss: 0.6931471824645996\n",
      "epoch: 20 step: 523 loss: 0.6931471824645996\n",
      "epoch: 20 step: 524 loss: 0.6931471824645996\n",
      "epoch: 20 step: 525 loss: 0.6931471824645996\n",
      "epoch: 20 step: 526 loss: 0.6931471824645996\n",
      "epoch: 20 step: 527 loss: 0.6931471824645996\n",
      "epoch: 20 step: 528 loss: 0.6931471824645996\n",
      "epoch: 20 step: 529 loss: 0.6931471824645996\n",
      "epoch: 20 step: 530 loss: 0.6931471824645996\n",
      "epoch: 20 step: 531 loss: 0.6931471824645996\n",
      "epoch: 20 step: 532 loss: 0.6931471824645996\n",
      "epoch: 20 step: 533 loss: 0.6931471824645996\n",
      "epoch: 20 step: 534 loss: 0.6931471824645996\n",
      "epoch: 20 step: 535 loss: 0.6931471824645996\n",
      "epoch: 20 step: 536 loss: 0.6931471824645996\n",
      "epoch: 20 step: 537 loss: 0.6931471824645996\n",
      "epoch: 20 step: 538 loss: 0.6931471824645996\n",
      "epoch: 20 step: 539 loss: 0.6931471824645996\n",
      "epoch: 20 step: 540 loss: 0.6931471824645996\n",
      "epoch: 20 step: 541 loss: 0.6931471824645996\n",
      "epoch: 20 step: 542 loss: 0.6931471824645996\n",
      "epoch: 20 step: 543 loss: 0.6931471824645996\n",
      "epoch: 20 step: 544 loss: 0.6931471824645996\n",
      "epoch: 20 step: 545 loss: 0.6931471824645996\n",
      "epoch: 20 step: 546 loss: 0.6931471824645996\n",
      "epoch: 20 step: 547 loss: 0.6931471824645996\n",
      "epoch: 20 step: 548 loss: 0.6931471824645996\n",
      "epoch: 20 step: 549 loss: 0.6931471824645996\n",
      "epoch: 20 step: 550 loss: 0.6931471824645996\n",
      "epoch: 20 step: 551 loss: 0.6931471824645996\n",
      "epoch: 20 step: 552 loss: 0.6931471824645996\n",
      "epoch: 20 step: 553 loss: 0.6931471824645996\n",
      "epoch: 20 step: 554 loss: 0.6931471824645996\n",
      "epoch: 20 step: 555 loss: 0.6931471824645996\n",
      "epoch: 20 step: 556 loss: 0.6931471824645996\n",
      "epoch: 20 step: 557 loss: 0.6931471824645996\n",
      "epoch: 20 step: 558 loss: 0.6931471824645996\n",
      "epoch: 20 step: 559 loss: 0.6931471824645996\n",
      "epoch: 20 step: 560 loss: 0.6931471824645996\n",
      "epoch: 20 step: 561 loss: 0.6931471824645996\n",
      "epoch: 20 step: 562 loss: 0.6931471824645996\n",
      "epoch: 20 step: 563 loss: 0.6931471824645996\n",
      "epoch: 20 step: 564 loss: 0.6931471824645996\n",
      "epoch: 20 step: 565 loss: 0.6931471824645996\n",
      "epoch: 20 step: 566 loss: 0.6931471824645996\n",
      "epoch: 20 step: 567 loss: 0.6931471824645996\n",
      "epoch: 20 step: 568 loss: 0.6931471824645996\n",
      "epoch: 20 step: 569 loss: 0.6931471824645996\n",
      "epoch: 20 step: 570 loss: 0.6931471824645996\n",
      "epoch: 20 step: 571 loss: 0.6931471824645996\n",
      "epoch: 20 step: 572 loss: 0.6931471824645996\n",
      "epoch: 20 step: 573 loss: 0.6931471824645996\n",
      "epoch: 20 step: 574 loss: 0.6931471824645996\n",
      "epoch: 20 step: 575 loss: 0.6931471824645996\n",
      "epoch: 20 step: 576 loss: 0.6931471824645996\n",
      "epoch: 20 step: 577 loss: 0.6931471824645996\n",
      "epoch: 20 step: 578 loss: 0.6931471824645996\n",
      "epoch: 20 step: 579 loss: 0.6931471824645996\n",
      "epoch: 20 step: 580 loss: 0.6931471824645996\n",
      "epoch: 20 step: 581 loss: 0.6931471824645996\n",
      "epoch: 20 step: 582 loss: 0.6931471824645996\n",
      "epoch: 20 step: 583 loss: 0.6931471824645996\n",
      "epoch: 20 step: 584 loss: 0.6931471824645996\n",
      "epoch: 20 step: 585 loss: 0.6931471824645996\n",
      "epoch: 20 step: 586 loss: 0.6931471824645996\n",
      "epoch: 20 step: 587 loss: 0.6931471824645996\n",
      "epoch: 20 step: 588 loss: 0.6931471824645996\n",
      "epoch: 20 step: 589 loss: 0.6931471824645996\n",
      "epoch: 20 step: 590 loss: 0.6931471824645996\n",
      "epoch: 20 step: 591 loss: 0.6931471824645996\n",
      "epoch: 20 step: 592 loss: 0.6931471824645996\n",
      "epoch: 20 step: 593 loss: 0.6931471824645996\n",
      "epoch: 20 step: 594 loss: 0.6931471824645996\n",
      "epoch: 20 step: 595 loss: 0.6931471824645996\n",
      "epoch: 20 step: 596 loss: 0.6931471824645996\n",
      "epoch: 20 step: 597 loss: 0.6931471824645996\n",
      "epoch: 20 step: 598 loss: 0.6931471824645996\n",
      "epoch: 20 step: 599 loss: 0.6931471824645996\n",
      "epoch: 20 step: 600 loss: 0.6931471824645996\n",
      "epoch: 20 step: 601 loss: 0.6931471824645996\n",
      "epoch: 20 step: 602 loss: 0.6931471824645996\n",
      "epoch: 20 step: 603 loss: 0.6931471824645996\n",
      "epoch: 20 step: 604 loss: 0.6931471824645996\n",
      "epoch: 20 step: 605 loss: 0.6931471824645996\n",
      "epoch: 20 step: 606 loss: 0.6931471824645996\n",
      "epoch: 20 step: 607 loss: 0.6931471824645996\n",
      "epoch: 20 step: 608 loss: 0.6931471824645996\n",
      "epoch: 20 step: 609 loss: 0.6931471824645996\n",
      "epoch: 20 step: 610 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 611 loss: 0.6931471824645996\n",
      "epoch: 20 step: 612 loss: 0.6931471824645996\n",
      "epoch: 20 step: 613 loss: 0.6931471824645996\n",
      "epoch: 20 step: 614 loss: 0.6931471824645996\n",
      "epoch: 20 step: 615 loss: 0.6931471824645996\n",
      "epoch: 20 step: 616 loss: 0.6931471824645996\n",
      "epoch: 20 step: 617 loss: 0.6931471824645996\n",
      "epoch: 20 step: 618 loss: 0.6931471824645996\n",
      "epoch: 20 step: 619 loss: 0.6931471824645996\n",
      "epoch: 20 step: 620 loss: 0.6931471824645996\n",
      "epoch: 20 step: 621 loss: 0.6931471824645996\n",
      "epoch: 20 step: 622 loss: 0.6931471824645996\n",
      "epoch: 20 step: 623 loss: 0.6931471824645996\n",
      "epoch: 20 step: 624 loss: 0.6931471824645996\n",
      "epoch: 20 step: 625 loss: 0.6931471824645996\n",
      "epoch: 20 step: 626 loss: 0.6931471824645996\n",
      "epoch: 20 step: 627 loss: 0.6931471824645996\n",
      "epoch: 20 step: 628 loss: 0.6931471824645996\n",
      "epoch: 20 step: 629 loss: 0.6931471824645996\n",
      "epoch: 20 step: 630 loss: 0.6931471824645996\n",
      "epoch: 20 step: 631 loss: 0.6931471824645996\n",
      "epoch: 20 step: 632 loss: 0.6931471824645996\n",
      "epoch: 20 step: 633 loss: 0.6931471824645996\n",
      "epoch: 20 step: 634 loss: 0.6931471824645996\n",
      "epoch: 20 step: 635 loss: 0.6931471824645996\n",
      "epoch: 20 step: 636 loss: 0.6931471824645996\n",
      "epoch: 20 step: 637 loss: 0.6931471824645996\n",
      "epoch: 20 step: 638 loss: 0.6931471824645996\n",
      "epoch: 20 step: 639 loss: 0.6931471824645996\n",
      "epoch: 20 step: 640 loss: 0.6931471824645996\n",
      "epoch: 20 step: 641 loss: 0.6931471824645996\n",
      "epoch: 20 step: 642 loss: 0.6931471824645996\n",
      "epoch: 20 step: 643 loss: 0.6931471824645996\n",
      "epoch: 20 step: 644 loss: 0.6931471824645996\n",
      "epoch: 20 step: 645 loss: 0.6931471824645996\n",
      "epoch: 20 step: 646 loss: 0.6931471824645996\n",
      "epoch: 20 step: 647 loss: 0.6931471824645996\n",
      "epoch: 20 step: 648 loss: 0.6931471824645996\n",
      "epoch: 20 step: 649 loss: 0.6931471824645996\n",
      "epoch: 20 step: 650 loss: 0.6931471824645996\n",
      "epoch: 20 step: 651 loss: 0.6931471824645996\n",
      "epoch: 20 step: 652 loss: 0.6931471824645996\n",
      "epoch: 20 step: 653 loss: 0.6931471824645996\n",
      "epoch: 20 step: 654 loss: 0.6931471824645996\n",
      "epoch: 20 step: 655 loss: 0.6931471824645996\n",
      "epoch: 20 step: 656 loss: 0.6931471824645996\n",
      "epoch: 20 step: 657 loss: 0.6931471824645996\n",
      "epoch: 20 step: 658 loss: 0.6931471824645996\n",
      "epoch: 20 step: 659 loss: 0.6931471824645996\n",
      "epoch: 20 step: 660 loss: 0.6931471824645996\n",
      "epoch: 20 step: 661 loss: 0.6931471824645996\n",
      "epoch: 20 step: 662 loss: 0.6931471824645996\n",
      "epoch: 20 step: 663 loss: 0.6931471824645996\n",
      "epoch: 20 step: 664 loss: 0.6931471824645996\n",
      "epoch: 20 step: 665 loss: 0.6931471824645996\n",
      "epoch: 20 step: 666 loss: 0.6931471824645996\n",
      "epoch: 20 step: 667 loss: 0.6931471824645996\n",
      "epoch: 20 step: 668 loss: 0.6931471824645996\n",
      "epoch: 20 step: 669 loss: 0.6931471824645996\n",
      "epoch: 20 step: 670 loss: 0.6931471824645996\n",
      "epoch: 20 step: 671 loss: 0.6931471824645996\n",
      "epoch: 20 step: 672 loss: 0.6931471824645996\n",
      "epoch: 20 step: 673 loss: 0.6931471824645996\n",
      "epoch: 20 step: 674 loss: 0.6931471824645996\n",
      "epoch: 20 step: 675 loss: 0.6931471824645996\n",
      "epoch: 20 step: 676 loss: 0.6931471824645996\n",
      "epoch: 20 step: 677 loss: 0.6931471824645996\n",
      "epoch: 20 step: 678 loss: 0.6931471824645996\n",
      "epoch: 20 step: 679 loss: 0.6931471824645996\n",
      "epoch: 20 step: 680 loss: 0.6931471824645996\n",
      "epoch: 20 step: 681 loss: 0.6931471824645996\n",
      "epoch: 20 step: 682 loss: 0.6931471824645996\n",
      "epoch: 20 step: 683 loss: 0.6931471824645996\n",
      "epoch: 20 step: 684 loss: 0.6931471824645996\n",
      "epoch: 20 step: 685 loss: 0.6931471824645996\n",
      "epoch: 20 step: 686 loss: 0.6931471824645996\n",
      "epoch: 20 step: 687 loss: 0.6931471824645996\n",
      "epoch: 20 step: 688 loss: 0.6931471824645996\n",
      "epoch: 20 step: 689 loss: 0.6931471824645996\n",
      "epoch: 20 step: 690 loss: 0.6931471824645996\n",
      "epoch: 20 step: 691 loss: 0.6931471824645996\n",
      "epoch: 20 step: 692 loss: 0.6931471824645996\n",
      "epoch: 20 step: 693 loss: 0.6931471824645996\n",
      "epoch: 20 step: 694 loss: 0.6931471824645996\n",
      "epoch: 20 step: 695 loss: 0.6931471824645996\n",
      "epoch: 20 step: 696 loss: 0.6931471824645996\n",
      "epoch: 20 step: 697 loss: 0.6931471824645996\n",
      "epoch: 20 step: 698 loss: 0.6931471824645996\n",
      "epoch: 20 step: 699 loss: 0.6931471824645996\n",
      "epoch: 20 step: 700 loss: 0.6931471824645996\n",
      "epoch: 20 step: 701 loss: 0.6931471824645996\n",
      "epoch: 20 step: 702 loss: 0.6931471824645996\n",
      "epoch: 20 step: 703 loss: 0.6931471824645996\n",
      "epoch: 20 step: 704 loss: 0.6931471824645996\n",
      "epoch: 20 step: 705 loss: 0.6931471824645996\n",
      "epoch: 20 step: 706 loss: 0.6931471824645996\n",
      "epoch: 20 step: 707 loss: 0.6931471824645996\n",
      "epoch: 20 step: 708 loss: 0.6931471824645996\n",
      "epoch: 20 step: 709 loss: 0.6931471824645996\n",
      "epoch: 20 step: 710 loss: 0.6931471824645996\n",
      "epoch: 20 step: 711 loss: 0.6931471824645996\n",
      "epoch: 20 step: 712 loss: 0.6931471824645996\n",
      "epoch: 20 step: 713 loss: 0.6931471824645996\n",
      "epoch: 20 step: 714 loss: 0.6931471824645996\n",
      "epoch: 20 step: 715 loss: 0.6931471824645996\n",
      "epoch: 20 step: 716 loss: 0.6931471824645996\n",
      "epoch: 20 step: 717 loss: 0.6931471824645996\n",
      "epoch: 20 step: 718 loss: 0.6931471824645996\n",
      "epoch: 20 step: 719 loss: 0.6931471824645996\n",
      "epoch: 20 step: 720 loss: 0.6931471824645996\n",
      "epoch: 20 step: 721 loss: 0.6931471824645996\n",
      "epoch: 20 step: 722 loss: 0.6931471824645996\n",
      "epoch: 20 step: 723 loss: 0.6931471824645996\n",
      "epoch: 20 step: 724 loss: 0.6931471824645996\n",
      "epoch: 20 step: 725 loss: 0.6931471824645996\n",
      "epoch: 20 step: 726 loss: 0.6931471824645996\n",
      "epoch: 20 step: 727 loss: 0.6931471824645996\n",
      "epoch: 20 step: 728 loss: 0.6931471824645996\n",
      "epoch: 20 step: 729 loss: 0.6931471824645996\n",
      "epoch: 20 step: 730 loss: 0.6931471824645996\n",
      "epoch: 20 step: 731 loss: 0.6931471824645996\n",
      "epoch: 20 step: 732 loss: 0.6931471824645996\n",
      "epoch: 20 step: 733 loss: 0.6931471824645996\n",
      "epoch: 20 step: 734 loss: 0.6931471824645996\n",
      "epoch: 20 step: 735 loss: 0.6931471824645996\n",
      "epoch: 20 step: 736 loss: 0.6931471824645996\n",
      "epoch: 20 step: 737 loss: 0.6931471824645996\n",
      "epoch: 20 step: 738 loss: 0.6931471824645996\n",
      "epoch: 20 step: 739 loss: 0.6931471824645996\n",
      "epoch: 20 step: 740 loss: 0.6931471824645996\n",
      "epoch: 20 step: 741 loss: 0.6931471824645996\n",
      "epoch: 20 step: 742 loss: 0.6931471824645996\n",
      "epoch: 20 step: 743 loss: 0.6931471824645996\n",
      "epoch: 20 step: 744 loss: 0.6931471824645996\n",
      "epoch: 20 step: 745 loss: 0.6931471824645996\n",
      "epoch: 20 step: 746 loss: 0.6931471824645996\n",
      "epoch: 20 step: 747 loss: 0.6931471824645996\n",
      "epoch: 20 step: 748 loss: 0.6931471824645996\n",
      "epoch: 20 step: 749 loss: 0.6931471824645996\n",
      "epoch: 20 step: 750 loss: 0.6931471824645996\n",
      "epoch: 20 step: 751 loss: 0.6931471824645996\n",
      "epoch: 20 step: 752 loss: 0.6931471824645996\n",
      "epoch: 20 step: 753 loss: 0.6931471824645996\n",
      "epoch: 20 step: 754 loss: 0.6931471824645996\n",
      "epoch: 20 step: 755 loss: 0.6931471824645996\n",
      "epoch: 20 step: 756 loss: 0.6931471824645996\n",
      "epoch: 20 step: 757 loss: 0.6931471824645996\n",
      "epoch: 20 step: 758 loss: 0.6931471824645996\n",
      "epoch: 20 step: 759 loss: 0.6931471824645996\n",
      "epoch: 20 step: 760 loss: 0.6931471824645996\n",
      "epoch: 20 step: 761 loss: 0.6931471824645996\n",
      "epoch: 20 step: 762 loss: 0.6931471824645996\n",
      "epoch: 20 step: 763 loss: 0.6931471824645996\n",
      "epoch: 20 step: 764 loss: 0.6931471824645996\n",
      "epoch: 20 step: 765 loss: 0.6931471824645996\n",
      "epoch: 20 step: 766 loss: 0.6931471824645996\n",
      "epoch: 20 step: 767 loss: 0.6931471824645996\n",
      "epoch: 20 step: 768 loss: 0.6931471824645996\n",
      "epoch: 20 step: 769 loss: 0.6931471824645996\n",
      "epoch: 20 step: 770 loss: 0.6931471824645996\n",
      "epoch: 20 step: 771 loss: 0.6931471824645996\n",
      "epoch: 20 step: 772 loss: 0.6931471824645996\n",
      "epoch: 20 step: 773 loss: 0.6931471824645996\n",
      "epoch: 20 step: 774 loss: 0.6931471824645996\n",
      "epoch: 20 step: 775 loss: 0.6931471824645996\n",
      "epoch: 20 step: 776 loss: 0.6931471824645996\n",
      "epoch: 20 step: 777 loss: 0.6931471824645996\n",
      "epoch: 20 step: 778 loss: 0.6931471824645996\n",
      "epoch: 20 step: 779 loss: 0.6931471824645996\n",
      "epoch: 20 step: 780 loss: 0.6931471824645996\n",
      "epoch: 20 step: 781 loss: 0.6931471824645996\n",
      "epoch: 21 step: 1 loss: 0.6931471824645996\n",
      "epoch: 21 step: 2 loss: 0.6931471824645996\n",
      "epoch: 21 step: 3 loss: 0.6931471824645996\n",
      "epoch: 21 step: 4 loss: 0.6931471824645996\n",
      "epoch: 21 step: 5 loss: 0.6931471824645996\n",
      "epoch: 21 step: 6 loss: 0.6931471824645996\n",
      "epoch: 21 step: 7 loss: 0.6931471824645996\n",
      "epoch: 21 step: 8 loss: 0.6931471824645996\n",
      "epoch: 21 step: 9 loss: 0.6931471824645996\n",
      "epoch: 21 step: 10 loss: 0.6931471824645996\n",
      "epoch: 21 step: 11 loss: 0.6931471824645996\n",
      "epoch: 21 step: 12 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 13 loss: 0.6931471824645996\n",
      "epoch: 21 step: 14 loss: 0.6931471824645996\n",
      "epoch: 21 step: 15 loss: 0.6931471824645996\n",
      "epoch: 21 step: 16 loss: 0.6931471824645996\n",
      "epoch: 21 step: 17 loss: 0.6931471824645996\n",
      "epoch: 21 step: 18 loss: 0.6931471824645996\n",
      "epoch: 21 step: 19 loss: 0.6931471824645996\n",
      "epoch: 21 step: 20 loss: 0.6931471824645996\n",
      "epoch: 21 step: 21 loss: 0.6931471824645996\n",
      "epoch: 21 step: 22 loss: 0.6931471824645996\n",
      "epoch: 21 step: 23 loss: 0.6931471824645996\n",
      "epoch: 21 step: 24 loss: 0.6931471824645996\n",
      "epoch: 21 step: 25 loss: 0.6931471824645996\n",
      "epoch: 21 step: 26 loss: 0.6931471824645996\n",
      "epoch: 21 step: 27 loss: 0.6931471824645996\n",
      "epoch: 21 step: 28 loss: 0.6931471824645996\n",
      "epoch: 21 step: 29 loss: 0.6931471824645996\n",
      "epoch: 21 step: 30 loss: 0.6931471824645996\n",
      "epoch: 21 step: 31 loss: 0.6931471824645996\n",
      "epoch: 21 step: 32 loss: 0.6931471824645996\n",
      "epoch: 21 step: 33 loss: 0.6931471824645996\n",
      "epoch: 21 step: 34 loss: 0.6931471824645996\n",
      "epoch: 21 step: 35 loss: 0.6931471824645996\n",
      "epoch: 21 step: 36 loss: 0.6931471824645996\n",
      "epoch: 21 step: 37 loss: 0.6931471824645996\n",
      "epoch: 21 step: 38 loss: 0.6931471824645996\n",
      "epoch: 21 step: 39 loss: 0.6931471824645996\n",
      "epoch: 21 step: 40 loss: 0.6931471824645996\n",
      "epoch: 21 step: 41 loss: 0.6931471824645996\n",
      "epoch: 21 step: 42 loss: 0.6931471824645996\n",
      "epoch: 21 step: 43 loss: 0.6931471824645996\n",
      "epoch: 21 step: 44 loss: 0.6931471824645996\n",
      "epoch: 21 step: 45 loss: 0.6931471824645996\n",
      "epoch: 21 step: 46 loss: 0.6931471824645996\n",
      "epoch: 21 step: 47 loss: 0.6931471824645996\n",
      "epoch: 21 step: 48 loss: 0.6931471824645996\n",
      "epoch: 21 step: 49 loss: 0.6931471824645996\n",
      "epoch: 21 step: 50 loss: 0.6931471824645996\n",
      "epoch: 21 step: 51 loss: 0.6931471824645996\n",
      "epoch: 21 step: 52 loss: 0.6931471824645996\n",
      "epoch: 21 step: 53 loss: 0.6931471824645996\n",
      "epoch: 21 step: 54 loss: 0.6931471824645996\n",
      "epoch: 21 step: 55 loss: 0.6931471824645996\n",
      "epoch: 21 step: 56 loss: 0.6931471824645996\n",
      "epoch: 21 step: 57 loss: 0.6931471824645996\n",
      "epoch: 21 step: 58 loss: 0.6931471824645996\n",
      "epoch: 21 step: 59 loss: 0.6931471824645996\n",
      "epoch: 21 step: 60 loss: 0.6931471824645996\n",
      "epoch: 21 step: 61 loss: 0.6931471824645996\n",
      "epoch: 21 step: 62 loss: 0.6931471824645996\n",
      "epoch: 21 step: 63 loss: 0.6931471824645996\n",
      "epoch: 21 step: 64 loss: 0.6931471824645996\n",
      "epoch: 21 step: 65 loss: 0.6931471824645996\n",
      "epoch: 21 step: 66 loss: 0.6931471824645996\n",
      "epoch: 21 step: 67 loss: 0.6931471824645996\n",
      "epoch: 21 step: 68 loss: 0.6931471824645996\n",
      "epoch: 21 step: 69 loss: 0.6931471824645996\n",
      "epoch: 21 step: 70 loss: 0.6931471824645996\n",
      "epoch: 21 step: 71 loss: 0.6931471824645996\n",
      "epoch: 21 step: 72 loss: 0.6931471824645996\n",
      "epoch: 21 step: 73 loss: 0.6931471824645996\n",
      "epoch: 21 step: 74 loss: 0.6931471824645996\n",
      "epoch: 21 step: 75 loss: 0.6931471824645996\n",
      "epoch: 21 step: 76 loss: 0.6931471824645996\n",
      "epoch: 21 step: 77 loss: 0.6931471824645996\n",
      "epoch: 21 step: 78 loss: 0.6931471824645996\n",
      "epoch: 21 step: 79 loss: 0.6931471824645996\n",
      "epoch: 21 step: 80 loss: 0.6931471824645996\n",
      "epoch: 21 step: 81 loss: 0.6931471824645996\n",
      "epoch: 21 step: 82 loss: 0.6931471824645996\n",
      "epoch: 21 step: 83 loss: 0.6931471824645996\n",
      "epoch: 21 step: 84 loss: 0.6931471824645996\n",
      "epoch: 21 step: 85 loss: 0.6931471824645996\n",
      "epoch: 21 step: 86 loss: 0.6931471824645996\n",
      "epoch: 21 step: 87 loss: 0.6931471824645996\n",
      "epoch: 21 step: 88 loss: 0.6931471824645996\n",
      "epoch: 21 step: 89 loss: 0.6931471824645996\n",
      "epoch: 21 step: 90 loss: 0.6931471824645996\n",
      "epoch: 21 step: 91 loss: 0.6931471824645996\n",
      "epoch: 21 step: 92 loss: 0.6931471824645996\n",
      "epoch: 21 step: 93 loss: 0.6931471824645996\n",
      "epoch: 21 step: 94 loss: 0.6931471824645996\n",
      "epoch: 21 step: 95 loss: 0.6931471824645996\n",
      "epoch: 21 step: 96 loss: 0.6931471824645996\n",
      "epoch: 21 step: 97 loss: 0.6931471824645996\n",
      "epoch: 21 step: 98 loss: 0.6931471824645996\n",
      "epoch: 21 step: 99 loss: 0.6931471824645996\n",
      "epoch: 21 step: 100 loss: 0.6931471824645996\n",
      "epoch: 21 step: 101 loss: 0.6931471824645996\n",
      "epoch: 21 step: 102 loss: 0.6931471824645996\n",
      "epoch: 21 step: 103 loss: 0.6931471824645996\n",
      "epoch: 21 step: 104 loss: 0.6931471824645996\n",
      "epoch: 21 step: 105 loss: 0.6931471824645996\n",
      "epoch: 21 step: 106 loss: 0.6931471824645996\n",
      "epoch: 21 step: 107 loss: 0.6931471824645996\n",
      "epoch: 21 step: 108 loss: 0.6931471824645996\n",
      "epoch: 21 step: 109 loss: 0.6931471824645996\n",
      "epoch: 21 step: 110 loss: 0.6931471824645996\n",
      "epoch: 21 step: 111 loss: 0.6931471824645996\n",
      "epoch: 21 step: 112 loss: 0.6931471824645996\n",
      "epoch: 21 step: 113 loss: 0.6931471824645996\n",
      "epoch: 21 step: 114 loss: 0.6931471824645996\n",
      "epoch: 21 step: 115 loss: 0.6931471824645996\n",
      "epoch: 21 step: 116 loss: 0.6931471824645996\n",
      "epoch: 21 step: 117 loss: 0.6931471824645996\n",
      "epoch: 21 step: 118 loss: 0.6931471824645996\n",
      "epoch: 21 step: 119 loss: 0.6931471824645996\n",
      "epoch: 21 step: 120 loss: 0.6931471824645996\n",
      "epoch: 21 step: 121 loss: 0.6931471824645996\n",
      "epoch: 21 step: 122 loss: 0.6931471824645996\n",
      "epoch: 21 step: 123 loss: 0.6931471824645996\n",
      "epoch: 21 step: 124 loss: 0.6931471824645996\n",
      "epoch: 21 step: 125 loss: 0.6931471824645996\n",
      "epoch: 21 step: 126 loss: 0.6931471824645996\n",
      "epoch: 21 step: 127 loss: 0.6931471824645996\n",
      "epoch: 21 step: 128 loss: 0.6931471824645996\n",
      "epoch: 21 step: 129 loss: 0.6931471824645996\n",
      "epoch: 21 step: 130 loss: 0.6931471824645996\n",
      "epoch: 21 step: 131 loss: 0.6931471824645996\n",
      "epoch: 21 step: 132 loss: 0.6931471824645996\n",
      "epoch: 21 step: 133 loss: 0.6931471824645996\n",
      "epoch: 21 step: 134 loss: 0.6931471824645996\n",
      "epoch: 21 step: 135 loss: 0.6931471824645996\n",
      "epoch: 21 step: 136 loss: 0.6931471824645996\n",
      "epoch: 21 step: 137 loss: 0.6931471824645996\n",
      "epoch: 21 step: 138 loss: 0.6931471824645996\n",
      "epoch: 21 step: 139 loss: 0.6931471824645996\n",
      "epoch: 21 step: 140 loss: 0.6931471824645996\n",
      "epoch: 21 step: 141 loss: 0.6931471824645996\n",
      "epoch: 21 step: 142 loss: 0.6931471824645996\n",
      "epoch: 21 step: 143 loss: 0.6931471824645996\n",
      "epoch: 21 step: 144 loss: 0.6931471824645996\n",
      "epoch: 21 step: 145 loss: 0.6931471824645996\n",
      "epoch: 21 step: 146 loss: 0.6931471824645996\n",
      "epoch: 21 step: 147 loss: 0.6931471824645996\n",
      "epoch: 21 step: 148 loss: 0.6931471824645996\n",
      "epoch: 21 step: 149 loss: 0.6931471824645996\n",
      "epoch: 21 step: 150 loss: 0.6931471824645996\n",
      "epoch: 21 step: 151 loss: 0.6931471824645996\n",
      "epoch: 21 step: 152 loss: 0.6931471824645996\n",
      "epoch: 21 step: 153 loss: 0.6931471824645996\n",
      "epoch: 21 step: 154 loss: 0.6931471824645996\n",
      "epoch: 21 step: 155 loss: 0.6931471824645996\n",
      "epoch: 21 step: 156 loss: 0.6931471824645996\n",
      "epoch: 21 step: 157 loss: 0.6931471824645996\n",
      "epoch: 21 step: 158 loss: 0.6931471824645996\n",
      "epoch: 21 step: 159 loss: 0.6931471824645996\n",
      "epoch: 21 step: 160 loss: 0.6931471824645996\n",
      "epoch: 21 step: 161 loss: 0.6931471824645996\n",
      "epoch: 21 step: 162 loss: 0.6931471824645996\n",
      "epoch: 21 step: 163 loss: 0.6931471824645996\n",
      "epoch: 21 step: 164 loss: 0.6931471824645996\n",
      "epoch: 21 step: 165 loss: 0.6931471824645996\n",
      "epoch: 21 step: 166 loss: 0.6931471824645996\n",
      "epoch: 21 step: 167 loss: 0.6931471824645996\n",
      "epoch: 21 step: 168 loss: 0.6931471824645996\n",
      "epoch: 21 step: 169 loss: 0.6931471824645996\n",
      "epoch: 21 step: 170 loss: 0.6931471824645996\n",
      "epoch: 21 step: 171 loss: 0.6931471824645996\n",
      "epoch: 21 step: 172 loss: 0.6931471824645996\n",
      "epoch: 21 step: 173 loss: 0.6931471824645996\n",
      "epoch: 21 step: 174 loss: 0.6931471824645996\n",
      "epoch: 21 step: 175 loss: 0.6931471824645996\n",
      "epoch: 21 step: 176 loss: 0.6931471824645996\n",
      "epoch: 21 step: 177 loss: 0.6931471824645996\n",
      "epoch: 21 step: 178 loss: 0.6931471824645996\n",
      "epoch: 21 step: 179 loss: 0.6931471824645996\n",
      "epoch: 21 step: 180 loss: 0.6931471824645996\n",
      "epoch: 21 step: 181 loss: 0.6931471824645996\n",
      "epoch: 21 step: 182 loss: 0.6931471824645996\n",
      "epoch: 21 step: 183 loss: 0.6931471824645996\n",
      "epoch: 21 step: 184 loss: 0.6931471824645996\n",
      "epoch: 21 step: 185 loss: 0.6931471824645996\n",
      "epoch: 21 step: 186 loss: 0.6931471824645996\n",
      "epoch: 21 step: 187 loss: 0.6931471824645996\n",
      "epoch: 21 step: 188 loss: 0.6931471824645996\n",
      "epoch: 21 step: 189 loss: 0.6931471824645996\n",
      "epoch: 21 step: 190 loss: 0.6931471824645996\n",
      "epoch: 21 step: 191 loss: 0.6931471824645996\n",
      "epoch: 21 step: 192 loss: 0.6931471824645996\n",
      "epoch: 21 step: 193 loss: 0.6931471824645996\n",
      "epoch: 21 step: 194 loss: 0.6931471824645996\n",
      "epoch: 21 step: 195 loss: 0.6931471824645996\n",
      "epoch: 21 step: 196 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 197 loss: 0.6931471824645996\n",
      "epoch: 21 step: 198 loss: 0.6931471824645996\n",
      "epoch: 21 step: 199 loss: 0.6931471824645996\n",
      "epoch: 21 step: 200 loss: 0.6931471824645996\n",
      "epoch: 21 step: 201 loss: 0.6931471824645996\n",
      "epoch: 21 step: 202 loss: 0.6931471824645996\n",
      "epoch: 21 step: 203 loss: 0.6931471824645996\n",
      "epoch: 21 step: 204 loss: 0.6931471824645996\n",
      "epoch: 21 step: 205 loss: 0.6931471824645996\n",
      "epoch: 21 step: 206 loss: 0.6931471824645996\n",
      "epoch: 21 step: 207 loss: 0.6931471824645996\n",
      "epoch: 21 step: 208 loss: 0.6931471824645996\n",
      "epoch: 21 step: 209 loss: 0.6931471824645996\n",
      "epoch: 21 step: 210 loss: 0.6931471824645996\n",
      "epoch: 21 step: 211 loss: 0.6931471824645996\n",
      "epoch: 21 step: 212 loss: 0.6931471824645996\n",
      "epoch: 21 step: 213 loss: 0.6931471824645996\n",
      "epoch: 21 step: 214 loss: 0.6931471824645996\n",
      "epoch: 21 step: 215 loss: 0.6931471824645996\n",
      "epoch: 21 step: 216 loss: 0.6931471824645996\n",
      "epoch: 21 step: 217 loss: 0.6931471824645996\n",
      "epoch: 21 step: 218 loss: 0.6931471824645996\n",
      "epoch: 21 step: 219 loss: 0.6931471824645996\n",
      "epoch: 21 step: 220 loss: 0.6931471824645996\n",
      "epoch: 21 step: 221 loss: 0.6931471824645996\n",
      "epoch: 21 step: 222 loss: 0.6931471824645996\n",
      "epoch: 21 step: 223 loss: 0.6931471824645996\n",
      "epoch: 21 step: 224 loss: 0.6931471824645996\n",
      "epoch: 21 step: 225 loss: 0.6931471824645996\n",
      "epoch: 21 step: 226 loss: 0.6931471824645996\n",
      "epoch: 21 step: 227 loss: 0.6931471824645996\n",
      "epoch: 21 step: 228 loss: 0.6931471824645996\n",
      "epoch: 21 step: 229 loss: 0.6931471824645996\n",
      "epoch: 21 step: 230 loss: 0.6931471824645996\n",
      "epoch: 21 step: 231 loss: 0.6931471824645996\n",
      "epoch: 21 step: 232 loss: 0.6931471824645996\n",
      "epoch: 21 step: 233 loss: 0.6931471824645996\n",
      "epoch: 21 step: 234 loss: 0.6931471824645996\n",
      "epoch: 21 step: 235 loss: 0.6931471824645996\n",
      "epoch: 21 step: 236 loss: 0.6931471824645996\n",
      "epoch: 21 step: 237 loss: 0.6931471824645996\n",
      "epoch: 21 step: 238 loss: 0.6931471824645996\n",
      "epoch: 21 step: 239 loss: 0.6931471824645996\n",
      "epoch: 21 step: 240 loss: 0.6931471824645996\n",
      "epoch: 21 step: 241 loss: 0.6931471824645996\n",
      "epoch: 21 step: 242 loss: 0.6931471824645996\n",
      "epoch: 21 step: 243 loss: 0.6931471824645996\n",
      "epoch: 21 step: 244 loss: 0.6931471824645996\n",
      "epoch: 21 step: 245 loss: 0.6931471824645996\n",
      "epoch: 21 step: 246 loss: 0.6931471824645996\n",
      "epoch: 21 step: 247 loss: 0.6931471824645996\n",
      "epoch: 21 step: 248 loss: 0.6931471824645996\n",
      "epoch: 21 step: 249 loss: 0.6931471824645996\n",
      "epoch: 21 step: 250 loss: 0.6931471824645996\n",
      "epoch: 21 step: 251 loss: 0.6931471824645996\n",
      "epoch: 21 step: 252 loss: 0.6931471824645996\n",
      "epoch: 21 step: 253 loss: 0.6931471824645996\n",
      "epoch: 21 step: 254 loss: 0.6931471824645996\n",
      "epoch: 21 step: 255 loss: 0.6931471824645996\n",
      "epoch: 21 step: 256 loss: 0.6931471824645996\n",
      "epoch: 21 step: 257 loss: 0.6931471824645996\n",
      "epoch: 21 step: 258 loss: 0.6931471824645996\n",
      "epoch: 21 step: 259 loss: 0.6931471824645996\n",
      "epoch: 21 step: 260 loss: 0.6931471824645996\n",
      "epoch: 21 step: 261 loss: 0.6931471824645996\n",
      "epoch: 21 step: 262 loss: 0.6931471824645996\n",
      "epoch: 21 step: 263 loss: 0.6931471824645996\n",
      "epoch: 21 step: 264 loss: 0.6931471824645996\n",
      "epoch: 21 step: 265 loss: 0.6931471824645996\n",
      "epoch: 21 step: 266 loss: 0.6931471824645996\n",
      "epoch: 21 step: 267 loss: 0.6931471824645996\n",
      "epoch: 21 step: 268 loss: 0.6931471824645996\n",
      "epoch: 21 step: 269 loss: 0.6931471824645996\n",
      "epoch: 21 step: 270 loss: 0.6931471824645996\n",
      "epoch: 21 step: 271 loss: 0.6931471824645996\n",
      "epoch: 21 step: 272 loss: 0.6931471824645996\n",
      "epoch: 21 step: 273 loss: 0.6931471824645996\n",
      "epoch: 21 step: 274 loss: 0.6931471824645996\n",
      "epoch: 21 step: 275 loss: 0.6931471824645996\n",
      "epoch: 21 step: 276 loss: 0.6931471824645996\n",
      "epoch: 21 step: 277 loss: 0.6931471824645996\n",
      "epoch: 21 step: 278 loss: 0.6931471824645996\n",
      "epoch: 21 step: 279 loss: 0.6931471824645996\n",
      "epoch: 21 step: 280 loss: 0.6931471824645996\n",
      "epoch: 21 step: 281 loss: 0.6931471824645996\n",
      "epoch: 21 step: 282 loss: 0.6931471824645996\n",
      "epoch: 21 step: 283 loss: 0.6931471824645996\n",
      "epoch: 21 step: 284 loss: 0.6931471824645996\n",
      "epoch: 21 step: 285 loss: 0.6931471824645996\n",
      "epoch: 21 step: 286 loss: 0.6931471824645996\n",
      "epoch: 21 step: 287 loss: 0.6931471824645996\n",
      "epoch: 21 step: 288 loss: 0.6931471824645996\n",
      "epoch: 21 step: 289 loss: 0.6931471824645996\n",
      "epoch: 21 step: 290 loss: 0.6931471824645996\n",
      "epoch: 21 step: 291 loss: 0.6931471824645996\n",
      "epoch: 21 step: 292 loss: 0.6931471824645996\n",
      "epoch: 21 step: 293 loss: 0.6931471824645996\n",
      "epoch: 21 step: 294 loss: 0.6931471824645996\n",
      "epoch: 21 step: 295 loss: 0.6931471824645996\n",
      "epoch: 21 step: 296 loss: 0.6931471824645996\n",
      "epoch: 21 step: 297 loss: 0.6931471824645996\n",
      "epoch: 21 step: 298 loss: 0.6931471824645996\n",
      "epoch: 21 step: 299 loss: 0.6931471824645996\n",
      "epoch: 21 step: 300 loss: 0.6931471824645996\n",
      "epoch: 21 step: 301 loss: 0.6931471824645996\n",
      "epoch: 21 step: 302 loss: 0.6931471824645996\n",
      "epoch: 21 step: 303 loss: 0.6931471824645996\n",
      "epoch: 21 step: 304 loss: 0.6931471824645996\n",
      "epoch: 21 step: 305 loss: 0.6931471824645996\n",
      "epoch: 21 step: 306 loss: 0.6931471824645996\n",
      "epoch: 21 step: 307 loss: 0.6931471824645996\n",
      "epoch: 21 step: 308 loss: 0.6931471824645996\n",
      "epoch: 21 step: 309 loss: 0.6931471824645996\n",
      "epoch: 21 step: 310 loss: 0.6931471824645996\n",
      "epoch: 21 step: 311 loss: 0.6931471824645996\n",
      "epoch: 21 step: 312 loss: 0.6931471824645996\n",
      "epoch: 21 step: 313 loss: 0.6931471824645996\n",
      "epoch: 21 step: 314 loss: 0.6931471824645996\n",
      "epoch: 21 step: 315 loss: 0.6931471824645996\n",
      "epoch: 21 step: 316 loss: 0.6931471824645996\n",
      "epoch: 21 step: 317 loss: 0.6931471824645996\n",
      "epoch: 21 step: 318 loss: 0.6931471824645996\n",
      "epoch: 21 step: 319 loss: 0.6931471824645996\n",
      "epoch: 21 step: 320 loss: 0.6931471824645996\n",
      "epoch: 21 step: 321 loss: 0.6931471824645996\n",
      "epoch: 21 step: 322 loss: 0.6931471824645996\n",
      "epoch: 21 step: 323 loss: 0.6931471824645996\n",
      "epoch: 21 step: 324 loss: 0.6931471824645996\n",
      "epoch: 21 step: 325 loss: 0.6931471824645996\n",
      "epoch: 21 step: 326 loss: 0.6931471824645996\n",
      "epoch: 21 step: 327 loss: 0.6931471824645996\n",
      "epoch: 21 step: 328 loss: 0.6931471824645996\n",
      "epoch: 21 step: 329 loss: 0.6931471824645996\n",
      "epoch: 21 step: 330 loss: 0.6931471824645996\n",
      "epoch: 21 step: 331 loss: 0.6931471824645996\n",
      "epoch: 21 step: 332 loss: 0.6931471824645996\n",
      "epoch: 21 step: 333 loss: 0.6931471824645996\n",
      "epoch: 21 step: 334 loss: 0.6931471824645996\n",
      "epoch: 21 step: 335 loss: 0.6931471824645996\n",
      "epoch: 21 step: 336 loss: 0.6931471824645996\n",
      "epoch: 21 step: 337 loss: 0.6931471824645996\n",
      "epoch: 21 step: 338 loss: 0.6931471824645996\n",
      "epoch: 21 step: 339 loss: 0.6931471824645996\n",
      "epoch: 21 step: 340 loss: 0.6931471824645996\n",
      "epoch: 21 step: 341 loss: 0.6931471824645996\n",
      "epoch: 21 step: 342 loss: 0.6931471824645996\n",
      "epoch: 21 step: 343 loss: 0.6931471824645996\n",
      "epoch: 21 step: 344 loss: 0.6931471824645996\n",
      "epoch: 21 step: 345 loss: 0.6931471824645996\n",
      "epoch: 21 step: 346 loss: 0.6931471824645996\n",
      "epoch: 21 step: 347 loss: 0.6931471824645996\n",
      "epoch: 21 step: 348 loss: 0.6931471824645996\n",
      "epoch: 21 step: 349 loss: 0.6931471824645996\n",
      "epoch: 21 step: 350 loss: 0.6931471824645996\n",
      "epoch: 21 step: 351 loss: 0.6931471824645996\n",
      "epoch: 21 step: 352 loss: 0.6931471824645996\n",
      "epoch: 21 step: 353 loss: 0.6931471824645996\n",
      "epoch: 21 step: 354 loss: 0.6931471824645996\n",
      "epoch: 21 step: 355 loss: 0.6931471824645996\n",
      "epoch: 21 step: 356 loss: 0.6931471824645996\n",
      "epoch: 21 step: 357 loss: 0.6931471824645996\n",
      "epoch: 21 step: 358 loss: 0.6931471824645996\n",
      "epoch: 21 step: 359 loss: 0.6931471824645996\n",
      "epoch: 21 step: 360 loss: 0.6931471824645996\n",
      "epoch: 21 step: 361 loss: 0.6931471824645996\n",
      "epoch: 21 step: 362 loss: 0.6931471824645996\n",
      "epoch: 21 step: 363 loss: 0.6931471824645996\n",
      "epoch: 21 step: 364 loss: 0.6931471824645996\n",
      "epoch: 21 step: 365 loss: 0.6931471824645996\n",
      "epoch: 21 step: 366 loss: 0.6931471824645996\n",
      "epoch: 21 step: 367 loss: 0.6931471824645996\n",
      "epoch: 21 step: 368 loss: 0.6931471824645996\n",
      "epoch: 21 step: 369 loss: 0.6931471824645996\n",
      "epoch: 21 step: 370 loss: 0.6931471824645996\n",
      "epoch: 21 step: 371 loss: 0.6931471824645996\n",
      "epoch: 21 step: 372 loss: 0.6931471824645996\n",
      "epoch: 21 step: 373 loss: 0.6931471824645996\n",
      "epoch: 21 step: 374 loss: 0.6931471824645996\n",
      "epoch: 21 step: 375 loss: 0.6931471824645996\n",
      "epoch: 21 step: 376 loss: 0.6931471824645996\n",
      "epoch: 21 step: 377 loss: 0.6931471824645996\n",
      "epoch: 21 step: 378 loss: 0.6931471824645996\n",
      "epoch: 21 step: 379 loss: 0.6931471824645996\n",
      "epoch: 21 step: 380 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 381 loss: 0.6931471824645996\n",
      "epoch: 21 step: 382 loss: 0.6931471824645996\n",
      "epoch: 21 step: 383 loss: 0.6931471824645996\n",
      "epoch: 21 step: 384 loss: 0.6931471824645996\n",
      "epoch: 21 step: 385 loss: 0.6931471824645996\n",
      "epoch: 21 step: 386 loss: 0.6931471824645996\n",
      "epoch: 21 step: 387 loss: 0.6931471824645996\n",
      "epoch: 21 step: 388 loss: 0.6931471824645996\n",
      "epoch: 21 step: 389 loss: 0.6931471824645996\n",
      "epoch: 21 step: 390 loss: 0.6931471824645996\n",
      "epoch: 21 step: 391 loss: 0.6931471824645996\n",
      "epoch: 21 step: 392 loss: 0.6931471824645996\n",
      "epoch: 21 step: 393 loss: 0.6931471824645996\n",
      "epoch: 21 step: 394 loss: 0.6931471824645996\n",
      "epoch: 21 step: 395 loss: 0.6931471824645996\n",
      "epoch: 21 step: 396 loss: 0.6931471824645996\n",
      "epoch: 21 step: 397 loss: 0.6931471824645996\n",
      "epoch: 21 step: 398 loss: 0.6931471824645996\n",
      "epoch: 21 step: 399 loss: 0.6931471824645996\n",
      "epoch: 21 step: 400 loss: 0.6931471824645996\n",
      "epoch: 21 step: 401 loss: 0.6931471824645996\n",
      "epoch: 21 step: 402 loss: 0.6931471824645996\n",
      "epoch: 21 step: 403 loss: 0.6931471824645996\n",
      "epoch: 21 step: 404 loss: 0.6931471824645996\n",
      "epoch: 21 step: 405 loss: 0.6931471824645996\n",
      "epoch: 21 step: 406 loss: 0.6931471824645996\n",
      "epoch: 21 step: 407 loss: 0.6931471824645996\n",
      "epoch: 21 step: 408 loss: 0.6931471824645996\n",
      "epoch: 21 step: 409 loss: 0.6931471824645996\n",
      "epoch: 21 step: 410 loss: 0.6931471824645996\n",
      "epoch: 21 step: 411 loss: 0.6931471824645996\n",
      "epoch: 21 step: 412 loss: 0.6931471824645996\n",
      "epoch: 21 step: 413 loss: 0.6931471824645996\n",
      "epoch: 21 step: 414 loss: 0.6931471824645996\n",
      "epoch: 21 step: 415 loss: 0.6931471824645996\n",
      "epoch: 21 step: 416 loss: 0.6931471824645996\n",
      "epoch: 21 step: 417 loss: 0.6931471824645996\n",
      "epoch: 21 step: 418 loss: 0.6931471824645996\n",
      "epoch: 21 step: 419 loss: 0.6931471824645996\n",
      "epoch: 21 step: 420 loss: 0.6931471824645996\n",
      "epoch: 21 step: 421 loss: 0.6931471824645996\n",
      "epoch: 21 step: 422 loss: 0.6931471824645996\n",
      "epoch: 21 step: 423 loss: 0.6931471824645996\n",
      "epoch: 21 step: 424 loss: 0.6931471824645996\n",
      "epoch: 21 step: 425 loss: 0.6931471824645996\n",
      "epoch: 21 step: 426 loss: 0.6931471824645996\n",
      "epoch: 21 step: 427 loss: 0.6931471824645996\n",
      "epoch: 21 step: 428 loss: 0.6931471824645996\n",
      "epoch: 21 step: 429 loss: 0.6931471824645996\n",
      "epoch: 21 step: 430 loss: 0.6931471824645996\n",
      "epoch: 21 step: 431 loss: 0.6931471824645996\n",
      "epoch: 21 step: 432 loss: 0.6931471824645996\n",
      "epoch: 21 step: 433 loss: 0.6931471824645996\n",
      "epoch: 21 step: 434 loss: 0.6931471824645996\n",
      "epoch: 21 step: 435 loss: 0.6931471824645996\n",
      "epoch: 21 step: 436 loss: 0.6931471824645996\n",
      "epoch: 21 step: 437 loss: 0.6931471824645996\n",
      "epoch: 21 step: 438 loss: 0.6931471824645996\n",
      "epoch: 21 step: 439 loss: 0.6931471824645996\n",
      "epoch: 21 step: 440 loss: 0.6931471824645996\n",
      "epoch: 21 step: 441 loss: 0.6931471824645996\n",
      "epoch: 21 step: 442 loss: 0.6931471824645996\n",
      "epoch: 21 step: 443 loss: 0.6931471824645996\n",
      "epoch: 21 step: 444 loss: 0.6931471824645996\n",
      "epoch: 21 step: 445 loss: 0.6931471824645996\n",
      "epoch: 21 step: 446 loss: 0.6931471824645996\n",
      "epoch: 21 step: 447 loss: 0.6931471824645996\n",
      "epoch: 21 step: 448 loss: 0.6931471824645996\n",
      "epoch: 21 step: 449 loss: 0.6931471824645996\n",
      "epoch: 21 step: 450 loss: 0.6931471824645996\n",
      "epoch: 21 step: 451 loss: 0.6931471824645996\n",
      "epoch: 21 step: 452 loss: 0.6931471824645996\n",
      "epoch: 21 step: 453 loss: 0.6931471824645996\n",
      "epoch: 21 step: 454 loss: 0.6931471824645996\n",
      "epoch: 21 step: 455 loss: 0.6931471824645996\n",
      "epoch: 21 step: 456 loss: 0.6931471824645996\n",
      "epoch: 21 step: 457 loss: 0.6931471824645996\n",
      "epoch: 21 step: 458 loss: 0.6931471824645996\n",
      "epoch: 21 step: 459 loss: 0.6931471824645996\n",
      "epoch: 21 step: 460 loss: 0.6931471824645996\n",
      "epoch: 21 step: 461 loss: 0.6931471824645996\n",
      "epoch: 21 step: 462 loss: 0.6931471824645996\n",
      "epoch: 21 step: 463 loss: 0.6931471824645996\n",
      "epoch: 21 step: 464 loss: 0.6931471824645996\n",
      "epoch: 21 step: 465 loss: 0.6931471824645996\n",
      "epoch: 21 step: 466 loss: 0.6931471824645996\n",
      "epoch: 21 step: 467 loss: 0.6931471824645996\n",
      "epoch: 21 step: 468 loss: 0.6931471824645996\n",
      "epoch: 21 step: 469 loss: 0.6931471824645996\n",
      "epoch: 21 step: 470 loss: 0.6931471824645996\n",
      "epoch: 21 step: 471 loss: 0.6931471824645996\n",
      "epoch: 21 step: 472 loss: 0.6931471824645996\n",
      "epoch: 21 step: 473 loss: 0.6931471824645996\n",
      "epoch: 21 step: 474 loss: 0.6931471824645996\n",
      "epoch: 21 step: 475 loss: 0.6931471824645996\n",
      "epoch: 21 step: 476 loss: 0.6931471824645996\n",
      "epoch: 21 step: 477 loss: 0.6931471824645996\n",
      "epoch: 21 step: 478 loss: 0.6931471824645996\n",
      "epoch: 21 step: 479 loss: 0.6931471824645996\n",
      "epoch: 21 step: 480 loss: 0.6931471824645996\n",
      "epoch: 21 step: 481 loss: 0.6931471824645996\n",
      "epoch: 21 step: 482 loss: 0.6931471824645996\n",
      "epoch: 21 step: 483 loss: 0.6931471824645996\n",
      "epoch: 21 step: 484 loss: 0.6931471824645996\n",
      "epoch: 21 step: 485 loss: 0.6931471824645996\n",
      "epoch: 21 step: 486 loss: 0.6931471824645996\n",
      "epoch: 21 step: 487 loss: 0.6931471824645996\n",
      "epoch: 21 step: 488 loss: 0.6931471824645996\n",
      "epoch: 21 step: 489 loss: 0.6931471824645996\n",
      "epoch: 21 step: 490 loss: 0.6931471824645996\n",
      "epoch: 21 step: 491 loss: 0.6931471824645996\n",
      "epoch: 21 step: 492 loss: 0.6931471824645996\n",
      "epoch: 21 step: 493 loss: 0.6931471824645996\n",
      "epoch: 21 step: 494 loss: 0.6931471824645996\n",
      "epoch: 21 step: 495 loss: 0.6931471824645996\n",
      "epoch: 21 step: 496 loss: 0.6931471824645996\n",
      "epoch: 21 step: 497 loss: 0.6931471824645996\n",
      "epoch: 21 step: 498 loss: 0.6931471824645996\n",
      "epoch: 21 step: 499 loss: 0.6931471824645996\n",
      "epoch: 21 step: 500 loss: 0.6931471824645996\n",
      "epoch: 21 step: 501 loss: 0.6931471824645996\n",
      "epoch: 21 step: 502 loss: 0.6931471824645996\n",
      "epoch: 21 step: 503 loss: 0.6931471824645996\n",
      "epoch: 21 step: 504 loss: 0.6931471824645996\n",
      "epoch: 21 step: 505 loss: 0.6931471824645996\n",
      "epoch: 21 step: 506 loss: 0.6931471824645996\n",
      "epoch: 21 step: 507 loss: 0.6931471824645996\n",
      "epoch: 21 step: 508 loss: 0.6931471824645996\n",
      "epoch: 21 step: 509 loss: 0.6931471824645996\n",
      "epoch: 21 step: 510 loss: 0.6931471824645996\n",
      "epoch: 21 step: 511 loss: 0.6931471824645996\n",
      "epoch: 21 step: 512 loss: 0.6931471824645996\n",
      "epoch: 21 step: 513 loss: 0.6931471824645996\n",
      "epoch: 21 step: 514 loss: 0.6931471824645996\n",
      "epoch: 21 step: 515 loss: 0.6931471824645996\n",
      "epoch: 21 step: 516 loss: 0.6931471824645996\n",
      "epoch: 21 step: 517 loss: 0.6931471824645996\n",
      "epoch: 21 step: 518 loss: 0.6931471824645996\n",
      "epoch: 21 step: 519 loss: 0.6931471824645996\n",
      "epoch: 21 step: 520 loss: 0.6931471824645996\n",
      "epoch: 21 step: 521 loss: 0.6931471824645996\n",
      "epoch: 21 step: 522 loss: 0.6931471824645996\n",
      "epoch: 21 step: 523 loss: 0.6931471824645996\n",
      "epoch: 21 step: 524 loss: 0.6931471824645996\n",
      "epoch: 21 step: 525 loss: 0.6931471824645996\n",
      "epoch: 21 step: 526 loss: 0.6931471824645996\n",
      "epoch: 21 step: 527 loss: 0.6931471824645996\n",
      "epoch: 21 step: 528 loss: 0.6931471824645996\n",
      "epoch: 21 step: 529 loss: 0.6931471824645996\n",
      "epoch: 21 step: 530 loss: 0.6931471824645996\n",
      "epoch: 21 step: 531 loss: 0.6931471824645996\n",
      "epoch: 21 step: 532 loss: 0.6931471824645996\n",
      "epoch: 21 step: 533 loss: 0.6931471824645996\n",
      "epoch: 21 step: 534 loss: 0.6931471824645996\n",
      "epoch: 21 step: 535 loss: 0.6931471824645996\n",
      "epoch: 21 step: 536 loss: 0.6931471824645996\n",
      "epoch: 21 step: 537 loss: 0.6931471824645996\n",
      "epoch: 21 step: 538 loss: 0.6931471824645996\n",
      "epoch: 21 step: 539 loss: 0.6931471824645996\n",
      "epoch: 21 step: 540 loss: 0.6931471824645996\n",
      "epoch: 21 step: 541 loss: 0.6931471824645996\n",
      "epoch: 21 step: 542 loss: 0.6931471824645996\n",
      "epoch: 21 step: 543 loss: 0.6931471824645996\n",
      "epoch: 21 step: 544 loss: 0.6931471824645996\n",
      "epoch: 21 step: 545 loss: 0.6931471824645996\n",
      "epoch: 21 step: 546 loss: 0.6931471824645996\n",
      "epoch: 21 step: 547 loss: 0.6931471824645996\n",
      "epoch: 21 step: 548 loss: 0.6931471824645996\n",
      "epoch: 21 step: 549 loss: 0.6931471824645996\n",
      "epoch: 21 step: 550 loss: 0.6931471824645996\n",
      "epoch: 21 step: 551 loss: 0.6931471824645996\n",
      "epoch: 21 step: 552 loss: 0.6931471824645996\n",
      "epoch: 21 step: 553 loss: 0.6931471824645996\n",
      "epoch: 21 step: 554 loss: 0.6931471824645996\n",
      "epoch: 21 step: 555 loss: 0.6931471824645996\n",
      "epoch: 21 step: 556 loss: 0.6931471824645996\n",
      "epoch: 21 step: 557 loss: 0.6931471824645996\n",
      "epoch: 21 step: 558 loss: 0.6931471824645996\n",
      "epoch: 21 step: 559 loss: 0.6931471824645996\n",
      "epoch: 21 step: 560 loss: 0.6931471824645996\n",
      "epoch: 21 step: 561 loss: 0.6931471824645996\n",
      "epoch: 21 step: 562 loss: 0.6931471824645996\n",
      "epoch: 21 step: 563 loss: 0.6931471824645996\n",
      "epoch: 21 step: 564 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 565 loss: 0.6931471824645996\n",
      "epoch: 21 step: 566 loss: 0.6931471824645996\n",
      "epoch: 21 step: 567 loss: 0.6931471824645996\n",
      "epoch: 21 step: 568 loss: 0.6931471824645996\n",
      "epoch: 21 step: 569 loss: 0.6931471824645996\n",
      "epoch: 21 step: 570 loss: 0.6931471824645996\n",
      "epoch: 21 step: 571 loss: 0.6931471824645996\n",
      "epoch: 21 step: 572 loss: 0.6931471824645996\n",
      "epoch: 21 step: 573 loss: 0.6931471824645996\n",
      "epoch: 21 step: 574 loss: 0.6931471824645996\n",
      "epoch: 21 step: 575 loss: 0.6931471824645996\n",
      "epoch: 21 step: 576 loss: 0.6931471824645996\n",
      "epoch: 21 step: 577 loss: 0.6931471824645996\n",
      "epoch: 21 step: 578 loss: 0.6931471824645996\n",
      "epoch: 21 step: 579 loss: 0.6931471824645996\n",
      "epoch: 21 step: 580 loss: 0.6931471824645996\n",
      "epoch: 21 step: 581 loss: 0.6931471824645996\n",
      "epoch: 21 step: 582 loss: 0.6931471824645996\n",
      "epoch: 21 step: 583 loss: 0.6931471824645996\n",
      "epoch: 21 step: 584 loss: 0.6931471824645996\n",
      "epoch: 21 step: 585 loss: 0.6931471824645996\n",
      "epoch: 21 step: 586 loss: 0.6931471824645996\n",
      "epoch: 21 step: 587 loss: 0.6931471824645996\n",
      "epoch: 21 step: 588 loss: 0.6931471824645996\n",
      "epoch: 21 step: 589 loss: 0.6931471824645996\n",
      "epoch: 21 step: 590 loss: 0.6931471824645996\n",
      "epoch: 21 step: 591 loss: 0.6931471824645996\n",
      "epoch: 21 step: 592 loss: 0.6931471824645996\n",
      "epoch: 21 step: 593 loss: 0.6931471824645996\n",
      "epoch: 21 step: 594 loss: 0.6931471824645996\n",
      "epoch: 21 step: 595 loss: 0.6931471824645996\n",
      "epoch: 21 step: 596 loss: 0.6931471824645996\n",
      "epoch: 21 step: 597 loss: 0.6931471824645996\n",
      "epoch: 21 step: 598 loss: 0.6931471824645996\n",
      "epoch: 21 step: 599 loss: 0.6931471824645996\n",
      "epoch: 21 step: 600 loss: 0.6931471824645996\n",
      "epoch: 21 step: 601 loss: 0.6931471824645996\n",
      "epoch: 21 step: 602 loss: 0.6931471824645996\n",
      "epoch: 21 step: 603 loss: 0.6931471824645996\n",
      "epoch: 21 step: 604 loss: 0.6931471824645996\n",
      "epoch: 21 step: 605 loss: 0.6931471824645996\n",
      "epoch: 21 step: 606 loss: 0.6931471824645996\n",
      "epoch: 21 step: 607 loss: 0.6931471824645996\n",
      "epoch: 21 step: 608 loss: 0.6931471824645996\n",
      "epoch: 21 step: 609 loss: 0.6931471824645996\n",
      "epoch: 21 step: 610 loss: 0.6931471824645996\n",
      "epoch: 21 step: 611 loss: 0.6931471824645996\n",
      "epoch: 21 step: 612 loss: 0.6931471824645996\n",
      "epoch: 21 step: 613 loss: 0.6931471824645996\n",
      "epoch: 21 step: 614 loss: 0.6931471824645996\n",
      "epoch: 21 step: 615 loss: 0.6931471824645996\n",
      "epoch: 21 step: 616 loss: 0.6931471824645996\n",
      "epoch: 21 step: 617 loss: 0.6931471824645996\n",
      "epoch: 21 step: 618 loss: 0.6931471824645996\n",
      "epoch: 21 step: 619 loss: 0.6931471824645996\n",
      "epoch: 21 step: 620 loss: 0.6931471824645996\n",
      "epoch: 21 step: 621 loss: 0.6931471824645996\n",
      "epoch: 21 step: 622 loss: 0.6931471824645996\n",
      "epoch: 21 step: 623 loss: 0.6931471824645996\n",
      "epoch: 21 step: 624 loss: 0.6931471824645996\n",
      "epoch: 21 step: 625 loss: 0.6931471824645996\n",
      "epoch: 21 step: 626 loss: 0.6931471824645996\n",
      "epoch: 21 step: 627 loss: 0.6931471824645996\n",
      "epoch: 21 step: 628 loss: 0.6931471824645996\n",
      "epoch: 21 step: 629 loss: 0.6931471824645996\n",
      "epoch: 21 step: 630 loss: 0.6931471824645996\n",
      "epoch: 21 step: 631 loss: 0.6931471824645996\n",
      "epoch: 21 step: 632 loss: 0.6931471824645996\n",
      "epoch: 21 step: 633 loss: 0.6931471824645996\n",
      "epoch: 21 step: 634 loss: 0.6931471824645996\n",
      "epoch: 21 step: 635 loss: 0.6931471824645996\n",
      "epoch: 21 step: 636 loss: 0.6931471824645996\n",
      "epoch: 21 step: 637 loss: 0.6931471824645996\n",
      "epoch: 21 step: 638 loss: 0.6931471824645996\n",
      "epoch: 21 step: 639 loss: 0.6931471824645996\n",
      "epoch: 21 step: 640 loss: 0.6931471824645996\n",
      "epoch: 21 step: 641 loss: 0.6931471824645996\n",
      "epoch: 21 step: 642 loss: 0.6931471824645996\n",
      "epoch: 21 step: 643 loss: 0.6931471824645996\n",
      "epoch: 21 step: 644 loss: 0.6931471824645996\n",
      "epoch: 21 step: 645 loss: 0.6931471824645996\n",
      "epoch: 21 step: 646 loss: 0.6931471824645996\n",
      "epoch: 21 step: 647 loss: 0.6931471824645996\n",
      "epoch: 21 step: 648 loss: 0.6931471824645996\n",
      "epoch: 21 step: 649 loss: 0.6931471824645996\n",
      "epoch: 21 step: 650 loss: 0.6931471824645996\n",
      "epoch: 21 step: 651 loss: 0.6931471824645996\n",
      "epoch: 21 step: 652 loss: 0.6931471824645996\n",
      "epoch: 21 step: 653 loss: 0.6931471824645996\n",
      "epoch: 21 step: 654 loss: 0.6931471824645996\n",
      "epoch: 21 step: 655 loss: 0.6931471824645996\n",
      "epoch: 21 step: 656 loss: 0.6931471824645996\n",
      "epoch: 21 step: 657 loss: 0.6931471824645996\n",
      "epoch: 21 step: 658 loss: 0.6931471824645996\n",
      "epoch: 21 step: 659 loss: 0.6931471824645996\n",
      "epoch: 21 step: 660 loss: 0.6931471824645996\n",
      "epoch: 21 step: 661 loss: 0.6931471824645996\n",
      "epoch: 21 step: 662 loss: 0.6931471824645996\n",
      "epoch: 21 step: 663 loss: 0.6931471824645996\n",
      "epoch: 21 step: 664 loss: 0.6931471824645996\n",
      "epoch: 21 step: 665 loss: 0.6931471824645996\n",
      "epoch: 21 step: 666 loss: 0.6931471824645996\n",
      "epoch: 21 step: 667 loss: 0.6931471824645996\n",
      "epoch: 21 step: 668 loss: 0.6931471824645996\n",
      "epoch: 21 step: 669 loss: 0.6931471824645996\n",
      "epoch: 21 step: 670 loss: 0.6931471824645996\n",
      "epoch: 21 step: 671 loss: 0.6931471824645996\n",
      "epoch: 21 step: 672 loss: 0.6931471824645996\n",
      "epoch: 21 step: 673 loss: 0.6931471824645996\n",
      "epoch: 21 step: 674 loss: 0.6931471824645996\n",
      "epoch: 21 step: 675 loss: 0.6931471824645996\n",
      "epoch: 21 step: 676 loss: 0.6931471824645996\n",
      "epoch: 21 step: 677 loss: 0.6931471824645996\n",
      "epoch: 21 step: 678 loss: 0.6931471824645996\n",
      "epoch: 21 step: 679 loss: 0.6931471824645996\n",
      "epoch: 21 step: 680 loss: 0.6931471824645996\n",
      "epoch: 21 step: 681 loss: 0.6931471824645996\n",
      "epoch: 21 step: 682 loss: 0.6931471824645996\n",
      "epoch: 21 step: 683 loss: 0.6931471824645996\n",
      "epoch: 21 step: 684 loss: 0.6931471824645996\n",
      "epoch: 21 step: 685 loss: 0.6931471824645996\n",
      "epoch: 21 step: 686 loss: 0.6931471824645996\n",
      "epoch: 21 step: 687 loss: 0.6931471824645996\n",
      "epoch: 21 step: 688 loss: 0.6931471824645996\n",
      "epoch: 21 step: 689 loss: 0.6931471824645996\n",
      "epoch: 21 step: 690 loss: 0.6931471824645996\n",
      "epoch: 21 step: 691 loss: 0.6931471824645996\n",
      "epoch: 21 step: 692 loss: 0.6931471824645996\n",
      "epoch: 21 step: 693 loss: 0.6931471824645996\n",
      "epoch: 21 step: 694 loss: 0.6931471824645996\n",
      "epoch: 21 step: 695 loss: 0.6931471824645996\n",
      "epoch: 21 step: 696 loss: 0.6931471824645996\n",
      "epoch: 21 step: 697 loss: 0.6931471824645996\n",
      "epoch: 21 step: 698 loss: 0.6931471824645996\n",
      "epoch: 21 step: 699 loss: 0.6931471824645996\n",
      "epoch: 21 step: 700 loss: 0.6931471824645996\n",
      "epoch: 21 step: 701 loss: 0.6931471824645996\n",
      "epoch: 21 step: 702 loss: 0.6931471824645996\n",
      "epoch: 21 step: 703 loss: 0.6931471824645996\n",
      "epoch: 21 step: 704 loss: 0.6931471824645996\n",
      "epoch: 21 step: 705 loss: 0.6931471824645996\n",
      "epoch: 21 step: 706 loss: 0.6931471824645996\n",
      "epoch: 21 step: 707 loss: 0.6931471824645996\n",
      "epoch: 21 step: 708 loss: 0.6931471824645996\n",
      "epoch: 21 step: 709 loss: 0.6931471824645996\n",
      "epoch: 21 step: 710 loss: 0.6931471824645996\n",
      "epoch: 21 step: 711 loss: 0.6931471824645996\n",
      "epoch: 21 step: 712 loss: 0.6931471824645996\n",
      "epoch: 21 step: 713 loss: 0.6931471824645996\n",
      "epoch: 21 step: 714 loss: 0.6931471824645996\n",
      "epoch: 21 step: 715 loss: 0.6931471824645996\n",
      "epoch: 21 step: 716 loss: 0.6931471824645996\n",
      "epoch: 21 step: 717 loss: 0.6931471824645996\n",
      "epoch: 21 step: 718 loss: 0.6931471824645996\n",
      "epoch: 21 step: 719 loss: 0.6931471824645996\n",
      "epoch: 21 step: 720 loss: 0.6931471824645996\n",
      "epoch: 21 step: 721 loss: 0.6931471824645996\n",
      "epoch: 21 step: 722 loss: 0.6931471824645996\n",
      "epoch: 21 step: 723 loss: 0.6931471824645996\n",
      "epoch: 21 step: 724 loss: 0.6931471824645996\n",
      "epoch: 21 step: 725 loss: 0.6931471824645996\n",
      "epoch: 21 step: 726 loss: 0.6931471824645996\n",
      "epoch: 21 step: 727 loss: 0.6931471824645996\n",
      "epoch: 21 step: 728 loss: 0.6931471824645996\n",
      "epoch: 21 step: 729 loss: 0.6931471824645996\n",
      "epoch: 21 step: 730 loss: 0.6931471824645996\n",
      "epoch: 21 step: 731 loss: 0.6931471824645996\n",
      "epoch: 21 step: 732 loss: 0.6931471824645996\n",
      "epoch: 21 step: 733 loss: 0.6931471824645996\n",
      "epoch: 21 step: 734 loss: 0.6931471824645996\n",
      "epoch: 21 step: 735 loss: 0.6931471824645996\n",
      "epoch: 21 step: 736 loss: 0.6931471824645996\n",
      "epoch: 21 step: 737 loss: 0.6931471824645996\n",
      "epoch: 21 step: 738 loss: 0.6931471824645996\n",
      "epoch: 21 step: 739 loss: 0.6931471824645996\n",
      "epoch: 21 step: 740 loss: 0.6931471824645996\n",
      "epoch: 21 step: 741 loss: 0.6931471824645996\n",
      "epoch: 21 step: 742 loss: 0.6931471824645996\n",
      "epoch: 21 step: 743 loss: 0.6931471824645996\n",
      "epoch: 21 step: 744 loss: 0.6931471824645996\n",
      "epoch: 21 step: 745 loss: 0.6931471824645996\n",
      "epoch: 21 step: 746 loss: 0.6931471824645996\n",
      "epoch: 21 step: 747 loss: 0.6931471824645996\n",
      "epoch: 21 step: 748 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 749 loss: 0.6931471824645996\n",
      "epoch: 21 step: 750 loss: 0.6931471824645996\n",
      "epoch: 21 step: 751 loss: 0.6931471824645996\n",
      "epoch: 21 step: 752 loss: 0.6931471824645996\n",
      "epoch: 21 step: 753 loss: 0.6931471824645996\n",
      "epoch: 21 step: 754 loss: 0.6931471824645996\n",
      "epoch: 21 step: 755 loss: 0.6931471824645996\n",
      "epoch: 21 step: 756 loss: 0.6931471824645996\n",
      "epoch: 21 step: 757 loss: 0.6931471824645996\n",
      "epoch: 21 step: 758 loss: 0.6931471824645996\n",
      "epoch: 21 step: 759 loss: 0.6931471824645996\n",
      "epoch: 21 step: 760 loss: 0.6931471824645996\n",
      "epoch: 21 step: 761 loss: 0.6931471824645996\n",
      "epoch: 21 step: 762 loss: 0.6931471824645996\n",
      "epoch: 21 step: 763 loss: 0.6931471824645996\n",
      "epoch: 21 step: 764 loss: 0.6931471824645996\n",
      "epoch: 21 step: 765 loss: 0.6931471824645996\n",
      "epoch: 21 step: 766 loss: 0.6931471824645996\n",
      "epoch: 21 step: 767 loss: 0.6931471824645996\n",
      "epoch: 21 step: 768 loss: 0.6931471824645996\n",
      "epoch: 21 step: 769 loss: 0.6931471824645996\n",
      "epoch: 21 step: 770 loss: 0.6931471824645996\n",
      "epoch: 21 step: 771 loss: 0.6931471824645996\n",
      "epoch: 21 step: 772 loss: 0.6931471824645996\n",
      "epoch: 21 step: 773 loss: 0.6931471824645996\n",
      "epoch: 21 step: 774 loss: 0.6931471824645996\n",
      "epoch: 21 step: 775 loss: 0.6931471824645996\n",
      "epoch: 21 step: 776 loss: 0.6931471824645996\n",
      "epoch: 21 step: 777 loss: 0.6931471824645996\n",
      "epoch: 21 step: 778 loss: 0.6931471824645996\n",
      "epoch: 21 step: 779 loss: 0.6931471824645996\n",
      "epoch: 21 step: 780 loss: 0.6931471824645996\n",
      "epoch: 21 step: 781 loss: 0.6931471824645996\n",
      "epoch: 22 step: 1 loss: 0.6931471824645996\n",
      "epoch: 22 step: 2 loss: 0.6931471824645996\n",
      "epoch: 22 step: 3 loss: 0.6931471824645996\n",
      "epoch: 22 step: 4 loss: 0.6931471824645996\n",
      "epoch: 22 step: 5 loss: 0.6931471824645996\n",
      "epoch: 22 step: 6 loss: 0.6931471824645996\n",
      "epoch: 22 step: 7 loss: 0.6931471824645996\n",
      "epoch: 22 step: 8 loss: 0.6931471824645996\n",
      "epoch: 22 step: 9 loss: 0.6931471824645996\n",
      "epoch: 22 step: 10 loss: 0.6931471824645996\n",
      "epoch: 22 step: 11 loss: 0.6931471824645996\n",
      "epoch: 22 step: 12 loss: 0.6931471824645996\n",
      "epoch: 22 step: 13 loss: 0.6931471824645996\n",
      "epoch: 22 step: 14 loss: 0.6931471824645996\n",
      "epoch: 22 step: 15 loss: 0.6931471824645996\n",
      "epoch: 22 step: 16 loss: 0.6931471824645996\n",
      "epoch: 22 step: 17 loss: 0.6931471824645996\n",
      "epoch: 22 step: 18 loss: 0.6931471824645996\n",
      "epoch: 22 step: 19 loss: 0.6931471824645996\n",
      "epoch: 22 step: 20 loss: 0.6931471824645996\n",
      "epoch: 22 step: 21 loss: 0.6931471824645996\n",
      "epoch: 22 step: 22 loss: 0.6931471824645996\n",
      "epoch: 22 step: 23 loss: 0.6931471824645996\n",
      "epoch: 22 step: 24 loss: 0.6931471824645996\n",
      "epoch: 22 step: 25 loss: 0.6931471824645996\n",
      "epoch: 22 step: 26 loss: 0.6931471824645996\n",
      "epoch: 22 step: 27 loss: 0.6931471824645996\n",
      "epoch: 22 step: 28 loss: 0.6931471824645996\n",
      "epoch: 22 step: 29 loss: 0.6931471824645996\n",
      "epoch: 22 step: 30 loss: 0.6931471824645996\n",
      "epoch: 22 step: 31 loss: 0.6931471824645996\n",
      "epoch: 22 step: 32 loss: 0.6931471824645996\n",
      "epoch: 22 step: 33 loss: 0.6931471824645996\n",
      "epoch: 22 step: 34 loss: 0.6931471824645996\n",
      "epoch: 22 step: 35 loss: 0.6931471824645996\n",
      "epoch: 22 step: 36 loss: 0.6931471824645996\n",
      "epoch: 22 step: 37 loss: 0.6931471824645996\n",
      "epoch: 22 step: 38 loss: 0.6931471824645996\n",
      "epoch: 22 step: 39 loss: 0.6931471824645996\n",
      "epoch: 22 step: 40 loss: 0.6931471824645996\n",
      "epoch: 22 step: 41 loss: 0.6931471824645996\n",
      "epoch: 22 step: 42 loss: 0.6931471824645996\n",
      "epoch: 22 step: 43 loss: 0.6931471824645996\n",
      "epoch: 22 step: 44 loss: 0.6931471824645996\n",
      "epoch: 22 step: 45 loss: 0.6931471824645996\n",
      "epoch: 22 step: 46 loss: 0.6931471824645996\n",
      "epoch: 22 step: 47 loss: 0.6931471824645996\n",
      "epoch: 22 step: 48 loss: 0.6931471824645996\n",
      "epoch: 22 step: 49 loss: 0.6931471824645996\n",
      "epoch: 22 step: 50 loss: 0.6931471824645996\n",
      "epoch: 22 step: 51 loss: 0.6931471824645996\n",
      "epoch: 22 step: 52 loss: 0.6931471824645996\n",
      "epoch: 22 step: 53 loss: 0.6931471824645996\n",
      "epoch: 22 step: 54 loss: 0.6931471824645996\n",
      "epoch: 22 step: 55 loss: 0.6931471824645996\n",
      "epoch: 22 step: 56 loss: 0.6931471824645996\n",
      "epoch: 22 step: 57 loss: 0.6931471824645996\n",
      "epoch: 22 step: 58 loss: 0.6931471824645996\n",
      "epoch: 22 step: 59 loss: 0.6931471824645996\n",
      "epoch: 22 step: 60 loss: 0.6931471824645996\n",
      "epoch: 22 step: 61 loss: 0.6931471824645996\n",
      "epoch: 22 step: 62 loss: 0.6931471824645996\n",
      "epoch: 22 step: 63 loss: 0.6931471824645996\n",
      "epoch: 22 step: 64 loss: 0.6931471824645996\n",
      "epoch: 22 step: 65 loss: 0.6931471824645996\n",
      "epoch: 22 step: 66 loss: 0.6931471824645996\n",
      "epoch: 22 step: 67 loss: 0.6931471824645996\n",
      "epoch: 22 step: 68 loss: 0.6931471824645996\n",
      "epoch: 22 step: 69 loss: 0.6931471824645996\n",
      "epoch: 22 step: 70 loss: 0.6931471824645996\n",
      "epoch: 22 step: 71 loss: 0.6931471824645996\n",
      "epoch: 22 step: 72 loss: 0.6931471824645996\n",
      "epoch: 22 step: 73 loss: 0.6931471824645996\n",
      "epoch: 22 step: 74 loss: 0.6931471824645996\n",
      "epoch: 22 step: 75 loss: 0.6931471824645996\n",
      "epoch: 22 step: 76 loss: 0.6931471824645996\n",
      "epoch: 22 step: 77 loss: 0.6931471824645996\n",
      "epoch: 22 step: 78 loss: 0.6931471824645996\n",
      "epoch: 22 step: 79 loss: 0.6931471824645996\n",
      "epoch: 22 step: 80 loss: 0.6931471824645996\n",
      "epoch: 22 step: 81 loss: 0.6931471824645996\n",
      "epoch: 22 step: 82 loss: 0.6931471824645996\n",
      "epoch: 22 step: 83 loss: 0.6931471824645996\n",
      "epoch: 22 step: 84 loss: 0.6931471824645996\n",
      "epoch: 22 step: 85 loss: 0.6931471824645996\n",
      "epoch: 22 step: 86 loss: 0.6931471824645996\n",
      "epoch: 22 step: 87 loss: 0.6931471824645996\n",
      "epoch: 22 step: 88 loss: 0.6931471824645996\n",
      "epoch: 22 step: 89 loss: 0.6931471824645996\n",
      "epoch: 22 step: 90 loss: 0.6931471824645996\n",
      "epoch: 22 step: 91 loss: 0.6931471824645996\n",
      "epoch: 22 step: 92 loss: 0.6931471824645996\n",
      "epoch: 22 step: 93 loss: 0.6931471824645996\n",
      "epoch: 22 step: 94 loss: 0.6931471824645996\n",
      "epoch: 22 step: 95 loss: 0.6931471824645996\n",
      "epoch: 22 step: 96 loss: 0.6931471824645996\n",
      "epoch: 22 step: 97 loss: 0.6931471824645996\n",
      "epoch: 22 step: 98 loss: 0.6931471824645996\n",
      "epoch: 22 step: 99 loss: 0.6931471824645996\n",
      "epoch: 22 step: 100 loss: 0.6931471824645996\n",
      "epoch: 22 step: 101 loss: 0.6931471824645996\n",
      "epoch: 22 step: 102 loss: 0.6931471824645996\n",
      "epoch: 22 step: 103 loss: 0.6931471824645996\n",
      "epoch: 22 step: 104 loss: 0.6931471824645996\n",
      "epoch: 22 step: 105 loss: 0.6931471824645996\n",
      "epoch: 22 step: 106 loss: 0.6931471824645996\n",
      "epoch: 22 step: 107 loss: 0.6931471824645996\n",
      "epoch: 22 step: 108 loss: 0.6931471824645996\n",
      "epoch: 22 step: 109 loss: 0.6931471824645996\n",
      "epoch: 22 step: 110 loss: 0.6931471824645996\n",
      "epoch: 22 step: 111 loss: 0.6931471824645996\n",
      "epoch: 22 step: 112 loss: 0.6931471824645996\n",
      "epoch: 22 step: 113 loss: 0.6931471824645996\n",
      "epoch: 22 step: 114 loss: 0.6931471824645996\n",
      "epoch: 22 step: 115 loss: 0.6931471824645996\n",
      "epoch: 22 step: 116 loss: 0.6931471824645996\n",
      "epoch: 22 step: 117 loss: 0.6931471824645996\n",
      "epoch: 22 step: 118 loss: 0.6931471824645996\n",
      "epoch: 22 step: 119 loss: 0.6931471824645996\n",
      "epoch: 22 step: 120 loss: 0.6931471824645996\n",
      "epoch: 22 step: 121 loss: 0.6931471824645996\n",
      "epoch: 22 step: 122 loss: 0.6931471824645996\n",
      "epoch: 22 step: 123 loss: 0.6931471824645996\n",
      "epoch: 22 step: 124 loss: 0.6931471824645996\n",
      "epoch: 22 step: 125 loss: 0.6931471824645996\n",
      "epoch: 22 step: 126 loss: 0.6931471824645996\n",
      "epoch: 22 step: 127 loss: 0.6931471824645996\n",
      "epoch: 22 step: 128 loss: 0.6931471824645996\n",
      "epoch: 22 step: 129 loss: 0.6931471824645996\n",
      "epoch: 22 step: 130 loss: 0.6931471824645996\n",
      "epoch: 22 step: 131 loss: 0.6931471824645996\n",
      "epoch: 22 step: 132 loss: 0.6931471824645996\n",
      "epoch: 22 step: 133 loss: 0.6931471824645996\n",
      "epoch: 22 step: 134 loss: 0.6931471824645996\n",
      "epoch: 22 step: 135 loss: 0.6931471824645996\n",
      "epoch: 22 step: 136 loss: 0.6931471824645996\n",
      "epoch: 22 step: 137 loss: 0.6931471824645996\n",
      "epoch: 22 step: 138 loss: 0.6931471824645996\n",
      "epoch: 22 step: 139 loss: 0.6931471824645996\n",
      "epoch: 22 step: 140 loss: 0.6931471824645996\n",
      "epoch: 22 step: 141 loss: 0.6931471824645996\n",
      "epoch: 22 step: 142 loss: 0.6931471824645996\n",
      "epoch: 22 step: 143 loss: 0.6931471824645996\n",
      "epoch: 22 step: 144 loss: 0.6931471824645996\n",
      "epoch: 22 step: 145 loss: 0.6931471824645996\n",
      "epoch: 22 step: 146 loss: 0.6931471824645996\n",
      "epoch: 22 step: 147 loss: 0.6931471824645996\n",
      "epoch: 22 step: 148 loss: 0.6931471824645996\n",
      "epoch: 22 step: 149 loss: 0.6931471824645996\n",
      "epoch: 22 step: 150 loss: 0.6931471824645996\n",
      "epoch: 22 step: 151 loss: 0.6931471824645996\n",
      "epoch: 22 step: 152 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 153 loss: 0.6931471824645996\n",
      "epoch: 22 step: 154 loss: 0.6931471824645996\n",
      "epoch: 22 step: 155 loss: 0.6931471824645996\n",
      "epoch: 22 step: 156 loss: 0.6931471824645996\n",
      "epoch: 22 step: 157 loss: 0.6931471824645996\n",
      "epoch: 22 step: 158 loss: 0.6931471824645996\n",
      "epoch: 22 step: 159 loss: 0.6931471824645996\n",
      "epoch: 22 step: 160 loss: 0.6931471824645996\n",
      "epoch: 22 step: 161 loss: 0.6931471824645996\n",
      "epoch: 22 step: 162 loss: 0.6931471824645996\n",
      "epoch: 22 step: 163 loss: 0.6931471824645996\n",
      "epoch: 22 step: 164 loss: 0.6931471824645996\n",
      "epoch: 22 step: 165 loss: 0.6931471824645996\n",
      "epoch: 22 step: 166 loss: 0.6931471824645996\n",
      "epoch: 22 step: 167 loss: 0.6931471824645996\n",
      "epoch: 22 step: 168 loss: 0.6931471824645996\n",
      "epoch: 22 step: 169 loss: 0.6931471824645996\n",
      "epoch: 22 step: 170 loss: 0.6931471824645996\n",
      "epoch: 22 step: 171 loss: 0.6931471824645996\n",
      "epoch: 22 step: 172 loss: 0.6931471824645996\n",
      "epoch: 22 step: 173 loss: 0.6931471824645996\n",
      "epoch: 22 step: 174 loss: 0.6931471824645996\n",
      "epoch: 22 step: 175 loss: 0.6931471824645996\n",
      "epoch: 22 step: 176 loss: 0.6931471824645996\n",
      "epoch: 22 step: 177 loss: 0.6931471824645996\n",
      "epoch: 22 step: 178 loss: 0.6931471824645996\n",
      "epoch: 22 step: 179 loss: 0.6931471824645996\n",
      "epoch: 22 step: 180 loss: 0.6931471824645996\n",
      "epoch: 22 step: 181 loss: 0.6931471824645996\n",
      "epoch: 22 step: 182 loss: 0.6931471824645996\n",
      "epoch: 22 step: 183 loss: 0.6931471824645996\n",
      "epoch: 22 step: 184 loss: 0.6931471824645996\n",
      "epoch: 22 step: 185 loss: 0.6931471824645996\n",
      "epoch: 22 step: 186 loss: 0.6931471824645996\n",
      "epoch: 22 step: 187 loss: 0.6931471824645996\n",
      "epoch: 22 step: 188 loss: 0.6931471824645996\n",
      "epoch: 22 step: 189 loss: 0.6931471824645996\n",
      "epoch: 22 step: 190 loss: 0.6931471824645996\n",
      "epoch: 22 step: 191 loss: 0.6931471824645996\n",
      "epoch: 22 step: 192 loss: 0.6931471824645996\n",
      "epoch: 22 step: 193 loss: 0.6931471824645996\n",
      "epoch: 22 step: 194 loss: 0.6931471824645996\n",
      "epoch: 22 step: 195 loss: 0.6931471824645996\n",
      "epoch: 22 step: 196 loss: 0.6931471824645996\n",
      "epoch: 22 step: 197 loss: 0.6931471824645996\n",
      "epoch: 22 step: 198 loss: 0.6931471824645996\n",
      "epoch: 22 step: 199 loss: 0.6931471824645996\n",
      "epoch: 22 step: 200 loss: 0.6931471824645996\n",
      "epoch: 22 step: 201 loss: 0.6931471824645996\n",
      "epoch: 22 step: 202 loss: 0.6931471824645996\n",
      "epoch: 22 step: 203 loss: 0.6931471824645996\n",
      "epoch: 22 step: 204 loss: 0.6931471824645996\n",
      "epoch: 22 step: 205 loss: 0.6931471824645996\n",
      "epoch: 22 step: 206 loss: 0.6931471824645996\n",
      "epoch: 22 step: 207 loss: 0.6931471824645996\n",
      "epoch: 22 step: 208 loss: 0.6931471824645996\n",
      "epoch: 22 step: 209 loss: 0.6931471824645996\n",
      "epoch: 22 step: 210 loss: 0.6931471824645996\n",
      "epoch: 22 step: 211 loss: 0.6931471824645996\n",
      "epoch: 22 step: 212 loss: 0.6931471824645996\n",
      "epoch: 22 step: 213 loss: 0.6931471824645996\n",
      "epoch: 22 step: 214 loss: 0.6931471824645996\n",
      "epoch: 22 step: 215 loss: 0.6931471824645996\n",
      "epoch: 22 step: 216 loss: 0.6931471824645996\n",
      "epoch: 22 step: 217 loss: 0.6931471824645996\n",
      "epoch: 22 step: 218 loss: 0.6931471824645996\n",
      "epoch: 22 step: 219 loss: 0.6931471824645996\n",
      "epoch: 22 step: 220 loss: 0.6931471824645996\n",
      "epoch: 22 step: 221 loss: 0.6931471824645996\n",
      "epoch: 22 step: 222 loss: 0.6931471824645996\n",
      "epoch: 22 step: 223 loss: 0.6931471824645996\n",
      "epoch: 22 step: 224 loss: 0.6931471824645996\n",
      "epoch: 22 step: 225 loss: 0.6931471824645996\n",
      "epoch: 22 step: 226 loss: 0.6931471824645996\n",
      "epoch: 22 step: 227 loss: 0.6931471824645996\n",
      "epoch: 22 step: 228 loss: 0.6931471824645996\n",
      "epoch: 22 step: 229 loss: 0.6931471824645996\n",
      "epoch: 22 step: 230 loss: 0.6931471824645996\n",
      "epoch: 22 step: 231 loss: 0.6931471824645996\n",
      "epoch: 22 step: 232 loss: 0.6931471824645996\n",
      "epoch: 22 step: 233 loss: 0.6931471824645996\n",
      "epoch: 22 step: 234 loss: 0.6931471824645996\n",
      "epoch: 22 step: 235 loss: 0.6931471824645996\n",
      "epoch: 22 step: 236 loss: 0.6931471824645996\n",
      "epoch: 22 step: 237 loss: 0.6931471824645996\n",
      "epoch: 22 step: 238 loss: 0.6931471824645996\n",
      "epoch: 22 step: 239 loss: 0.6931471824645996\n",
      "epoch: 22 step: 240 loss: 0.6931471824645996\n",
      "epoch: 22 step: 241 loss: 0.6931471824645996\n",
      "epoch: 22 step: 242 loss: 0.6931471824645996\n",
      "epoch: 22 step: 243 loss: 0.6931471824645996\n",
      "epoch: 22 step: 244 loss: 0.6931471824645996\n",
      "epoch: 22 step: 245 loss: 0.6931471824645996\n",
      "epoch: 22 step: 246 loss: 0.6931471824645996\n",
      "epoch: 22 step: 247 loss: 0.6931471824645996\n",
      "epoch: 22 step: 248 loss: 0.6931471824645996\n",
      "epoch: 22 step: 249 loss: 0.6931471824645996\n",
      "epoch: 22 step: 250 loss: 0.6931471824645996\n",
      "epoch: 22 step: 251 loss: 0.6931471824645996\n",
      "epoch: 22 step: 252 loss: 0.6931471824645996\n",
      "epoch: 22 step: 253 loss: 0.6931471824645996\n",
      "epoch: 22 step: 254 loss: 0.6931471824645996\n",
      "epoch: 22 step: 255 loss: 0.6931471824645996\n",
      "epoch: 22 step: 256 loss: 0.6931471824645996\n",
      "epoch: 22 step: 257 loss: 0.6931471824645996\n",
      "epoch: 22 step: 258 loss: 0.6931471824645996\n",
      "epoch: 22 step: 259 loss: 0.6931471824645996\n",
      "epoch: 22 step: 260 loss: 0.6931471824645996\n",
      "epoch: 22 step: 261 loss: 0.6931471824645996\n",
      "epoch: 22 step: 262 loss: 0.6931471824645996\n",
      "epoch: 22 step: 263 loss: 0.6931471824645996\n",
      "epoch: 22 step: 264 loss: 0.6931471824645996\n",
      "epoch: 22 step: 265 loss: 0.6931471824645996\n",
      "epoch: 22 step: 266 loss: 0.6931471824645996\n",
      "epoch: 22 step: 267 loss: 0.6931471824645996\n",
      "epoch: 22 step: 268 loss: 0.6931471824645996\n",
      "epoch: 22 step: 269 loss: 0.6931471824645996\n",
      "epoch: 22 step: 270 loss: 0.6931471824645996\n",
      "epoch: 22 step: 271 loss: 0.6931471824645996\n",
      "epoch: 22 step: 272 loss: 0.6931471824645996\n",
      "epoch: 22 step: 273 loss: 0.6931471824645996\n",
      "epoch: 22 step: 274 loss: 0.6931471824645996\n",
      "epoch: 22 step: 275 loss: 0.6931471824645996\n",
      "epoch: 22 step: 276 loss: 0.6931471824645996\n",
      "epoch: 22 step: 277 loss: 0.6931471824645996\n",
      "epoch: 22 step: 278 loss: 0.6931471824645996\n",
      "epoch: 22 step: 279 loss: 0.6931471824645996\n",
      "epoch: 22 step: 280 loss: 0.6931471824645996\n",
      "epoch: 22 step: 281 loss: 0.6931471824645996\n",
      "epoch: 22 step: 282 loss: 0.6931471824645996\n",
      "epoch: 22 step: 283 loss: 0.6931471824645996\n",
      "epoch: 22 step: 284 loss: 0.6931471824645996\n",
      "epoch: 22 step: 285 loss: 0.6931471824645996\n",
      "epoch: 22 step: 286 loss: 0.6931471824645996\n",
      "epoch: 22 step: 287 loss: 0.6931471824645996\n",
      "epoch: 22 step: 288 loss: 0.6931471824645996\n",
      "epoch: 22 step: 289 loss: 0.6931471824645996\n",
      "epoch: 22 step: 290 loss: 0.6931471824645996\n",
      "epoch: 22 step: 291 loss: 0.6931471824645996\n",
      "epoch: 22 step: 292 loss: 0.6931471824645996\n",
      "epoch: 22 step: 293 loss: 0.6931471824645996\n",
      "epoch: 22 step: 294 loss: 0.6931471824645996\n",
      "epoch: 22 step: 295 loss: 0.6931471824645996\n",
      "epoch: 22 step: 296 loss: 0.6931471824645996\n",
      "epoch: 22 step: 297 loss: 0.6931471824645996\n",
      "epoch: 22 step: 298 loss: 0.6931471824645996\n",
      "epoch: 22 step: 299 loss: 0.6931471824645996\n",
      "epoch: 22 step: 300 loss: 0.6931471824645996\n",
      "epoch: 22 step: 301 loss: 0.6931471824645996\n",
      "epoch: 22 step: 302 loss: 0.6931471824645996\n",
      "epoch: 22 step: 303 loss: 0.6931471824645996\n",
      "epoch: 22 step: 304 loss: 0.6931471824645996\n",
      "epoch: 22 step: 305 loss: 0.6931471824645996\n",
      "epoch: 22 step: 306 loss: 0.6931471824645996\n",
      "epoch: 22 step: 307 loss: 0.6931471824645996\n",
      "epoch: 22 step: 308 loss: 0.6931471824645996\n",
      "epoch: 22 step: 309 loss: 0.6931471824645996\n",
      "epoch: 22 step: 310 loss: 0.6931471824645996\n",
      "epoch: 22 step: 311 loss: 0.6931471824645996\n",
      "epoch: 22 step: 312 loss: 0.6931471824645996\n",
      "epoch: 22 step: 313 loss: 0.6931471824645996\n",
      "epoch: 22 step: 314 loss: 0.6931471824645996\n",
      "epoch: 22 step: 315 loss: 0.6931471824645996\n",
      "epoch: 22 step: 316 loss: 0.6931471824645996\n",
      "epoch: 22 step: 317 loss: 0.6931471824645996\n",
      "epoch: 22 step: 318 loss: 0.6931471824645996\n",
      "epoch: 22 step: 319 loss: 0.6931471824645996\n",
      "epoch: 22 step: 320 loss: 0.6931471824645996\n",
      "epoch: 22 step: 321 loss: 0.6931471824645996\n",
      "epoch: 22 step: 322 loss: 0.6931471824645996\n",
      "epoch: 22 step: 323 loss: 0.6931471824645996\n",
      "epoch: 22 step: 324 loss: 0.6931471824645996\n",
      "epoch: 22 step: 325 loss: 0.6931471824645996\n",
      "epoch: 22 step: 326 loss: 0.6931471824645996\n",
      "epoch: 22 step: 327 loss: 0.6931471824645996\n",
      "epoch: 22 step: 328 loss: 0.6931471824645996\n",
      "epoch: 22 step: 329 loss: 0.6931471824645996\n",
      "epoch: 22 step: 330 loss: 0.6931471824645996\n",
      "epoch: 22 step: 331 loss: 0.6931471824645996\n",
      "epoch: 22 step: 332 loss: 0.6931471824645996\n",
      "epoch: 22 step: 333 loss: 0.6931471824645996\n",
      "epoch: 22 step: 334 loss: 0.6931471824645996\n",
      "epoch: 22 step: 335 loss: 0.6931471824645996\n",
      "epoch: 22 step: 336 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 337 loss: 0.6931471824645996\n",
      "epoch: 22 step: 338 loss: 0.6931471824645996\n",
      "epoch: 22 step: 339 loss: 0.6931471824645996\n",
      "epoch: 22 step: 340 loss: 0.6931471824645996\n",
      "epoch: 22 step: 341 loss: 0.6931471824645996\n",
      "epoch: 22 step: 342 loss: 0.6931471824645996\n",
      "epoch: 22 step: 343 loss: 0.6931471824645996\n",
      "epoch: 22 step: 344 loss: 0.6931471824645996\n",
      "epoch: 22 step: 345 loss: 0.6931471824645996\n",
      "epoch: 22 step: 346 loss: 0.6931471824645996\n",
      "epoch: 22 step: 347 loss: 0.6931471824645996\n",
      "epoch: 22 step: 348 loss: 0.6931471824645996\n",
      "epoch: 22 step: 349 loss: 0.6931471824645996\n",
      "epoch: 22 step: 350 loss: 0.6931471824645996\n",
      "epoch: 22 step: 351 loss: 0.6931471824645996\n",
      "epoch: 22 step: 352 loss: 0.6931471824645996\n",
      "epoch: 22 step: 353 loss: 0.6931471824645996\n",
      "epoch: 22 step: 354 loss: 0.6931471824645996\n",
      "epoch: 22 step: 355 loss: 0.6931471824645996\n",
      "epoch: 22 step: 356 loss: 0.6931471824645996\n",
      "epoch: 22 step: 357 loss: 0.6931471824645996\n",
      "epoch: 22 step: 358 loss: 0.6931471824645996\n",
      "epoch: 22 step: 359 loss: 0.6931471824645996\n",
      "epoch: 22 step: 360 loss: 0.6931471824645996\n",
      "epoch: 22 step: 361 loss: 0.6931471824645996\n",
      "epoch: 22 step: 362 loss: 0.6931471824645996\n",
      "epoch: 22 step: 363 loss: 0.6931471824645996\n",
      "epoch: 22 step: 364 loss: 0.6931471824645996\n",
      "epoch: 22 step: 365 loss: 0.6931471824645996\n",
      "epoch: 22 step: 366 loss: 0.6931471824645996\n",
      "epoch: 22 step: 367 loss: 0.6931471824645996\n",
      "epoch: 22 step: 368 loss: 0.6931471824645996\n",
      "epoch: 22 step: 369 loss: 0.6931471824645996\n",
      "epoch: 22 step: 370 loss: 0.6931471824645996\n",
      "epoch: 22 step: 371 loss: 0.6931471824645996\n",
      "epoch: 22 step: 372 loss: 0.6931471824645996\n",
      "epoch: 22 step: 373 loss: 0.6931471824645996\n",
      "epoch: 22 step: 374 loss: 0.6931471824645996\n",
      "epoch: 22 step: 375 loss: 0.6931471824645996\n",
      "epoch: 22 step: 376 loss: 0.6931471824645996\n",
      "epoch: 22 step: 377 loss: 0.6931471824645996\n",
      "epoch: 22 step: 378 loss: 0.6931471824645996\n",
      "epoch: 22 step: 379 loss: 0.6931471824645996\n",
      "epoch: 22 step: 380 loss: 0.6931471824645996\n",
      "epoch: 22 step: 381 loss: 0.6931471824645996\n",
      "epoch: 22 step: 382 loss: 0.6931471824645996\n",
      "epoch: 22 step: 383 loss: 0.6931471824645996\n",
      "epoch: 22 step: 384 loss: 0.6931471824645996\n",
      "epoch: 22 step: 385 loss: 0.6931471824645996\n",
      "epoch: 22 step: 386 loss: 0.6931471824645996\n",
      "epoch: 22 step: 387 loss: 0.6931471824645996\n",
      "epoch: 22 step: 388 loss: 0.6931471824645996\n",
      "epoch: 22 step: 389 loss: 0.6931471824645996\n",
      "epoch: 22 step: 390 loss: 0.6931471824645996\n",
      "epoch: 22 step: 391 loss: 0.6931471824645996\n",
      "epoch: 22 step: 392 loss: 0.6931471824645996\n",
      "epoch: 22 step: 393 loss: 0.6931471824645996\n",
      "epoch: 22 step: 394 loss: 0.6931471824645996\n",
      "epoch: 22 step: 395 loss: 0.6931471824645996\n",
      "epoch: 22 step: 396 loss: 0.6931471824645996\n",
      "epoch: 22 step: 397 loss: 0.6931471824645996\n",
      "epoch: 22 step: 398 loss: 0.6931471824645996\n",
      "epoch: 22 step: 399 loss: 0.6931471824645996\n",
      "epoch: 22 step: 400 loss: 0.6931471824645996\n",
      "epoch: 22 step: 401 loss: 0.6931471824645996\n",
      "epoch: 22 step: 402 loss: 0.6931471824645996\n",
      "epoch: 22 step: 403 loss: 0.6931471824645996\n",
      "epoch: 22 step: 404 loss: 0.6931471824645996\n",
      "epoch: 22 step: 405 loss: 0.6931471824645996\n",
      "epoch: 22 step: 406 loss: 0.6931471824645996\n",
      "epoch: 22 step: 407 loss: 0.6931471824645996\n",
      "epoch: 22 step: 408 loss: 0.6931471824645996\n",
      "epoch: 22 step: 409 loss: 0.6931471824645996\n",
      "epoch: 22 step: 410 loss: 0.6931471824645996\n",
      "epoch: 22 step: 411 loss: 0.6931471824645996\n",
      "epoch: 22 step: 412 loss: 0.6931471824645996\n",
      "epoch: 22 step: 413 loss: 0.6931471824645996\n",
      "epoch: 22 step: 414 loss: 0.6931471824645996\n",
      "epoch: 22 step: 415 loss: 0.6931471824645996\n",
      "epoch: 22 step: 416 loss: 0.6931471824645996\n",
      "epoch: 22 step: 417 loss: 0.6931471824645996\n",
      "epoch: 22 step: 418 loss: 0.6931471824645996\n",
      "epoch: 22 step: 419 loss: 0.6931471824645996\n",
      "epoch: 22 step: 420 loss: 0.6931471824645996\n",
      "epoch: 22 step: 421 loss: 0.6931471824645996\n",
      "epoch: 22 step: 422 loss: 0.6931471824645996\n",
      "epoch: 22 step: 423 loss: 0.6931471824645996\n",
      "epoch: 22 step: 424 loss: 0.6931471824645996\n",
      "epoch: 22 step: 425 loss: 0.6931471824645996\n",
      "epoch: 22 step: 426 loss: 0.6931471824645996\n",
      "epoch: 22 step: 427 loss: 0.6931471824645996\n",
      "epoch: 22 step: 428 loss: 0.6931471824645996\n",
      "epoch: 22 step: 429 loss: 0.6931471824645996\n",
      "epoch: 22 step: 430 loss: 0.6931471824645996\n",
      "epoch: 22 step: 431 loss: 0.6931471824645996\n",
      "epoch: 22 step: 432 loss: 0.6931471824645996\n",
      "epoch: 22 step: 433 loss: 0.6931471824645996\n",
      "epoch: 22 step: 434 loss: 0.6931471824645996\n",
      "epoch: 22 step: 435 loss: 0.6931471824645996\n",
      "epoch: 22 step: 436 loss: 0.6931471824645996\n",
      "epoch: 22 step: 437 loss: 0.6931471824645996\n",
      "epoch: 22 step: 438 loss: 0.6931471824645996\n",
      "epoch: 22 step: 439 loss: 0.6931471824645996\n",
      "epoch: 22 step: 440 loss: 0.6931471824645996\n",
      "epoch: 22 step: 441 loss: 0.6931471824645996\n",
      "epoch: 22 step: 442 loss: 0.6931471824645996\n",
      "epoch: 22 step: 443 loss: 0.6931471824645996\n",
      "epoch: 22 step: 444 loss: 0.6931471824645996\n",
      "epoch: 22 step: 445 loss: 0.6931471824645996\n",
      "epoch: 22 step: 446 loss: 0.6931471824645996\n",
      "epoch: 22 step: 447 loss: 0.6931471824645996\n",
      "epoch: 22 step: 448 loss: 0.6931471824645996\n",
      "epoch: 22 step: 449 loss: 0.6931471824645996\n",
      "epoch: 22 step: 450 loss: 0.6931471824645996\n",
      "epoch: 22 step: 451 loss: 0.6931471824645996\n",
      "epoch: 22 step: 452 loss: 0.6931471824645996\n",
      "epoch: 22 step: 453 loss: 0.6931471824645996\n",
      "epoch: 22 step: 454 loss: 0.6931471824645996\n",
      "epoch: 22 step: 455 loss: 0.6931471824645996\n",
      "epoch: 22 step: 456 loss: 0.6931471824645996\n",
      "epoch: 22 step: 457 loss: 0.6931471824645996\n",
      "epoch: 22 step: 458 loss: 0.6931471824645996\n",
      "epoch: 22 step: 459 loss: 0.6931471824645996\n",
      "epoch: 22 step: 460 loss: 0.6931471824645996\n",
      "epoch: 22 step: 461 loss: 0.6931471824645996\n",
      "epoch: 22 step: 462 loss: 0.6931471824645996\n",
      "epoch: 22 step: 463 loss: 0.6931471824645996\n",
      "epoch: 22 step: 464 loss: 0.6931471824645996\n",
      "epoch: 22 step: 465 loss: 0.6931471824645996\n",
      "epoch: 22 step: 466 loss: 0.6931471824645996\n",
      "epoch: 22 step: 467 loss: 0.6931471824645996\n",
      "epoch: 22 step: 468 loss: 0.6931471824645996\n",
      "epoch: 22 step: 469 loss: 0.6931471824645996\n",
      "epoch: 22 step: 470 loss: 0.6931471824645996\n",
      "epoch: 22 step: 471 loss: 0.6931471824645996\n",
      "epoch: 22 step: 472 loss: 0.6931471824645996\n",
      "epoch: 22 step: 473 loss: 0.6931471824645996\n",
      "epoch: 22 step: 474 loss: 0.6931471824645996\n",
      "epoch: 22 step: 475 loss: 0.6931471824645996\n",
      "epoch: 22 step: 476 loss: 0.6931471824645996\n",
      "epoch: 22 step: 477 loss: 0.6931471824645996\n",
      "epoch: 22 step: 478 loss: 0.6931471824645996\n",
      "epoch: 22 step: 479 loss: 0.6931471824645996\n",
      "epoch: 22 step: 480 loss: 0.6931471824645996\n",
      "epoch: 22 step: 481 loss: 0.6931471824645996\n",
      "epoch: 22 step: 482 loss: 0.6931471824645996\n",
      "epoch: 22 step: 483 loss: 0.6931471824645996\n",
      "epoch: 22 step: 484 loss: 0.6931471824645996\n",
      "epoch: 22 step: 485 loss: 0.6931471824645996\n",
      "epoch: 22 step: 486 loss: 0.6931471824645996\n",
      "epoch: 22 step: 487 loss: 0.6931471824645996\n",
      "epoch: 22 step: 488 loss: 0.6931471824645996\n",
      "epoch: 22 step: 489 loss: 0.6931471824645996\n",
      "epoch: 22 step: 490 loss: 0.6931471824645996\n",
      "epoch: 22 step: 491 loss: 0.6931471824645996\n",
      "epoch: 22 step: 492 loss: 0.6931471824645996\n",
      "epoch: 22 step: 493 loss: 0.6931471824645996\n",
      "epoch: 22 step: 494 loss: 0.6931471824645996\n",
      "epoch: 22 step: 495 loss: 0.6931471824645996\n",
      "epoch: 22 step: 496 loss: 0.6931471824645996\n",
      "epoch: 22 step: 497 loss: 0.6931471824645996\n",
      "epoch: 22 step: 498 loss: 0.6931471824645996\n",
      "epoch: 22 step: 499 loss: 0.6931471824645996\n",
      "epoch: 22 step: 500 loss: 0.6931471824645996\n",
      "epoch: 22 step: 501 loss: 0.6931471824645996\n",
      "epoch: 22 step: 502 loss: 0.6931471824645996\n",
      "epoch: 22 step: 503 loss: 0.6931471824645996\n",
      "epoch: 22 step: 504 loss: 0.6931471824645996\n",
      "epoch: 22 step: 505 loss: 0.6931471824645996\n",
      "epoch: 22 step: 506 loss: 0.6931471824645996\n",
      "epoch: 22 step: 507 loss: 0.6931471824645996\n",
      "epoch: 22 step: 508 loss: 0.6931471824645996\n",
      "epoch: 22 step: 509 loss: 0.6931471824645996\n",
      "epoch: 22 step: 510 loss: 0.6931471824645996\n",
      "epoch: 22 step: 511 loss: 0.6931471824645996\n",
      "epoch: 22 step: 512 loss: 0.6931471824645996\n",
      "epoch: 22 step: 513 loss: 0.6931471824645996\n",
      "epoch: 22 step: 514 loss: 0.6931471824645996\n",
      "epoch: 22 step: 515 loss: 0.6931471824645996\n",
      "epoch: 22 step: 516 loss: 0.6931471824645996\n",
      "epoch: 22 step: 517 loss: 0.6931471824645996\n",
      "epoch: 22 step: 518 loss: 0.6931471824645996\n",
      "epoch: 22 step: 519 loss: 0.6931471824645996\n",
      "epoch: 22 step: 520 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 521 loss: 0.6931471824645996\n",
      "epoch: 22 step: 522 loss: 0.6931471824645996\n",
      "epoch: 22 step: 523 loss: 0.6931471824645996\n",
      "epoch: 22 step: 524 loss: 0.6931471824645996\n",
      "epoch: 22 step: 525 loss: 0.6931471824645996\n",
      "epoch: 22 step: 526 loss: 0.6931471824645996\n",
      "epoch: 22 step: 527 loss: 0.6931471824645996\n",
      "epoch: 22 step: 528 loss: 0.6931471824645996\n",
      "epoch: 22 step: 529 loss: 0.6931471824645996\n",
      "epoch: 22 step: 530 loss: 0.6931471824645996\n",
      "epoch: 22 step: 531 loss: 0.6931471824645996\n",
      "epoch: 22 step: 532 loss: 0.6931471824645996\n",
      "epoch: 22 step: 533 loss: 0.6931471824645996\n",
      "epoch: 22 step: 534 loss: 0.6931471824645996\n",
      "epoch: 22 step: 535 loss: 0.6931471824645996\n",
      "epoch: 22 step: 536 loss: 0.6931471824645996\n",
      "epoch: 22 step: 537 loss: 0.6931471824645996\n",
      "epoch: 22 step: 538 loss: 0.6931471824645996\n",
      "epoch: 22 step: 539 loss: 0.6931471824645996\n",
      "epoch: 22 step: 540 loss: 0.6931471824645996\n",
      "epoch: 22 step: 541 loss: 0.6931471824645996\n",
      "epoch: 22 step: 542 loss: 0.6931471824645996\n",
      "epoch: 22 step: 543 loss: 0.6931471824645996\n",
      "epoch: 22 step: 544 loss: 0.6931471824645996\n",
      "epoch: 22 step: 545 loss: 0.6931471824645996\n",
      "epoch: 22 step: 546 loss: 0.6931471824645996\n",
      "epoch: 22 step: 547 loss: 0.6931471824645996\n",
      "epoch: 22 step: 548 loss: 0.6931471824645996\n",
      "epoch: 22 step: 549 loss: 0.6931471824645996\n",
      "epoch: 22 step: 550 loss: 0.6931471824645996\n",
      "epoch: 22 step: 551 loss: 0.6931471824645996\n",
      "epoch: 22 step: 552 loss: 0.6931471824645996\n",
      "epoch: 22 step: 553 loss: 0.6931471824645996\n",
      "epoch: 22 step: 554 loss: 0.6931471824645996\n",
      "epoch: 22 step: 555 loss: 0.6931471824645996\n",
      "epoch: 22 step: 556 loss: 0.6931471824645996\n",
      "epoch: 22 step: 557 loss: 0.6931471824645996\n",
      "epoch: 22 step: 558 loss: 0.6931471824645996\n",
      "epoch: 22 step: 559 loss: 0.6931471824645996\n",
      "epoch: 22 step: 560 loss: 0.6931471824645996\n",
      "epoch: 22 step: 561 loss: 0.6931471824645996\n",
      "epoch: 22 step: 562 loss: 0.6931471824645996\n",
      "epoch: 22 step: 563 loss: 0.6931471824645996\n",
      "epoch: 22 step: 564 loss: 0.6931471824645996\n",
      "epoch: 22 step: 565 loss: 0.6931471824645996\n",
      "epoch: 22 step: 566 loss: 0.6931471824645996\n",
      "epoch: 22 step: 567 loss: 0.6931471824645996\n",
      "epoch: 22 step: 568 loss: 0.6931471824645996\n",
      "epoch: 22 step: 569 loss: 0.6931471824645996\n",
      "epoch: 22 step: 570 loss: 0.6931471824645996\n",
      "epoch: 22 step: 571 loss: 0.6931471824645996\n",
      "epoch: 22 step: 572 loss: 0.6931471824645996\n",
      "epoch: 22 step: 573 loss: 0.6931471824645996\n",
      "epoch: 22 step: 574 loss: 0.6931471824645996\n",
      "epoch: 22 step: 575 loss: 0.6931471824645996\n",
      "epoch: 22 step: 576 loss: 0.6931471824645996\n",
      "epoch: 22 step: 577 loss: 0.6931471824645996\n",
      "epoch: 22 step: 578 loss: 0.6931471824645996\n",
      "epoch: 22 step: 579 loss: 0.6931471824645996\n",
      "epoch: 22 step: 580 loss: 0.6931471824645996\n",
      "epoch: 22 step: 581 loss: 0.6931471824645996\n",
      "epoch: 22 step: 582 loss: 0.6931471824645996\n",
      "epoch: 22 step: 583 loss: 0.6931471824645996\n",
      "epoch: 22 step: 584 loss: 0.6931471824645996\n",
      "epoch: 22 step: 585 loss: 0.6931471824645996\n",
      "epoch: 22 step: 586 loss: 0.6931471824645996\n",
      "epoch: 22 step: 587 loss: 0.6931471824645996\n",
      "epoch: 22 step: 588 loss: 0.6931471824645996\n",
      "epoch: 22 step: 589 loss: 0.6931471824645996\n",
      "epoch: 22 step: 590 loss: 0.6931471824645996\n",
      "epoch: 22 step: 591 loss: 0.6931471824645996\n",
      "epoch: 22 step: 592 loss: 0.6931471824645996\n",
      "epoch: 22 step: 593 loss: 0.6931471824645996\n",
      "epoch: 22 step: 594 loss: 0.6931471824645996\n",
      "epoch: 22 step: 595 loss: 0.6931471824645996\n",
      "epoch: 22 step: 596 loss: 0.6931471824645996\n",
      "epoch: 22 step: 597 loss: 0.6931471824645996\n",
      "epoch: 22 step: 598 loss: 0.6931471824645996\n",
      "epoch: 22 step: 599 loss: 0.6931471824645996\n",
      "epoch: 22 step: 600 loss: 0.6931471824645996\n",
      "epoch: 22 step: 601 loss: 0.6931471824645996\n",
      "epoch: 22 step: 602 loss: 0.6931471824645996\n",
      "epoch: 22 step: 603 loss: 0.6931471824645996\n",
      "epoch: 22 step: 604 loss: 0.6931471824645996\n",
      "epoch: 22 step: 605 loss: 0.6931471824645996\n",
      "epoch: 22 step: 606 loss: 0.6931471824645996\n",
      "epoch: 22 step: 607 loss: 0.6931471824645996\n",
      "epoch: 22 step: 608 loss: 0.6931471824645996\n",
      "epoch: 22 step: 609 loss: 0.6931471824645996\n",
      "epoch: 22 step: 610 loss: 0.6931471824645996\n",
      "epoch: 22 step: 611 loss: 0.6931471824645996\n",
      "epoch: 22 step: 612 loss: 0.6931471824645996\n",
      "epoch: 22 step: 613 loss: 0.6931471824645996\n",
      "epoch: 22 step: 614 loss: 0.6931471824645996\n",
      "epoch: 22 step: 615 loss: 0.6931471824645996\n",
      "epoch: 22 step: 616 loss: 0.6931471824645996\n",
      "epoch: 22 step: 617 loss: 0.6931471824645996\n",
      "epoch: 22 step: 618 loss: 0.6931471824645996\n",
      "epoch: 22 step: 619 loss: 0.6931471824645996\n",
      "epoch: 22 step: 620 loss: 0.6931471824645996\n",
      "epoch: 22 step: 621 loss: 0.6931471824645996\n",
      "epoch: 22 step: 622 loss: 0.6931471824645996\n",
      "epoch: 22 step: 623 loss: 0.6931471824645996\n",
      "epoch: 22 step: 624 loss: 0.6931471824645996\n",
      "epoch: 22 step: 625 loss: 0.6931471824645996\n",
      "epoch: 22 step: 626 loss: 0.6931471824645996\n",
      "epoch: 22 step: 627 loss: 0.6931471824645996\n",
      "epoch: 22 step: 628 loss: 0.6931471824645996\n",
      "epoch: 22 step: 629 loss: 0.6931471824645996\n",
      "epoch: 22 step: 630 loss: 0.6931471824645996\n",
      "epoch: 22 step: 631 loss: 0.6931471824645996\n",
      "epoch: 22 step: 632 loss: 0.6931471824645996\n",
      "epoch: 22 step: 633 loss: 0.6931471824645996\n",
      "epoch: 22 step: 634 loss: 0.6931471824645996\n",
      "epoch: 22 step: 635 loss: 0.6931471824645996\n",
      "epoch: 22 step: 636 loss: 0.6931471824645996\n",
      "epoch: 22 step: 637 loss: 0.6931471824645996\n",
      "epoch: 22 step: 638 loss: 0.6931471824645996\n",
      "epoch: 22 step: 639 loss: 0.6931471824645996\n",
      "epoch: 22 step: 640 loss: 0.6931471824645996\n",
      "epoch: 22 step: 641 loss: 0.6931471824645996\n",
      "epoch: 22 step: 642 loss: 0.6931471824645996\n",
      "epoch: 22 step: 643 loss: 0.6931471824645996\n",
      "epoch: 22 step: 644 loss: 0.6931471824645996\n",
      "epoch: 22 step: 645 loss: 0.6931471824645996\n",
      "epoch: 22 step: 646 loss: 0.6931471824645996\n",
      "epoch: 22 step: 647 loss: 0.6931471824645996\n",
      "epoch: 22 step: 648 loss: 0.6931471824645996\n",
      "epoch: 22 step: 649 loss: 0.6931471824645996\n",
      "epoch: 22 step: 650 loss: 0.6931471824645996\n",
      "epoch: 22 step: 651 loss: 0.6931471824645996\n",
      "epoch: 22 step: 652 loss: 0.6931471824645996\n",
      "epoch: 22 step: 653 loss: 0.6931471824645996\n",
      "epoch: 22 step: 654 loss: 0.6931471824645996\n",
      "epoch: 22 step: 655 loss: 0.6931471824645996\n",
      "epoch: 22 step: 656 loss: 0.6931471824645996\n",
      "epoch: 22 step: 657 loss: 0.6931471824645996\n",
      "epoch: 22 step: 658 loss: 0.6931471824645996\n",
      "epoch: 22 step: 659 loss: 0.6931471824645996\n",
      "epoch: 22 step: 660 loss: 0.6931471824645996\n",
      "epoch: 22 step: 661 loss: 0.6931471824645996\n",
      "epoch: 22 step: 662 loss: 0.6931471824645996\n",
      "epoch: 22 step: 663 loss: 0.6931471824645996\n",
      "epoch: 22 step: 664 loss: 0.6931471824645996\n",
      "epoch: 22 step: 665 loss: 0.6931471824645996\n",
      "epoch: 22 step: 666 loss: 0.6931471824645996\n",
      "epoch: 22 step: 667 loss: 0.6931471824645996\n",
      "epoch: 22 step: 668 loss: 0.6931471824645996\n",
      "epoch: 22 step: 669 loss: 0.6931471824645996\n",
      "epoch: 22 step: 670 loss: 0.6931471824645996\n",
      "epoch: 22 step: 671 loss: 0.6931471824645996\n",
      "epoch: 22 step: 672 loss: 0.6931471824645996\n",
      "epoch: 22 step: 673 loss: 0.6931471824645996\n",
      "epoch: 22 step: 674 loss: 0.6931471824645996\n",
      "epoch: 22 step: 675 loss: 0.6931471824645996\n",
      "epoch: 22 step: 676 loss: 0.6931471824645996\n",
      "epoch: 22 step: 677 loss: 0.6931471824645996\n",
      "epoch: 22 step: 678 loss: 0.6931471824645996\n",
      "epoch: 22 step: 679 loss: 0.6931471824645996\n",
      "epoch: 22 step: 680 loss: 0.6931471824645996\n",
      "epoch: 22 step: 681 loss: 0.6931471824645996\n",
      "epoch: 22 step: 682 loss: 0.6931471824645996\n",
      "epoch: 22 step: 683 loss: 0.6931471824645996\n",
      "epoch: 22 step: 684 loss: 0.6931471824645996\n",
      "epoch: 22 step: 685 loss: 0.6931471824645996\n",
      "epoch: 22 step: 686 loss: 0.6931471824645996\n",
      "epoch: 22 step: 687 loss: 0.6931471824645996\n",
      "epoch: 22 step: 688 loss: 0.6931471824645996\n",
      "epoch: 22 step: 689 loss: 0.6931471824645996\n",
      "epoch: 22 step: 690 loss: 0.6931471824645996\n",
      "epoch: 22 step: 691 loss: 0.6931471824645996\n",
      "epoch: 22 step: 692 loss: 0.6931471824645996\n",
      "epoch: 22 step: 693 loss: 0.6931471824645996\n",
      "epoch: 22 step: 694 loss: 0.6931471824645996\n",
      "epoch: 22 step: 695 loss: 0.6931471824645996\n",
      "epoch: 22 step: 696 loss: 0.6931471824645996\n",
      "epoch: 22 step: 697 loss: 0.6931471824645996\n",
      "epoch: 22 step: 698 loss: 0.6931471824645996\n",
      "epoch: 22 step: 699 loss: 0.6931471824645996\n",
      "epoch: 22 step: 700 loss: 0.6931471824645996\n",
      "epoch: 22 step: 701 loss: 0.6931471824645996\n",
      "epoch: 22 step: 702 loss: 0.6931471824645996\n",
      "epoch: 22 step: 703 loss: 0.6931471824645996\n",
      "epoch: 22 step: 704 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 705 loss: 0.6931471824645996\n",
      "epoch: 22 step: 706 loss: 0.6931471824645996\n",
      "epoch: 22 step: 707 loss: 0.6931471824645996\n",
      "epoch: 22 step: 708 loss: 0.6931471824645996\n",
      "epoch: 22 step: 709 loss: 0.6931471824645996\n",
      "epoch: 22 step: 710 loss: 0.6931471824645996\n",
      "epoch: 22 step: 711 loss: 0.6931471824645996\n",
      "epoch: 22 step: 712 loss: 0.6931471824645996\n",
      "epoch: 22 step: 713 loss: 0.6931471824645996\n",
      "epoch: 22 step: 714 loss: 0.6931471824645996\n",
      "epoch: 22 step: 715 loss: 0.6931471824645996\n",
      "epoch: 22 step: 716 loss: 0.6931471824645996\n",
      "epoch: 22 step: 717 loss: 0.6931471824645996\n",
      "epoch: 22 step: 718 loss: 0.6931471824645996\n",
      "epoch: 22 step: 719 loss: 0.6931471824645996\n",
      "epoch: 22 step: 720 loss: 0.6931471824645996\n",
      "epoch: 22 step: 721 loss: 0.6931471824645996\n",
      "epoch: 22 step: 722 loss: 0.6931471824645996\n",
      "epoch: 22 step: 723 loss: 0.6931471824645996\n",
      "epoch: 22 step: 724 loss: 0.6931471824645996\n",
      "epoch: 22 step: 725 loss: 0.6931471824645996\n",
      "epoch: 22 step: 726 loss: 0.6931471824645996\n",
      "epoch: 22 step: 727 loss: 0.6931471824645996\n",
      "epoch: 22 step: 728 loss: 0.6931471824645996\n",
      "epoch: 22 step: 729 loss: 0.6931471824645996\n",
      "epoch: 22 step: 730 loss: 0.6931471824645996\n",
      "epoch: 22 step: 731 loss: 0.6931471824645996\n",
      "epoch: 22 step: 732 loss: 0.6931471824645996\n",
      "epoch: 22 step: 733 loss: 0.6931471824645996\n",
      "epoch: 22 step: 734 loss: 0.6931471824645996\n",
      "epoch: 22 step: 735 loss: 0.6931471824645996\n",
      "epoch: 22 step: 736 loss: 0.6931471824645996\n",
      "epoch: 22 step: 737 loss: 0.6931471824645996\n",
      "epoch: 22 step: 738 loss: 0.6931471824645996\n",
      "epoch: 22 step: 739 loss: 0.6931471824645996\n",
      "epoch: 22 step: 740 loss: 0.6931471824645996\n",
      "epoch: 22 step: 741 loss: 0.6931471824645996\n",
      "epoch: 22 step: 742 loss: 0.6931471824645996\n",
      "epoch: 22 step: 743 loss: 0.6931471824645996\n",
      "epoch: 22 step: 744 loss: 0.6931471824645996\n",
      "epoch: 22 step: 745 loss: 0.6931471824645996\n",
      "epoch: 22 step: 746 loss: 0.6931471824645996\n",
      "epoch: 22 step: 747 loss: 0.6931471824645996\n",
      "epoch: 22 step: 748 loss: 0.6931471824645996\n",
      "epoch: 22 step: 749 loss: 0.6931471824645996\n",
      "epoch: 22 step: 750 loss: 0.6931471824645996\n",
      "epoch: 22 step: 751 loss: 0.6931471824645996\n",
      "epoch: 22 step: 752 loss: 0.6931471824645996\n",
      "epoch: 22 step: 753 loss: 0.6931471824645996\n",
      "epoch: 22 step: 754 loss: 0.6931471824645996\n",
      "epoch: 22 step: 755 loss: 0.6931471824645996\n",
      "epoch: 22 step: 756 loss: 0.6931471824645996\n",
      "epoch: 22 step: 757 loss: 0.6931471824645996\n",
      "epoch: 22 step: 758 loss: 0.6931471824645996\n",
      "epoch: 22 step: 759 loss: 0.6931471824645996\n",
      "epoch: 22 step: 760 loss: 0.6931471824645996\n",
      "epoch: 22 step: 761 loss: 0.6931471824645996\n",
      "epoch: 22 step: 762 loss: 0.6931471824645996\n",
      "epoch: 22 step: 763 loss: 0.6931471824645996\n",
      "epoch: 22 step: 764 loss: 0.6931471824645996\n",
      "epoch: 22 step: 765 loss: 0.6931471824645996\n",
      "epoch: 22 step: 766 loss: 0.6931471824645996\n",
      "epoch: 22 step: 767 loss: 0.6931471824645996\n",
      "epoch: 22 step: 768 loss: 0.6931471824645996\n",
      "epoch: 22 step: 769 loss: 0.6931471824645996\n",
      "epoch: 22 step: 770 loss: 0.6931471824645996\n",
      "epoch: 22 step: 771 loss: 0.6931471824645996\n",
      "epoch: 22 step: 772 loss: 0.6931471824645996\n",
      "epoch: 22 step: 773 loss: 0.6931471824645996\n",
      "epoch: 22 step: 774 loss: 0.6931471824645996\n",
      "epoch: 22 step: 775 loss: 0.6931471824645996\n",
      "epoch: 22 step: 776 loss: 0.6931471824645996\n",
      "epoch: 22 step: 777 loss: 0.6931471824645996\n",
      "epoch: 22 step: 778 loss: 0.6931471824645996\n",
      "epoch: 22 step: 779 loss: 0.6931471824645996\n",
      "epoch: 22 step: 780 loss: 0.6931471824645996\n",
      "epoch: 22 step: 781 loss: 0.6931471824645996\n",
      "epoch: 23 step: 1 loss: 0.6931471824645996\n",
      "epoch: 23 step: 2 loss: 0.6931471824645996\n",
      "epoch: 23 step: 3 loss: 0.6931471824645996\n",
      "epoch: 23 step: 4 loss: 0.6931471824645996\n",
      "epoch: 23 step: 5 loss: 0.6931471824645996\n",
      "epoch: 23 step: 6 loss: 0.6931471824645996\n",
      "epoch: 23 step: 7 loss: 0.6931471824645996\n",
      "epoch: 23 step: 8 loss: 0.6931471824645996\n",
      "epoch: 23 step: 9 loss: 0.6931471824645996\n",
      "epoch: 23 step: 10 loss: 0.6931471824645996\n",
      "epoch: 23 step: 11 loss: 0.6931471824645996\n",
      "epoch: 23 step: 12 loss: 0.6931471824645996\n",
      "epoch: 23 step: 13 loss: 0.6931471824645996\n",
      "epoch: 23 step: 14 loss: 0.6931471824645996\n",
      "epoch: 23 step: 15 loss: 0.6931471824645996\n",
      "epoch: 23 step: 16 loss: 0.6931471824645996\n",
      "epoch: 23 step: 17 loss: 0.6931471824645996\n",
      "epoch: 23 step: 18 loss: 0.6931471824645996\n",
      "epoch: 23 step: 19 loss: 0.6931471824645996\n",
      "epoch: 23 step: 20 loss: 0.6931471824645996\n",
      "epoch: 23 step: 21 loss: 0.6931471824645996\n",
      "epoch: 23 step: 22 loss: 0.6931471824645996\n",
      "epoch: 23 step: 23 loss: 0.6931471824645996\n",
      "epoch: 23 step: 24 loss: 0.6931471824645996\n",
      "epoch: 23 step: 25 loss: 0.6931471824645996\n",
      "epoch: 23 step: 26 loss: 0.6931471824645996\n",
      "epoch: 23 step: 27 loss: 0.6931471824645996\n",
      "epoch: 23 step: 28 loss: 0.6931471824645996\n",
      "epoch: 23 step: 29 loss: 0.6931471824645996\n",
      "epoch: 23 step: 30 loss: 0.6931471824645996\n",
      "epoch: 23 step: 31 loss: 0.6931471824645996\n",
      "epoch: 23 step: 32 loss: 0.6931471824645996\n",
      "epoch: 23 step: 33 loss: 0.6931471824645996\n",
      "epoch: 23 step: 34 loss: 0.6931471824645996\n",
      "epoch: 23 step: 35 loss: 0.6931471824645996\n",
      "epoch: 23 step: 36 loss: 0.6931471824645996\n",
      "epoch: 23 step: 37 loss: 0.6931471824645996\n",
      "epoch: 23 step: 38 loss: 0.6931471824645996\n",
      "epoch: 23 step: 39 loss: 0.6931471824645996\n",
      "epoch: 23 step: 40 loss: 0.6931471824645996\n",
      "epoch: 23 step: 41 loss: 0.6931471824645996\n",
      "epoch: 23 step: 42 loss: 0.6931471824645996\n",
      "epoch: 23 step: 43 loss: 0.6931471824645996\n",
      "epoch: 23 step: 44 loss: 0.6931471824645996\n",
      "epoch: 23 step: 45 loss: 0.6931471824645996\n",
      "epoch: 23 step: 46 loss: 0.6931471824645996\n",
      "epoch: 23 step: 47 loss: 0.6931471824645996\n",
      "epoch: 23 step: 48 loss: 0.6931471824645996\n",
      "epoch: 23 step: 49 loss: 0.6931471824645996\n",
      "epoch: 23 step: 50 loss: 0.6931471824645996\n",
      "epoch: 23 step: 51 loss: 0.6931471824645996\n",
      "epoch: 23 step: 52 loss: 0.6931471824645996\n",
      "epoch: 23 step: 53 loss: 0.6931471824645996\n",
      "epoch: 23 step: 54 loss: 0.6931471824645996\n",
      "epoch: 23 step: 55 loss: 0.6931471824645996\n",
      "epoch: 23 step: 56 loss: 0.6931471824645996\n",
      "epoch: 23 step: 57 loss: 0.6931471824645996\n",
      "epoch: 23 step: 58 loss: 0.6931471824645996\n",
      "epoch: 23 step: 59 loss: 0.6931471824645996\n",
      "epoch: 23 step: 60 loss: 0.6931471824645996\n",
      "epoch: 23 step: 61 loss: 0.6931471824645996\n",
      "epoch: 23 step: 62 loss: 0.6931471824645996\n",
      "epoch: 23 step: 63 loss: 0.6931471824645996\n",
      "epoch: 23 step: 64 loss: 0.6931471824645996\n",
      "epoch: 23 step: 65 loss: 0.6931471824645996\n",
      "epoch: 23 step: 66 loss: 0.6931471824645996\n",
      "epoch: 23 step: 67 loss: 0.6931471824645996\n",
      "epoch: 23 step: 68 loss: 0.6931471824645996\n",
      "epoch: 23 step: 69 loss: 0.6931471824645996\n",
      "epoch: 23 step: 70 loss: 0.6931471824645996\n",
      "epoch: 23 step: 71 loss: 0.6931471824645996\n",
      "epoch: 23 step: 72 loss: 0.6931471824645996\n",
      "epoch: 23 step: 73 loss: 0.6931471824645996\n",
      "epoch: 23 step: 74 loss: 0.6931471824645996\n",
      "epoch: 23 step: 75 loss: 0.6931471824645996\n",
      "epoch: 23 step: 76 loss: 0.6931471824645996\n",
      "epoch: 23 step: 77 loss: 0.6931471824645996\n",
      "epoch: 23 step: 78 loss: 0.6931471824645996\n",
      "epoch: 23 step: 79 loss: 0.6931471824645996\n",
      "epoch: 23 step: 80 loss: 0.6931471824645996\n",
      "epoch: 23 step: 81 loss: 0.6931471824645996\n",
      "epoch: 23 step: 82 loss: 0.6931471824645996\n",
      "epoch: 23 step: 83 loss: 0.6931471824645996\n",
      "epoch: 23 step: 84 loss: 0.6931471824645996\n",
      "epoch: 23 step: 85 loss: 0.6931471824645996\n",
      "epoch: 23 step: 86 loss: 0.6931471824645996\n",
      "epoch: 23 step: 87 loss: 0.6931471824645996\n",
      "epoch: 23 step: 88 loss: 0.6931471824645996\n",
      "epoch: 23 step: 89 loss: 0.6931471824645996\n",
      "epoch: 23 step: 90 loss: 0.6931471824645996\n",
      "epoch: 23 step: 91 loss: 0.6931471824645996\n",
      "epoch: 23 step: 92 loss: 0.6931471824645996\n",
      "epoch: 23 step: 93 loss: 0.6931471824645996\n",
      "epoch: 23 step: 94 loss: 0.6931471824645996\n",
      "epoch: 23 step: 95 loss: 0.6931471824645996\n",
      "epoch: 23 step: 96 loss: 0.6931471824645996\n",
      "epoch: 23 step: 97 loss: 0.6931471824645996\n",
      "epoch: 23 step: 98 loss: 0.6931471824645996\n",
      "epoch: 23 step: 99 loss: 0.6931471824645996\n",
      "epoch: 23 step: 100 loss: 0.6931471824645996\n",
      "epoch: 23 step: 101 loss: 0.6931471824645996\n",
      "epoch: 23 step: 102 loss: 0.6931471824645996\n",
      "epoch: 23 step: 103 loss: 0.6931471824645996\n",
      "epoch: 23 step: 104 loss: 0.6931471824645996\n",
      "epoch: 23 step: 105 loss: 0.6931471824645996\n",
      "epoch: 23 step: 106 loss: 0.6931471824645996\n",
      "epoch: 23 step: 107 loss: 0.6931471824645996\n",
      "epoch: 23 step: 108 loss: 0.6931471824645996\n",
      "epoch: 23 step: 109 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 110 loss: 0.6931471824645996\n",
      "epoch: 23 step: 111 loss: 0.6931471824645996\n",
      "epoch: 23 step: 112 loss: 0.6931471824645996\n",
      "epoch: 23 step: 113 loss: 0.6931471824645996\n",
      "epoch: 23 step: 114 loss: 0.6931471824645996\n",
      "epoch: 23 step: 115 loss: 0.6931471824645996\n",
      "epoch: 23 step: 116 loss: 0.6931471824645996\n",
      "epoch: 23 step: 117 loss: 0.6931471824645996\n",
      "epoch: 23 step: 118 loss: 0.6931471824645996\n",
      "epoch: 23 step: 119 loss: 0.6931471824645996\n",
      "epoch: 23 step: 120 loss: 0.6931471824645996\n",
      "epoch: 23 step: 121 loss: 0.6931471824645996\n",
      "epoch: 23 step: 122 loss: 0.6931471824645996\n",
      "epoch: 23 step: 123 loss: 0.6931471824645996\n",
      "epoch: 23 step: 124 loss: 0.6931471824645996\n",
      "epoch: 23 step: 125 loss: 0.6931471824645996\n",
      "epoch: 23 step: 126 loss: 0.6931471824645996\n",
      "epoch: 23 step: 127 loss: 0.6931471824645996\n",
      "epoch: 23 step: 128 loss: 0.6931471824645996\n",
      "epoch: 23 step: 129 loss: 0.6931471824645996\n",
      "epoch: 23 step: 130 loss: 0.6931471824645996\n",
      "epoch: 23 step: 131 loss: 0.6931471824645996\n",
      "epoch: 23 step: 132 loss: 0.6931471824645996\n",
      "epoch: 23 step: 133 loss: 0.6931471824645996\n",
      "epoch: 23 step: 134 loss: 0.6931471824645996\n",
      "epoch: 23 step: 135 loss: 0.6931471824645996\n",
      "epoch: 23 step: 136 loss: 0.6931471824645996\n",
      "epoch: 23 step: 137 loss: 0.6931471824645996\n",
      "epoch: 23 step: 138 loss: 0.6931471824645996\n",
      "epoch: 23 step: 139 loss: 0.6931471824645996\n",
      "epoch: 23 step: 140 loss: 0.6931471824645996\n",
      "epoch: 23 step: 141 loss: 0.6931471824645996\n",
      "epoch: 23 step: 142 loss: 0.6931471824645996\n",
      "epoch: 23 step: 143 loss: 0.6931471824645996\n",
      "epoch: 23 step: 144 loss: 0.6931471824645996\n",
      "epoch: 23 step: 145 loss: 0.6931471824645996\n",
      "epoch: 23 step: 146 loss: 0.6931471824645996\n",
      "epoch: 23 step: 147 loss: 0.6931471824645996\n",
      "epoch: 23 step: 148 loss: 0.6931471824645996\n",
      "epoch: 23 step: 149 loss: 0.6931471824645996\n",
      "epoch: 23 step: 150 loss: 0.6931471824645996\n",
      "epoch: 23 step: 151 loss: 0.6931471824645996\n",
      "epoch: 23 step: 152 loss: 0.6931471824645996\n",
      "epoch: 23 step: 153 loss: 0.6931471824645996\n",
      "epoch: 23 step: 154 loss: 0.6931471824645996\n",
      "epoch: 23 step: 155 loss: 0.6931471824645996\n",
      "epoch: 23 step: 156 loss: 0.6931471824645996\n",
      "epoch: 23 step: 157 loss: 0.6931471824645996\n",
      "epoch: 23 step: 158 loss: 0.6931471824645996\n",
      "epoch: 23 step: 159 loss: 0.6931471824645996\n",
      "epoch: 23 step: 160 loss: 0.6931471824645996\n",
      "epoch: 23 step: 161 loss: 0.6931471824645996\n",
      "epoch: 23 step: 162 loss: 0.6931471824645996\n",
      "epoch: 23 step: 163 loss: 0.6931471824645996\n",
      "epoch: 23 step: 164 loss: 0.6931471824645996\n",
      "epoch: 23 step: 165 loss: 0.6931471824645996\n",
      "epoch: 23 step: 166 loss: 0.6931471824645996\n",
      "epoch: 23 step: 167 loss: 0.6931471824645996\n",
      "epoch: 23 step: 168 loss: 0.6931471824645996\n",
      "epoch: 23 step: 169 loss: 0.6931471824645996\n",
      "epoch: 23 step: 170 loss: 0.6931471824645996\n",
      "epoch: 23 step: 171 loss: 0.6931471824645996\n",
      "epoch: 23 step: 172 loss: 0.6931471824645996\n",
      "epoch: 23 step: 173 loss: 0.6931471824645996\n",
      "epoch: 23 step: 174 loss: 0.6931471824645996\n",
      "epoch: 23 step: 175 loss: 0.6931471824645996\n",
      "epoch: 23 step: 176 loss: 0.6931471824645996\n",
      "epoch: 23 step: 177 loss: 0.6931471824645996\n",
      "epoch: 23 step: 178 loss: 0.6931471824645996\n",
      "epoch: 23 step: 179 loss: 0.6931471824645996\n",
      "epoch: 23 step: 180 loss: 0.6931471824645996\n",
      "epoch: 23 step: 181 loss: 0.6931471824645996\n",
      "epoch: 23 step: 182 loss: 0.6931471824645996\n",
      "epoch: 23 step: 183 loss: 0.6931471824645996\n",
      "epoch: 23 step: 184 loss: 0.6931471824645996\n",
      "epoch: 23 step: 185 loss: 0.6931471824645996\n",
      "epoch: 23 step: 186 loss: 0.6931471824645996\n",
      "epoch: 23 step: 187 loss: 0.6931471824645996\n",
      "epoch: 23 step: 188 loss: 0.6931471824645996\n",
      "epoch: 23 step: 189 loss: 0.6931471824645996\n",
      "epoch: 23 step: 190 loss: 0.6931471824645996\n",
      "epoch: 23 step: 191 loss: 0.6931471824645996\n",
      "epoch: 23 step: 192 loss: 0.6931471824645996\n",
      "epoch: 23 step: 193 loss: 0.6931471824645996\n",
      "epoch: 23 step: 194 loss: 0.6931471824645996\n",
      "epoch: 23 step: 195 loss: 0.6931471824645996\n",
      "epoch: 23 step: 196 loss: 0.6931471824645996\n",
      "epoch: 23 step: 197 loss: 0.6931471824645996\n",
      "epoch: 23 step: 198 loss: 0.6931471824645996\n",
      "epoch: 23 step: 199 loss: 0.6931471824645996\n",
      "epoch: 23 step: 200 loss: 0.6931471824645996\n",
      "epoch: 23 step: 201 loss: 0.6931471824645996\n",
      "epoch: 23 step: 202 loss: 0.6931471824645996\n",
      "epoch: 23 step: 203 loss: 0.6931471824645996\n",
      "epoch: 23 step: 204 loss: 0.6931471824645996\n",
      "epoch: 23 step: 205 loss: 0.6931471824645996\n",
      "epoch: 23 step: 206 loss: 0.6931471824645996\n",
      "epoch: 23 step: 207 loss: 0.6931471824645996\n",
      "epoch: 23 step: 208 loss: 0.6931471824645996\n",
      "epoch: 23 step: 209 loss: 0.6931471824645996\n",
      "epoch: 23 step: 210 loss: 0.6931471824645996\n",
      "epoch: 23 step: 211 loss: 0.6931471824645996\n",
      "epoch: 23 step: 212 loss: 0.6931471824645996\n",
      "epoch: 23 step: 213 loss: 0.6931471824645996\n",
      "epoch: 23 step: 214 loss: 0.6931471824645996\n",
      "epoch: 23 step: 215 loss: 0.6931471824645996\n",
      "epoch: 23 step: 216 loss: 0.6931471824645996\n",
      "epoch: 23 step: 217 loss: 0.6931471824645996\n",
      "epoch: 23 step: 218 loss: 0.6931471824645996\n",
      "epoch: 23 step: 219 loss: 0.6931471824645996\n",
      "epoch: 23 step: 220 loss: 0.6931471824645996\n",
      "epoch: 23 step: 221 loss: 0.6931471824645996\n",
      "epoch: 23 step: 222 loss: 0.6931471824645996\n",
      "epoch: 23 step: 223 loss: 0.6931471824645996\n",
      "epoch: 23 step: 224 loss: 0.6931471824645996\n",
      "epoch: 23 step: 225 loss: 0.6931471824645996\n",
      "epoch: 23 step: 226 loss: 0.6931471824645996\n",
      "epoch: 23 step: 227 loss: 0.6931471824645996\n",
      "epoch: 23 step: 228 loss: 0.6931471824645996\n",
      "epoch: 23 step: 229 loss: 0.6931471824645996\n",
      "epoch: 23 step: 230 loss: 0.6931471824645996\n",
      "epoch: 23 step: 231 loss: 0.6931471824645996\n",
      "epoch: 23 step: 232 loss: 0.6931471824645996\n",
      "epoch: 23 step: 233 loss: 0.6931471824645996\n",
      "epoch: 23 step: 234 loss: 0.6931471824645996\n",
      "epoch: 23 step: 235 loss: 0.6931471824645996\n",
      "epoch: 23 step: 236 loss: 0.6931471824645996\n",
      "epoch: 23 step: 237 loss: 0.6931471824645996\n",
      "epoch: 23 step: 238 loss: 0.6931471824645996\n",
      "epoch: 23 step: 239 loss: 0.6931471824645996\n",
      "epoch: 23 step: 240 loss: 0.6931471824645996\n",
      "epoch: 23 step: 241 loss: 0.6931471824645996\n",
      "epoch: 23 step: 242 loss: 0.6931471824645996\n",
      "epoch: 23 step: 243 loss: 0.6931471824645996\n",
      "epoch: 23 step: 244 loss: 0.6931471824645996\n",
      "epoch: 23 step: 245 loss: 0.6931471824645996\n",
      "epoch: 23 step: 246 loss: 0.6931471824645996\n",
      "epoch: 23 step: 247 loss: 0.6931471824645996\n",
      "epoch: 23 step: 248 loss: 0.6931471824645996\n",
      "epoch: 23 step: 249 loss: 0.6931471824645996\n",
      "epoch: 23 step: 250 loss: 0.6931471824645996\n",
      "epoch: 23 step: 251 loss: 0.6931471824645996\n",
      "epoch: 23 step: 252 loss: 0.6931471824645996\n",
      "epoch: 23 step: 253 loss: 0.6931471824645996\n",
      "epoch: 23 step: 254 loss: 0.6931471824645996\n",
      "epoch: 23 step: 255 loss: 0.6931471824645996\n",
      "epoch: 23 step: 256 loss: 0.6931471824645996\n",
      "epoch: 23 step: 257 loss: 0.6931471824645996\n",
      "epoch: 23 step: 258 loss: 0.6931471824645996\n",
      "epoch: 23 step: 259 loss: 0.6931471824645996\n",
      "epoch: 23 step: 260 loss: 0.6931471824645996\n",
      "epoch: 23 step: 261 loss: 0.6931471824645996\n",
      "epoch: 23 step: 262 loss: 0.6931471824645996\n",
      "epoch: 23 step: 263 loss: 0.6931471824645996\n",
      "epoch: 23 step: 264 loss: 0.6931471824645996\n",
      "epoch: 23 step: 265 loss: 0.6931471824645996\n",
      "epoch: 23 step: 266 loss: 0.6931471824645996\n",
      "epoch: 23 step: 267 loss: 0.6931471824645996\n",
      "epoch: 23 step: 268 loss: 0.6931471824645996\n",
      "epoch: 23 step: 269 loss: 0.6931471824645996\n",
      "epoch: 23 step: 270 loss: 0.6931471824645996\n",
      "epoch: 23 step: 271 loss: 0.6931471824645996\n",
      "epoch: 23 step: 272 loss: 0.6931471824645996\n",
      "epoch: 23 step: 273 loss: 0.6931471824645996\n",
      "epoch: 23 step: 274 loss: 0.6931471824645996\n",
      "epoch: 23 step: 275 loss: 0.6931471824645996\n",
      "epoch: 23 step: 276 loss: 0.6931471824645996\n",
      "epoch: 23 step: 277 loss: 0.6931471824645996\n",
      "epoch: 23 step: 278 loss: 0.6931471824645996\n",
      "epoch: 23 step: 279 loss: 0.6931471824645996\n",
      "epoch: 23 step: 280 loss: 0.6931471824645996\n",
      "epoch: 23 step: 281 loss: 0.6931471824645996\n",
      "epoch: 23 step: 282 loss: 0.6931471824645996\n",
      "epoch: 23 step: 283 loss: 0.6931471824645996\n",
      "epoch: 23 step: 284 loss: 0.6931471824645996\n",
      "epoch: 23 step: 285 loss: 0.6931471824645996\n",
      "epoch: 23 step: 286 loss: 0.6931471824645996\n",
      "epoch: 23 step: 287 loss: 0.6931471824645996\n",
      "epoch: 23 step: 288 loss: 0.6931471824645996\n",
      "epoch: 23 step: 289 loss: 0.6931471824645996\n",
      "epoch: 23 step: 290 loss: 0.6931471824645996\n",
      "epoch: 23 step: 291 loss: 0.6931471824645996\n",
      "epoch: 23 step: 292 loss: 0.6931471824645996\n",
      "epoch: 23 step: 293 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 294 loss: 0.6931471824645996\n",
      "epoch: 23 step: 295 loss: 0.6931471824645996\n",
      "epoch: 23 step: 296 loss: 0.6931471824645996\n",
      "epoch: 23 step: 297 loss: 0.6931471824645996\n",
      "epoch: 23 step: 298 loss: 0.6931471824645996\n",
      "epoch: 23 step: 299 loss: 0.6931471824645996\n",
      "epoch: 23 step: 300 loss: 0.6931471824645996\n",
      "epoch: 23 step: 301 loss: 0.6931471824645996\n",
      "epoch: 23 step: 302 loss: 0.6931471824645996\n",
      "epoch: 23 step: 303 loss: 0.6931471824645996\n",
      "epoch: 23 step: 304 loss: 0.6931471824645996\n",
      "epoch: 23 step: 305 loss: 0.6931471824645996\n",
      "epoch: 23 step: 306 loss: 0.6931471824645996\n",
      "epoch: 23 step: 307 loss: 0.6931471824645996\n",
      "epoch: 23 step: 308 loss: 0.6931471824645996\n",
      "epoch: 23 step: 309 loss: 0.6931471824645996\n",
      "epoch: 23 step: 310 loss: 0.6931471824645996\n",
      "epoch: 23 step: 311 loss: 0.6931471824645996\n",
      "epoch: 23 step: 312 loss: 0.6931471824645996\n",
      "epoch: 23 step: 313 loss: 0.6931471824645996\n",
      "epoch: 23 step: 314 loss: 0.6931471824645996\n",
      "epoch: 23 step: 315 loss: 0.6931471824645996\n",
      "epoch: 23 step: 316 loss: 0.6931471824645996\n",
      "epoch: 23 step: 317 loss: 0.6931471824645996\n",
      "epoch: 23 step: 318 loss: 0.6931471824645996\n",
      "epoch: 23 step: 319 loss: 0.6931471824645996\n",
      "epoch: 23 step: 320 loss: 0.6931471824645996\n",
      "epoch: 23 step: 321 loss: 0.6931471824645996\n",
      "epoch: 23 step: 322 loss: 0.6931471824645996\n",
      "epoch: 23 step: 323 loss: 0.6931471824645996\n",
      "epoch: 23 step: 324 loss: 0.6931471824645996\n",
      "epoch: 23 step: 325 loss: 0.6931471824645996\n",
      "epoch: 23 step: 326 loss: 0.6931471824645996\n",
      "epoch: 23 step: 327 loss: 0.6931471824645996\n",
      "epoch: 23 step: 328 loss: 0.6931471824645996\n",
      "epoch: 23 step: 329 loss: 0.6931471824645996\n",
      "epoch: 23 step: 330 loss: 0.6931471824645996\n",
      "epoch: 23 step: 331 loss: 0.6931471824645996\n",
      "epoch: 23 step: 332 loss: 0.6931471824645996\n",
      "epoch: 23 step: 333 loss: 0.6931471824645996\n",
      "epoch: 23 step: 334 loss: 0.6931471824645996\n",
      "epoch: 23 step: 335 loss: 0.6931471824645996\n",
      "epoch: 23 step: 336 loss: 0.6931471824645996\n",
      "epoch: 23 step: 337 loss: 0.6931471824645996\n",
      "epoch: 23 step: 338 loss: 0.6931471824645996\n",
      "epoch: 23 step: 339 loss: 0.6931471824645996\n",
      "epoch: 23 step: 340 loss: 0.6931471824645996\n",
      "epoch: 23 step: 341 loss: 0.6931471824645996\n",
      "epoch: 23 step: 342 loss: 0.6931471824645996\n",
      "epoch: 23 step: 343 loss: 0.6931471824645996\n",
      "epoch: 23 step: 344 loss: 0.6931471824645996\n",
      "epoch: 23 step: 345 loss: 0.6931471824645996\n",
      "epoch: 23 step: 346 loss: 0.6931471824645996\n",
      "epoch: 23 step: 347 loss: 0.6931471824645996\n",
      "epoch: 23 step: 348 loss: 0.6931471824645996\n",
      "epoch: 23 step: 349 loss: 0.6931471824645996\n",
      "epoch: 23 step: 350 loss: 0.6931471824645996\n",
      "epoch: 23 step: 351 loss: 0.6931471824645996\n",
      "epoch: 23 step: 352 loss: 0.6931471824645996\n",
      "epoch: 23 step: 353 loss: 0.6931471824645996\n",
      "epoch: 23 step: 354 loss: 0.6931471824645996\n",
      "epoch: 23 step: 355 loss: 0.6931471824645996\n",
      "epoch: 23 step: 356 loss: 0.6931471824645996\n",
      "epoch: 23 step: 357 loss: 0.6931471824645996\n",
      "epoch: 23 step: 358 loss: 0.6931471824645996\n",
      "epoch: 23 step: 359 loss: 0.6931471824645996\n",
      "epoch: 23 step: 360 loss: 0.6931471824645996\n",
      "epoch: 23 step: 361 loss: 0.6931471824645996\n",
      "epoch: 23 step: 362 loss: 0.6931471824645996\n",
      "epoch: 23 step: 363 loss: 0.6931471824645996\n",
      "epoch: 23 step: 364 loss: 0.6931471824645996\n",
      "epoch: 23 step: 365 loss: 0.6931471824645996\n",
      "epoch: 23 step: 366 loss: 0.6931471824645996\n",
      "epoch: 23 step: 367 loss: 0.6931471824645996\n",
      "epoch: 23 step: 368 loss: 0.6931471824645996\n",
      "epoch: 23 step: 369 loss: 0.6931471824645996\n",
      "epoch: 23 step: 370 loss: 0.6931471824645996\n",
      "epoch: 23 step: 371 loss: 0.6931471824645996\n",
      "epoch: 23 step: 372 loss: 0.6931471824645996\n",
      "epoch: 23 step: 373 loss: 0.6931471824645996\n",
      "epoch: 23 step: 374 loss: 0.6931471824645996\n",
      "epoch: 23 step: 375 loss: 0.6931471824645996\n",
      "epoch: 23 step: 376 loss: 0.6931471824645996\n",
      "epoch: 23 step: 377 loss: 0.6931471824645996\n",
      "epoch: 23 step: 378 loss: 0.6931471824645996\n",
      "epoch: 23 step: 379 loss: 0.6931471824645996\n",
      "epoch: 23 step: 380 loss: 0.6931471824645996\n",
      "epoch: 23 step: 381 loss: 0.6931471824645996\n",
      "epoch: 23 step: 382 loss: 0.6931471824645996\n",
      "epoch: 23 step: 383 loss: 0.6931471824645996\n",
      "epoch: 23 step: 384 loss: 0.6931471824645996\n",
      "epoch: 23 step: 385 loss: 0.6931471824645996\n",
      "epoch: 23 step: 386 loss: 0.6931471824645996\n",
      "epoch: 23 step: 387 loss: 0.6931471824645996\n",
      "epoch: 23 step: 388 loss: 0.6931471824645996\n",
      "epoch: 23 step: 389 loss: 0.6931471824645996\n",
      "epoch: 23 step: 390 loss: 0.6931471824645996\n",
      "epoch: 23 step: 391 loss: 0.6931471824645996\n",
      "epoch: 23 step: 392 loss: 0.6931471824645996\n",
      "epoch: 23 step: 393 loss: 0.6931471824645996\n",
      "epoch: 23 step: 394 loss: 0.6931471824645996\n",
      "epoch: 23 step: 395 loss: 0.6931471824645996\n",
      "epoch: 23 step: 396 loss: 0.6931471824645996\n",
      "epoch: 23 step: 397 loss: 0.6931471824645996\n",
      "epoch: 23 step: 398 loss: 0.6931471824645996\n",
      "epoch: 23 step: 399 loss: 0.6931471824645996\n",
      "epoch: 23 step: 400 loss: 0.6931471824645996\n",
      "epoch: 23 step: 401 loss: 0.6931471824645996\n",
      "epoch: 23 step: 402 loss: 0.6931471824645996\n",
      "epoch: 23 step: 403 loss: 0.6931471824645996\n",
      "epoch: 23 step: 404 loss: 0.6931471824645996\n",
      "epoch: 23 step: 405 loss: 0.6931471824645996\n",
      "epoch: 23 step: 406 loss: 0.6931471824645996\n",
      "epoch: 23 step: 407 loss: 0.6931471824645996\n",
      "epoch: 23 step: 408 loss: 0.6931471824645996\n",
      "epoch: 23 step: 409 loss: 0.6931471824645996\n",
      "epoch: 23 step: 410 loss: 0.6931471824645996\n",
      "epoch: 23 step: 411 loss: 0.6931471824645996\n",
      "epoch: 23 step: 412 loss: 0.6931471824645996\n",
      "epoch: 23 step: 413 loss: 0.6931471824645996\n",
      "epoch: 23 step: 414 loss: 0.6931471824645996\n",
      "epoch: 23 step: 415 loss: 0.6931471824645996\n",
      "epoch: 23 step: 416 loss: 0.6931471824645996\n",
      "epoch: 23 step: 417 loss: 0.6931471824645996\n",
      "epoch: 23 step: 418 loss: 0.6931471824645996\n",
      "epoch: 23 step: 419 loss: 0.6931471824645996\n",
      "epoch: 23 step: 420 loss: 0.6931471824645996\n",
      "epoch: 23 step: 421 loss: 0.6931471824645996\n",
      "epoch: 23 step: 422 loss: 0.6931471824645996\n",
      "epoch: 23 step: 423 loss: 0.6931471824645996\n",
      "epoch: 23 step: 424 loss: 0.6931471824645996\n",
      "epoch: 23 step: 425 loss: 0.6931471824645996\n",
      "epoch: 23 step: 426 loss: 0.6931471824645996\n",
      "epoch: 23 step: 427 loss: 0.6931471824645996\n",
      "epoch: 23 step: 428 loss: 0.6931471824645996\n",
      "epoch: 23 step: 429 loss: 0.6931471824645996\n",
      "epoch: 23 step: 430 loss: 0.6931471824645996\n",
      "epoch: 23 step: 431 loss: 0.6931471824645996\n",
      "epoch: 23 step: 432 loss: 0.6931471824645996\n",
      "epoch: 23 step: 433 loss: 0.6931471824645996\n",
      "epoch: 23 step: 434 loss: 0.6931471824645996\n",
      "epoch: 23 step: 435 loss: 0.6931471824645996\n",
      "epoch: 23 step: 436 loss: 0.6931471824645996\n",
      "epoch: 23 step: 437 loss: 0.6931471824645996\n",
      "epoch: 23 step: 438 loss: 0.6931471824645996\n",
      "epoch: 23 step: 439 loss: 0.6931471824645996\n",
      "epoch: 23 step: 440 loss: 0.6931471824645996\n",
      "epoch: 23 step: 441 loss: 0.6931471824645996\n",
      "epoch: 23 step: 442 loss: 0.6931471824645996\n",
      "epoch: 23 step: 443 loss: 0.6931471824645996\n",
      "epoch: 23 step: 444 loss: 0.6931471824645996\n",
      "epoch: 23 step: 445 loss: 0.6931471824645996\n",
      "epoch: 23 step: 446 loss: 0.6931471824645996\n",
      "epoch: 23 step: 447 loss: 0.6931471824645996\n",
      "epoch: 23 step: 448 loss: 0.6931471824645996\n",
      "epoch: 23 step: 449 loss: 0.6931471824645996\n",
      "epoch: 23 step: 450 loss: 0.6931471824645996\n",
      "epoch: 23 step: 451 loss: 0.6931471824645996\n",
      "epoch: 23 step: 452 loss: 0.6931471824645996\n",
      "epoch: 23 step: 453 loss: 0.6931471824645996\n",
      "epoch: 23 step: 454 loss: 0.6931471824645996\n",
      "epoch: 23 step: 455 loss: 0.6931471824645996\n",
      "epoch: 23 step: 456 loss: 0.6931471824645996\n",
      "epoch: 23 step: 457 loss: 0.6931471824645996\n",
      "epoch: 23 step: 458 loss: 0.6931471824645996\n",
      "epoch: 23 step: 459 loss: 0.6931471824645996\n",
      "epoch: 23 step: 460 loss: 0.6931471824645996\n",
      "epoch: 23 step: 461 loss: 0.6931471824645996\n",
      "epoch: 23 step: 462 loss: 0.6931471824645996\n",
      "epoch: 23 step: 463 loss: 0.6931471824645996\n",
      "epoch: 23 step: 464 loss: 0.6931471824645996\n",
      "epoch: 23 step: 465 loss: 0.6931471824645996\n",
      "epoch: 23 step: 466 loss: 0.6931471824645996\n",
      "epoch: 23 step: 467 loss: 0.6931471824645996\n",
      "epoch: 23 step: 468 loss: 0.6931471824645996\n",
      "epoch: 23 step: 469 loss: 0.6931471824645996\n",
      "epoch: 23 step: 470 loss: 0.6931471824645996\n",
      "epoch: 23 step: 471 loss: 0.6931471824645996\n",
      "epoch: 23 step: 472 loss: 0.6931471824645996\n",
      "epoch: 23 step: 473 loss: 0.6931471824645996\n",
      "epoch: 23 step: 474 loss: 0.6931471824645996\n",
      "epoch: 23 step: 475 loss: 0.6931471824645996\n",
      "epoch: 23 step: 476 loss: 0.6931471824645996\n",
      "epoch: 23 step: 477 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 478 loss: 0.6931471824645996\n",
      "epoch: 23 step: 479 loss: 0.6931471824645996\n",
      "epoch: 23 step: 480 loss: 0.6931471824645996\n",
      "epoch: 23 step: 481 loss: 0.6931471824645996\n",
      "epoch: 23 step: 482 loss: 0.6931471824645996\n",
      "epoch: 23 step: 483 loss: 0.6931471824645996\n",
      "epoch: 23 step: 484 loss: 0.6931471824645996\n",
      "epoch: 23 step: 485 loss: 0.6931471824645996\n",
      "epoch: 23 step: 486 loss: 0.6931471824645996\n",
      "epoch: 23 step: 487 loss: 0.6931471824645996\n",
      "epoch: 23 step: 488 loss: 0.6931471824645996\n",
      "epoch: 23 step: 489 loss: 0.6931471824645996\n",
      "epoch: 23 step: 490 loss: 0.6931471824645996\n",
      "epoch: 23 step: 491 loss: 0.6931471824645996\n",
      "epoch: 23 step: 492 loss: 0.6931471824645996\n",
      "epoch: 23 step: 493 loss: 0.6931471824645996\n",
      "epoch: 23 step: 494 loss: 0.6931471824645996\n",
      "epoch: 23 step: 495 loss: 0.6931471824645996\n",
      "epoch: 23 step: 496 loss: 0.6931471824645996\n",
      "epoch: 23 step: 497 loss: 0.6931471824645996\n",
      "epoch: 23 step: 498 loss: 0.6931471824645996\n",
      "epoch: 23 step: 499 loss: 0.6931471824645996\n",
      "epoch: 23 step: 500 loss: 0.6931471824645996\n",
      "epoch: 23 step: 501 loss: 0.6931471824645996\n",
      "epoch: 23 step: 502 loss: 0.6931471824645996\n",
      "epoch: 23 step: 503 loss: 0.6931471824645996\n",
      "epoch: 23 step: 504 loss: 0.6931471824645996\n",
      "epoch: 23 step: 505 loss: 0.6931471824645996\n",
      "epoch: 23 step: 506 loss: 0.6931471824645996\n",
      "epoch: 23 step: 507 loss: 0.6931471824645996\n",
      "epoch: 23 step: 508 loss: 0.6931471824645996\n",
      "epoch: 23 step: 509 loss: 0.6931471824645996\n",
      "epoch: 23 step: 510 loss: 0.6931471824645996\n",
      "epoch: 23 step: 511 loss: 0.6931471824645996\n",
      "epoch: 23 step: 512 loss: 0.6931471824645996\n",
      "epoch: 23 step: 513 loss: 0.6931471824645996\n",
      "epoch: 23 step: 514 loss: 0.6931471824645996\n",
      "epoch: 23 step: 515 loss: 0.6931471824645996\n",
      "epoch: 23 step: 516 loss: 0.6931471824645996\n",
      "epoch: 23 step: 517 loss: 0.6931471824645996\n",
      "epoch: 23 step: 518 loss: 0.6931471824645996\n",
      "epoch: 23 step: 519 loss: 0.6931471824645996\n",
      "epoch: 23 step: 520 loss: 0.6931471824645996\n",
      "epoch: 23 step: 521 loss: 0.6931471824645996\n",
      "epoch: 23 step: 522 loss: 0.6931471824645996\n",
      "epoch: 23 step: 523 loss: 0.6931471824645996\n",
      "epoch: 23 step: 524 loss: 0.6931471824645996\n",
      "epoch: 23 step: 525 loss: 0.6931471824645996\n",
      "epoch: 23 step: 526 loss: 0.6931471824645996\n",
      "epoch: 23 step: 527 loss: 0.6931471824645996\n",
      "epoch: 23 step: 528 loss: 0.6931471824645996\n",
      "epoch: 23 step: 529 loss: 0.6931471824645996\n",
      "epoch: 23 step: 530 loss: 0.6931471824645996\n",
      "epoch: 23 step: 531 loss: 0.6931471824645996\n",
      "epoch: 23 step: 532 loss: 0.6931471824645996\n",
      "epoch: 23 step: 533 loss: 0.6931471824645996\n",
      "epoch: 23 step: 534 loss: 0.6931471824645996\n",
      "epoch: 23 step: 535 loss: 0.6931471824645996\n",
      "epoch: 23 step: 536 loss: 0.6931471824645996\n",
      "epoch: 23 step: 537 loss: 0.6931471824645996\n",
      "epoch: 23 step: 538 loss: 0.6931471824645996\n",
      "epoch: 23 step: 539 loss: 0.6931471824645996\n",
      "epoch: 23 step: 540 loss: 0.6931471824645996\n",
      "epoch: 23 step: 541 loss: 0.6931471824645996\n",
      "epoch: 23 step: 542 loss: 0.6931471824645996\n",
      "epoch: 23 step: 543 loss: 0.6931471824645996\n",
      "epoch: 23 step: 544 loss: 0.6931471824645996\n",
      "epoch: 23 step: 545 loss: 0.6931471824645996\n",
      "epoch: 23 step: 546 loss: 0.6931471824645996\n",
      "epoch: 23 step: 547 loss: 0.6931471824645996\n",
      "epoch: 23 step: 548 loss: 0.6931471824645996\n",
      "epoch: 23 step: 549 loss: 0.6931471824645996\n",
      "epoch: 23 step: 550 loss: 0.6931471824645996\n",
      "epoch: 23 step: 551 loss: 0.6931471824645996\n",
      "epoch: 23 step: 552 loss: 0.6931471824645996\n",
      "epoch: 23 step: 553 loss: 0.6931471824645996\n",
      "epoch: 23 step: 554 loss: 0.6931471824645996\n",
      "epoch: 23 step: 555 loss: 0.6931471824645996\n",
      "epoch: 23 step: 556 loss: 0.6931471824645996\n",
      "epoch: 23 step: 557 loss: 0.6931471824645996\n",
      "epoch: 23 step: 558 loss: 0.6931471824645996\n",
      "epoch: 23 step: 559 loss: 0.6931471824645996\n",
      "epoch: 23 step: 560 loss: 0.6931471824645996\n",
      "epoch: 23 step: 561 loss: 0.6931471824645996\n",
      "epoch: 23 step: 562 loss: 0.6931471824645996\n",
      "epoch: 23 step: 563 loss: 0.6931471824645996\n",
      "epoch: 23 step: 564 loss: 0.6931471824645996\n",
      "epoch: 23 step: 565 loss: 0.6931471824645996\n",
      "epoch: 23 step: 566 loss: 0.6931471824645996\n",
      "epoch: 23 step: 567 loss: 0.6931471824645996\n",
      "epoch: 23 step: 568 loss: 0.6931471824645996\n",
      "epoch: 23 step: 569 loss: 0.6931471824645996\n",
      "epoch: 23 step: 570 loss: 0.6931471824645996\n",
      "epoch: 23 step: 571 loss: 0.6931471824645996\n",
      "epoch: 23 step: 572 loss: 0.6931471824645996\n",
      "epoch: 23 step: 573 loss: 0.6931471824645996\n",
      "epoch: 23 step: 574 loss: 0.6931471824645996\n",
      "epoch: 23 step: 575 loss: 0.6931471824645996\n",
      "epoch: 23 step: 576 loss: 0.6931471824645996\n",
      "epoch: 23 step: 577 loss: 0.6931471824645996\n",
      "epoch: 23 step: 578 loss: 0.6931471824645996\n",
      "epoch: 23 step: 579 loss: 0.6931471824645996\n",
      "epoch: 23 step: 580 loss: 0.6931471824645996\n",
      "epoch: 23 step: 581 loss: 0.6931471824645996\n",
      "epoch: 23 step: 582 loss: 0.6931471824645996\n",
      "epoch: 23 step: 583 loss: 0.6931471824645996\n",
      "epoch: 23 step: 584 loss: 0.6931471824645996\n",
      "epoch: 23 step: 585 loss: 0.6931471824645996\n",
      "epoch: 23 step: 586 loss: 0.6931471824645996\n",
      "epoch: 23 step: 587 loss: 0.6931471824645996\n",
      "epoch: 23 step: 588 loss: 0.6931471824645996\n",
      "epoch: 23 step: 589 loss: 0.6931471824645996\n",
      "epoch: 23 step: 590 loss: 0.6931471824645996\n",
      "epoch: 23 step: 591 loss: 0.6931471824645996\n",
      "epoch: 23 step: 592 loss: 0.6931471824645996\n",
      "epoch: 23 step: 593 loss: 0.6931471824645996\n",
      "epoch: 23 step: 594 loss: 0.6931471824645996\n",
      "epoch: 23 step: 595 loss: 0.6931471824645996\n",
      "epoch: 23 step: 596 loss: 0.6931471824645996\n",
      "epoch: 23 step: 597 loss: 0.6931471824645996\n",
      "epoch: 23 step: 598 loss: 0.6931471824645996\n",
      "epoch: 23 step: 599 loss: 0.6931471824645996\n",
      "epoch: 23 step: 600 loss: 0.6931471824645996\n",
      "epoch: 23 step: 601 loss: 0.6931471824645996\n",
      "epoch: 23 step: 602 loss: 0.6931471824645996\n",
      "epoch: 23 step: 603 loss: 0.6931471824645996\n",
      "epoch: 23 step: 604 loss: 0.6931471824645996\n",
      "epoch: 23 step: 605 loss: 0.6931471824645996\n",
      "epoch: 23 step: 606 loss: 0.6931471824645996\n",
      "epoch: 23 step: 607 loss: 0.6931471824645996\n",
      "epoch: 23 step: 608 loss: 0.6931471824645996\n",
      "epoch: 23 step: 609 loss: 0.6931471824645996\n",
      "epoch: 23 step: 610 loss: 0.6931471824645996\n",
      "epoch: 23 step: 611 loss: 0.6931471824645996\n",
      "epoch: 23 step: 612 loss: 0.6931471824645996\n",
      "epoch: 23 step: 613 loss: 0.6931471824645996\n",
      "epoch: 23 step: 614 loss: 0.6931471824645996\n",
      "epoch: 23 step: 615 loss: 0.6931471824645996\n",
      "epoch: 23 step: 616 loss: 0.6931471824645996\n",
      "epoch: 23 step: 617 loss: 0.6931471824645996\n",
      "epoch: 23 step: 618 loss: 0.6931471824645996\n",
      "epoch: 23 step: 619 loss: 0.6931471824645996\n",
      "epoch: 23 step: 620 loss: 0.6931471824645996\n",
      "epoch: 23 step: 621 loss: 0.6931471824645996\n",
      "epoch: 23 step: 622 loss: 0.6931471824645996\n",
      "epoch: 23 step: 623 loss: 0.6931471824645996\n",
      "epoch: 23 step: 624 loss: 0.6931471824645996\n",
      "epoch: 23 step: 625 loss: 0.6931471824645996\n",
      "epoch: 23 step: 626 loss: 0.6931471824645996\n",
      "epoch: 23 step: 627 loss: 0.6931471824645996\n",
      "epoch: 23 step: 628 loss: 0.6931471824645996\n",
      "epoch: 23 step: 629 loss: 0.6931471824645996\n",
      "epoch: 23 step: 630 loss: 0.6931471824645996\n",
      "epoch: 23 step: 631 loss: 0.6931471824645996\n",
      "epoch: 23 step: 632 loss: 0.6931471824645996\n",
      "epoch: 23 step: 633 loss: 0.6931471824645996\n",
      "epoch: 23 step: 634 loss: 0.6931471824645996\n",
      "epoch: 23 step: 635 loss: 0.6931471824645996\n",
      "epoch: 23 step: 636 loss: 0.6931471824645996\n",
      "epoch: 23 step: 637 loss: 0.6931471824645996\n",
      "epoch: 23 step: 638 loss: 0.6931471824645996\n",
      "epoch: 23 step: 639 loss: 0.6931471824645996\n",
      "epoch: 23 step: 640 loss: 0.6931471824645996\n",
      "epoch: 23 step: 641 loss: 0.6931471824645996\n",
      "epoch: 23 step: 642 loss: 0.6931471824645996\n",
      "epoch: 23 step: 643 loss: 0.6931471824645996\n",
      "epoch: 23 step: 644 loss: 0.6931471824645996\n",
      "epoch: 23 step: 645 loss: 0.6931471824645996\n",
      "epoch: 23 step: 646 loss: 0.6931471824645996\n",
      "epoch: 23 step: 647 loss: 0.6931471824645996\n",
      "epoch: 23 step: 648 loss: 0.6931471824645996\n",
      "epoch: 23 step: 649 loss: 0.6931471824645996\n",
      "epoch: 23 step: 650 loss: 0.6931471824645996\n",
      "epoch: 23 step: 651 loss: 0.6931471824645996\n",
      "epoch: 23 step: 652 loss: 0.6931471824645996\n",
      "epoch: 23 step: 653 loss: 0.6931471824645996\n",
      "epoch: 23 step: 654 loss: 0.6931471824645996\n",
      "epoch: 23 step: 655 loss: 0.6931471824645996\n",
      "epoch: 23 step: 656 loss: 0.6931471824645996\n",
      "epoch: 23 step: 657 loss: 0.6931471824645996\n",
      "epoch: 23 step: 658 loss: 0.6931471824645996\n",
      "epoch: 23 step: 659 loss: 0.6931471824645996\n",
      "epoch: 23 step: 660 loss: 0.6931471824645996\n",
      "epoch: 23 step: 661 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 662 loss: 0.6931471824645996\n",
      "epoch: 23 step: 663 loss: 0.6931471824645996\n",
      "epoch: 23 step: 664 loss: 0.6931471824645996\n",
      "epoch: 23 step: 665 loss: 0.6931471824645996\n",
      "epoch: 23 step: 666 loss: 0.6931471824645996\n",
      "epoch: 23 step: 667 loss: 0.6931471824645996\n",
      "epoch: 23 step: 668 loss: 0.6931471824645996\n",
      "epoch: 23 step: 669 loss: 0.6931471824645996\n",
      "epoch: 23 step: 670 loss: 0.6931471824645996\n",
      "epoch: 23 step: 671 loss: 0.6931471824645996\n",
      "epoch: 23 step: 672 loss: 0.6931471824645996\n",
      "epoch: 23 step: 673 loss: 0.6931471824645996\n",
      "epoch: 23 step: 674 loss: 0.6931471824645996\n",
      "epoch: 23 step: 675 loss: 0.6931471824645996\n",
      "epoch: 23 step: 676 loss: 0.6931471824645996\n",
      "epoch: 23 step: 677 loss: 0.6931471824645996\n",
      "epoch: 23 step: 678 loss: 0.6931471824645996\n",
      "epoch: 23 step: 679 loss: 0.6931471824645996\n",
      "epoch: 23 step: 680 loss: 0.6931471824645996\n",
      "epoch: 23 step: 681 loss: 0.6931471824645996\n",
      "epoch: 23 step: 682 loss: 0.6931471824645996\n",
      "epoch: 23 step: 683 loss: 0.6931471824645996\n",
      "epoch: 23 step: 684 loss: 0.6931471824645996\n",
      "epoch: 23 step: 685 loss: 0.6931471824645996\n",
      "epoch: 23 step: 686 loss: 0.6931471824645996\n",
      "epoch: 23 step: 687 loss: 0.6931471824645996\n",
      "epoch: 23 step: 688 loss: 0.6931471824645996\n",
      "epoch: 23 step: 689 loss: 0.6931471824645996\n",
      "epoch: 23 step: 690 loss: 0.6931471824645996\n",
      "epoch: 23 step: 691 loss: 0.6931471824645996\n",
      "epoch: 23 step: 692 loss: 0.6931471824645996\n",
      "epoch: 23 step: 693 loss: 0.6931471824645996\n",
      "epoch: 23 step: 694 loss: 0.6931471824645996\n",
      "epoch: 23 step: 695 loss: 0.6931471824645996\n",
      "epoch: 23 step: 696 loss: 0.6931471824645996\n",
      "epoch: 23 step: 697 loss: 0.6931471824645996\n",
      "epoch: 23 step: 698 loss: 0.6931471824645996\n",
      "epoch: 23 step: 699 loss: 0.6931471824645996\n",
      "epoch: 23 step: 700 loss: 0.6931471824645996\n",
      "epoch: 23 step: 701 loss: 0.6931471824645996\n",
      "epoch: 23 step: 702 loss: 0.6931471824645996\n",
      "epoch: 23 step: 703 loss: 0.6931471824645996\n",
      "epoch: 23 step: 704 loss: 0.6931471824645996\n",
      "epoch: 23 step: 705 loss: 0.6931471824645996\n",
      "epoch: 23 step: 706 loss: 0.6931471824645996\n",
      "epoch: 23 step: 707 loss: 0.6931471824645996\n",
      "epoch: 23 step: 708 loss: 0.6931471824645996\n",
      "epoch: 23 step: 709 loss: 0.6931471824645996\n",
      "epoch: 23 step: 710 loss: 0.6931471824645996\n",
      "epoch: 23 step: 711 loss: 0.6931471824645996\n",
      "epoch: 23 step: 712 loss: 0.6931471824645996\n",
      "epoch: 23 step: 713 loss: 0.6931471824645996\n",
      "epoch: 23 step: 714 loss: 0.6931471824645996\n",
      "epoch: 23 step: 715 loss: 0.6931471824645996\n",
      "epoch: 23 step: 716 loss: 0.6931471824645996\n",
      "epoch: 23 step: 717 loss: 0.6931471824645996\n",
      "epoch: 23 step: 718 loss: 0.6931471824645996\n",
      "epoch: 23 step: 719 loss: 0.6931471824645996\n",
      "epoch: 23 step: 720 loss: 0.6931471824645996\n",
      "epoch: 23 step: 721 loss: 0.6931471824645996\n",
      "epoch: 23 step: 722 loss: 0.6931471824645996\n",
      "epoch: 23 step: 723 loss: 0.6931471824645996\n",
      "epoch: 23 step: 724 loss: 0.6931471824645996\n",
      "epoch: 23 step: 725 loss: 0.6931471824645996\n",
      "epoch: 23 step: 726 loss: 0.6931471824645996\n",
      "epoch: 23 step: 727 loss: 0.6931471824645996\n",
      "epoch: 23 step: 728 loss: 0.6931471824645996\n",
      "epoch: 23 step: 729 loss: 0.6931471824645996\n",
      "epoch: 23 step: 730 loss: 0.6931471824645996\n",
      "epoch: 23 step: 731 loss: 0.6931471824645996\n",
      "epoch: 23 step: 732 loss: 0.6931471824645996\n",
      "epoch: 23 step: 733 loss: 0.6931471824645996\n",
      "epoch: 23 step: 734 loss: 0.6931471824645996\n",
      "epoch: 23 step: 735 loss: 0.6931471824645996\n",
      "epoch: 23 step: 736 loss: 0.6931471824645996\n",
      "epoch: 23 step: 737 loss: 0.6931471824645996\n",
      "epoch: 23 step: 738 loss: 0.6931471824645996\n",
      "epoch: 23 step: 739 loss: 0.6931471824645996\n",
      "epoch: 23 step: 740 loss: 0.6931471824645996\n",
      "epoch: 23 step: 741 loss: 0.6931471824645996\n",
      "epoch: 23 step: 742 loss: 0.6931471824645996\n",
      "epoch: 23 step: 743 loss: 0.6931471824645996\n",
      "epoch: 23 step: 744 loss: 0.6931471824645996\n",
      "epoch: 23 step: 745 loss: 0.6931471824645996\n",
      "epoch: 23 step: 746 loss: 0.6931471824645996\n",
      "epoch: 23 step: 747 loss: 0.6931471824645996\n",
      "epoch: 23 step: 748 loss: 0.6931471824645996\n",
      "epoch: 23 step: 749 loss: 0.6931471824645996\n",
      "epoch: 23 step: 750 loss: 0.6931471824645996\n",
      "epoch: 23 step: 751 loss: 0.6931471824645996\n",
      "epoch: 23 step: 752 loss: 0.6931471824645996\n",
      "epoch: 23 step: 753 loss: 0.6931471824645996\n",
      "epoch: 23 step: 754 loss: 0.6931471824645996\n",
      "epoch: 23 step: 755 loss: 0.6931471824645996\n",
      "epoch: 23 step: 756 loss: 0.6931471824645996\n",
      "epoch: 23 step: 757 loss: 0.6931471824645996\n",
      "epoch: 23 step: 758 loss: 0.6931471824645996\n",
      "epoch: 23 step: 759 loss: 0.6931471824645996\n",
      "epoch: 23 step: 760 loss: 0.6931471824645996\n",
      "epoch: 23 step: 761 loss: 0.6931471824645996\n",
      "epoch: 23 step: 762 loss: 0.6931471824645996\n",
      "epoch: 23 step: 763 loss: 0.6931471824645996\n",
      "epoch: 23 step: 764 loss: 0.6931471824645996\n",
      "epoch: 23 step: 765 loss: 0.6931471824645996\n",
      "epoch: 23 step: 766 loss: 0.6931471824645996\n",
      "epoch: 23 step: 767 loss: 0.6931471824645996\n",
      "epoch: 23 step: 768 loss: 0.6931471824645996\n",
      "epoch: 23 step: 769 loss: 0.6931471824645996\n",
      "epoch: 23 step: 770 loss: 0.6931471824645996\n",
      "epoch: 23 step: 771 loss: 0.6931471824645996\n",
      "epoch: 23 step: 772 loss: 0.6931471824645996\n",
      "epoch: 23 step: 773 loss: 0.6931471824645996\n",
      "epoch: 23 step: 774 loss: 0.6931471824645996\n",
      "epoch: 23 step: 775 loss: 0.6931471824645996\n",
      "epoch: 23 step: 776 loss: 0.6931471824645996\n",
      "epoch: 23 step: 777 loss: 0.6931471824645996\n",
      "epoch: 23 step: 778 loss: 0.6931471824645996\n",
      "epoch: 23 step: 779 loss: 0.6931471824645996\n",
      "epoch: 23 step: 780 loss: 0.6931471824645996\n",
      "epoch: 23 step: 781 loss: 0.6931471824645996\n",
      "epoch: 24 step: 1 loss: 0.6931471824645996\n",
      "epoch: 24 step: 2 loss: 0.6931471824645996\n",
      "epoch: 24 step: 3 loss: 0.6931471824645996\n",
      "epoch: 24 step: 4 loss: 0.6931471824645996\n",
      "epoch: 24 step: 5 loss: 0.6931471824645996\n",
      "epoch: 24 step: 6 loss: 0.6931471824645996\n",
      "epoch: 24 step: 7 loss: 0.6931471824645996\n",
      "epoch: 24 step: 8 loss: 0.6931471824645996\n",
      "epoch: 24 step: 9 loss: 0.6931471824645996\n",
      "epoch: 24 step: 10 loss: 0.6931471824645996\n",
      "epoch: 24 step: 11 loss: 0.6931471824645996\n",
      "epoch: 24 step: 12 loss: 0.6931471824645996\n",
      "epoch: 24 step: 13 loss: 0.6931471824645996\n",
      "epoch: 24 step: 14 loss: 0.6931471824645996\n",
      "epoch: 24 step: 15 loss: 0.6931471824645996\n",
      "epoch: 24 step: 16 loss: 0.6931471824645996\n",
      "epoch: 24 step: 17 loss: 0.6931471824645996\n",
      "epoch: 24 step: 18 loss: 0.6931471824645996\n",
      "epoch: 24 step: 19 loss: 0.6931471824645996\n",
      "epoch: 24 step: 20 loss: 0.6931471824645996\n",
      "epoch: 24 step: 21 loss: 0.6931471824645996\n",
      "epoch: 24 step: 22 loss: 0.6931471824645996\n",
      "epoch: 24 step: 23 loss: 0.6931471824645996\n",
      "epoch: 24 step: 24 loss: 0.6931471824645996\n",
      "epoch: 24 step: 25 loss: 0.6931471824645996\n",
      "epoch: 24 step: 26 loss: 0.6931471824645996\n",
      "epoch: 24 step: 27 loss: 0.6931471824645996\n",
      "epoch: 24 step: 28 loss: 0.6931471824645996\n",
      "epoch: 24 step: 29 loss: 0.6931471824645996\n",
      "epoch: 24 step: 30 loss: 0.6931471824645996\n",
      "epoch: 24 step: 31 loss: 0.6931471824645996\n",
      "epoch: 24 step: 32 loss: 0.6931471824645996\n",
      "epoch: 24 step: 33 loss: 0.6931471824645996\n",
      "epoch: 24 step: 34 loss: 0.6931471824645996\n",
      "epoch: 24 step: 35 loss: 0.6931471824645996\n",
      "epoch: 24 step: 36 loss: 0.6931471824645996\n",
      "epoch: 24 step: 37 loss: 0.6931471824645996\n",
      "epoch: 24 step: 38 loss: 0.6931471824645996\n",
      "epoch: 24 step: 39 loss: 0.6931471824645996\n",
      "epoch: 24 step: 40 loss: 0.6931471824645996\n",
      "epoch: 24 step: 41 loss: 0.6931471824645996\n",
      "epoch: 24 step: 42 loss: 0.6931471824645996\n",
      "epoch: 24 step: 43 loss: 0.6931471824645996\n",
      "epoch: 24 step: 44 loss: 0.6931471824645996\n",
      "epoch: 24 step: 45 loss: 0.6931471824645996\n",
      "epoch: 24 step: 46 loss: 0.6931471824645996\n",
      "epoch: 24 step: 47 loss: 0.6931471824645996\n",
      "epoch: 24 step: 48 loss: 0.6931471824645996\n",
      "epoch: 24 step: 49 loss: 0.6931471824645996\n",
      "epoch: 24 step: 50 loss: 0.6931471824645996\n",
      "epoch: 24 step: 51 loss: 0.6931471824645996\n",
      "epoch: 24 step: 52 loss: 0.6931471824645996\n",
      "epoch: 24 step: 53 loss: 0.6931471824645996\n",
      "epoch: 24 step: 54 loss: 0.6931471824645996\n",
      "epoch: 24 step: 55 loss: 0.6931471824645996\n",
      "epoch: 24 step: 56 loss: 0.6931471824645996\n",
      "epoch: 24 step: 57 loss: 0.6931471824645996\n",
      "epoch: 24 step: 58 loss: 0.6931471824645996\n",
      "epoch: 24 step: 59 loss: 0.6931471824645996\n",
      "epoch: 24 step: 60 loss: 0.6931471824645996\n",
      "epoch: 24 step: 61 loss: 0.6931471824645996\n",
      "epoch: 24 step: 62 loss: 0.6931471824645996\n",
      "epoch: 24 step: 63 loss: 0.6931471824645996\n",
      "epoch: 24 step: 64 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 65 loss: 0.6931471824645996\n",
      "epoch: 24 step: 66 loss: 0.6931471824645996\n",
      "epoch: 24 step: 67 loss: 0.6931471824645996\n",
      "epoch: 24 step: 68 loss: 0.6931471824645996\n",
      "epoch: 24 step: 69 loss: 0.6931471824645996\n",
      "epoch: 24 step: 70 loss: 0.6931471824645996\n",
      "epoch: 24 step: 71 loss: 0.6931471824645996\n",
      "epoch: 24 step: 72 loss: 0.6931471824645996\n",
      "epoch: 24 step: 73 loss: 0.6931471824645996\n",
      "epoch: 24 step: 74 loss: 0.6931471824645996\n",
      "epoch: 24 step: 75 loss: 0.6931471824645996\n",
      "epoch: 24 step: 76 loss: 0.6931471824645996\n",
      "epoch: 24 step: 77 loss: 0.6931471824645996\n",
      "epoch: 24 step: 78 loss: 0.6931471824645996\n",
      "epoch: 24 step: 79 loss: 0.6931471824645996\n",
      "epoch: 24 step: 80 loss: 0.6931471824645996\n",
      "epoch: 24 step: 81 loss: 0.6931471824645996\n",
      "epoch: 24 step: 82 loss: 0.6931471824645996\n",
      "epoch: 24 step: 83 loss: 0.6931471824645996\n",
      "epoch: 24 step: 84 loss: 0.6931471824645996\n",
      "epoch: 24 step: 85 loss: 0.6931471824645996\n",
      "epoch: 24 step: 86 loss: 0.6931471824645996\n",
      "epoch: 24 step: 87 loss: 0.6931471824645996\n",
      "epoch: 24 step: 88 loss: 0.6931471824645996\n",
      "epoch: 24 step: 89 loss: 0.6931471824645996\n",
      "epoch: 24 step: 90 loss: 0.6931471824645996\n",
      "epoch: 24 step: 91 loss: 0.6931471824645996\n",
      "epoch: 24 step: 92 loss: 0.6931471824645996\n",
      "epoch: 24 step: 93 loss: 0.6931471824645996\n",
      "epoch: 24 step: 94 loss: 0.6931471824645996\n",
      "epoch: 24 step: 95 loss: 0.6931471824645996\n",
      "epoch: 24 step: 96 loss: 0.6931471824645996\n",
      "epoch: 24 step: 97 loss: 0.6931471824645996\n",
      "epoch: 24 step: 98 loss: 0.6931471824645996\n",
      "epoch: 24 step: 99 loss: 0.6931471824645996\n",
      "epoch: 24 step: 100 loss: 0.6931471824645996\n",
      "epoch: 24 step: 101 loss: 0.6931471824645996\n",
      "epoch: 24 step: 102 loss: 0.6931471824645996\n",
      "epoch: 24 step: 103 loss: 0.6931471824645996\n",
      "epoch: 24 step: 104 loss: 0.6931471824645996\n",
      "epoch: 24 step: 105 loss: 0.6931471824645996\n",
      "epoch: 24 step: 106 loss: 0.6931471824645996\n",
      "epoch: 24 step: 107 loss: 0.6931471824645996\n",
      "epoch: 24 step: 108 loss: 0.6931471824645996\n",
      "epoch: 24 step: 109 loss: 0.6931471824645996\n",
      "epoch: 24 step: 110 loss: 0.6931471824645996\n",
      "epoch: 24 step: 111 loss: 0.6931471824645996\n",
      "epoch: 24 step: 112 loss: 0.6931471824645996\n",
      "epoch: 24 step: 113 loss: 0.6931471824645996\n",
      "epoch: 24 step: 114 loss: 0.6931471824645996\n",
      "epoch: 24 step: 115 loss: 0.6931471824645996\n",
      "epoch: 24 step: 116 loss: 0.6931471824645996\n",
      "epoch: 24 step: 117 loss: 0.6931471824645996\n",
      "epoch: 24 step: 118 loss: 0.6931471824645996\n",
      "epoch: 24 step: 119 loss: 0.6931471824645996\n",
      "epoch: 24 step: 120 loss: 0.6931471824645996\n",
      "epoch: 24 step: 121 loss: 0.6931471824645996\n",
      "epoch: 24 step: 122 loss: 0.6931471824645996\n",
      "epoch: 24 step: 123 loss: 0.6931471824645996\n",
      "epoch: 24 step: 124 loss: 0.6931471824645996\n",
      "epoch: 24 step: 125 loss: 0.6931471824645996\n",
      "epoch: 24 step: 126 loss: 0.6931471824645996\n",
      "epoch: 24 step: 127 loss: 0.6931471824645996\n",
      "epoch: 24 step: 128 loss: 0.6931471824645996\n",
      "epoch: 24 step: 129 loss: 0.6931471824645996\n",
      "epoch: 24 step: 130 loss: 0.6931471824645996\n",
      "epoch: 24 step: 131 loss: 0.6931471824645996\n",
      "epoch: 24 step: 132 loss: 0.6931471824645996\n",
      "epoch: 24 step: 133 loss: 0.6931471824645996\n",
      "epoch: 24 step: 134 loss: 0.6931471824645996\n",
      "epoch: 24 step: 135 loss: 0.6931471824645996\n",
      "epoch: 24 step: 136 loss: 0.6931471824645996\n",
      "epoch: 24 step: 137 loss: 0.6931471824645996\n",
      "epoch: 24 step: 138 loss: 0.6931471824645996\n",
      "epoch: 24 step: 139 loss: 0.6931471824645996\n",
      "epoch: 24 step: 140 loss: 0.6931471824645996\n",
      "epoch: 24 step: 141 loss: 0.6931471824645996\n",
      "epoch: 24 step: 142 loss: 0.6931471824645996\n",
      "epoch: 24 step: 143 loss: 0.6931471824645996\n",
      "epoch: 24 step: 144 loss: 0.6931471824645996\n",
      "epoch: 24 step: 145 loss: 0.6931471824645996\n",
      "epoch: 24 step: 146 loss: 0.6931471824645996\n",
      "epoch: 24 step: 147 loss: 0.6931471824645996\n",
      "epoch: 24 step: 148 loss: 0.6931471824645996\n",
      "epoch: 24 step: 149 loss: 0.6931471824645996\n",
      "epoch: 24 step: 150 loss: 0.6931471824645996\n",
      "epoch: 24 step: 151 loss: 0.6931471824645996\n",
      "epoch: 24 step: 152 loss: 0.6931471824645996\n",
      "epoch: 24 step: 153 loss: 0.6931471824645996\n",
      "epoch: 24 step: 154 loss: 0.6931471824645996\n",
      "epoch: 24 step: 155 loss: 0.6931471824645996\n",
      "epoch: 24 step: 156 loss: 0.6931471824645996\n",
      "epoch: 24 step: 157 loss: 0.6931471824645996\n",
      "epoch: 24 step: 158 loss: 0.6931471824645996\n",
      "epoch: 24 step: 159 loss: 0.6931471824645996\n",
      "epoch: 24 step: 160 loss: 0.6931471824645996\n",
      "epoch: 24 step: 161 loss: 0.6931471824645996\n",
      "epoch: 24 step: 162 loss: 0.6931471824645996\n",
      "epoch: 24 step: 163 loss: 0.6931471824645996\n",
      "epoch: 24 step: 164 loss: 0.6931471824645996\n",
      "epoch: 24 step: 165 loss: 0.6931471824645996\n",
      "epoch: 24 step: 166 loss: 0.6931471824645996\n",
      "epoch: 24 step: 167 loss: 0.6931471824645996\n",
      "epoch: 24 step: 168 loss: 0.6931471824645996\n",
      "epoch: 24 step: 169 loss: 0.6931471824645996\n",
      "epoch: 24 step: 170 loss: 0.6931471824645996\n",
      "epoch: 24 step: 171 loss: 0.6931471824645996\n",
      "epoch: 24 step: 172 loss: 0.6931471824645996\n",
      "epoch: 24 step: 173 loss: 0.6931471824645996\n",
      "epoch: 24 step: 174 loss: 0.6931471824645996\n",
      "epoch: 24 step: 175 loss: 0.6931471824645996\n",
      "epoch: 24 step: 176 loss: 0.6931471824645996\n",
      "epoch: 24 step: 177 loss: 0.6931471824645996\n",
      "epoch: 24 step: 178 loss: 0.6931471824645996\n",
      "epoch: 24 step: 179 loss: 0.6931471824645996\n",
      "epoch: 24 step: 180 loss: 0.6931471824645996\n",
      "epoch: 24 step: 181 loss: 0.6931471824645996\n",
      "epoch: 24 step: 182 loss: 0.6931471824645996\n",
      "epoch: 24 step: 183 loss: 0.6931471824645996\n",
      "epoch: 24 step: 184 loss: 0.6931471824645996\n",
      "epoch: 24 step: 185 loss: 0.6931471824645996\n",
      "epoch: 24 step: 186 loss: 0.6931471824645996\n",
      "epoch: 24 step: 187 loss: 0.6931471824645996\n",
      "epoch: 24 step: 188 loss: 0.6931471824645996\n",
      "epoch: 24 step: 189 loss: 0.6931471824645996\n",
      "epoch: 24 step: 190 loss: 0.6931471824645996\n",
      "epoch: 24 step: 191 loss: 0.6931471824645996\n",
      "epoch: 24 step: 192 loss: 0.6931471824645996\n",
      "epoch: 24 step: 193 loss: 0.6931471824645996\n",
      "epoch: 24 step: 194 loss: 0.6931471824645996\n",
      "epoch: 24 step: 195 loss: 0.6931471824645996\n",
      "epoch: 24 step: 196 loss: 0.6931471824645996\n",
      "epoch: 24 step: 197 loss: 0.6931471824645996\n",
      "epoch: 24 step: 198 loss: 0.6931471824645996\n",
      "epoch: 24 step: 199 loss: 0.6931471824645996\n",
      "epoch: 24 step: 200 loss: 0.6931471824645996\n",
      "epoch: 24 step: 201 loss: 0.6931471824645996\n",
      "epoch: 24 step: 202 loss: 0.6931471824645996\n",
      "epoch: 24 step: 203 loss: 0.6931471824645996\n",
      "epoch: 24 step: 204 loss: 0.6931471824645996\n",
      "epoch: 24 step: 205 loss: 0.6931471824645996\n",
      "epoch: 24 step: 206 loss: 0.6931471824645996\n",
      "epoch: 24 step: 207 loss: 0.6931471824645996\n",
      "epoch: 24 step: 208 loss: 0.6931471824645996\n",
      "epoch: 24 step: 209 loss: 0.6931471824645996\n",
      "epoch: 24 step: 210 loss: 0.6931471824645996\n",
      "epoch: 24 step: 211 loss: 0.6931471824645996\n",
      "epoch: 24 step: 212 loss: 0.6931471824645996\n",
      "epoch: 24 step: 213 loss: 0.6931471824645996\n",
      "epoch: 24 step: 214 loss: 0.6931471824645996\n",
      "epoch: 24 step: 215 loss: 0.6931471824645996\n",
      "epoch: 24 step: 216 loss: 0.6931471824645996\n",
      "epoch: 24 step: 217 loss: 0.6931471824645996\n",
      "epoch: 24 step: 218 loss: 0.6931471824645996\n",
      "epoch: 24 step: 219 loss: 0.6931471824645996\n",
      "epoch: 24 step: 220 loss: 0.6931471824645996\n",
      "epoch: 24 step: 221 loss: 0.6931471824645996\n",
      "epoch: 24 step: 222 loss: 0.6931471824645996\n",
      "epoch: 24 step: 223 loss: 0.6931471824645996\n",
      "epoch: 24 step: 224 loss: 0.6931471824645996\n",
      "epoch: 24 step: 225 loss: 0.6931471824645996\n",
      "epoch: 24 step: 226 loss: 0.6931471824645996\n",
      "epoch: 24 step: 227 loss: 0.6931471824645996\n",
      "epoch: 24 step: 228 loss: 0.6931471824645996\n",
      "epoch: 24 step: 229 loss: 0.6931471824645996\n",
      "epoch: 24 step: 230 loss: 0.6931471824645996\n",
      "epoch: 24 step: 231 loss: 0.6931471824645996\n",
      "epoch: 24 step: 232 loss: 0.6931471824645996\n",
      "epoch: 24 step: 233 loss: 0.6931471824645996\n",
      "epoch: 24 step: 234 loss: 0.6931471824645996\n",
      "epoch: 24 step: 235 loss: 0.6931471824645996\n",
      "epoch: 24 step: 236 loss: 0.6931471824645996\n",
      "epoch: 24 step: 237 loss: 0.6931471824645996\n",
      "epoch: 24 step: 238 loss: 0.6931471824645996\n",
      "epoch: 24 step: 239 loss: 0.6931471824645996\n",
      "epoch: 24 step: 240 loss: 0.6931471824645996\n",
      "epoch: 24 step: 241 loss: 0.6931471824645996\n",
      "epoch: 24 step: 242 loss: 0.6931471824645996\n",
      "epoch: 24 step: 243 loss: 0.6931471824645996\n",
      "epoch: 24 step: 244 loss: 0.6931471824645996\n",
      "epoch: 24 step: 245 loss: 0.6931471824645996\n",
      "epoch: 24 step: 246 loss: 0.6931471824645996\n",
      "epoch: 24 step: 247 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 248 loss: 0.6931471824645996\n",
      "epoch: 24 step: 249 loss: 0.6931471824645996\n",
      "epoch: 24 step: 250 loss: 0.6931471824645996\n",
      "epoch: 24 step: 251 loss: 0.6931471824645996\n",
      "epoch: 24 step: 252 loss: 0.6931471824645996\n",
      "epoch: 24 step: 253 loss: 0.6931471824645996\n",
      "epoch: 24 step: 254 loss: 0.6931471824645996\n",
      "epoch: 24 step: 255 loss: 0.6931471824645996\n",
      "epoch: 24 step: 256 loss: 0.6931471824645996\n",
      "epoch: 24 step: 257 loss: 0.6931471824645996\n",
      "epoch: 24 step: 258 loss: 0.6931471824645996\n",
      "epoch: 24 step: 259 loss: 0.6931471824645996\n",
      "epoch: 24 step: 260 loss: 0.6931471824645996\n",
      "epoch: 24 step: 261 loss: 0.6931471824645996\n",
      "epoch: 24 step: 262 loss: 0.6931471824645996\n",
      "epoch: 24 step: 263 loss: 0.6931471824645996\n",
      "epoch: 24 step: 264 loss: 0.6931471824645996\n",
      "epoch: 24 step: 265 loss: 0.6931471824645996\n",
      "epoch: 24 step: 266 loss: 0.6931471824645996\n",
      "epoch: 24 step: 267 loss: 0.6931471824645996\n",
      "epoch: 24 step: 268 loss: 0.6931471824645996\n",
      "epoch: 24 step: 269 loss: 0.6931471824645996\n",
      "epoch: 24 step: 270 loss: 0.6931471824645996\n",
      "epoch: 24 step: 271 loss: 0.6931471824645996\n",
      "epoch: 24 step: 272 loss: 0.6931471824645996\n",
      "epoch: 24 step: 273 loss: 0.6931471824645996\n",
      "epoch: 24 step: 274 loss: 0.6931471824645996\n",
      "epoch: 24 step: 275 loss: 0.6931471824645996\n",
      "epoch: 24 step: 276 loss: 0.6931471824645996\n",
      "epoch: 24 step: 277 loss: 0.6931471824645996\n",
      "epoch: 24 step: 278 loss: 0.6931471824645996\n",
      "epoch: 24 step: 279 loss: 0.6931471824645996\n",
      "epoch: 24 step: 280 loss: 0.6931471824645996\n",
      "epoch: 24 step: 281 loss: 0.6931471824645996\n",
      "epoch: 24 step: 282 loss: 0.6931471824645996\n",
      "epoch: 24 step: 283 loss: 0.6931471824645996\n",
      "epoch: 24 step: 284 loss: 0.6931471824645996\n",
      "epoch: 24 step: 285 loss: 0.6931471824645996\n",
      "epoch: 24 step: 286 loss: 0.6931471824645996\n",
      "epoch: 24 step: 287 loss: 0.6931471824645996\n",
      "epoch: 24 step: 288 loss: 0.6931471824645996\n",
      "epoch: 24 step: 289 loss: 0.6931471824645996\n",
      "epoch: 24 step: 290 loss: 0.6931471824645996\n",
      "epoch: 24 step: 291 loss: 0.6931471824645996\n",
      "epoch: 24 step: 292 loss: 0.6931471824645996\n",
      "epoch: 24 step: 293 loss: 0.6931471824645996\n",
      "epoch: 24 step: 294 loss: 0.6931471824645996\n",
      "epoch: 24 step: 295 loss: 0.6931471824645996\n",
      "epoch: 24 step: 296 loss: 0.6931471824645996\n",
      "epoch: 24 step: 297 loss: 0.6931471824645996\n",
      "epoch: 24 step: 298 loss: 0.6931471824645996\n",
      "epoch: 24 step: 299 loss: 0.6931471824645996\n",
      "epoch: 24 step: 300 loss: 0.6931471824645996\n",
      "epoch: 24 step: 301 loss: 0.6931471824645996\n",
      "epoch: 24 step: 302 loss: 0.6931471824645996\n",
      "epoch: 24 step: 303 loss: 0.6931471824645996\n",
      "epoch: 24 step: 304 loss: 0.6931471824645996\n",
      "epoch: 24 step: 305 loss: 0.6931471824645996\n",
      "epoch: 24 step: 306 loss: 0.6931471824645996\n",
      "epoch: 24 step: 307 loss: 0.6931471824645996\n",
      "epoch: 24 step: 308 loss: 0.6931471824645996\n",
      "epoch: 24 step: 309 loss: 0.6931471824645996\n",
      "epoch: 24 step: 310 loss: 0.6931471824645996\n",
      "epoch: 24 step: 311 loss: 0.6931471824645996\n",
      "epoch: 24 step: 312 loss: 0.6931471824645996\n",
      "epoch: 24 step: 313 loss: 0.6931471824645996\n",
      "epoch: 24 step: 314 loss: 0.6931471824645996\n",
      "epoch: 24 step: 315 loss: 0.6931471824645996\n",
      "epoch: 24 step: 316 loss: 0.6931471824645996\n",
      "epoch: 24 step: 317 loss: 0.6931471824645996\n",
      "epoch: 24 step: 318 loss: 0.6931471824645996\n",
      "epoch: 24 step: 319 loss: 0.6931471824645996\n",
      "epoch: 24 step: 320 loss: 0.6931471824645996\n",
      "epoch: 24 step: 321 loss: 0.6931471824645996\n",
      "epoch: 24 step: 322 loss: 0.6931471824645996\n",
      "epoch: 24 step: 323 loss: 0.6931471824645996\n",
      "epoch: 24 step: 324 loss: 0.6931471824645996\n",
      "epoch: 24 step: 325 loss: 0.6931471824645996\n",
      "epoch: 24 step: 326 loss: 0.6931471824645996\n",
      "epoch: 24 step: 327 loss: 0.6931471824645996\n",
      "epoch: 24 step: 328 loss: 0.6931471824645996\n",
      "epoch: 24 step: 329 loss: 0.6931471824645996\n",
      "epoch: 24 step: 330 loss: 0.6931471824645996\n",
      "epoch: 24 step: 331 loss: 0.6931471824645996\n",
      "epoch: 24 step: 332 loss: 0.6931471824645996\n",
      "epoch: 24 step: 333 loss: 0.6931471824645996\n",
      "epoch: 24 step: 334 loss: 0.6931471824645996\n",
      "epoch: 24 step: 335 loss: 0.6931471824645996\n",
      "epoch: 24 step: 336 loss: 0.6931471824645996\n",
      "epoch: 24 step: 337 loss: 0.6931471824645996\n",
      "epoch: 24 step: 338 loss: 0.6931471824645996\n",
      "epoch: 24 step: 339 loss: 0.6931471824645996\n",
      "epoch: 24 step: 340 loss: 0.6931471824645996\n",
      "epoch: 24 step: 341 loss: 0.6931471824645996\n",
      "epoch: 24 step: 342 loss: 0.6931471824645996\n",
      "epoch: 24 step: 343 loss: 0.6931471824645996\n",
      "epoch: 24 step: 344 loss: 0.6931471824645996\n",
      "epoch: 24 step: 345 loss: 0.6931471824645996\n",
      "epoch: 24 step: 346 loss: 0.6931471824645996\n",
      "epoch: 24 step: 347 loss: 0.6931471824645996\n",
      "epoch: 24 step: 348 loss: 0.6931471824645996\n",
      "epoch: 24 step: 349 loss: 0.6931471824645996\n",
      "epoch: 24 step: 350 loss: 0.6931471824645996\n",
      "epoch: 24 step: 351 loss: 0.6931471824645996\n",
      "epoch: 24 step: 352 loss: 0.6931471824645996\n",
      "epoch: 24 step: 353 loss: 0.6931471824645996\n",
      "epoch: 24 step: 354 loss: 0.6931471824645996\n",
      "epoch: 24 step: 355 loss: 0.6931471824645996\n",
      "epoch: 24 step: 356 loss: 0.6931471824645996\n",
      "epoch: 24 step: 357 loss: 0.6931471824645996\n",
      "epoch: 24 step: 358 loss: 0.6931471824645996\n",
      "epoch: 24 step: 359 loss: 0.6931471824645996\n",
      "epoch: 24 step: 360 loss: 0.6931471824645996\n",
      "epoch: 24 step: 361 loss: 0.6931471824645996\n",
      "epoch: 24 step: 362 loss: 0.6931471824645996\n",
      "epoch: 24 step: 363 loss: 0.6931471824645996\n",
      "epoch: 24 step: 364 loss: 0.6931471824645996\n",
      "epoch: 24 step: 365 loss: 0.6931471824645996\n",
      "epoch: 24 step: 366 loss: 0.6931471824645996\n",
      "epoch: 24 step: 367 loss: 0.6931471824645996\n",
      "epoch: 24 step: 368 loss: 0.6931471824645996\n",
      "epoch: 24 step: 369 loss: 0.6931471824645996\n",
      "epoch: 24 step: 370 loss: 0.6931471824645996\n",
      "epoch: 24 step: 371 loss: 0.6931471824645996\n",
      "epoch: 24 step: 372 loss: 0.6931471824645996\n",
      "epoch: 24 step: 373 loss: 0.6931471824645996\n",
      "epoch: 24 step: 374 loss: 0.6931471824645996\n",
      "epoch: 24 step: 375 loss: 0.6931471824645996\n",
      "epoch: 24 step: 376 loss: 0.6931471824645996\n",
      "epoch: 24 step: 377 loss: 0.6931471824645996\n",
      "epoch: 24 step: 378 loss: 0.6931471824645996\n",
      "epoch: 24 step: 379 loss: 0.6931471824645996\n",
      "epoch: 24 step: 380 loss: 0.6931471824645996\n",
      "epoch: 24 step: 381 loss: 0.6931471824645996\n",
      "epoch: 24 step: 382 loss: 0.6931471824645996\n",
      "epoch: 24 step: 383 loss: 0.6931471824645996\n",
      "epoch: 24 step: 384 loss: 0.6931471824645996\n",
      "epoch: 24 step: 385 loss: 0.6931471824645996\n",
      "epoch: 24 step: 386 loss: 0.6931471824645996\n",
      "epoch: 24 step: 387 loss: 0.6931471824645996\n",
      "epoch: 24 step: 388 loss: 0.6931471824645996\n",
      "epoch: 24 step: 389 loss: 0.6931471824645996\n",
      "epoch: 24 step: 390 loss: 0.6931471824645996\n",
      "epoch: 24 step: 391 loss: 0.6931471824645996\n",
      "epoch: 24 step: 392 loss: 0.6931471824645996\n",
      "epoch: 24 step: 393 loss: 0.6931471824645996\n",
      "epoch: 24 step: 394 loss: 0.6931471824645996\n",
      "epoch: 24 step: 395 loss: 0.6931471824645996\n",
      "epoch: 24 step: 396 loss: 0.6931471824645996\n",
      "epoch: 24 step: 397 loss: 0.6931471824645996\n",
      "epoch: 24 step: 398 loss: 0.6931471824645996\n",
      "epoch: 24 step: 399 loss: 0.6931471824645996\n",
      "epoch: 24 step: 400 loss: 0.6931471824645996\n",
      "epoch: 24 step: 401 loss: 0.6931471824645996\n",
      "epoch: 24 step: 402 loss: 0.6931471824645996\n",
      "epoch: 24 step: 403 loss: 0.6931471824645996\n",
      "epoch: 24 step: 404 loss: 0.6931471824645996\n",
      "epoch: 24 step: 405 loss: 0.6931471824645996\n",
      "epoch: 24 step: 406 loss: 0.6931471824645996\n",
      "epoch: 24 step: 407 loss: 0.6931471824645996\n",
      "epoch: 24 step: 408 loss: 0.6931471824645996\n",
      "epoch: 24 step: 409 loss: 0.6931471824645996\n",
      "epoch: 24 step: 410 loss: 0.6931471824645996\n",
      "epoch: 24 step: 411 loss: 0.6931471824645996\n",
      "epoch: 24 step: 412 loss: 0.6931471824645996\n",
      "epoch: 24 step: 413 loss: 0.6931471824645996\n",
      "epoch: 24 step: 414 loss: 0.6931471824645996\n",
      "epoch: 24 step: 415 loss: 0.6931471824645996\n",
      "epoch: 24 step: 416 loss: 0.6931471824645996\n",
      "epoch: 24 step: 417 loss: 0.6931471824645996\n",
      "epoch: 24 step: 418 loss: 0.6931471824645996\n",
      "epoch: 24 step: 419 loss: 0.6931471824645996\n",
      "epoch: 24 step: 420 loss: 0.6931471824645996\n",
      "epoch: 24 step: 421 loss: 0.6931471824645996\n",
      "epoch: 24 step: 422 loss: 0.6931471824645996\n",
      "epoch: 24 step: 423 loss: 0.6931471824645996\n",
      "epoch: 24 step: 424 loss: 0.6931471824645996\n",
      "epoch: 24 step: 425 loss: 0.6931471824645996\n",
      "epoch: 24 step: 426 loss: 0.6931471824645996\n",
      "epoch: 24 step: 427 loss: 0.6931471824645996\n",
      "epoch: 24 step: 428 loss: 0.6931471824645996\n",
      "epoch: 24 step: 429 loss: 0.6931471824645996\n",
      "epoch: 24 step: 430 loss: 0.6931471824645996\n",
      "epoch: 24 step: 431 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 432 loss: 0.6931471824645996\n",
      "epoch: 24 step: 433 loss: 0.6931471824645996\n",
      "epoch: 24 step: 434 loss: 0.6931471824645996\n",
      "epoch: 24 step: 435 loss: 0.6931471824645996\n",
      "epoch: 24 step: 436 loss: 0.6931471824645996\n",
      "epoch: 24 step: 437 loss: 0.6931471824645996\n",
      "epoch: 24 step: 438 loss: 0.6931471824645996\n",
      "epoch: 24 step: 439 loss: 0.6931471824645996\n",
      "epoch: 24 step: 440 loss: 0.6931471824645996\n",
      "epoch: 24 step: 441 loss: 0.6931471824645996\n",
      "epoch: 24 step: 442 loss: 0.6931471824645996\n",
      "epoch: 24 step: 443 loss: 0.6931471824645996\n",
      "epoch: 24 step: 444 loss: 0.6931471824645996\n",
      "epoch: 24 step: 445 loss: 0.6931471824645996\n",
      "epoch: 24 step: 446 loss: 0.6931471824645996\n",
      "epoch: 24 step: 447 loss: 0.6931471824645996\n",
      "epoch: 24 step: 448 loss: 0.6931471824645996\n",
      "epoch: 24 step: 449 loss: 0.6931471824645996\n",
      "epoch: 24 step: 450 loss: 0.6931471824645996\n",
      "epoch: 24 step: 451 loss: 0.6931471824645996\n",
      "epoch: 24 step: 452 loss: 0.6931471824645996\n",
      "epoch: 24 step: 453 loss: 0.6931471824645996\n",
      "epoch: 24 step: 454 loss: 0.6931471824645996\n",
      "epoch: 24 step: 455 loss: 0.6931471824645996\n",
      "epoch: 24 step: 456 loss: 0.6931471824645996\n",
      "epoch: 24 step: 457 loss: 0.6931471824645996\n",
      "epoch: 24 step: 458 loss: 0.6931471824645996\n",
      "epoch: 24 step: 459 loss: 0.6931471824645996\n",
      "epoch: 24 step: 460 loss: 0.6931471824645996\n",
      "epoch: 24 step: 461 loss: 0.6931471824645996\n",
      "epoch: 24 step: 462 loss: 0.6931471824645996\n",
      "epoch: 24 step: 463 loss: 0.6931471824645996\n",
      "epoch: 24 step: 464 loss: 0.6931471824645996\n",
      "epoch: 24 step: 465 loss: 0.6931471824645996\n",
      "epoch: 24 step: 466 loss: 0.6931471824645996\n",
      "epoch: 24 step: 467 loss: 0.6931471824645996\n",
      "epoch: 24 step: 468 loss: 0.6931471824645996\n",
      "epoch: 24 step: 469 loss: 0.6931471824645996\n",
      "epoch: 24 step: 470 loss: 0.6931471824645996\n",
      "epoch: 24 step: 471 loss: 0.6931471824645996\n",
      "epoch: 24 step: 472 loss: 0.6931471824645996\n",
      "epoch: 24 step: 473 loss: 0.6931471824645996\n",
      "epoch: 24 step: 474 loss: 0.6931471824645996\n",
      "epoch: 24 step: 475 loss: 0.6931471824645996\n",
      "epoch: 24 step: 476 loss: 0.6931471824645996\n",
      "epoch: 24 step: 477 loss: 0.6931471824645996\n",
      "epoch: 24 step: 478 loss: 0.6931471824645996\n",
      "epoch: 24 step: 479 loss: 0.6931471824645996\n",
      "epoch: 24 step: 480 loss: 0.6931471824645996\n",
      "epoch: 24 step: 481 loss: 0.6931471824645996\n",
      "epoch: 24 step: 482 loss: 0.6931471824645996\n",
      "epoch: 24 step: 483 loss: 0.6931471824645996\n",
      "epoch: 24 step: 484 loss: 0.6931471824645996\n",
      "epoch: 24 step: 485 loss: 0.6931471824645996\n",
      "epoch: 24 step: 486 loss: 0.6931471824645996\n",
      "epoch: 24 step: 487 loss: 0.6931471824645996\n",
      "epoch: 24 step: 488 loss: 0.6931471824645996\n",
      "epoch: 24 step: 489 loss: 0.6931471824645996\n",
      "epoch: 24 step: 490 loss: 0.6931471824645996\n",
      "epoch: 24 step: 491 loss: 0.6931471824645996\n",
      "epoch: 24 step: 492 loss: 0.6931471824645996\n",
      "epoch: 24 step: 493 loss: 0.6931471824645996\n",
      "epoch: 24 step: 494 loss: 0.6931471824645996\n",
      "epoch: 24 step: 495 loss: 0.6931471824645996\n",
      "epoch: 24 step: 496 loss: 0.6931471824645996\n",
      "epoch: 24 step: 497 loss: 0.6931471824645996\n",
      "epoch: 24 step: 498 loss: 0.6931471824645996\n",
      "epoch: 24 step: 499 loss: 0.6931471824645996\n",
      "epoch: 24 step: 500 loss: 0.6931471824645996\n",
      "epoch: 24 step: 501 loss: 0.6931471824645996\n",
      "epoch: 24 step: 502 loss: 0.6931471824645996\n",
      "epoch: 24 step: 503 loss: 0.6931471824645996\n",
      "epoch: 24 step: 504 loss: 0.6931471824645996\n",
      "epoch: 24 step: 505 loss: 0.6931471824645996\n",
      "epoch: 24 step: 506 loss: 0.6931471824645996\n",
      "epoch: 24 step: 507 loss: 0.6931471824645996\n",
      "epoch: 24 step: 508 loss: 0.6931471824645996\n",
      "epoch: 24 step: 509 loss: 0.6931471824645996\n",
      "epoch: 24 step: 510 loss: 0.6931471824645996\n",
      "epoch: 24 step: 511 loss: 0.6931471824645996\n",
      "epoch: 24 step: 512 loss: 0.6931471824645996\n",
      "epoch: 24 step: 513 loss: 0.6931471824645996\n",
      "epoch: 24 step: 514 loss: 0.6931471824645996\n",
      "epoch: 24 step: 515 loss: 0.6931471824645996\n",
      "epoch: 24 step: 516 loss: 0.6931471824645996\n",
      "epoch: 24 step: 517 loss: 0.6931471824645996\n",
      "epoch: 24 step: 518 loss: 0.6931471824645996\n",
      "epoch: 24 step: 519 loss: 0.6931471824645996\n",
      "epoch: 24 step: 520 loss: 0.6931471824645996\n",
      "epoch: 24 step: 521 loss: 0.6931471824645996\n",
      "epoch: 24 step: 522 loss: 0.6931471824645996\n",
      "epoch: 24 step: 523 loss: 0.6931471824645996\n",
      "epoch: 24 step: 524 loss: 0.6931471824645996\n",
      "epoch: 24 step: 525 loss: 0.6931471824645996\n",
      "epoch: 24 step: 526 loss: 0.6931471824645996\n",
      "epoch: 24 step: 527 loss: 0.6931471824645996\n",
      "epoch: 24 step: 528 loss: 0.6931471824645996\n",
      "epoch: 24 step: 529 loss: 0.6931471824645996\n",
      "epoch: 24 step: 530 loss: 0.6931471824645996\n",
      "epoch: 24 step: 531 loss: 0.6931471824645996\n",
      "epoch: 24 step: 532 loss: 0.6931471824645996\n",
      "epoch: 24 step: 533 loss: 0.6931471824645996\n",
      "epoch: 24 step: 534 loss: 0.6931471824645996\n",
      "epoch: 24 step: 535 loss: 0.6931471824645996\n",
      "epoch: 24 step: 536 loss: 0.6931471824645996\n",
      "epoch: 24 step: 537 loss: 0.6931471824645996\n",
      "epoch: 24 step: 538 loss: 0.6931471824645996\n",
      "epoch: 24 step: 539 loss: 0.6931471824645996\n",
      "epoch: 24 step: 540 loss: 0.6931471824645996\n",
      "epoch: 24 step: 541 loss: 0.6931471824645996\n",
      "epoch: 24 step: 542 loss: 0.6931471824645996\n",
      "epoch: 24 step: 543 loss: 0.6931471824645996\n",
      "epoch: 24 step: 544 loss: 0.6931471824645996\n",
      "epoch: 24 step: 545 loss: 0.6931471824645996\n",
      "epoch: 24 step: 546 loss: 0.6931471824645996\n",
      "epoch: 24 step: 547 loss: 0.6931471824645996\n",
      "epoch: 24 step: 548 loss: 0.6931471824645996\n",
      "epoch: 24 step: 549 loss: 0.6931471824645996\n",
      "epoch: 24 step: 550 loss: 0.6931471824645996\n",
      "epoch: 24 step: 551 loss: 0.6931471824645996\n",
      "epoch: 24 step: 552 loss: 0.6931471824645996\n",
      "epoch: 24 step: 553 loss: 0.6931471824645996\n",
      "epoch: 24 step: 554 loss: 0.6931471824645996\n",
      "epoch: 24 step: 555 loss: 0.6931471824645996\n",
      "epoch: 24 step: 556 loss: 0.6931471824645996\n",
      "epoch: 24 step: 557 loss: 0.6931471824645996\n",
      "epoch: 24 step: 558 loss: 0.6931471824645996\n",
      "epoch: 24 step: 559 loss: 0.6931471824645996\n",
      "epoch: 24 step: 560 loss: 0.6931471824645996\n",
      "epoch: 24 step: 561 loss: 0.6931471824645996\n",
      "epoch: 24 step: 562 loss: 0.6931471824645996\n",
      "epoch: 24 step: 563 loss: 0.6931471824645996\n",
      "epoch: 24 step: 564 loss: 0.6931471824645996\n",
      "epoch: 24 step: 565 loss: 0.6931471824645996\n",
      "epoch: 24 step: 566 loss: 0.6931471824645996\n",
      "epoch: 24 step: 567 loss: 0.6931471824645996\n",
      "epoch: 24 step: 568 loss: 0.6931471824645996\n",
      "epoch: 24 step: 569 loss: 0.6931471824645996\n",
      "epoch: 24 step: 570 loss: 0.6931471824645996\n",
      "epoch: 24 step: 571 loss: 0.6931471824645996\n",
      "epoch: 24 step: 572 loss: 0.6931471824645996\n",
      "epoch: 24 step: 573 loss: 0.6931471824645996\n",
      "epoch: 24 step: 574 loss: 0.6931471824645996\n",
      "epoch: 24 step: 575 loss: 0.6931471824645996\n",
      "epoch: 24 step: 576 loss: 0.6931471824645996\n",
      "epoch: 24 step: 577 loss: 0.6931471824645996\n",
      "epoch: 24 step: 578 loss: 0.6931471824645996\n",
      "epoch: 24 step: 579 loss: 0.6931471824645996\n",
      "epoch: 24 step: 580 loss: 0.6931471824645996\n",
      "epoch: 24 step: 581 loss: 0.6931471824645996\n",
      "epoch: 24 step: 582 loss: 0.6931471824645996\n",
      "epoch: 24 step: 583 loss: 0.6931471824645996\n",
      "epoch: 24 step: 584 loss: 0.6931471824645996\n",
      "epoch: 24 step: 585 loss: 0.6931471824645996\n",
      "epoch: 24 step: 586 loss: 0.6931471824645996\n",
      "epoch: 24 step: 587 loss: 0.6931471824645996\n",
      "epoch: 24 step: 588 loss: 0.6931471824645996\n",
      "epoch: 24 step: 589 loss: 0.6931471824645996\n",
      "epoch: 24 step: 590 loss: 0.6931471824645996\n",
      "epoch: 24 step: 591 loss: 0.6931471824645996\n",
      "epoch: 24 step: 592 loss: 0.6931471824645996\n",
      "epoch: 24 step: 593 loss: 0.6931471824645996\n",
      "epoch: 24 step: 594 loss: 0.6931471824645996\n",
      "epoch: 24 step: 595 loss: 0.6931471824645996\n",
      "epoch: 24 step: 596 loss: 0.6931471824645996\n",
      "epoch: 24 step: 597 loss: 0.6931471824645996\n",
      "epoch: 24 step: 598 loss: 0.6931471824645996\n",
      "epoch: 24 step: 599 loss: 0.6931471824645996\n",
      "epoch: 24 step: 600 loss: 0.6931471824645996\n",
      "epoch: 24 step: 601 loss: 0.6931471824645996\n",
      "epoch: 24 step: 602 loss: 0.6931471824645996\n",
      "epoch: 24 step: 603 loss: 0.6931471824645996\n",
      "epoch: 24 step: 604 loss: 0.6931471824645996\n",
      "epoch: 24 step: 605 loss: 0.6931471824645996\n",
      "epoch: 24 step: 606 loss: 0.6931471824645996\n",
      "epoch: 24 step: 607 loss: 0.6931471824645996\n",
      "epoch: 24 step: 608 loss: 0.6931471824645996\n",
      "epoch: 24 step: 609 loss: 0.6931471824645996\n",
      "epoch: 24 step: 610 loss: 0.6931471824645996\n",
      "epoch: 24 step: 611 loss: 0.6931471824645996\n",
      "epoch: 24 step: 612 loss: 0.6931471824645996\n",
      "epoch: 24 step: 613 loss: 0.6931471824645996\n",
      "epoch: 24 step: 614 loss: 0.6931471824645996\n",
      "epoch: 24 step: 615 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 616 loss: 0.6931471824645996\n",
      "epoch: 24 step: 617 loss: 0.6931471824645996\n",
      "epoch: 24 step: 618 loss: 0.6931471824645996\n",
      "epoch: 24 step: 619 loss: 0.6931471824645996\n",
      "epoch: 24 step: 620 loss: 0.6931471824645996\n",
      "epoch: 24 step: 621 loss: 0.6931471824645996\n",
      "epoch: 24 step: 622 loss: 0.6931471824645996\n",
      "epoch: 24 step: 623 loss: 0.6931471824645996\n",
      "epoch: 24 step: 624 loss: 0.6931471824645996\n",
      "epoch: 24 step: 625 loss: 0.6931471824645996\n",
      "epoch: 24 step: 626 loss: 0.6931471824645996\n",
      "epoch: 24 step: 627 loss: 0.6931471824645996\n",
      "epoch: 24 step: 628 loss: 0.6931471824645996\n",
      "epoch: 24 step: 629 loss: 0.6931471824645996\n",
      "epoch: 24 step: 630 loss: 0.6931471824645996\n",
      "epoch: 24 step: 631 loss: 0.6931471824645996\n",
      "epoch: 24 step: 632 loss: 0.6931471824645996\n",
      "epoch: 24 step: 633 loss: 0.6931471824645996\n",
      "epoch: 24 step: 634 loss: 0.6931471824645996\n",
      "epoch: 24 step: 635 loss: 0.6931471824645996\n",
      "epoch: 24 step: 636 loss: 0.6931471824645996\n",
      "epoch: 24 step: 637 loss: 0.6931471824645996\n",
      "epoch: 24 step: 638 loss: 0.6931471824645996\n",
      "epoch: 24 step: 639 loss: 0.6931471824645996\n",
      "epoch: 24 step: 640 loss: 0.6931471824645996\n",
      "epoch: 24 step: 641 loss: 0.6931471824645996\n",
      "epoch: 24 step: 642 loss: 0.6931471824645996\n",
      "epoch: 24 step: 643 loss: 0.6931471824645996\n",
      "epoch: 24 step: 644 loss: 0.6931471824645996\n",
      "epoch: 24 step: 645 loss: 0.6931471824645996\n",
      "epoch: 24 step: 646 loss: 0.6931471824645996\n",
      "epoch: 24 step: 647 loss: 0.6931471824645996\n",
      "epoch: 24 step: 648 loss: 0.6931471824645996\n",
      "epoch: 24 step: 649 loss: 0.6931471824645996\n",
      "epoch: 24 step: 650 loss: 0.6931471824645996\n",
      "epoch: 24 step: 651 loss: 0.6931471824645996\n",
      "epoch: 24 step: 652 loss: 0.6931471824645996\n",
      "epoch: 24 step: 653 loss: 0.6931471824645996\n",
      "epoch: 24 step: 654 loss: 0.6931471824645996\n",
      "epoch: 24 step: 655 loss: 0.6931471824645996\n",
      "epoch: 24 step: 656 loss: 0.6931471824645996\n",
      "epoch: 24 step: 657 loss: 0.6931471824645996\n",
      "epoch: 24 step: 658 loss: 0.6931471824645996\n",
      "epoch: 24 step: 659 loss: 0.6931471824645996\n",
      "epoch: 24 step: 660 loss: 0.6931471824645996\n",
      "epoch: 24 step: 661 loss: 0.6931471824645996\n",
      "epoch: 24 step: 662 loss: 0.6931471824645996\n",
      "epoch: 24 step: 663 loss: 0.6931471824645996\n",
      "epoch: 24 step: 664 loss: 0.6931471824645996\n",
      "epoch: 24 step: 665 loss: 0.6931471824645996\n",
      "epoch: 24 step: 666 loss: 0.6931471824645996\n",
      "epoch: 24 step: 667 loss: 0.6931471824645996\n",
      "epoch: 24 step: 668 loss: 0.6931471824645996\n",
      "epoch: 24 step: 669 loss: 0.6931471824645996\n",
      "epoch: 24 step: 670 loss: 0.6931471824645996\n",
      "epoch: 24 step: 671 loss: 0.6931471824645996\n",
      "epoch: 24 step: 672 loss: 0.6931471824645996\n",
      "epoch: 24 step: 673 loss: 0.6931471824645996\n",
      "epoch: 24 step: 674 loss: 0.6931471824645996\n",
      "epoch: 24 step: 675 loss: 0.6931471824645996\n",
      "epoch: 24 step: 676 loss: 0.6931471824645996\n",
      "epoch: 24 step: 677 loss: 0.6931471824645996\n",
      "epoch: 24 step: 678 loss: 0.6931471824645996\n",
      "epoch: 24 step: 679 loss: 0.6931471824645996\n",
      "epoch: 24 step: 680 loss: 0.6931471824645996\n",
      "epoch: 24 step: 681 loss: 0.6931471824645996\n",
      "epoch: 24 step: 682 loss: 0.6931471824645996\n",
      "epoch: 24 step: 683 loss: 0.6931471824645996\n",
      "epoch: 24 step: 684 loss: 0.6931471824645996\n",
      "epoch: 24 step: 685 loss: 0.6931471824645996\n",
      "epoch: 24 step: 686 loss: 0.6931471824645996\n",
      "epoch: 24 step: 687 loss: 0.6931471824645996\n",
      "epoch: 24 step: 688 loss: 0.6931471824645996\n",
      "epoch: 24 step: 689 loss: 0.6931471824645996\n",
      "epoch: 24 step: 690 loss: 0.6931471824645996\n",
      "epoch: 24 step: 691 loss: 0.6931471824645996\n",
      "epoch: 24 step: 692 loss: 0.6931471824645996\n",
      "epoch: 24 step: 693 loss: 0.6931471824645996\n",
      "epoch: 24 step: 694 loss: 0.6931471824645996\n",
      "epoch: 24 step: 695 loss: 0.6931471824645996\n",
      "epoch: 24 step: 696 loss: 0.6931471824645996\n",
      "epoch: 24 step: 697 loss: 0.6931471824645996\n",
      "epoch: 24 step: 698 loss: 0.6931471824645996\n",
      "epoch: 24 step: 699 loss: 0.6931471824645996\n",
      "epoch: 24 step: 700 loss: 0.6931471824645996\n",
      "epoch: 24 step: 701 loss: 0.6931471824645996\n",
      "epoch: 24 step: 702 loss: 0.6931471824645996\n",
      "epoch: 24 step: 703 loss: 0.6931471824645996\n",
      "epoch: 24 step: 704 loss: 0.6931471824645996\n",
      "epoch: 24 step: 705 loss: 0.6931471824645996\n",
      "epoch: 24 step: 706 loss: 0.6931471824645996\n",
      "epoch: 24 step: 707 loss: 0.6931471824645996\n",
      "epoch: 24 step: 708 loss: 0.6931471824645996\n",
      "epoch: 24 step: 709 loss: 0.6931471824645996\n",
      "epoch: 24 step: 710 loss: 0.6931471824645996\n",
      "epoch: 24 step: 711 loss: 0.6931471824645996\n",
      "epoch: 24 step: 712 loss: 0.6931471824645996\n",
      "epoch: 24 step: 713 loss: 0.6931471824645996\n",
      "epoch: 24 step: 714 loss: 0.6931471824645996\n",
      "epoch: 24 step: 715 loss: 0.6931471824645996\n",
      "epoch: 24 step: 716 loss: 0.6931471824645996\n",
      "epoch: 24 step: 717 loss: 0.6931471824645996\n",
      "epoch: 24 step: 718 loss: 0.6931471824645996\n",
      "epoch: 24 step: 719 loss: 0.6931471824645996\n",
      "epoch: 24 step: 720 loss: 0.6931471824645996\n",
      "epoch: 24 step: 721 loss: 0.6931471824645996\n",
      "epoch: 24 step: 722 loss: 0.6931471824645996\n",
      "epoch: 24 step: 723 loss: 0.6931471824645996\n",
      "epoch: 24 step: 724 loss: 0.6931471824645996\n",
      "epoch: 24 step: 725 loss: 0.6931471824645996\n",
      "epoch: 24 step: 726 loss: 0.6931471824645996\n",
      "epoch: 24 step: 727 loss: 0.6931471824645996\n",
      "epoch: 24 step: 728 loss: 0.6931471824645996\n",
      "epoch: 24 step: 729 loss: 0.6931471824645996\n",
      "epoch: 24 step: 730 loss: 0.6931471824645996\n",
      "epoch: 24 step: 731 loss: 0.6931471824645996\n",
      "epoch: 24 step: 732 loss: 0.6931471824645996\n",
      "epoch: 24 step: 733 loss: 0.6931471824645996\n",
      "epoch: 24 step: 734 loss: 0.6931471824645996\n",
      "epoch: 24 step: 735 loss: 0.6931471824645996\n",
      "epoch: 24 step: 736 loss: 0.6931471824645996\n",
      "epoch: 24 step: 737 loss: 0.6931471824645996\n",
      "epoch: 24 step: 738 loss: 0.6931471824645996\n",
      "epoch: 24 step: 739 loss: 0.6931471824645996\n",
      "epoch: 24 step: 740 loss: 0.6931471824645996\n",
      "epoch: 24 step: 741 loss: 0.6931471824645996\n",
      "epoch: 24 step: 742 loss: 0.6931471824645996\n",
      "epoch: 24 step: 743 loss: 0.6931471824645996\n",
      "epoch: 24 step: 744 loss: 0.6931471824645996\n",
      "epoch: 24 step: 745 loss: 0.6931471824645996\n",
      "epoch: 24 step: 746 loss: 0.6931471824645996\n",
      "epoch: 24 step: 747 loss: 0.6931471824645996\n",
      "epoch: 24 step: 748 loss: 0.6931471824645996\n",
      "epoch: 24 step: 749 loss: 0.6931471824645996\n",
      "epoch: 24 step: 750 loss: 0.6931471824645996\n",
      "epoch: 24 step: 751 loss: 0.6931471824645996\n",
      "epoch: 24 step: 752 loss: 0.6931471824645996\n",
      "epoch: 24 step: 753 loss: 0.6931471824645996\n",
      "epoch: 24 step: 754 loss: 0.6931471824645996\n",
      "epoch: 24 step: 755 loss: 0.6931471824645996\n",
      "epoch: 24 step: 756 loss: 0.6931471824645996\n",
      "epoch: 24 step: 757 loss: 0.6931471824645996\n",
      "epoch: 24 step: 758 loss: 0.6931471824645996\n",
      "epoch: 24 step: 759 loss: 0.6931471824645996\n",
      "epoch: 24 step: 760 loss: 0.6931471824645996\n",
      "epoch: 24 step: 761 loss: 0.6931471824645996\n",
      "epoch: 24 step: 762 loss: 0.6931471824645996\n",
      "epoch: 24 step: 763 loss: 0.6931471824645996\n",
      "epoch: 24 step: 764 loss: 0.6931471824645996\n",
      "epoch: 24 step: 765 loss: 0.6931471824645996\n",
      "epoch: 24 step: 766 loss: 0.6931471824645996\n",
      "epoch: 24 step: 767 loss: 0.6931471824645996\n",
      "epoch: 24 step: 768 loss: 0.6931471824645996\n",
      "epoch: 24 step: 769 loss: 0.6931471824645996\n",
      "epoch: 24 step: 770 loss: 0.6931471824645996\n",
      "epoch: 24 step: 771 loss: 0.6931471824645996\n",
      "epoch: 24 step: 772 loss: 0.6931471824645996\n",
      "epoch: 24 step: 773 loss: 0.6931471824645996\n",
      "epoch: 24 step: 774 loss: 0.6931471824645996\n",
      "epoch: 24 step: 775 loss: 0.6931471824645996\n",
      "epoch: 24 step: 776 loss: 0.6931471824645996\n",
      "epoch: 24 step: 777 loss: 0.6931471824645996\n",
      "epoch: 24 step: 778 loss: 0.6931471824645996\n",
      "epoch: 24 step: 779 loss: 0.6931471824645996\n",
      "epoch: 24 step: 780 loss: 0.6931471824645996\n",
      "epoch: 24 step: 781 loss: 0.6931471824645996\n",
      "epoch: 25 step: 1 loss: 0.6931471824645996\n",
      "epoch: 25 step: 2 loss: 0.6931471824645996\n",
      "epoch: 25 step: 3 loss: 0.6931471824645996\n",
      "epoch: 25 step: 4 loss: 0.6931471824645996\n",
      "epoch: 25 step: 5 loss: 0.6931471824645996\n",
      "epoch: 25 step: 6 loss: 0.6931471824645996\n",
      "epoch: 25 step: 7 loss: 0.6931471824645996\n",
      "epoch: 25 step: 8 loss: 0.6931471824645996\n",
      "epoch: 25 step: 9 loss: 0.6931471824645996\n",
      "epoch: 25 step: 10 loss: 0.6931471824645996\n",
      "epoch: 25 step: 11 loss: 0.6931471824645996\n",
      "epoch: 25 step: 12 loss: 0.6931471824645996\n",
      "epoch: 25 step: 13 loss: 0.6931471824645996\n",
      "epoch: 25 step: 14 loss: 0.6931471824645996\n",
      "epoch: 25 step: 15 loss: 0.6931471824645996\n",
      "epoch: 25 step: 16 loss: 0.6931471824645996\n",
      "epoch: 25 step: 17 loss: 0.6931471824645996\n",
      "epoch: 25 step: 18 loss: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 step: 19 loss: 0.6931471824645996\n",
      "epoch: 25 step: 20 loss: 0.6931471824645996\n",
      "epoch: 25 step: 21 loss: 0.6931471824645996\n",
      "epoch: 25 step: 22 loss: 0.6931471824645996\n",
      "epoch: 25 step: 23 loss: 0.6931471824645996\n",
      "epoch: 25 step: 24 loss: 0.6931471824645996\n",
      "epoch: 25 step: 25 loss: 0.6931471824645996\n",
      "epoch: 25 step: 26 loss: 0.6931471824645996\n",
      "epoch: 25 step: 27 loss: 0.6931471824645996\n",
      "epoch: 25 step: 28 loss: 0.6931471824645996\n",
      "epoch: 25 step: 29 loss: 0.6931471824645996\n",
      "epoch: 25 step: 30 loss: 0.6931471824645996\n",
      "epoch: 25 step: 31 loss: 0.6931471824645996\n",
      "epoch: 25 step: 32 loss: 0.6931471824645996\n",
      "epoch: 25 step: 33 loss: 0.6931471824645996\n",
      "epoch: 25 step: 34 loss: 0.6931471824645996\n",
      "epoch: 25 step: 35 loss: 0.6931471824645996\n",
      "epoch: 25 step: 36 loss: 0.6931471824645996\n",
      "epoch: 25 step: 37 loss: 0.6931471824645996\n",
      "epoch: 25 step: 38 loss: 0.6931471824645996\n",
      "epoch: 25 step: 39 loss: 0.6931471824645996\n",
      "epoch: 25 step: 40 loss: 0.6931471824645996\n",
      "epoch: 25 step: 41 loss: 0.6931471824645996\n",
      "epoch: 25 step: 42 loss: 0.6931471824645996\n",
      "epoch: 25 step: 43 loss: 0.6931471824645996\n",
      "epoch: 25 step: 44 loss: 0.6931471824645996\n",
      "epoch: 25 step: 45 loss: 0.6931471824645996\n",
      "epoch: 25 step: 46 loss: 0.6931471824645996\n",
      "epoch: 25 step: 47 loss: 0.6931471824645996\n",
      "epoch: 25 step: 48 loss: 0.6931471824645996\n",
      "epoch: 25 step: 49 loss: 0.6931471824645996\n",
      "epoch: 25 step: 50 loss: 0.6931471824645996\n",
      "epoch: 25 step: 51 loss: 0.6931471824645996\n",
      "epoch: 25 step: 52 loss: 0.6931471824645996\n",
      "epoch: 25 step: 53 loss: 0.6931471824645996\n",
      "epoch: 25 step: 54 loss: 0.6931471824645996\n",
      "epoch: 25 step: 55 loss: 0.6931471824645996\n",
      "epoch: 25 step: 56 loss: 0.6931471824645996\n",
      "epoch: 25 step: 57 loss: 0.6931471824645996\n",
      "epoch: 25 step: 58 loss: 0.6931471824645996\n",
      "epoch: 25 step: 59 loss: 0.6931471824645996\n",
      "epoch: 25 step: 60 loss: 0.6931471824645996\n",
      "epoch: 25 step: 61 loss: 0.6931471824645996\n",
      "epoch: 25 step: 62 loss: 0.6931471824645996\n",
      "epoch: 25 step: 63 loss: 0.6931471824645996\n",
      "epoch: 25 step: 64 loss: 0.6931471824645996\n",
      "epoch: 25 step: 65 loss: 0.6931471824645996\n",
      "epoch: 25 step: 66 loss: 0.6931471824645996\n",
      "epoch: 25 step: 67 loss: 0.6931471824645996\n",
      "epoch: 25 step: 68 loss: 0.6931471824645996\n",
      "epoch: 25 step: 69 loss: 0.6931471824645996\n",
      "epoch: 25 step: 70 loss: 0.6931471824645996\n",
      "epoch: 25 step: 71 loss: 0.6931471824645996\n",
      "epoch: 25 step: 72 loss: 0.6931471824645996\n",
      "epoch: 25 step: 73 loss: 0.6931471824645996\n",
      "epoch: 25 step: 74 loss: 0.6931471824645996\n",
      "epoch: 25 step: 75 loss: 0.6931471824645996\n",
      "epoch: 25 step: 76 loss: 0.6931471824645996\n",
      "epoch: 25 step: 77 loss: 0.6931471824645996\n",
      "epoch: 25 step: 78 loss: 0.6931471824645996\n",
      "epoch: 25 step: 79 loss: 0.6931471824645996\n",
      "epoch: 25 step: 80 loss: 0.6931471824645996\n",
      "epoch: 25 step: 81 loss: 0.6931471824645996\n",
      "epoch: 25 step: 82 loss: 0.6931471824645996\n",
      "epoch: 25 step: 83 loss: 0.6931471824645996\n",
      "epoch: 25 step: 84 loss: 0.6931471824645996\n",
      "epoch: 25 step: 85 loss: 0.6931471824645996\n",
      "epoch: 25 step: 86 loss: 0.6931471824645996\n",
      "epoch: 25 step: 87 loss: 0.6931471824645996\n",
      "epoch: 25 step: 88 loss: 0.6931471824645996\n",
      "epoch: 25 step: 89 loss: 0.6931471824645996\n",
      "epoch: 25 step: 90 loss: 0.6931471824645996\n",
      "epoch: 25 step: 91 loss: 0.6931471824645996\n",
      "epoch: 25 step: 92 loss: 0.6931471824645996\n",
      "epoch: 25 step: 93 loss: 0.6931471824645996\n",
      "epoch: 25 step: 94 loss: 0.6931471824645996\n",
      "epoch: 25 step: 95 loss: 0.6931471824645996\n",
      "epoch: 25 step: 96 loss: 0.6931471824645996\n",
      "epoch: 25 step: 97 loss: 0.6931471824645996\n",
      "epoch: 25 step: 98 loss: 0.6931471824645996\n",
      "epoch: 25 step: 99 loss: 0.6931471824645996\n",
      "epoch: 25 step: 100 loss: 0.6931471824645996\n",
      "epoch: 25 step: 101 loss: 0.6931471824645996\n",
      "epoch: 25 step: 102 loss: 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, ohev, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        ohev = Variable(ohev.float()).cuda()\n",
    "        pred = new_model(img)\n",
    "        loss = loss_func(pred, ohev)\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "        print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_model.state_dict(), 'models/30epochstrainedmodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = ResNet()\n",
    "saved_model.load_state_dict(torch.load('models/30epochstrainedmodel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.eval()\n",
    "saved_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlossarr = []\n",
    "#loss = torch.zeros(1, dtype=torch.double)\n",
    "#loss.cuda()\n",
    "avgloss = 0\n",
    "for step, i in enumerate(test_dl):\n",
    "    img, ohev, label = i\n",
    "    img = Variable(img).cuda()\n",
    "    ohev = Variable(ohev.float()).cuda()\n",
    "    pred = saved_model(img)\n",
    "    loss = loss_func(pred, ohev)\n",
    "    avgloss +=loss.item()\n",
    "    testlossarr.append(loss.cpu().detach().numpy())\n",
    "    print('step:', step+1, 'loss:', loss.item())\n",
    "    #testlossarr.append()\n",
    "print(avgloss/17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlossarr = np.array(testlossarr)\n",
    "np.mean(testlossarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(train_dl))\n",
    "img0 = Variable(temp[0][3][None, :]).cuda()\n",
    "pred = saved_model(img0)\n",
    "pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(saved_model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
